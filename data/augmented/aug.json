[
    {
        "id": "aug00smp0905q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa has infomration  about rachability of other networks from its own lan (s).\n\nduring backwards learning, frames are forwarded from source to target. those entries are stored with timestamps consociate with receiving time. these are sporadically updatet and scanned to adapt to network changes or delete dead connections.",
        "answer_feedback": "the response correctly explains the information contained in the bridge table. the explanation of backward learning is incomplete. the response does not provide information on how the table is used during the forwarding process and what benefits this brings.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the table has infomration  about rachability of other networks from its own lan (s).\n\nduring backwards learning, frames are forwarded from source to target. those entries are stored with timestamps associated with receiving time. these are periodically updatet and scanned to adapt to network changes or delete dead connections.",
        "original_sample_id": "smp0905q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1115q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning tree has no hertz, this is especially useful in broad and multicast as otherwise packets might end up looping in the network forever. to setup a spanning tree for multicasting, all is periodically send link state packets to all other is to update them on their local state. all is can then compute a worldwide spanning tree using the worldwide state of the network that they now have. since the algorithms are deterministic all is will arrive at the same spanning tree that they can then use for multicasting.",
        "answer_feedback": "while the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes does not state how a node gets to know about the other members of the multicast group and how this information is propagated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a spanning tree has no cycles, this is especially useful in broad and multicast as otherwise packets might end up looping in the network forever. to setup a spanning tree for multicasting, all is periodically send link state packets to all other is to update them on their local state. all is can then compute a global spanning tree using the global state of the network that they now have. since the algorithms are deterministic all is will arrive at the same spanning tree that they can then use for multicasting.",
        "original_sample_id": "smp1115q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1099q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees prevent cringle in your topology. you only have to modify the link nation packets by adding entropy on multicast groups. with that entropy each is can calculate a multicast tree",
        "answer_feedback": "the response correctly identifies the spanning-tree property and explains how the link state routing can be modified to construct a spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees prevent loops in your topology. you only have to modify the link state packets by adding information on multicast groups. with that information each is can calculate a multicast tree",
        "original_sample_id": "smp1099q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1099q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees prevent loops in your topology. you only have to modify the nexus land packets by impart information on multicast groups. with that information each is can calculate a multicast tree",
        "answer_feedback": "the response correctly identifies the spanning-tree property and explains how the link state routing can be modified to construct a spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees prevent loops in your topology. you only have to modify the link state packets by adding information on multicast groups. with that information each is can calculate a multicast tree",
        "original_sample_id": "smp1099q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1690q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0000 0000",
        "answer_feedback": "what do you mean by this?",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0000 0000",
        "original_sample_id": "smp1690q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0899q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the span table stores for each station the production line (lan) to where it has to send a packet, to reach that station. when a packet from a source station s is received on in input lan l, the span stores on its table that in order to reach s as a address station needs to send the packet to the production lan l. then, when a packet comes for station s, the span just needs to check to which production lan forwards the packet. if a packet comes to an unknown address, the span does flooding.\ntransparent spans allow for stations to communicate without regard if the other stations are on the same lan or not.",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge table stores for each station the output line (lan) to where it has to send a packet, to reach that station. when a packet from a source station s is received on in input lan l, the bridge stores on its table that in order to reach s as a destination station needs to send the packet to the output lan l. then, when a packet comes for station s, the bridge just needs to check to which output lan forwards the packet. if a packet comes to an unknown destination, the bridge does flooding.\ntransparent bridges allow for stations to communicate without regard if the other stations are on the same lan or not.",
        "original_sample_id": "smp0899q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1057q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "there is no loop in sweep tree. sweep trees will select the best itinerary with the lowest cost.  all the is send link state packets periodically to all the others, and the calculates a multicast tree. last is determines the outgoing lines based on the multicast tree, on the outgoing lines packets have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast. the modification of the link-state algorithm to construct a multicast spanning-tree is not complete as it also needs to explain how link-state packets are expanded with the sender's multicast group information, and used by each node to create a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "there is no loop in spanning tree. spanning trees will select the best path with the lowest cost.  all the is send link state packets periodically to all the others, and the calculates a multicast tree. finally is determines the outgoing lines based on the multicast tree, on the outgoing lines packets have to be transmitted.",
        "original_sample_id": "smp1057q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0856q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not this is not maintained for internet traffic, because if you look at data that exceeds the standard package size (e.g. streaming videos), receiving another package that depends on the previous one and potentially took the same route is a likely occurrence. the Poisson process also does not count for packet falls where a forwarding might be necessary, so it also depends on the rate of packet loss.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no this does not hold for internet traffic, because if you look at data that exceeds the standard packet size (e.g. streaming of videos), receiving another packet that depends on the previous one and potentially took the same path is a likely occurrence. the poisson process also doesn’t account for packet drops where a resend might be necessary, making it also dependent on packet loss rate.",
        "original_sample_id": "smp0856q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0137q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Manchester encoding. 1. Due to self-chronization there is no need to have a specific line to transmit the synchronization signal. 2. Manchester encoding is less complex than differential manchester encoding, and sufficiently convenient for the local network with 3 users.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "manchester encoding.\n1. because of the self-clocking there is no need to have specific line to transmit the synchronisation signal.\n2. manchester encoding is less complex than differential manchester encoding, and convenient enough for local network with 3 users.",
        "original_sample_id": "smp0137q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0137q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "manchester encryption.\n1. because of the ego-clocking there is no need to have specific line to transmit the synchronisation signal.\n2. manchester encryption is less complex than differential manchester encryption, and convenient enough for local meshing with 3 users.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "manchester encoding.\n1. because of the self-clocking there is no need to have specific line to transmit the synchronisation signal.\n2. manchester encoding is less complex than differential manchester encoding, and convenient enough for local network with 3 users.",
        "original_sample_id": "smp0137q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we learned that some problems may arise if two or more users send information at the same time.With these independent intervals the system cannot ensure that there will be no collisions, overflowing or congestion that could affect the correct arrival of packages (there is a risk that the information will not be sent correctly) . but on the condition given to the conference that this delta t interval is infinitely small all these problems will be avoided and there would be no problem in the real Internet traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we learned that some problems may arise if two or more users send information at the same time.With these independent intervals the system cannot ensure that there will be no collisions, overflowing or congestion that could affect the correct arrival of packages (there is a risk that the information will not be sent correctly) . but on the condition given to the conference that this delta t interval is infinitely small all these problems will be avoided and there would be no problem in the real Internet traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug02smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we learned that some problems may arise if two or more users send information at the same time.With these independent intervals the system cannot ensure that there will be no collisions, overflowing or congestion that could affect the correct arrival of packages (there is a risk that the information will not be sent correctly) . but on the condition given to the conference that this delta t interval is infinitely small all these problems will be avoided and there would be no problem in the real Internet traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug03smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we have learned that some issues can surge if two exploiter or more place entropy at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the entropy won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug04smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we learned that some problems may arise if two or more users send information at the same time.With these independent intervals the system cannot ensure that there will be no collisions, overflowing or congestion that could affect the correct arrival of packages (there is a risk that the information will not be sent correctly) . but on the condition given to the conference that this delta t interval is infinitely small all these problems will be avoided and there would be no problem in the real Internet traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug05smp0841q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "through the whole lesson we have learned that some issues can zoom if two users or more air information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real net traffic.",
        "answer_feedback": "the assumption does not hold for the internet. so the stated response is incorrect as it relates to the situation when multiple users send at the same time while the question asked if a packet arrival at a node is dependent on the previous arrivals.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "through the whole lesson we have learned that some issues can surge if two users or more send information at the same time.with these independent intervals the system cannot assure that there won't be collisions, overflow or congestion which might affect the correct arrival of the packets (there is a risk that the information won't be correctly sent) . but with the condition given on the lecture that this interval delta t is infinitely  small all of this problems will be avoided and there would not be any problem in the real internet traffic.",
        "original_sample_id": "smp0841q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0357q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:\n(a,b, frontward), (a,c, frontward)(a,d, drop) <= from node d there is no promotion to node f, because d is not on the unicast path from a to d\nhops 2:\n(b,e,frontward)\n(c,f,drop) <= from node f there is no promotion to node d e and g, because node d is not on the unicast path from a to d, e or g\nhops 3:\n(e,g,frontward)\nhops 4:\n(g,h,drop) <= there is no more promotion, because there h is the last node on this path",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b, forward), (a,c, forward)(a,d, drop) <= from node d there is no forwarding to node f, because d is not on the unicast path from a to d\nhop 2:\n(b,e,forward)\n(c,f,drop) <= from node f there is no forwarding to node d e and g, because node d is not on the unicast path from a to d, e or g\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop) <= there is no more forwarding, because there h is the last node on this path",
        "original_sample_id": "smp0357q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed offline data is transferred without taking into account packet loss, rather than the confirmed offline option. Confirmed offline data is transferred and recognized, contrary to the unconfirmed offline option. 3-stage communication oriented to connection with connection data transfer and disconnection, as opposed to offline option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectorless  data is transferred without regards for parcel loss, as opposed to the confirmed connectorless option.\nconfirmed connectorless data is transferred and acknowledged, contrary to the unconfirmed connectorless option.\nconnector-oriented 3-stage communication with connector data transfer and disconnect, opposed to the connectorless option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed offline data is transferred without taking into account packet loss, rather than the confirmed offline option. Confirmed offline data is transferred and recognized, contrary to the unconfirmed offline option. 3-stage communication oriented to connection with connection data transfer and disconnection, as opposed to offline option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless  datum is channelize without regards for packet loss, as fight to the confirmed connectionless option.\nconfirmed connectionless datum is channelize and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection datum transfer and disconnect, fight to the connectionless option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "uncorroborate connectionless  data is transferred without regards for packet loss, as opposed to the corroborate connectionless alternative.\ncorroborate connectionless data is transferred and acknowledged, wayward to the uncorroborate connectionless alternative.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless alternative.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connexionless  data is transferred without regards for packet loss, as opposed to the confirmed connexionless pick.\nconfirmed connexionless data is transferred and acknowledged, contrary to the unconfirmed connexionless pick.\nconnexion-oriented 3-phase communication with connexion data transfer and gulf, opposed to the connexionless pick.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1038q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of reverse track forwarding and reverse track broadcast is to reduce the network load.   to perform reverse track forwarding, each node must know which larboard to use to send (unicast-)packets to every other node. incoming packets are then treated calculate on the larboard, they arrive by. if they are received via the larboard used to send packets to the source, they are resent over all edges. if they are received over any other larboard, they did not use the best route and are discarded.  reverse track broadcast works slightly different. by observing the packets, a node forwards, it can learn, whether it is on the unicast track between any two nodes. if it now receives a broadcast packet from any source, it will forward the packet in all directions, where it is part of the unicast route to the source. for all other directions/neighbors it can assume, that they will receive the packet via their unicast route.",
        "answer_feedback": "the response correctly explains both rpf and rpb. however, the purpose should explain how network load is reduced by reducing duplicates during broadcasting.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.9,
        "original_answer": "the purpose of reverse path forwarding and reverse path broadcast is to reduce the network load.   to perform reverse path forwarding, each node must know which port to use to send (unicast-)packets to every other node. incoming packets are then treated depending on the port, they arrive by. if they are received via the port used to send packets to the source, they are resent over all edges. if they are received over any other port, they did not use the best route and are discarded.  reverse path broadcast works slightly different. by observing the packets, a node forwards, it can learn, whether it is on the unicast path between any two nodes. if it now receives a broadcast packet from any source, it will forward the packet in all directions, where it is part of the unicast route to the source. for all other directions/neighbors it can assume, that they will receive the packet via their unicast route.",
        "original_sample_id": "smp1038q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1522q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a duplex run mode for data transport is expect",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a duplex operating mode for data transfer is required",
        "original_sample_id": "smp1522q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0383q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward) because a is informant and curt route\n(a, c, forward) because a is informant and curt route\n(a, d, forward) because a is informant and curt route\nhop 2:\n(b, e, forward) because it is the best route\n(c, f, forward) because it is the best route\nhop 3:\n(e, g, forward) because it is the best route\nhop 4:\n(g, h, drop) becauseh has only 1 link, which is also the incoming link",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward) because a is source and shortest path\n(a, c, forward) because a is source and shortest path\n(a, d, forward) because a is source and shortest path\nhop 2:\n(b, e, forward) because it is the best path\n(c, f, forward) because it is the best path\nhop 3:\n(e, g, forward) because it is the best path\nhop 4:\n(g, h, drop) becauseh has only 1 link, which is also the incoming link",
        "original_sample_id": "smp0383q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1663q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/8 10.00.0/8 127,00,0/8",
        "answer_feedback": "the addresses have ranges: from 127.0.0.0 - 127.255.255.255, the /8 is not a range",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n127.0.0.0/8",
        "original_sample_id": "smp1663q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1663q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/8 10.00.0/8 127,00,0/8",
        "answer_feedback": "the addresses have ranges: from 127.0.0.0 - 127.255.255.255, the /8 is not a range",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n127.0.0.0/8",
        "original_sample_id": "smp1663q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1520q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking only play if the transporter and  liquidator are both able to transport and  receive. it’s a duplex operation.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking only works if the sender and  receiver are both able to send and  receive. it’s a duplex operation.",
        "original_sample_id": "smp1520q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1523q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "at least a semi-duplex communicating canal is take",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "at least a semi-duplex communication channel is required",
        "original_sample_id": "smp1523q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only postulate to send out the data as one mailboat and dont have to send a single mailboat for each receiver, you also dont postulate to recognise all the receivers as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only want to send out the data as one mailboat and dont have to send a single mailboat for each recipient, you also dont want to know all the recipients as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug02smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only need to send out the data as one mailboat and dont have to send a exclusive mailboat for each receiver, you also dont need to know all the receivers as the tree will plow the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug03smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only require to air out the data as one mailboat and dont have to air a single mailboat for each receiver, you also dont require to know all the receivers as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug04smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only take to ship out the data as one mailboat and dont have to ship a single mailboat for each receiver, you also dont take to know all the receivers as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug05smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only need to post out the data as one packet and dont have to post a single packet for each receiver, you also dont need to fuck all the liquidator as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0793q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is an offline transport service and tcp is oriented to the connection. Therefore, sending data on the loss of udp data is possible because it is unreliable and has no error control or diffusion. it can be transmitted from the application, but not from udp itself. udp is much faster than tcp and uses less resources (buffering, state information, timer, ...). These differences explain the different headers of udp and tcp. The udp header consists only in the port of the sender, receiving port, package length and a checksum (8 byte long). The ttcp header also includes a (1) sequence number, (2) recognition number, (3) options field and (4) tcp flags.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the response states some additional points that are more the general differences between udp and tcp.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is a connectionless transport service and tcp is connection oriented. therefore, sending data over udp data loss is possible because it is unreliable and has no error control or retransmission. it may be retransmit from application, but not from udp itself.\nudp is way more faster than tcp and uses less resources (buffering, status information, timer, …).\n\nthese differences explain the different headers of udp and tcp. the udp header consists of only of sender port, receiver port, packet length and a checksum (8 byte long). the tcp header additionally consist of a \n(1) sequence number,\n(2) acknowledgement number,\n(3) options field and\n(4) the tcp flags",
        "original_sample_id": "smp0793q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0238q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1) calculate the probability for the dos p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 package p( less than 10) = 1 - p10 = 0.949\n3) expected number of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the balance dos during the entire minute.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1) calculate the probability for the state p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 packets p( less than 10) = 1 - p10 = 0.949\n3) expected number of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the equilibrium state during the entire minute.",
        "original_sample_id": "smp0238q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0238q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1) cypher the probability for the state p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 packets p( less than 10) = 1 - p10 = 0.949\n3) expected turn of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the balance state during the entire minute.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1) calculate the probability for the state p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 packets p( less than 10) = 1 - p10 = 0.949\n3) expected number of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the equilibrium state during the entire minute.",
        "original_sample_id": "smp0238q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0347q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (a, b, front) (a, c, front) (a, d, front) hop 2: (b, c, drop) < = because b never got a package for c in the past (because ac is the best way) (b, e, front) (c, b, drop) < = because c never got a package for b in the past (because ab is the best way) (c, d, drop) < = because c never got a package for d in the past (because the ad is the best way) (c, f, drop) (d, c, drop) < = because d never got a package for c in the past (because ac, drop) < get a package for c in the past (e, c, drop) < get a package for c in the past (e, get a < < < < < < < < < < < < < < < < < < < < package for the past (e, drop) p, c, drop) < get a package for f, drop) < get a package for f in the past (e, get a package for the past (e, get a package for the < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:(a, b, forward)\n(a, c, forward)\n(a, d, forward) \nhop 2:\n(b, c, drop) <= because b never got a packet for c in the past (because ac is the best path)\n(b, e, forward)\n(c, b, drop) <= because c never got a packet for b in the past (because ab is the best path)\n(c, d, drop) <= because c never got a packet for d in the past (because ad is the best path)\n(c, f, forward)\n(d, c, drop) <= because d never got a packet for c in the past (because ac is the best path)\n(d, f, drop) <= because d never got a packet for f  in the past (because acf is the best path)\nhop 3:\n(e, c, drop) <= because e never got a packet for c in the past (because ac is the best path)\n(e, f, drop) <= because e never got a packet for f in the past (because acf ist the best path)\n(e, g, forward)\n(f, d, drop) <= because f never got a packet for d in the past (because ad is the best path)\n(f, e, drop) <= because f never got a packet for e in the past (because abe is the best path)\n(f, g, drop) <= because f never got a packet for g in the past (because abeg is the best path)\nhop 4: \n(g, f, drop) <= because g never got a packet for f in the past (because acf is the best path)\n(g, h, drop) <= because h has no further links to forward to",
        "original_sample_id": "smp0347q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0811q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is mainly ip with a short transport header (8 bytes) with only the source and destination port and the length of the package and checksum. while the tcp header can be more complex and is at least 20 bytes large. the tcp header contains the source port, the port dest., the sequence number, the recognition number, hl/resv/flags, the announced victory., the urgent checksum pointer and other optional options. the header length only represents the size of the header, while the length of the udp package also contains the size of the payload.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv, should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is mostly ip with a short transport header (8 byte) with only source and destination port and packet length and checksum. while the tcp header can be more complex and is at least 20 byte big. the tcp header contains source port, dest. port, sequence number,\nacknowledgment number, hl/resv/flags, advertised win., checksum urgent pointer and optional further options. the header length represents only the header size, while udp packet length contains also the size of the payload.",
        "original_sample_id": "smp0811q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0806q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the udp header is composed of 4 parts while the tcp header is composed of 9 parts -the udp header carries information about the length of the package, the tcp header is not -each tcp header has an integrated sequence number, the udp header is not -the tcp header has a 31-bit space for options at the end where the udp header does not leave space for improvements.",
        "answer_feedback": "the first point is partially correct as the tcp header parts contain 10 mandatory fields, not 9. the second and third points are correct. the fourth point is partially correct as the options field can be up to 40 bytes long instead of 31 bit.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "-the udp header is made up by 4 parts whereas the tcp header consists of 9 parts\n-the udp header carries the information about the packet length, the tcp header not\n-each tcp header has a sequence number embedded, the udp header not\n-the tcp header has a 31 bit space for options at the end where the  udp header   leaves no space for improvements.",
        "original_sample_id": "smp0806q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0806q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the udp cope is made up by 4 parts whereas the tcp cope consists of 9 parts\n-the udp cope carries the information about the packet length, the tcp cope not\n-each tcp cope has a sequence number embedded, the udp cope not\n-the tcp cope has a 31 bit distance for options at the last where the  udp cope   leaves no distance for improvements.",
        "answer_feedback": "the first point is partially correct as the tcp header parts contain 10 mandatory fields, not 9. the second and third points are correct. the fourth point is partially correct as the options field can be up to 40 bytes long instead of 31 bit.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "-the udp header is made up by 4 parts whereas the tcp header consists of 9 parts\n-the udp header carries the information about the packet length, the tcp header not\n-each tcp header has a sequence number embedded, the udp header not\n-the tcp header has a 31 bit space for options at the end where the  udp header   leaves no space for improvements.",
        "original_sample_id": "smp0806q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0806q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the udp cope is made up by 4 parts whereas the tcp cope consists of 9 parts\n-the udp cope carries the information about the packet length, the tcp cope not\n-each tcp cope has a sequence number embedded, the udp cope not\n-the tcp cope has a 31 bit place for options at the end where the  udp cope   leaves no place for betterment.",
        "answer_feedback": "the first point is partially correct as the tcp header parts contain 10 mandatory fields, not 9. the second and third points are correct. the fourth point is partially correct as the options field can be up to 40 bytes long instead of 31 bit.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "-the udp header is made up by 4 parts whereas the tcp header consists of 9 parts\n-the udp header carries the information about the packet length, the tcp header not\n-each tcp header has a sequence number embedded, the udp header not\n-the tcp header has a 31 bit space for options at the end where the  udp header   leaves no space for improvements.",
        "original_sample_id": "smp0806q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0806q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the udp header is composed of 4 parts while the tcp header is composed of 9 parts -the udp header carries information about the length of the package, the tcp header is not -each tcp header has an integrated sequence number, the udp header is not -the tcp header has a 31-bit space for options at the end where the udp header does not leave space for improvements.",
        "answer_feedback": "the first point is partially correct as the tcp header parts contain 10 mandatory fields, not 9. the second and third points are correct. the fourth point is partially correct as the options field can be up to 40 bytes long instead of 31 bit.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "-the udp header is made up by 4 parts whereas the tcp header consists of 9 parts\n-the udp header carries the information about the packet length, the tcp header not\n-each tcp header has a sequence number embedded, the udp header not\n-the tcp header has a 31 bit space for options at the end where the  udp header   leaves no space for improvements.",
        "original_sample_id": "smp0806q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1691q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0~0.255.255,2555 127,00,0~127,255,2555",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0~0.255.255.255\n127.0.0.0~127.255.255.255",
        "original_sample_id": "smp1691q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0867q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, in real internet traffic, the probability of arrivals in each time interval is not always independent, i.e. downloads require several packages over a certain period of time. This means that if there has been arrival in time interval 1, the probability of arrival in the following intervals is high.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, in real internet traffic the probability for arrivals in each time interval are not always independent. i.e. downloads require multiple packets over a certain amount of time. this means if there is an arrival in time interval 1 the probability of an arrival in the following intervals is high. the same goes for video streaming (-> on/off bursty traffic).",
        "original_sample_id": "smp0867q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0359q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: from a: (a,b,forward), (a,c,forward), (a,d,forward) hop 2: from b: (b,c,drop), because he sent directly to c, (b,e,forward) from c: (c,b,d,drop) because he sent a, (c,d,drop), because he sent to d (c,e,drop), because b sent to e (c,f,forward) from d: (d,c,d,d,drop), because he sent to c (d,f,drop) because c sent to e hop 3: from: (e,c,drop), because he sent to c (e,f,d,drop), because c sent to f (e,g,g,award) from f: (f,d,drop), because he sent to (f,d,d), because he sent to e (f,g,d,d,d), because c sent to f (e,f,d,d,d) because h (f,d,d,d,d,d, because h (f,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: from a: (a,b,forward), (a,c, forward), (a,d, forward)\n\nhop 2:\nfrom b: (b, c, drop), because a sends directly to c, (b, e, forward)\nfrom c: (c, b, drop) because a sends to a, (c, d, drop), because a sends to d (c, e, drop), because b sends to e (c, f, forward)\nfrom d: (d, c, drop), because a sends to c (d, f, drop) because c sends to e \n\nhop 3:\nfrom e: (e, c, drop), because a sends to c (e, f, drop), because c sends to f (e, g, forward)\nfrom f: (f, d, drop), because a sends to a (f, e, drop), because b sends to e (f, g, drop) because e sends to g\n\nhop 4:\nfrom g: (g, f, drop), because c sends to e (g, h, drop) because h doesn´t have any other destination to forward the message",
        "original_sample_id": "smp0359q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0846q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being watercourseed via netflix, the package will always arrive with time interval 1. especially, for the swarm service, the package will arrive via a watercourse buffer with more package in a row, meaning the arrivals are not independent.",
        "answer_feedback": "the correct answer is \"no\" but the explanation of requiring constant time intervals for packet arrival is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with time interval 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "original_sample_id": "smp0846q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0846q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "for real cyberspace traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the cyberspace, the metre separation will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with metre separation 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "answer_feedback": "the correct answer is \"no\" but the explanation of requiring constant time intervals for packet arrival is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with time interval 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "original_sample_id": "smp0846q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  help preclude ip address spoofing. 2. rpf a chargeer broadcasts to all the stations. when a packet reaches a is ,the is will agree the path. if it is the usually path. it will charge to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "2. rpf a sender transmits to all stations. when a package reaches an is , the is will check the path. if it is the usual route. it will be sent to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug02smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  avail prevent ip address spoofing. 2. rpf a sender broadcasts to all the post. when a packet reaches a is ,the is will checker the path. if it is the usually path. it will send to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug03smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  avail prevent ip address spoofing. 2. rpf a commiter broadcasts to all the stations. when a packet reaches a is ,the is will check the itinerary. if it is the usually itinerary. it will commit to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug04smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  avail keep ip reference spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug05smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "2. rpf a sender transmits to all stations. when a package reaches an is , the is will check the path. if it is the usual route. it will be sent to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug06smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "2. rpf a sender transmits to all stations. when a package reaches an is , the is will check the path. if it is the usual route. it will be sent to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug07smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  avail prevent ip address spoofing. 2. rpf a transmitter broadcasts to all the place. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1050q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "overrule path forwarding (rpf) and overrule path broadcast (rpb) are broadcast routing algorithms used to broadcast a message from a sender node to all nodes on the network. they make use of a spanning tree. while each sender has a spanning tree, the is do not know these trees. rpf: each receiving node checks if the arrived packet has taken the best (fastest/shortest) route by investigating if the packet took the path, that the receiving node normally also takes to send packets. if the best route was taken, then the packet will be resend over all edges, except the incoming one, if not the packet will be disposeed. if for example a receives a packet via b, with the source address of s (s → b → a) and a normally takes the path via b to s (in routing table a → b → s) for sending packets, this path will be seen as the best route. hence a will resend the packet over all edges (except the incoming one). if a packet from s would arrive via node c to a (s to c to a), then a would dispose it, because this would not be seen as the best route. rpb: works exactly like the rpf, except that packets do not get resend over all edges (except the incoming one) but only on the edge at which packets normally arrive in overrule direction. if for example s sends a packet to a via c and also via b (s → c → a / s → b → a). and a normally sends packets to s via b (a →b→s), then b knows that it is on the unicast path from a to s. c knows that it is not on the unicast path from a to s, because no such packets appear. therefore only b will forward the packet to a and c will dispose the packet. with rpb the number of copies on the network can be reduced a lot.",
        "answer_feedback": "the response is incomplete as it does not state the purpose of rpf which is also to reduce duplicates during broadcasting compared to flooding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are broadcast routing algorithms used to broadcast a message from a sender node to all nodes on the network. they make use of a spanning tree. while each sender has a spanning tree, the is do not know these trees. rpf: each receiving node checks if the arrived packet has taken the best (fastest/shortest) route by investigating if the packet took the path, that the receiving node usually also takes to send packets. if the best route was taken, then the packet will be resend over all edges, except the incoming one, if not the packet will be discarded. if for example a receives a packet via b, with the source address of s (s → b → a) and a usually takes the path via b to s (in routing table a → b → s) for sending packets, this path will be seen as the best route. hence a will resend the packet over all edges (except the incoming one). if a packet from s would arrive via node c to a (s to c to a), then a would discard it, because this would not be seen as the best route. rpb: works exactly like the rpf, except that packets do not get resend over all edges (except the incoming one) but only on the edge at which packets normally arrive in reverse direction. if for example s sends a packet to a via c and also via b (s → c → a / s → b → a). and a usually sends packets to s via b (a →b→s), then b knows that it is on the unicast path from a to s. c knows that it is not on the unicast path from a to s, because no such packets appear. therefore only b will forward the packet to a and c will discard the packet. with rpb the number of copies on the network can be reduced a lot.",
        "original_sample_id": "smp1050q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "the use of temporarily valid tsaps identify connections individually - disadvantage: only for connection-oriented services identify the pdus individually - disadvantage: use of higher bandwidth",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "the use of temporarily valid tsaps identify connections individually - disadvantage: only for connection-oriented services identify the pdus individually - disadvantage: use of higher bandwidth",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "use temporarily valid tsaps\n\nplace association separately\n- disadvantage: only for connection-oriented services\n\nplace pdus separately\n- disadvantage: higher bandwidth usage",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "use temporarily valid tsaps\n\nkey connectors individually\n- disadvantage: only for connector-oriented services\n\nkey pdus individually\n- disadvantage: eminent bandwidth usage",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1030q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "circulateing methods which were previously introduced such as individual sending to every destination and flooding have their own disadvantages. individual sending wastes bandwidth and requires the sender to know all destinations. flooding may produce too many duplicates. circulate routing like reverse path fowarding and reverse path circulate can be used to avoid such problems. specifically, reverse path circulate can be used to avoid another problem of reverse path furtherance, since it forwards packets over suitable edges instead of resend them over all edges. both algorithms use spanning tree for router initiating circulate, which is based on a subset of subnets including all routers with no loops. upon arrival of a packet at an is, both algorithms make the following decisions: furtherance: if the packet has arrived at the is incoming port over which the packets for this station/source are usually also sent, the packet is resent over all edges excluding the incoming one. if not, the packet is discarded. circulate: if the packet has arrived at the is incoming port over which the packets for this station/source s are usually also sent, and if the packet used the best route until now, the edge is selected at which the packets arrived and from which they are then rerouted to source s, if not, the algorithm does not send over all edges, i.e., not as in reverse path furtherance. otherwise, the packet is discarded, since it is most likely a duplicate.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "broadcasting methods which were previously introduced such as individual sending to every destination and flooding have their own disadvantages. individual sending wastes bandwidth and requires the sender to know all destinations. flooding may produce too many duplicates. broadcast routing like reverse path fowarding and reverse path broadcast can be used to avoid such problems. specifically, reverse path broadcast can be used to avoid another problem of reverse path forwarding, since it forwards packets over suitable edges instead of resend them over all edges. both algorithms use spanning tree for router initiating broadcast, which is based on a subset of subnets including all routers with no loops. upon arrival of a packet at an is, both algorithms make the following decisions: forwarding: if the packet has arrived at the is entry port over which the packets for this station/source are usually also sent, the packet is resent over all edges excluding the incoming one. if not, the packet is discarded. broadcast: if the packet has arrived at the is entry port over which the packets for this station/source s are usually also sent, and if the packet used the best route until now, the edge is selected at which the packets arrived and from which they are then rerouted to source s, if not, the algorithm does not send over all edges, i.e., not as in reverse path forwarding. otherwise, the packet is discarded, since it is most likely a duplicate.",
        "original_sample_id": "smp1030q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1030q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "transmiting methods which were previously introduced such as individual sending to every destination and flooding have their own disadvantages. individual sending wastes bandwidth and requires the sender to know all destinations. flooding may produce too many duplicates. transmit routing like reverse course fowarding and reverse course transmit can be used to avoid such problems. specifically, reverse course transmit can be used to avoid another problem of reverse course forwarding, since it forwards mailboats over suitable edges instead of resend them over all edges. both algorithms use spanning tree for router initiating transmit, which is based on a subset of subnets including all routers with no loops. upon arrival of a mailboat at an is, both algorithms make the following decisions: forwarding: if the mailboat has arrived at the is entry port over which the mailboats for this station/source are usually also sent, the mailboat is resent over all edges excluding the incoming one. if not, the mailboat is discarded. transmit: if the mailboat has arrived at the is entry port over which the mailboats for this station/source s are usually also sent, and if the mailboat used the best route until now, the edge is selected at which the mailboats arrived and from which they are then rerouted to source s, if not, the algorithm does not send over all edges, i.e., not as in reverse course forwarding. otherwise, the mailboat is discarded, since it is most likely a duplicate.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "broadcasting methods which were previously introduced such as individual sending to every destination and flooding have their own disadvantages. individual sending wastes bandwidth and requires the sender to know all destinations. flooding may produce too many duplicates. broadcast routing like reverse path fowarding and reverse path broadcast can be used to avoid such problems. specifically, reverse path broadcast can be used to avoid another problem of reverse path forwarding, since it forwards packets over suitable edges instead of resend them over all edges. both algorithms use spanning tree for router initiating broadcast, which is based on a subset of subnets including all routers with no loops. upon arrival of a packet at an is, both algorithms make the following decisions: forwarding: if the packet has arrived at the is entry port over which the packets for this station/source are usually also sent, the packet is resent over all edges excluding the incoming one. if not, the packet is discarded. broadcast: if the packet has arrived at the is entry port over which the packets for this station/source s are usually also sent, and if the packet used the best route until now, the edge is selected at which the packets arrived and from which they are then rerouted to source s, if not, the algorithm does not send over all edges, i.e., not as in reverse path forwarding. otherwise, the packet is discarded, since it is most likely a duplicate.",
        "original_sample_id": "smp1030q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1659q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "\"this host\": 0.0.0.0\nhosts/broadcast at this network: 0.0.0.1 - 0.255.255.254 / 0.255.255.255\nnetwork speech: 1-126.0.0.0\nbroadcast speech: 1-126.255.255.255\nloopback: 127.0.0.0 - 127.255.255.255\nalthough definitions vary whether or not 0.x.x.x and 127.x.x.x speech go to category a networks, i listed these for completeness; in my opinion, the definition of category a networks includes these ranges as well and hence, they go to the reserved speech.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "\"this host\": 0.0.0.0\nhosts/broadcast at this network: 0.0.0.1 - 0.255.255.254 / 0.255.255.255\nnetwork addresses: 1-126.0.0.0\nbroadcast addresses: 1-126.255.255.255\nloopback: 127.0.0.0 - 127.255.255.255\nalthough definitions vary whether or not 0.x.x.x and 127.x.x.x addresses belong to class a networks, i listed these for completeness; in my opinion, the definition of class a networks includes these ranges as well and hence, they belong to the reserved addresses.",
        "original_sample_id": "smp1659q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not charge faster than a receiver can receive\n2. framing: datum are packed in a inning, this inning contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to charge the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. period control: ensures that a sender does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, finish address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a chargeer does not charge faster than a receiver can receive\n2. framing: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to charge the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive 2. framming: the data is packed in a frame, this framework contains, for example, the data, the destination address and the source 3. error detection: important to ensure that all the data have been correctly received. if an error is detected, the receiver can be reported to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. menses control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to send the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow ascendance: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. misplay espial: important to ensure that all data has been received correctly. if an misplay is detected, the receiver may be signalled to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug06smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive 2. framming: the data is packed in a frame, this framework contains, for example, the data, the destination address and the source 3. error detection: important to ensure that all the data have been correctly received. if an error is detected, the receiver can be reported to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug07smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: check that a transmitter does not send faster than a receiver can receive\n2. frame: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to send the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1068q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Extending trees identify in multiple ways, from node to node, and transfer them to a tree topology with shorter paths ensuring loopless communication (package) * overall knowledge of the multicast tree that extends by sharing them with each other, e.g. via the routing of the link state * routing of the link state and the range tree: * in the routing of the link state, each one collects information on distances to adjacent stations, and now knows to which multicast group it belongs * distributes this information (distances + multicast group) in the link state packages * with this complete state information each can calculate a multicast tree and based on those that determine outgoing lines",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees identify multiple ways from node to node and transfer them into a tree topology with shortest paths ensuring loop free (packet) communication * global knowledge of the multicast group’s spanning tree by sharing them with each other e.g. via link state routing  * link state routing and spanning tree: * in link state routing each is gathers information about distances to the adjacent stations, and now also knows which multicast group it belongs to * is distribute these information (distances + multicast group) in periodically send link state packets  * with these complete state information each is can calculate a multicast tree and based on those determine outgoing lines",
        "original_sample_id": "smp1068q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1068q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Extending trees identify in multiple ways, from node to node, and transfer them to a tree topology with shorter paths ensuring loopless communication (package) * overall knowledge of the multicast tree that extends by sharing them with each other, e.g. via the routing of the link state * routing of the link state and the range tree: * in the routing of the link state, each one collects information on distances to adjacent stations, and now knows to which multicast group it belongs * distributes this information (distances + multicast group) in the link state packages * with this complete state information each can calculate a multicast tree and based on those that determine outgoing lines",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees identify multiple ways from node to node and transfer them into a tree topology with shortest paths ensuring loop free (packet) communication * global knowledge of the multicast group’s spanning tree by sharing them with each other e.g. via link state routing  * link state routing and spanning tree: * in link state routing each is gathers information about distances to the adjacent stations, and now also knows which multicast group it belongs to * is distribute these information (distances + multicast group) in periodically send link state packets  * with these complete state information each is can calculate a multicast tree and based on those determine outgoing lines",
        "original_sample_id": "smp1068q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0864q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, this hypothesis is not supported for real Internet traffic because problems that can block the arrival of packages can usually persist more than a step of time. If for example the arrival is blocked by congestion is more likely to still have congestion in the next step of time. On the other hand, if the arrival is not blocked it is likely that the following packages will also arrive. the arrival of packages is not a completely random process, blocking is caused by observable problems.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the persistence of problems may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, this assumption does not hold for real internet traffic since problems that may block the arrival of packets may usually persist longer than one time step δt. if for example the arrival is blocked by congestion it is more likely to still have congestion in the next time step. on the other hand, if the arrival is not blocked it is likely that the following packets will also arrive. the arrival of packets is not a wholly random process, blocking is caused by observable problems.",
        "original_sample_id": "smp0864q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0864q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for real internet traffic since problems that may stymy the arrival of packets may usually persist longer than one clip step δt. if for example the arrival is stymyed by congestion it is more likely to still have congestion in the next clip step. on the other hand, if the arrival is not stymyed it is likely that the survey packets will also arrive. the arrival of packets is not a wholly random process, stymying is caused by observable problems.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the persistence of problems may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, this assumption does not hold for real internet traffic since problems that may block the arrival of packets may usually persist longer than one time step δt. if for example the arrival is blocked by congestion it is more likely to still have congestion in the next time step. on the other hand, if the arrival is not blocked it is likely that the following packets will also arrive. the arrival of packets is not a wholly random process, blocking is caused by observable problems.",
        "original_sample_id": "smp0864q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1054q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "goal: avoid flood duplicates and guarantee loopless rotation. how they work: when a multicast package enters a router's interface, look for the source of the multicast package in your unicat routing table to see if the output interface associated with this ip source address is the interface in which this package arrived. if it matches, the router doubles the package and returns it, if it fails, the package will be deleted.",
        "answer_feedback": "the response is partially correct because it's unclear whether the stated description is referring to the rpf or rpb algorithm.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.2,
        "original_answer": "purpose: avoid flood duplicates and ensure loop-free forwarding. how they work: when a multicast packeting enters a router's interface,  it looks up the source of the multicast packet in its unicast routing table to see if the outgoing interface associated with that source ip address is the interface on which that packet arrived. if matched, the router duplicate the packet and forward it, if fails, the packet will be discarded.",
        "original_sample_id": "smp1054q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1624q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0.0.0.0): network address 01111111 (127.255.255.255): transmission",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "00000000 (0.0.0.0): network address\n\n01111111 (127.255.255.255): broadcast",
        "original_sample_id": "smp1624q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1624q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0.0.0.0): network address 01111111 (127.255.255.255): transmission",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "00000000 (0.0.0.0): network address\n\n01111111 (127.255.255.255): broadcast",
        "original_sample_id": "smp1624q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0789q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header has a variable length of 20-60 bytes while the udp header has a fixed length of 8 bytes. udp has a field of length of 2 bytes while tcp has no field of length. tcp has a field of sequence number of 4 bytes while udp does not. tcp has a field of recognition number of 4 bytes while udp does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header has a 20-60 bytes variable length while the udp header has a 8 bytes fixed length.\nudp has a 2 bytes length field while tcp has no field for the length. \ntcp has a 4 bytes sequence number field while udp has not.\ntcp has a 4 bytes acknowledgement number field while udp has not.",
        "original_sample_id": "smp0789q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1111q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "with multicasting relative to broadcasting, you have a unique expedition instead of multiple shipping. so it is important for everyone to have a global knowledge of the multicast tree. this property applies to trees that extend and can therefore be used for multicasting. to use the link state routing to build a multicasting extension tree, the link state packets need to be expanded to contain information about the multicast groups. these are regularly transmitted to all the other is and now each can calculate a multicast tree.",
        "answer_feedback": "the response is incorrect regarding why multicast and broadcast use spanning tree. a spanning tree is used to reduce unnecessary duplicates by removing loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "with multicasting compared to broadcasting, you have one-time sending instead of multiple sending. therefore it is important for all the is to have global knowledge of the multicast tree. this property applies to spanning trees and thus they can be used for multicasting. to use link state routing to construct a spanning tree for multicasting, the link state packets have to be expanded to contain information on the multicast groups. these periodically get broadcasted to all the other is and now each is can calculate a multicast tree.",
        "original_sample_id": "smp1111q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0322q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward) \n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, f, forward) \n(c, e, driblet) - not the brusque path, as a->b->e is 3 farsighted while this is 4 farsighted\n(d, f, driblet) - not the brusque path, as a->c->f is 3 farsighted while this is 5 farsighted\n(b, c, driblet)\n(c, b, driblet) \n(c, d, driblet)\n(d, c, driblet)  - all not the brusque passes, as they all get their fastest packets directly form a\nhop 3:\n(e, f, driblet)\n(f, e, driblet) - both not the brusque path \n(e, g, forward)\n(f, g, driblet) - farsighteder path than e->ghop 4:\n(g, h, forward) - but no where to forward, but we dont ignore it",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward) \n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, f, forward) \n(c, e, drop) - not the shortest path, as a->b->e is 3 long while this is 4 long\n(d, f, drop) - not the shortest path, as a->c->f is 3 long while this is 5 long\n(b, c, drop)\n(c, b, drop) \n(c, d, drop)\n(d, c, drop)  - all not the shortest passes, as they all get their fastest packets directly form a\nhop 3:\n(e, f, drop)\n(f, e, drop) - both not the shortest path \n(e, g, forward)\n(f, g, drop) - longer path than e->ghop 4:\n(g, h, forward) - but no where to forward, but we dont ignore it",
        "original_sample_id": "smp0322q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0880q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no this assumption does not hold for real internet traffic because for example if i catch a tv and the bundles are transportet in bursty traffic, there is always a period in which it is more likely to have arrivals of bundles. so the arrivals would more look like a few ones followed by a few zeros followed by ones and so on instead of an independent arrival. also other factors like congestion or the time at which the network is used (evening or morning) can influence the bundle arrivals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no this assumption does not hold for real internet traffic because for example if i watch a video and the packets are transportet in bursty traffic, there is always a period in which it is more likely to have arrivals of packets. so the arrivals would more look like a few ones followed by a few zeros followed by ones and so on instead of an independent arrival. also other factors like congestion or the time at which the network is used (evening or morning) can influence the packet arrivals.",
        "original_sample_id": "smp0880q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0744q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it is about the problem, how can it be middling that  everybody bring the same possibility to approach to the data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb, but it lacks the reason behind it. the reservation of transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is about the problem, how can it be fair that  everybody gets the same possibility to access to the data.",
        "original_sample_id": "smp0744q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0744q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it is about the trouble, how can it be fair that  everybody contract the same hypothesis to access to the data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb, but it lacks the reason behind it. the reservation of transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is about the problem, how can it be fair that  everybody gets the same possibility to access to the data.",
        "original_sample_id": "smp0744q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0744q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it is about the trouble, how can it be fair that  everybody beat the same theory to access to the data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb, but it lacks the reason behind it. the reservation of transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is about the problem, how can it be fair that  everybody gets the same possibility to access to the data.",
        "original_sample_id": "smp0744q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0744q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it is about the trouble, how can it be mediocre that  everybody gets the same theory to access to the data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb, but it lacks the reason behind it. the reservation of transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is about the problem, how can it be fair that  everybody gets the same possibility to access to the data.",
        "original_sample_id": "smp0744q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0744q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it is about the job, how can it be fair that  everybody develop the same possibility to entree to the data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb, but it lacks the reason behind it. the reservation of transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is about the problem, how can it be fair that  everybody gets the same possibility to access to the data.",
        "original_sample_id": "smp0744q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0907q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "- deck table must hold the table that can map from the address to lan: for example, host_a_address: lan 1, which means, if we want to get to host a we have to go via lan 1. - how the table is changed: at the beginning, the table is empty. then whenever a package with the source address q comes to the bridge at lan x, the bridge will store this mapping information (q can be reached via lan x). over time, the complete table will be built. - how the table is used in the return process? the bridge will search in the table until it can find a match (there is an address q the table that corresponds to the address in the package). then it will transmit the package to the corresponding lan. - advantage: this table can very well be adapted in case of a change of topology.",
        "answer_feedback": "the correct benefit is that there is less traffic because of selective forwarding, not just topological change adaption. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- bridge table must hold the table which can map from address to lan: for example, host_a_address: lan 1, that means, if we want to get to host a we have to go via lan 1. - how is table modified: in the beginning, table is empty. then every time a packet with source address q comes to the bridge at lan x, the bridge will store this mapping information ( q can be reached via lan x). over time, the complete table will be built up. - how is the table used in the forwarding process? the bridge will search in the table until it can find a match(there is a q address the table which matches the address in the packet). then it will forward the packet to the corresponding lan. - benefit: this table can be adapted very well in case of change in topology.",
        "original_sample_id": "smp0907q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1695q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0. and 127.255,255,255",
        "answer_feedback": "the addresses have ranges: from x.0.0.0 and x.255.255.255 with x between 0 and 127\nmissing: loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0. und 127.255.255.255",
        "original_sample_id": "smp1695q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1538q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "A duplex operating mode is required, so that both communication partners can send data frames with backup recognition. (effective if window size is greater than 1 only.)",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a duplex operation mode is required, so that both communication partners can send data frames with piggybacked acknowledgments.\n(efficient if window size greater than 1 only.)",
        "original_sample_id": "smp1538q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1048q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the inverse path is used for the free broadcasts of multicast package loops, while the inverse path is an improved version of rpf. they work by assigning to each sender its own spanning tree, while it does not have to know them. if a node gets a package of a link that it knows of its spanning tree is the best possible route to it, it reverses it on each other port, if it gets a package on a port, it knows that it is not the best route it rejects. rpb on the other hand improves this algorithm in a way that it looks at the package, if it has always taken the best route, not only if it has arrived at the best port. so much less packets get reset, which reduces the traffic on the network.",
        "answer_feedback": "the purpose is not limited to multicast but also used in broadcast. in rpf, a node decides whether the packet used the best route so far based on its routing table consisting of unicast information, not from the spanning tree. in rpb, is only forward packets on edges that are part of a spanning tree, which is not clear from the explanation.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "reverse path forwarding is used for loop free broadcasts of multicast packages, while reverse path broadcasting is an improved version of rpf. they work by assigning every sender its own spanning tree, while the is does not have to know them. if a node gets a package from a link that it knows from its spanning tree is the best possible route to it, it resends it on every other port, if it gets a package on a port, that it knows is not the best route it discards it. rpb on the other hand improves this algorithm in a way that it looks at the package, if it always took the best route, not only if it arrived at the best port. this way far less packets get resend, which reduces the traffic on the network.",
        "original_sample_id": "smp1048q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1109q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Therefore, they allow routers to make copies on the last intermediate systems. in this way, traffic and duplicate packages are reduced on the network. for link status routing, the information that contains link status packets in addition to the distance and neighbors has to be expanded by information on multicast groups. with this information, each router can calculate a multicast tree using local and complete status information. based on the multicast tree, the intermediate systems determine the outgoing lines on which the packets must be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for link state routing, the containing information of link state packets besides distance and neighbors has to be expanded by information on multicast groups. with this information, every router can calculate a multicast tree using the now locally available and complete state information. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "original_sample_id": "smp1109q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1109q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for nexus state routing, the moderate entropy of nexus state packets besides distance and neighbors has to be expanded by entropy on multicast groups. with this entropy, every router can calculate a multicast tree using the now locally available and complete state entropy. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for link state routing, the containing information of link state packets besides distance and neighbors has to be expanded by information on multicast groups. with this information, every router can calculate a multicast tree using the now locally available and complete state information. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "original_sample_id": "smp1109q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1511q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the answer frames have to be able to contain datum + ack and not only ack or only datum. this direction the ack can be delayed and sent along with datum in one frame.",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. the above point is related to how piggybacking's implementation works and not what is required for piggybacking to work.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the answer frames have to be able to contain data + ack and not only ack or only data. this way the ack can be delayed and sent along with data in one frame.",
        "original_sample_id": "smp1511q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0372q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (a, b, forward) ; (a, c, forward); (a, d, pearl).acme d will not forword package to acme f(not the shortest), so acme d will pearl.\nhop 2: (b, e, forward);  (c, f,  pearl). acme f will not forword package to acme g(not the shortest), so acme f will pearl.\nhop 3: (e, g, forward).\nhop 4: (g, h, pearl). acme h has only one neighbour,so acme h doesn't forword .",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1: (a, b, forward) ; (a, c, forward); (a, d, drop).vertex d will not forword package to vertex f(not the shortest), so vertex d will drop.\nhop 2: (b, e, forward);  (c, f,  drop). vertex f will not forword package to vertex g(not the shortest), so vertex f will drop.\nhop 3: (e, g, forward).\nhop 4: (g, h, drop). vertex h has only one neighbor,so vertex h doesn't forword .",
        "original_sample_id": "smp0372q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0386q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: \n(a,b,forrad)\n(a,c, forrad)\n(a,d, forrad)\nhop 2:\n(b, e, forrad)\n(b, c, bead) c would not send package to a via b, it would send directly\n(c, b, bead) same reason as above\n(c, d, bead) d would not send package to a via b, it would send directly\n(c, f, forrad)\n(d, c, bead) c would not send package to a via d\n(d, f, bead) f would send package to a via c\nhop 3:\n(e, c, bead) c would sent package to a directly\n(e, f, bead) f would sent package to a via c\n(e,g, forrad)\n(f, e, bead) e would sent package to a via b\n(f, d, bead) d would sent package to a directly\n(f, g, bead) g would sent package to a via e\nhop 4:\n(g, f, bead) f would sent package to a via c\n(g, h, bead) h only has 1 link which is the incoming link",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: \n(a,b,forward)\n(a,c, forward)\n(a,d, forward)\nhop 2:\n(b, e, forward)\n(b, c, drop) c would not send packet to a via b, it would send directly\n(c, b, drop) same reason as above\n(c, d, drop) d would not send packet to a via b, it would send directly\n(c, f, forward)\n(d, c, drop) c would not send packet to a via d\n(d, f, drop) f would send packet to a via c\nhop 3:\n(e, c, drop) c would sent packet to a directly\n(e, f, drop) f would sent packet to a via c\n(e,g, forward)\n(f, e, drop) e would sent packet to a via b\n(f, d, drop) d would sent packet to a directly\n(f, g, drop) g would sent packet to a via e\nhop 4:\n(g, f, drop) f would sent packet to a via c\n(g, h, drop) h only has 1 link which is the incoming link",
        "original_sample_id": "smp0386q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0331q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b, forrad)\n(a,c, forrad)\n(a,d, dip) d does not forrad the package to f or c since both don't send package to a via d.\n\nhop 2:\n(b,e, forrad)\n(c,f, dip) f does not forrad the received packet to c,d,e or g since none of them send their packages to a via f.\n\nhop 3:\n(e, g forrad)\n\nhop 4:\n(g,h dip) since h only has one neighbor, from which it has received the packet, the packet is not forraded",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b, forward)\n(a,c, forward)\n(a,d, drop) d does not forward the packets to f or c since both don't send packets to a via d.\n\nhop 2:\n(b,e, forward)\n(c,f, drop) f does not forward the received packet to c,d,e or g since none of them send their packages to a via f.\n\nhop 3:\n(e, g forward)\n\nhop 4:\n(g,h drop) since h only has one neighbor, from which it has received the packet, the packet is not forwarded",
        "original_sample_id": "smp0331q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1046q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "both algorithms try to detect duplicate bundles in programs and only forward bundles that are likely new and need to be forwarded. other bundles are likely duplicates and are discarded.  in reverse course forwarding, each router saves which course a bundle takes from a sender s in a unicast communication, considering it to be the shortest course from s. from there on, program bundles from s that are not coming over that course are considered to be duplicates and are discarded. program bundles from s coming over that course are accepted and programed to all edges except to the incoming one. one disadvantage of rpf is that the bundle is resent over all edges (except the incoming one), but not forwarded only over suitable edges.  in reverse course program, a node also remembers the course taken from a sender s in a unicast communication. additionally, a node also learns that if it never received a unicast bundle from s to another node b, then it is likely not on the shortest course from s to b. to reduce the unnecessary bundle duplication in rpf, the bundle is not forwarded on all edges (except the incoming edge), but only on the edges which are in the reversed direction to source s.",
        "answer_feedback": "the response is correct with one exception. in rpb, unicast paths can be learned from both ways, s to node or node to s.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "both algorithms try to detect duplicate packets in broadcasts and only forward packets that are likely new and need to be forwarded. other packets are likely duplicates and are discarded.  in reverse path forwarding, each router saves which path a packet takes from a sender s in a unicast communication, considering it to be the shortest path from s. from there on, broadcast packets from s that are not coming over that path are considered to be duplicates and are discarded. broadcast packets from s coming over that path are accepted and broadcasted to all edges except to the incoming one. one disadvantage of rpf is that the packet is resent over all edges (except the incoming one), but not forwarded only over suitable edges.  in reverse path broadcast, a node also remembers the path taken from a sender s in a unicast communication. additionally, a node also learns that if it never received a unicast packet from s to another node b, then it is likely not on the shortest path from s to b. to reduce the unnecessary packet duplication in rpf, the packet is not forwarded on all edges (except the incoming edge), but only on the edges which are in the reversed direction to source s.",
        "original_sample_id": "smp1046q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0786q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp cope includes, unlike the tcp cope, the package length. the tcp cope is bigger than the udp cope, because it includes more entropy, for example a sequence number, an acknowledgement number, several flags and the receive window size.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header includes, unlike the tcp header, the packet length. the tcp header is bigger than the udp header, because it includes more informations, for example a sequence number, an acknowledgement number, several flags and the receive window size.",
        "original_sample_id": "smp0786q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug04smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug05smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug06smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug07smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug08smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug09smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug10smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug11smp0941q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table holds all the mac addresses on the lan as well as all the physical deck ports connected to the place where the address is located on the network. in the learning phase back, the table is updated whenever a packet of a source is sent through the bridge, the spring lan and the bridge are recorded to help advance future packages. the table is also updated periodically and the old entries are purged. when the packets are sent across the bridge in the future, they refer to the deck table and as they are implemented as span trees, it ensures that no loops are formed in the transfer process and that there is only one path connecting 2 lans.",
        "answer_feedback": "the response has the following errors: a)not all the mac addresses are stored, only the incoming packets' source addresses. b)during backward learning, the station, lan, and the timestamp is recorded, not the bridge. c)how the information learned is used in selective forwarding is not mentioned. d) the stated benefit is incorrect as it points to the benefit of using a spanning tree in the case of multiple transparent bridges. however, the question asked for the benefit derived from using the bridging table.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the bridge table holds all the mac addresses on the lan as well as all the physical bridge ports connected to where the address is located on the network. in the backwards learning phase, the table is updated every time a packet from a source is sent through the bridge, the source lan and bridge are recorded to help forward future packets. the table is also updated periodically and old entries are purged. when packets are sent through the bridge in the future, they refer to the bridge table and since they are implemented as spanning trees, it ensures no loops are formed in the forwarding process and that there exists only one path connecting 2 lans.",
        "original_sample_id": "smp0941q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0813q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Since tcp is much more complex compared to udp, it also displays a much more complicated header with more detailed information about the package and its routing. e.g. there are the following four differences between the headers of the two protocols: - first, tcp includes a sequence number to be sent to ensure that all packages can be organized by the receiver in the same order in which they were sent. udp does not give any information about the correct sequence of packages, so that there is no guarantee for the order that the receiver gets or can create. - moreover, tcp gives users confidence by including a recognition field in the header. to be more precise, the sequence number included functions as a recognition for a previous package receiver. on the other hand, udp does not give any guarantee about the reliability of the service, so that there is no space in the header for any type of recognition. - which is more, tcp includes the reception features for the same contact point so you can not use a contact point head.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "as tcp is much more complex in comparison to udp, it also shows a much more complicated header with more and detailed information about the package and its routing. for example, there are the following four differences between the headers of the two protocols: \n- first of all, tcp includes a sequence number for sending to ensure that all packages can be organized by the receiver in the same order as they were sent. udp does not give any information about the right sequence of packages, so there is no guarantee for the order that the receiver gets or can create.\n- furthermore, tcp gives reliability to the users by also including a field for acknowledgements in the header. to be more precise, the included sequence number works as an acknowledgement for a package receiver earlier. on the other hand, udp does not give any guarantee concerning reliability of service, so there is no space in the header for any kind of acknowledgement. \n- what is more, tcp includes possibilities for flow and congestion control by dynamically adjusting the window size for sending and receiving packets at the same time. this process makes use of the “advertised window” field in the header which can be used by a receiver to transmit its optimal window size for reception of packets. udp on the other hand does not include such features, so there is no space for windowing in the header. \n- finally, tcp also gives the user possibilities to prioritize packages for urgent processing at the receiver process. therefore, the header includes the so called 16-bit “urgent pointer” which is an offset to the sequence number and marks the last octet of a sequence of highly prioritized packets. udp does not have any included features for marking urgent data, so there is also no mechanism like the urgent pointer in the udp header.",
        "original_sample_id": "smp0813q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1684q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "first destination of the subnetwork: network destination\nlast destination of the subnetwork: broadcast destination",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "first address of the subnetwork: network address\nlast address of the subnetwork: broadcast address",
        "original_sample_id": "smp1684q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1684q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "first sub-network address: network address last sub-network address: distribution address",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "first address of the subnetwork: network address\nlast address of the subnetwork: broadcast address",
        "original_sample_id": "smp1684q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1092q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "This makes packets sent \"through the tree\" reach a) as quickly as possible and b) for example, flooding to reduce network load. As in the link state routing, each node knows the entire network topology (after it has been compiled), it can easily calculate an extension tree with, for example, the kruskal algorithm if it knows what other nodes are in the multicasting group for which the extension tree is calculated. To do this job, the link status packages must be expanded with information about multicast groups that require the link states to be sent frequently (to respond to multicast queries). Each of them calculates the multicast tree with locally available link status information that also contains the multicast group information. based on the newly calculated multicast tree, it is determined which line to forward incoming multicast packages.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing because they a) connect some router to every other router on the shortest path and b) doesn't allow for loops. this causes packets sent \"through the tree\" to arrive a) the fastest way possible and b) in e.g. flooding to reduce the network load. as in link state routing, each node knows the entire network topology (after it has been collected), it can easily compute a spanning tree with for example kruskal’s algorithm if it knows which other nodes are in the multicasting group for which the spanning tree is calculated. to make this work, link state packets need to be expanded with information on multicast groups which require the link states to be sent frequently (to answer the multicast queries). each is calculates the multicast tree with the locally available link state information which also contains the multicast group information. based on the newly calculated multicast tree, is determine on which line which incoming multicast packages have to forwarded to.",
        "original_sample_id": "smp1092q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1092q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "This makes packets sent \"through the tree\" reach a) as quickly as possible and b) for example, flooding to reduce network load. As in the link state routing, each node knows the entire network topology (after it has been compiled), it can easily calculate an extension tree with, for example, the kruskal algorithm if it knows what other nodes are in the multicasting group for which the extension tree is calculated. To do this job, the link status packages must be expanded with information about multicast groups that require the link states to be sent frequently (to respond to multicast queries). Each of them calculates the multicast tree with locally available link status information that also contains the multicast group information. based on the newly calculated multicast tree, it is determined which line to forward incoming multicast packages.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing because they a) connect some router to every other router on the shortest path and b) doesn't allow for loops. this causes packets sent \"through the tree\" to arrive a) the fastest way possible and b) in e.g. flooding to reduce the network load. as in link state routing, each node knows the entire network topology (after it has been collected), it can easily compute a spanning tree with for example kruskal’s algorithm if it knows which other nodes are in the multicasting group for which the spanning tree is calculated. to make this work, link state packets need to be expanded with information on multicast groups which require the link states to be sent frequently (to answer the multicast queries). each is calculates the multicast tree with the locally available link state information which also contains the multicast group information. based on the newly calculated multicast tree, is determine on which line which incoming multicast packages have to forwarded to.",
        "original_sample_id": "smp1092q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0394q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: from a: (a, b, forwards) (a, c, forwards) (a, d, downwards) - the forwards node d is not the ideal unicast path to nodes c and f. hop 2: from b: (b, e, forwards) from c: (c, f, downwards) - the forwards node f is not the ideal unicast path to nodes d, e and g. hop 3: from e: (e, g, forwards) hop 4: from g: (g, h, downwards) - since the h node has no more links than g where it receives its package package can be released",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\nfrom a:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) - the forward over node d is not the ideal unicast path towards nodes c and f.\n\nhop 2:\nfrom b:\n(b, e, forward)\nfrom c:\n(c, f, drop) - the forward over node f is not the ideal unicast path towards nodes d, e and g.\n\nhop 3:\nfrom e:\n(e, g, forward)\n\nhop 4:\nfrom g:\n(g, h, drop) - since node h has no links other than to g where it receives its packet from the packet can be dropped",
        "original_sample_id": "smp0394q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0809q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- the udp header does not contain a sequence number field (since udp delivers the data to the top layer in the sequence received from the network layer, there is no reordering or detection of duplicates), but tcp yes. - the udp header has a fixed length (8 bytes), the utcp header supports options and therefore is variable length and therefore tcp has a field for the length of the header. - the ttcp header provides flags to establish, maintain and release connections (syn, ack, end, rst), the udp header does not offer anything comparable (because it is message-oriented/without connection). - the ttcp header contains a field for the end-to-flow control (winds), while the udp header does not do so because an application sends as fast as desired and the network allows it. - the tacum field is optional (all zero) for udp (so error detection is optional), but not for tapp. - the sender (all at-to) is optional for tudp, but for udp.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- the udp header does not contain a sequence number field (since udp delivers the data to the upper layer in the sequence received from the network layer, there is no reordering or detection of duplicates), but tcp does.\n\n- the udp header has a fixed length (8 bytes), the tcp header supports options and is therefore of variable length and therefore tcp has a field for the header length.\n\n- the tcp header provides flags for establishing, holding and releasing connections (syn, ack, fin, rst), the udp header offers nothing comparable (because it is message-oriented/connectionless).\n\n- the tcp header contains a field for end-to-end flow control (windows), whereas the udp header doesn't because an application sends as fast as it wants and the network allows it.\n\n- the checksum field is optional (all zero) for udp (error detection is therefore optional), but not for tcp.\n\n- the sender port (all zero) is optional for udp, but not for tcp.",
        "original_sample_id": "smp0809q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0865q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it doesn't hold. on the real Internet, there are all kinds of traffic. on a tcp connection, for example, packages highly depend on each other in several ways. the sequence in which packages should arrive is critical. there are recognitions, which are only sent if a package arrives at its destination. and if some packages fail, they will be transmitted.",
        "answer_feedback": "as mentioned in the response, the correct answer is \"no\". real internet traffic is bursty, which is the main reason for the assumption being false. the above example attributes the burstiness to the sequencing, retransmission, and acknowledgement, which may contribute but are not the main cause of the assumption's violation.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it doesn’t hold. on the real internet, there’s all kind of traffic. in a tcp-connection for example, the packets strongly depend on one another in various ways. the sequence in which the packets need to arrive is critical. there are acknowledgements, which are only sent if a packet arrives at the destination. and if some packets don’t arrive, they will be retransmit.",
        "original_sample_id": "smp0865q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0865q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it doesn't hold. on the real Internet, there are all kinds of traffic. on a tcp connection, for example, packages highly depend on each other in several ways. the sequence in which packages should arrive is critical. there are recognitions, which are only sent if a package arrives at its destination. and if some packages fail, they will be transmitted.",
        "answer_feedback": "as mentioned in the response, the correct answer is \"no\". real internet traffic is bursty, which is the main reason for the assumption being false. the above example attributes the burstiness to the sequencing, retransmission, and acknowledgement, which may contribute but are not the main cause of the assumption's violation.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it doesn’t hold. on the real internet, there’s all kind of traffic. in a tcp-connection for example, the packets strongly depend on one another in various ways. the sequence in which the packets need to arrive is critical. there are acknowledgements, which are only sent if a packet arrives at the destination. and if some packets don’t arrive, they will be retransmit.",
        "original_sample_id": "smp0865q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1621q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8: dummy reference,\n10.0.0.0/8: individual web\n127.0.0.0/8: loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8: dummy address,\n10.0.0.0/8: private network\n127.0.0.0/8: loopback",
        "original_sample_id": "smp1621q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0749q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is an important issue in \"distributed queue buses.\" The problem is, how can you guarantee that everyone has the same chance of getting access to data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem of transmission rights in dqdb, but it lacks an explanation specific to dqdb. the likelihood of access depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "fairness is an  important issue in \"distributed queue dual buses\".  the problem is, how can it be ensured that everybody has the same likelihood to get access to data.",
        "original_sample_id": "smp0749q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0749q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is an important issue in \"distributed queue buses.\" The problem is, how can you guarantee that everyone has the same chance of getting access to data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem of transmission rights in dqdb, but it lacks an explanation specific to dqdb. the likelihood of access depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "fairness is an  important issue in \"distributed queue dual buses\".  the problem is, how can it be ensured that everybody has the same likelihood to get access to data.",
        "original_sample_id": "smp0749q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0749q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is an important issue in \"distributed queue buses.\" The problem is, how can you guarantee that everyone has the same chance of getting access to data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem of transmission rights in dqdb, but it lacks an explanation specific to dqdb. the likelihood of access depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "fairness is an  important issue in \"distributed queue dual buses\".  the problem is, how can it be ensured that everybody has the same likelihood to get access to data.",
        "original_sample_id": "smp0749q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0749q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is an important issue in \"distributed queue buses.\" The problem is, how can you guarantee that everyone has the same chance of getting access to data.",
        "answer_feedback": "the response is partially correct as it states the fairness problem of transmission rights in dqdb, but it lacks an explanation specific to dqdb. the likelihood of access depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "fairness is an  important issue in \"distributed queue dual buses\".  the problem is, how can it be ensured that everybody has the same likelihood to get access to data.",
        "original_sample_id": "smp0749q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0749q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is an  important issue in \"distributed queue twofold buses\".  the problem is, how can it be ascertain that everybody has the same likelihood to get access to datum.",
        "answer_feedback": "the response is partially correct as it states the fairness problem of transmission rights in dqdb, but it lacks an explanation specific to dqdb. the likelihood of access depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "fairness is an  important issue in \"distributed queue dual buses\".  the problem is, how can it be ensured that everybody has the same likelihood to get access to data.",
        "original_sample_id": "smp0749q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0377q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,onwards)\n(a,c,onwards)\n(a,d,drop)<=d doesn't foward a substance from a to f, because f doesn't receive unicast parcel via d.\nhop 2:\n(b,e,onwards)\n(c,f,drop)<=f doesn't foward a substance from a to g, because g doesn't receive unicast parcel via f.\nhop 3:\n(e,g,onwards)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the substance, vertex h does not onwards the substance.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=d doesn't foward a message from a to f, because f doesn't receive unicast packets via d.\nhop 2:\n(b,e,forward)\n(c,f,drop)<=f doesn't foward a message from a to g, because g doesn't receive unicast packets via f.\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the message, vertex h does not forward the message.",
        "original_sample_id": "smp0377q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1640q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/8 10.00.0/8 127,00,0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n127.0.0.0/8",
        "original_sample_id": "smp1640q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0101q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "for this network i suggest to use the differential manchester encryption: this encryption technique is robust in clock recovery and hence offers synchronicity facility at receiver because a transition is guaranteed at least once every second. in addition, it is less error-prone in noisy environments.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "for this network i suggest to use the differential manchester encoding: this encoding technique is robust in clock recovery and hence offers synchronization facility at receiver because a transition is guaranteed at least once every bit. in addition, it is less error-prone in noisy environments.",
        "original_sample_id": "smp0101q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0101q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "for this network i suggest to use the differential manchester encryption: this encryption technique is robust in clock recovery and hence offers synchronization facility at receiver because a passage is guaranteed at least once every bit. in plus, it is less error-prone in noisy environments.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "for this network i suggest to use the differential manchester encoding: this encoding technique is robust in clock recovery and hence offers synchronization facility at receiver because a transition is guaranteed at least once every bit. in addition, it is less error-prone in noisy environments.",
        "original_sample_id": "smp0101q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0929q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "information in the table：address source and  the known address of the destionation nosepiece have any frame on any of its land, of nosepiece have frames with source address q on lan l (q can be reached over l), create table entry accordingly. if it doesnt know the destination. it uses the flooding. as benefit we can mention the adjustment to changes in topology.",
        "answer_feedback": "the transparent bridge table contains the mapping between destinations/stations (macs) and outgoing lan interfaces based on previously received packets, not the source and destination address. it does not mention how this information is used in selective forwarding, and the stated benefit is not correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "information in the table：address source and  the known address of the destionation bridge receives any frame on any of its land, of bridge receives frames with source address q on lan l (q can be reached over l), create table entry accordingly. if it doesnt know the destination. it uses the flooding. as benefit we can mention the adaptation to changes in topology.",
        "original_sample_id": "smp0929q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0378q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (c, a, forward) (d, a, forward) (b, a, forward) hop 2: (b, c, drop) duplicate package, (b, e, forward) (c, b, drop) duplicate package, (c, drop) duplicate package, (c, f, drop) duplicate package, (c, f, drop) duplicate package, (d, f, drop) duplicate package hop 3: (e, c, drop) duplicate package hop 4: (e, g, f, drop) duplicate package, (e, g, drop), (f, drop) duplicate package h does not send the message.",
        "answer_feedback": "(a,d, drop) and subsequent flow will change accordingly. also (c, f, drop).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(c, a, forward)\n(d, a, forward)\n(b, a, forward)\n\nhop 2: \n(b, c, drop) duplicate packet  , (b, e, forward) \n(c, b, drop) duplicate packet, (c, d, drop) duplicate packet, (c, e, drop) duplicate packet, (c, f, forward) \n(d, c, drop) duplicate packet, (d, f, drop) duplicate packet\n\nhop 3: \n (e, c, drop) duplicate packet,\n (e, f, drop) duplicate packet,\n (e, g, forward),  \n(f, d, drop) duplicate packet, \n(f, e, drop) duplicate packet,\n (f, g, drop) duplicate packet\n\nhop 4:\n(g, f, drop) duplicate packet, \n(g, h, drop)  vertex h does not forward the message.",
        "original_sample_id": "smp0378q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0912q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge contains lan routing information in the mesa. the bridge mesa is initially empty and uses flooding for an unknown destination. because of the promiscuous mode, the bridge receives any frame on any of its lans. if the bridge receives skeleton with source address 'q' on lan 'l' a mesa entry can be create with given information. with the given mesa structure the route to the destination does not have to be remembered, only the next sub destination is necessary to know.",
        "answer_feedback": "the response correctly describes how transparent bridges build their bridge table. however, the response does not provide information on how the table is used during the forwarding process and in the stated benefit, is not clear what is meant by sub destination.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the bridge contains lan routing information in the table. the bridge table is initially empty and uses flooding for an unknown destination. because of the promiscuous mode, the bridge receives any frame on any of its lans. if the bridge receives frames with source address 'q' on lan 'l' a table entry can be created with given information. with the given table structure the route to the destination does not have to be remembered, only the next sub destination is necessary to know.",
        "original_sample_id": "smp0912q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0798q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp has a forgetful header, just ip with source and destination port, while tcp has a lot more information.\ntcp has a:\n1.sequence issue\n2.ack issue\n3.checksum\n4. flagstone",
        "answer_feedback": "though the udp header is short, it has 4 fields, not just 2 as stated. the other stated differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.88,
        "original_answer": "udp has a short header, just ip with source and destination port, while tcp has a lot more information.\ntcp has a:\n1.sequence number\n2.ack number\n3.checksum\n4. flags",
        "original_sample_id": "smp0798q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0798q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp has a poor header, just ip with source and finish port, while tcp has a lot more information.\ntcp has a:\n1.sequence issue\n2.ack issue\n3.checksum\n4. flags",
        "answer_feedback": "though the udp header is short, it has 4 fields, not just 2 as stated. the other stated differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.88,
        "original_answer": "udp has a short header, just ip with source and destination port, while tcp has a lot more information.\ntcp has a:\n1.sequence number\n2.ack number\n3.checksum\n4. flags",
        "original_sample_id": "smp0798q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0798q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp has a short header, only ip with port of origin and destination, while tcp has much more information. tcp has one: number of 1.incidence 2.ack number 3.checksum 4. flags",
        "answer_feedback": "though the udp header is short, it has 4 fields, not just 2 as stated. the other stated differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.88,
        "original_answer": "udp has a short header, just ip with source and destination port, while tcp has a lot more information.\ntcp has a:\n1.sequence number\n2.ack number\n3.checksum\n4. flags",
        "original_sample_id": "smp0798q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0798q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp has a forgetful lintel, just ip with source and destination larboard, while tcp has a lot more information.\ntcp has a:\n1.sequence number\n2.ack number\n3.checksum\n4. flags",
        "answer_feedback": "though the udp header is short, it has 4 fields, not just 2 as stated. the other stated differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.88,
        "original_answer": "udp has a short header, just ip with source and destination port, while tcp has a lot more information.\ntcp has a:\n1.sequence number\n2.ack number\n3.checksum\n4. flags",
        "original_sample_id": "smp0798q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1078q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "In general/multicast the goal is to reach the entire network or a group to share resources in the most efficient way possible. for the emission, you can use a simple algorithm like the flood. the algorithm is very robust, but there are a lot of overloads due to the many potential duplicates in the network. with a tree that encompasses the number of packages, especially duplicates, you can minimize/limit. in multicast, this tree that covers can also be reduced to nodes that belong to the group. to get such a large tree different protocols such as distance vector or routing status link can be used. for link status routing, each node sends information from all its neighbor nodes to all of them. with this information, the nodes can reconstruct the entire network and use for example the dijkstra algorithm to get a tree that extends. for multicast, each node also sends information in the packages to which they belong, so that you can also determine a multicast route for each node.",
        "answer_feedback": "the response does not state why spanning trees minimize duplicates. that is because they are loop-free. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "in broad/multicast the goal is to reach the whole network or a group to share the resources as efficient as possible. for broadcast, a simple algorithm like flooding can be used. the algorithm is very robust, but there is lots of overhead because of the many potential duplicates in the network. with a spanning tree the number of packets, especially the duplicates, can be minimized/limited. in multicast, this spanning tree can then also be reduced to the nodes belonging to the group.  to get such a spanning tree different protocols as for example distance vector or link state routing can be used. for link state routing, every node sends the information of all his neighbor nodes to everyone. with this information, the nodes can reconstruct the whole network and use e.g. dijkstra algorithm to get a spanning tree. for multicast, each node also sends the information in the packets to which group they belong, so there can be also determined a multicast path by every node. a multicast spanning tree is created.",
        "original_sample_id": "smp1078q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward path forwarding (rpf) and rearward path programme (rpb) are used in networks with programmeing ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and programme them to every knob attached to them, except to the knob where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination knob always take this exact is port. in this way, the programme is done by using unicast paths. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward route forwarding (rpf) and rearward route broadcast (rpb) are used in networks with broadcasting ability to find the best routes between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every knob attached to them, except to the knob where it came from. to accomplish the best route, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination knob always take this exact is port. in this way, the broadcast is done by using unicast routes. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug02smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding (rpf) and reverse path circularize (rpb) are used in networks with circularizeing ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and circularize them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has exact the best route. this is the case, when packets with a sealed destination node always take this exact is port. in this way, the circularize is done by using unicast paths. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug03smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse itinerary forwarding (rpf) and reverse itinerary program (rpb) are used in networks with programing ability to find the best itinerarys between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and program them to every node attached to them, except to the node where it came from. to accomplish the best itinerary, the is keeps track of where incoming packets were itineraryd and if the packet has taken the best itinerary. this is the case, when packets with a certain destination node always take this exact is port. in this way, the program is done by using unicast itinerarys. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug04smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug05smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug06smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug07smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0922q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The tables contain information about where to send frames from a station, for example, on a bridge with two lan networks, send frames to more than lan 2 and frames with dest. b on lan 1, without knowing where they actually are. during the reverse learning, you will receive all frames on one of your lan networks and add this information in your table, for example, received from src. c on lan 2 -> knowledge, that frameworks for det. c must be transferred to lan 2. the bridge makes its own redeployment decisions, for example, if it does not know on what a frame should be redeployed, it sends them to all (floated, adv.), if the src. and det. lan are the same as the frame is dropped, otherwise it is sent in agreement with the table. advantages: reduction of duplicates on a network, the frames will arrive at destination even if the bridge does not know the destination.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tables contain information of where to send the frames from a station, e.g. in a bridge with two lan-networks, sends frames with destination a over lan 2 and frames with dest. b over lan 1, without knowing where it is actually located.\nduring backwards learning, it will receive all frames on any of its lan-networks and adds this information in its table, e.g. received from src. c over lan 2 -> knowledge, that frames for dest. c should be forwarded over lan 2.\nthe bridge makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the table.\nadvantages: reduction of duplicates in a network, the frames will reach its destination even if the bridge doesn't know the destination.",
        "original_sample_id": "smp0922q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0922q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the tables contain information of where to send the entrap from a place, e.g. in a bridge with two lan-networks, sends entrap with destination a over lan 2 and entrap with dest. b over lan 1, without knowing where it is actually located.\nduring backwards instruct, it will receive all entrap on any of its lan-networks and adds this information in its table, e.g. received from src. c over lan 2 -> knowledge, that entrap for dest. c should be forwarded over lan 2.\nthe bridge makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the table.\nadvantages: reduction of duplicates in a network, the entrap will reach its destination even if the bridge doesn't know the destination.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tables contain information of where to send the frames from a station, e.g. in a bridge with two lan-networks, sends frames with destination a over lan 2 and frames with dest. b over lan 1, without knowing where it is actually located.\nduring backwards learning, it will receive all frames on any of its lan-networks and adds this information in its table, e.g. received from src. c over lan 2 -> knowledge, that frames for dest. c should be forwarded over lan 2.\nthe bridge makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the table.\nadvantages: reduction of duplicates in a network, the frames will reach its destination even if the bridge doesn't know the destination.",
        "original_sample_id": "smp0922q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0922q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesas contain information of where to send the inning from a station, e.g. in a nosepiece with two lan-networks, sends inning with destination a over lan 2 and inning with dest. b over lan 1, without knowing where it is actually located.\nduring backwards learning, it will receive all inning on any of its lan-networks and adds this information in its mesa, e.g. received from src. c over lan 2 -> knowledge, that inning for dest. c should be forwarded over lan 2.\nthe nosepiece makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the mesa.\nadvantages: reduction of duplicates in a network, the inning will reach its destination even if the nosepiece doesn't know the destination.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tables contain information of where to send the frames from a station, e.g. in a bridge with two lan-networks, sends frames with destination a over lan 2 and frames with dest. b over lan 1, without knowing where it is actually located.\nduring backwards learning, it will receive all frames on any of its lan-networks and adds this information in its table, e.g. received from src. c over lan 2 -> knowledge, that frames for dest. c should be forwarded over lan 2.\nthe bridge makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the table.\nadvantages: reduction of duplicates in a network, the frames will reach its destination even if the bridge doesn't know the destination.",
        "original_sample_id": "smp0922q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0922q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The tables contain information about where to send frames from a station, for example, on a bridge with two lan networks, send frames to more than lan 2 and frames with dest. b on lan 1, without knowing where they actually are. during the reverse learning, you will receive all frames on one of your lan networks and add this information in your table, for example, received from src. c on lan 2 -> knowledge, that frameworks for det. c must be transferred to lan 2. the bridge makes its own redeployment decisions, for example, if it does not know on what a frame should be redeployed, it sends them to all (floated, adv.), if the src. and det. lan are the same as the frame is dropped, otherwise it is sent in agreement with the table. advantages: reduction of duplicates on a network, the frames will arrive at destination even if the bridge does not know the destination.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tables contain information of where to send the frames from a station, e.g. in a bridge with two lan-networks, sends frames with destination a over lan 2 and frames with dest. b over lan 1, without knowing where it is actually located.\nduring backwards learning, it will receive all frames on any of its lan-networks and adds this information in its table, e.g. received from src. c over lan 2 -> knowledge, that frames for dest. c should be forwarded over lan 2.\nthe bridge makes its own forwarding decisions, for example if it doesn't know over which lan a frame should be forwarded, it sends it to everyone (flooding, adv.),if the src. and dest. lan are the same the frame is dropped, else it is forwarded according to the table.\nadvantages: reduction of duplicates in a network, the frames will reach its destination even if the bridge doesn't know the destination.",
        "original_sample_id": "smp0922q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1001q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward path forwarding and rearward path program serve as algorithms for program routing, that is, the routing of messages that should be send to every node of a network. with rearward path forwarding, a node receiving a program packet does forward it to every other adjacent node if it comes from the node the unicast routing would usually use as the next hop to the node which format the program. with rearward path program, this behaviour is further refined: again, a program packet is only forwarded by a node b if it comes from the node the unicast routing would usually use as the next hop to the node a which format the program, but this time, not to all other adjacent nodes, but only those which would usually receive unicast-packets from a over the current node b.",
        "answer_feedback": "the response is partially correct as rpf and rpb’s purpose is to reduce the number of duplicates and unnecessary packets in flooding/broadcasting by inspecting the optimal unicast paths. the remaining answer is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "reverse path forwarding and reverse path broadcast serve as algorithms for broadcast routing, that is, the routing of messages that should be send to every node of a network. with reverse path forwarding, a node receiving a broadcast packet does forward it to every other adjacent node if it comes from the node the unicast routing would usually use as the next hop to the node which initialized the broadcast. with reverse path broadcast, this behaviour is further refined: again, a broadcast packet is only forwarded by a node b if it comes from the node the unicast routing would usually use as the next hop to the node a which initialized the broadcast, but this time, not to all other adjacent nodes, but only those which would usually receive unicast-packets from a over the current node b.",
        "original_sample_id": "smp1001q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1097q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "holding: the span tree does not have any loop.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is not provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "property: the spanning tree does not have any loops.",
        "original_sample_id": "smp1097q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1103q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "What makes the trees that extend across a wide and multicasting is that they are a subset of the network or group including all nodes but are loop-free. This ensures that forwarding along the branches of a tree that extends will not result in packages that are forever forwarded in a loop and that all nodes of the network or group are reached. Link status packages have to be expanded by information about multicast groups that is basically the multicast group list to which they currently belong a. in this way, each not only knows the entire network topology, but also the status of each other, that is, to which groups they belong. selecting only the is of the same multicast group, one is able to calculate a multicast tree and use it to determine the output lines on which the packages should be transmitted.",
        "answer_feedback": "the explanation behind using a spanning tree for multicast and broadcast is partially correct because though the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "what makes spanning trees appealing for broad- and multicasting is that they are a subset of the network or group including all nodes but are free of loops. this ensures that forwarding along the branches of a spanning tree will not result in packets being forwarded forever in a loop and that all nodes in the network or group are reached. the link state packets have to be expanded by information on multicast groups which basically is the list of multicast groups an is currently belongs to. this way, each is not only knows the complete network topology, but also the state of every other is, meaning which groups they belong to. by selecting only the is of the same multicast group, an is is able to calculate a multicast tree and use it to determine the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1103q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0827q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. the tcp header has an announced win. field, but the dose is not udp. so tcp supports flow control. 2. tcp has a recognition number field, but the dose is not udp. so tcp supports a reliable two-way byte stream in order. 3. tcp has a sequence number field, but the dose is not udp. so tcp supports error control. 4.tcp has a range of options, but udp does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. tcp header has a advertised win. field, but udp dose not. so tcp supports flow control. \n2. tcp has a acknowledgement number field, but udp dose not. so tcp supports reliable bidirectional in-order byte stream. \n3. tcp has a sequence number field, but udp dose not. so tcp supports error control. \n4.tcp has a options field, but udp does not. so tcp's header length can change.",
        "original_sample_id": "smp0827q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1658q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.255,255,255 10.0.0",
        "answer_feedback": "missing: loopback and ranges",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "10.255.255.255\n10.0.0.0",
        "original_sample_id": "smp1658q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1042q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "-purpose: hosts distribute messages to many or all other hosts.For example, a service that distributes weather reports could work better by transmitting to all terminals and letting interested users read the data. -the way of working: -rpf: the retransmission sender sends a package to one along with the route, which is unicast from one before (for example, the route is: to send unicat to s via b). to accept it. but when you receive the package from another route (for example, s sends a package to a via x, but the route x via is not the shortest route, x forwards this package to a a aa), to ignore this package. -rpb: it is similar to rpf. the retransmission sender sends packets to one along with the route, which is unicat from one before (for example, the route is: to send unicat to s via b). to accept the package.",
        "answer_feedback": "the response states the incorrect purpose. rpf and rpb are used to reduce the number of duplicate and unnecessary packets in flooding/broadcasting by inspecting the optimal unicast paths. in both rpf and rpb, it is not mentioned how the packets are forwarded once they are accepted at the is. in rpb, which link is used to forward the received broadcast message is not mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.4,
        "original_answer": "-purpose:hosts distribute messages to many or all other hosts. for example a service distributing weather reports might work best by broadcasting to all terminals and letting those that are interested read the data.    -the way to work:   -rpf: broadcast sender s sends packet to a along with the path, which s got unicast from a before (e.g. the path is: a sends unicast to s via b). a accepts it. but when a receives the packet from another path (e.g. s sends a packet to a via x, but the path via x is not the shortest path, x forwards this packet to a), a will ignore this packet.  -rpb: it is similar to rpf. broadcast sender s sends packets to a along with the path, which s got unicast from a before (e.g. the path is: a sends unicast to s via b). a accepts the packet. but packets will not be forwarded via x in rpb, because x can learn by packets failing to appear that x is not located on the unicast path from a to s.",
        "original_sample_id": "smp1042q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is that all is know the multicast tree. to fabricate a spanning tree for multicasting, you also have to add the entropy of the other is of the multicast radical.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is that all is to know the multicast tree. to build an extension tree for multicasting, you also have to add the information of the other is from the multicast group.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug02smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is that all is know the multicast tree. to reconstruct a spanning tree for multicasting, you also have to summate the entropy of the other is of the multicast group.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug03smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is that all is to know the multicast tree. to build an extension tree for multicasting, you also have to add the information of the other is from the multicast group.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug04smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is that all is to know the multicast tree. to build an extension tree for multicasting, you also have to add the information of the other is from the multicast group.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug05smp1116q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the place is that all is screw the multicast tree. to construct a spanning tree for multicasting, you also have to add the entropy of the other is of the multicast group.",
        "answer_feedback": "initially, only each is is aware of which group it belongs to and still needs to discover other group members. to construct a multicast spanning tree, we need to add the information to which group each is belongs. the response does not state how this information is added, propagated, and used to construct the multicast spanning tree.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the property is that all is know the multicast tree. to construct a spanning tree for multicasting, you also have to add the information of the other is of the multicast group.",
        "original_sample_id": "smp1116q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0210q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "it’s expected about 57.97 seconds the system stays in the state which mentioned in the question.\nfrom the question we can get the ratio of the “arrival” pace and “serve” pace. under the finite polisher condition we calculate the probability that the polisher is empty. with the help of the balance equation it is able to know the probability that 10 packets are in the polisher. hence we can get the probability of the state in which there are less than 10 packets wait in the queue. it’s easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "answer_feedback": "the response is partially correct because it contains correct calculation steps but the final result is incorrect. the correct answer is 56.95 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it’s expected about 57.97 seconds the system stays in the state which mentioned in the question.\nfrom the question we can get the ratio of the “arrival” rate and “serve” rate. under the finite buffer condition we calculate the probability that the buffer is empty. with the help of the balance equation it is able to know the probability that 10 packets are in the buffer. hence we can get the probability of the state in which there are less than 10 packets waiting in the queue. it’s easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "original_sample_id": "smp0210q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0210q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "we expect that about 57.97 seconds the system will remain in the state mentioned in the question. of the question we can get the ratio of the rate of \"arrival\" and \"serve\" rate. under the condition of finished buffer we calculate the probability that the buffer is empty. using the equation of balance is able to know the probability that 10 packages are in the buffer. so we can get the probability that the state where there are less than 10 packages waiting in the queue. it is easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "answer_feedback": "the response is partially correct because it contains correct calculation steps but the final result is incorrect. the correct answer is 56.95 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it’s expected about 57.97 seconds the system stays in the state which mentioned in the question.\nfrom the question we can get the ratio of the “arrival” rate and “serve” rate. under the finite buffer condition we calculate the probability that the buffer is empty. with the help of the balance equation it is able to know the probability that 10 packets are in the buffer. hence we can get the probability of the state in which there are less than 10 packets waiting in the queue. it’s easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "original_sample_id": "smp0210q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0210q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "we expect that about 57.97 seconds the system will remain in the state mentioned in the question. of the question we can get the ratio of the rate of \"arrival\" and \"serve\" rate. under the condition of finished buffer we calculate the probability that the buffer is empty. using the equation of balance is able to know the probability that 10 packages are in the buffer. so we can get the probability that the state where there are less than 10 packages waiting in the queue. it is easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "answer_feedback": "the response is partially correct because it contains correct calculation steps but the final result is incorrect. the correct answer is 56.95 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it’s expected about 57.97 seconds the system stays in the state which mentioned in the question.\nfrom the question we can get the ratio of the “arrival” rate and “serve” rate. under the finite buffer condition we calculate the probability that the buffer is empty. with the help of the balance equation it is able to know the probability that 10 packets are in the buffer. hence we can get the probability of the state in which there are less than 10 packets waiting in the queue. it’s easy to know the product of 60 seconds and the last calculated probability is the answer.",
        "original_sample_id": "smp0210q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0787q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header is fixed and 64 bit long, while tcp is minimum 160 bit (more optional header) long. the udp header is very short, it consists only in the information of the sender and receiver, the length of the package and a sum of verification. the tcp header has much more information, because it offers complementary services such as two-way communication, the interaction based on connection and avoidance of congestion.Therefore there is a need to have more information recorded in the tcp header. uses the sequence and the recognition number to ensure that each package is received and in the correct order.",
        "answer_feedback": "all the stated differences between a tcp header and a udp header are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header is fixed and 64 bit long, while tcp is minimum 160 bit ( plus optional header) long. \nthe udp header is very short, it only consists of the sender and receiver information, the packet length and a checksum. \nthe tcp header has a lot more information, because it offers supplementary services like i.e. two-way communication, connection-based interaction and congestion avoidance. therefore there is a need to have more information saved inside of the tcp header. it uses the sequence and acknowledgement number to make sure that every packet is received and is in the correct order.",
        "original_sample_id": "smp0787q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1005q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and broadcast checks if the mailboats are send over the usual routes to prevent ip-spoofing every is checks if the received mailboat arrive at the port over which the mailboats for this station/source are usually sent. if this is the case, the mailboat is resend over all bound. if this is not the case, the mailboat is discarded.",
        "answer_feedback": "though rpf and rpb can prevent ip-spoofing, it is not their only use. as the name suggests, their main use is minimizing duplicates during broadcasting. the explanation of rpf is partially correct as the incoming edge is excluded from forwarding instead of resending. additionally, no explanation for rpb is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.2,
        "original_answer": "reverse path forwarding and broadcast checks if the packets are send over the usual routes to prevent ip-spoofing every is checks if the received packet arrived at the port over which the packets for this station/source are usually sent. if this is the case, the packet is resend over all edges. if this is not the case, the packet is discarded.",
        "original_sample_id": "smp1005q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0205q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "then you have to calculate the odds for 0.1,2,3,....9 packets in the buffer to get rate 9 and service rate 10. then you add all those odds. the result is the one-minute percentage with less than 10 packets in the buffer.",
        "answer_feedback": "the response correctly states the steps but does not provide the time out of 1 minute for which the packets in queue are less than 10.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "then you have to calculate the probabilities for 0,1,2,3,...,9 packages in the buffer for arriving rate 9 and serving rate 10. then you sum up all those probabilities. the result is the percent of one minute with less than 10 packages in the buffer.",
        "original_sample_id": "smp0205q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0205q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "then you have to calculate the odds for 0.1,2,3,....9 packets in the buffer to get rate 9 and service rate 10. then you add all those odds. the result is the one-minute percentage with less than 10 packets in the buffer.",
        "answer_feedback": "the response correctly states the steps but does not provide the time out of 1 minute for which the packets in queue are less than 10.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "then you have to calculate the probabilities for 0,1,2,3,...,9 packages in the buffer for arriving rate 9 and serving rate 10. then you sum up all those probabilities. the result is the percent of one minute with less than 10 packages in the buffer.",
        "original_sample_id": "smp0205q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0205q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "then you have to calculate the odds for 0.1,2,3,....9 packets in the buffer to get rate 9 and service rate 10. then you add all those odds. the result is the one-minute percentage with less than 10 packets in the buffer.",
        "answer_feedback": "the response correctly states the steps but does not provide the time out of 1 minute for which the packets in queue are less than 10.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "then you have to calculate the probabilities for 0,1,2,3,...,9 packages in the buffer for arriving rate 9 and serving rate 10. then you sum up all those probabilities. the result is the percent of one minute with less than 10 packages in the buffer.",
        "original_sample_id": "smp0205q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1074q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "with the cover trees you are able to acquire an overall knowledge of the multicast groups from an initial local knowledge, which makes the cover trees attractive. in order to modify the routing of the link state to build a cover tree for the multicasting you can use the normal procedure of routing the link state but also add information about the multicast groups. with each being calculated its own multicast trees with the information available locally. then based on the information about the multicast tree that it determines the paths to be used to transmit packages.",
        "answer_feedback": "yes, global knowledge can be obtained from local knowledge, but that is the description of constructing spanning trees with link-state, not a desirable property of spanning trees. it is desirable for use in multicast and broadcast because of the absence of loops which reduces unnecessary duplicates.  the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "with spanning trees you are able to gain global knowledge of the multicast groups from an initial local knowledge, which makes the spanning trees appealing. in order to modify the link state routing to construct a spanning tree for multicasting you can use the normal procedure of the link state routing but also add the information on the multicast groups. with that each is calculates its own multicast trees with the locally available information. then based on the information about the multicast tree it determines which paths to use for transmitting packets.",
        "original_sample_id": "smp1074q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1065q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "We can therefore use this structure to transmit a package in all directions from which we did not receive the package and finally each node will receive the package once only. the multicast basic principle implies that everything must know the multicast tree. for the status of the routing link everything is sending link state packets, containing important information, periodically broadcasting to all others. Each one is then calculated a multicast tree based on the state information now available locally and complete. based on the information on the multicast tree, it then determines the outgoing lines, on which the packets must be transmitted.",
        "answer_feedback": "the link-state modification description is partially correct. it is unclear which information link-state packets contain that then is used for constructing a multicast tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees contain all nodes without any loops. therefore we can use this structure to forward a package in all directions from which we have not received the package and eventually every node will receive the package a single time. \n\t the multicast basic principle involves all is having to know the multicast tree. for link state routing all is send link state packets, containing important information, periodically by broadcasting to all the others. each is then calculates a multicast tree from the now locally available and complete state information. based on the information about the multicast tree the is then determines the outgoing lines, on which the packets have to be transmitted.",
        "original_sample_id": "smp1065q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1688q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127,255,255,255",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing: loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0\n\n127.255.255.255",
        "original_sample_id": "smp1688q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1034q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose: to double the avoidance and find the “best” / shortest path with extending trees, easy to implement reverse path forward (rpf): each sender knows the network as a tree that extends itself. intermediate systems (es) should not know the trees that extend. once a package arrived at is two possible ways forward: (assuming that the transmission of the shortest route/ “best route”) * once a package arrived from the node to on the same link that the b node expects packets by its routing table, then this package will be sent to all other links except the incoming link. * once a package arrived from the node to another link as node b expect packages from to, then this package will be discarded. retransmission of the reverse route (rpb): it works as rpf but chooses specific links for outgoing traffic. resending packages one is e.g. m learns if it is located on the shortest route between two nodes (p. g. nod. is not a way forward).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "purpose: duplicate avoidance and find the “best” route / shortest path with spanning trees, easy to implement reverse path forwarding (rpf): each sender knows the network as spanning tree for itself. intermediate systems (is) must not know the spanning trees. once a packet arrived at a is there are two possible ways to forward: (assuming shortest path transmission/”best route”) * once a packet arrived from node a on the same link as node b expect packets by its routing table, then this packet will be forwarded to all other links except the incoming link. * once a packet arrived from node a on another link as node b expect packets from a, then this packet will be discarded. reverse path broadcast (rpb): works like rpf but chooses specific links for the outgoing traffic. by forwarding unicast packets an is e.g. m learns whether it is located on the shortest path between two other nodes (e.g. node s and d). if this is not the case and s is sending a broadcasting packet, m would not forward this packet towards d as it knows that it is not on the shortest path from s to d. if m has learned that it is on the shortest path, it will obviously forward a broadcast packet to the destination. depending on whether a certain path is used for unicast packets, an is will use it to forward broadcast packets or omits the packets. thus, the overall network throughput is reduced.",
        "original_sample_id": "smp1034q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1034q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose: to double the avoidance and find the “best” / shortest path with extending trees, easy to implement reverse path forward (rpf): each sender knows the network as a tree that extends itself. intermediate systems (es) should not know the trees that extend. once a package arrived at is two possible ways forward: (assuming that the transmission of the shortest route/ “best route”) * once a package arrived from the node to on the same link that the b node expects packets by its routing table, then this package will be sent to all other links except the incoming link. * once a package arrived from the node to another link as node b expect packages from to, then this package will be discarded. retransmission of the reverse route (rpb): it works as rpf but chooses specific links for outgoing traffic. resending packages one is e.g. m learns if it is located on the shortest route between two nodes (p. g. nod. is not a way forward).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "purpose: duplicate avoidance and find the “best” route / shortest path with spanning trees, easy to implement reverse path forwarding (rpf): each sender knows the network as spanning tree for itself. intermediate systems (is) must not know the spanning trees. once a packet arrived at a is there are two possible ways to forward: (assuming shortest path transmission/”best route”) * once a packet arrived from node a on the same link as node b expect packets by its routing table, then this packet will be forwarded to all other links except the incoming link. * once a packet arrived from node a on another link as node b expect packets from a, then this packet will be discarded. reverse path broadcast (rpb): works like rpf but chooses specific links for the outgoing traffic. by forwarding unicast packets an is e.g. m learns whether it is located on the shortest path between two other nodes (e.g. node s and d). if this is not the case and s is sending a broadcasting packet, m would not forward this packet towards d as it knows that it is not on the shortest path from s to d. if m has learned that it is on the shortest path, it will obviously forward a broadcast packet to the destination. depending on whether a certain path is used for unicast packets, an is will use it to forward broadcast packets or omits the packets. thus, the overall network throughput is reduced.",
        "original_sample_id": "smp1034q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1507q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the requisite are listed below\n1. an interlocal agreement between delegacy must be signed and filed with the county auditor or posted online;\n2. the original contracting agency has complied with all requisite and posts the appeal online; and\n3. the vendor agrees to the arrangement through the initial appeal.",
        "answer_feedback": "the response answers no parts of the question correctly and it is not related to the topic.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the requirements are listed below\n1. an interlocal agreement between agencies must be signed and filed with the county auditor or posted online;\n2. the original contracting agency has complied with all requirements and posts the solicitation online; and\n3. the vendor agrees to the arrangement through the initial solicitation.",
        "original_sample_id": "smp1507q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0825q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1.a udp header contains 8 bytes, but a tcp header has 20 bytes and an option for additional data, the 2.tcp header contains control flags to manage the data stream in specific situations. but the udp header does not. 3.tcp senders use a number, called window size, to regulate the amount of data they send to a receiver before requiring recognition in return. but the udp header does not.",
        "answer_feedback": "the response is incomplete because it states only three differences while the question requirement is to identify four differences.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.a udp header contains 8 bytes ，but a tcp header has  20 bytes and an option for additional data,\n2.tcp header contains control flags to manage data flow in specific situations. but udp header doesn't have it.\n\n3.tcp senders use a number, called window size, to regulate how much data they send to a receiver before requiring an acknowledgment in return. but udp header doesn't have it.",
        "original_sample_id": "smp0825q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0825q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1.a udp coping contains 8 bytes ，but a tcp coping has  20 bytes and an option for additional datum,\n2.tcp coping contains control flags to manage datum flow in specific spot. but udp coping doesn't have it.\n\n3.tcp senders use a number, called window size, to regulate how much datum they send to a receiver before requiring an acknowledgment in return. but udp coping doesn't have it.",
        "answer_feedback": "the response is incomplete because it states only three differences while the question requirement is to identify four differences.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.a udp header contains 8 bytes ，but a tcp header has  20 bytes and an option for additional data,\n2.tcp header contains control flags to manage data flow in specific situations. but udp header doesn't have it.\n\n3.tcp senders use a number, called window size, to regulate how much data they send to a receiver before requiring an acknowledgment in return. but udp header doesn't have it.",
        "original_sample_id": "smp0825q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0825q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1.a udp header contains 8 bytes, but a tcp header has 20 bytes and an option for additional data, the 2.tcp header contains control flags to manage the data stream in specific situations. but the udp header does not. 3.tcp senders use a number, called window size, to regulate the amount of data they send to a receiver before requiring recognition in return. but the udp header does not.",
        "answer_feedback": "the response is incomplete because it states only three differences while the question requirement is to identify four differences.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.a udp header contains 8 bytes ，but a tcp header has  20 bytes and an option for additional data,\n2.tcp header contains control flags to manage data flow in specific situations. but udp header doesn't have it.\n\n3.tcp senders use a number, called window size, to regulate how much data they send to a receiver before requiring an acknowledgment in return. but udp header doesn't have it.",
        "original_sample_id": "smp0825q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0825q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1.a udp header contains 8 bytes, but a tcp header has 20 bytes and an option for additional data, the 2.tcp header contains control flags to manage the data stream in specific situations. but the udp header does not. 3.tcp senders use a number, called window size, to regulate the amount of data they send to a receiver before requiring recognition in return. but the udp header does not.",
        "answer_feedback": "the response is incomplete because it states only three differences while the question requirement is to identify four differences.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.a udp header contains 8 bytes ，but a tcp header has  20 bytes and an option for additional data,\n2.tcp header contains control flags to manage data flow in specific situations. but udp header doesn't have it.\n\n3.tcp senders use a number, called window size, to regulate how much data they send to a receiver before requiring an acknowledgment in return. but udp header doesn't have it.",
        "original_sample_id": "smp0825q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0389q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1: \n(a, b, forwards)\n(a, c, forwards)\n(a, d, forwards)\n\nskip 2:\n(b, e, forwards)\n(c, f, forwards)\nskip 3:\n(e, g, forwards)\n\nskip 4:\n(g, h, forwards)",
        "answer_feedback": "the reasoning behind which packets are dropped is not stated.  please go through the model solution. packets will be considered drop if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7,
        "original_answer": "hop 1: \n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\n(b, e, forward)\n(c, f, forward)\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, forward)",
        "original_sample_id": "smp0389q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless service:\nstation motorcar sends frames to the receiving motorcar without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nstation motorcar sends frames to the receiving motorcar and drive feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the station motorcar sends it again.\n\nacknowledged connection-oriented service:\na logical connection between station- and receivin motorcar is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the station/receiving of data, the connection will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unreceipt connectionless service:\nbeam machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nreceipt connectionless service:\nbeam machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the beam machine sends it again.\n\nreceipt connection-oriented service:\na logical connection between beam- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the beam/receiving of data, the connection will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless service:\nbeam machine sends bod to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nbeam machine sends bod to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the beam machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between beam- and receivin machine is setted up.\non this connection the packets are sendet and list for a specific order.\nafter the beam/receiving of data, the connection will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connexionless service:\nsending machine post build to the receiving machine without feedback.\nno logical connexion.\n\nacknowledged connexionless service:\nsending machine post build to the receiving machine and gets feedback.\nno logical connexion.\nif there is no feedback for a frame in a specific time, the sending machine post it again.\n\nacknowledged connexion-oriented service:\na logical connexion between sending- and receivin machine is setted up.\non this connexion the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connexion will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless service:\nsending motorcar sends skeleton to the receiving motorcar without feedback.\nno legitimate connection.\n\nacknowledged connectionless service:\nsending motorcar sends skeleton to the receiving motorcar and gets feedback.\nno legitimate connection.\nif there is no feedback for a frame in a specific time, the sending motorcar sends it again.\n\nacknowledged connection-oriented service:\na legitimate connection between sending- and receivin motorcar is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0705q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognised offline service: the sending machine sends frames to the receiving machine without feedback. no logical connection. no recognized offline service: the sending machine sends frames to the receiving machine and receives feedback. no logical connection. if there is no feedback for a box at a specific time, the sending machine sends it back. recognized connection-oriented service: a logical connection between the sending machine and receipt is established. in this connection the packages are sent and numbered for a specific order. after sending/receiving data, the connection will be closed.",
        "answer_feedback": "the response answers the differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service:\nsending machine sends frames to the receiving machine without feedback.\nno logical connection.\n\nacknowledged connectionless service:\nsending machine sends frames to the receiving machine and gets feedback.\nno logical connection.\nif there is no feedback for a frame in a specific time, the sending machine sends it again.\n\nacknowledged connection-oriented service:\na logical connection between sending- and receivin machine is setted up.\non this connection the packets are sendet and numbered for a specific order.\nafter the sending/receiving of data, the connection will be closed.",
        "original_sample_id": "smp0705q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1108q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "- good property: not all roads between roads should be used. Therefore, the topology of the network will be simplified and the formation of the loop can be avoided. In other words, the accessibility of the network remains the same even though some links between routers are freed. - extended tree construction mechanism with routing of the state of the link: nodes will send its distance (or delay) to its neighbours periodically. then they can calculate the tree based on this information.",
        "answer_feedback": "the response correctly answers why using a spanning tree is desirable in multicast and broadcast. the provided explanation just partially states the original link-state algorithm,  which can only be used to create a unicast spanning-tree, not a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "- good property: not all paths between the routes must be used. therefore, the network topology will be simplified and loop formation can be prevented. in other word, the reachability of network remains the same even though some links between routers are released. - mechanism to build spanning tree with link state routing: nodes will send its distance (or delay) to its neighbors periodically. then they can calculate the tree based on these information.",
        "original_sample_id": "smp1108q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1077q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The goal of multicasting is to achieve multiple - all in the case of broadcasting - other nodes in a network. an extension tree contains the minimum amount of hops to reach all destinations that makes it a perfect candidate for this purpose. in the link status routing, this tree is shared across all nodes. link status packages now also contain information about multicast groups. nodes now calculate separate trees that span depending on the new information from other nodes. now, we have an extension tree for each multicast group that can be used to send data on the shortest route.",
        "answer_feedback": "spanning trees are used for broadcasting because they are loop-free and hence, reduce duplicates, and do not necessarily contain paths with minimal hops. the explanation for the modification of the link-state algorithm to form a multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the goal of multicasting is to reach multiple - all in the case of broadcasting -other nodes in a network. a spanning tree contains the minimal amount of hops to reach all destinations which makes it a perfect candidate for this purpose.    \n\t\n\tin link state routing, this tree is shared across all nodes. link state packets now also contain information about the multicast groups. the nodes now calculate separate spanning trees depending on the new information from other nodes. now, we have a spanning tree for each multicast group which can be used to send the data on the shortest path.",
        "original_sample_id": "smp1077q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0833q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is an unreliable and connectionless protocol on the transport layer. in comparison to tcp it does not offer flow control, error control or retransmission of mailboat like tcp. udp transfers datagrams and tcp transfers segments. their protocol headers differ due to their different properties. their headers have the following fields in common: - generator port and destination port - packet length (in bytes, minimum is 8 bytes which think only header no payload) - checksum (calculated over header and payload for error detection. in case of error, udp cannot correct it) tcp has additional header fields: - sequence number: every tcp segment has a sequence number. this allows to sort the mailboat later and bring them in the correct order - acknowledgement number: the next sequence number which is expected by the sender as acknowledgement - different flags - advertised win. - urgent pointer - options: additional information",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the first few points are general differences between udp and tcp.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is an unreliable and connectionless protocol on the transport layer. in comparison to tcp it does not offer flow control, error control or retransmission of packets like tcp. udp transfers datagrams and tcp transfers segments. their protocol headers differ due to their different properties. their headers have the following fields in common: - source port and destination port - packet length (in bytes, minimum is 8 bytes which means only header no payload) - checksum (calculated over header and payload for error detection. in case of error, udp cannot correct it) tcp has additional header fields: - sequence number: every tcp segment has a sequence number. this allows to sort the packets later and bring them in the correct order - acknowledgement number: the next sequence number which is expected by the sender as acknowledgement - different flags - advertised win. - urgent pointer - options: additional information",
        "original_sample_id": "smp0833q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is degraded and simple, but is not always applicable.\nprivate conn designation\nprivate pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is riotous and simple, but is not always applicable.\nprivate conn recognition\nprivate pdu recognition",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is degenerate and childlike, but is not always applicable.\nindividual conn designation\nindividual pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is dissipated and elementary, but is not always applicable.\nindividual conn designation\nindividual pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0796q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- both have original port, destination port and checksum - udp a separate package length field, tcp no - tcp in addition a: - recognition number - header length (data displacement) / reservation bits/ flags - window size announced - emergency pointer - variable length options (+padding)",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- both have source port, destination port and checksum - udp has seperate packet length field, tcp not - tcp furthermore has: - acknowledgment number - header length (data offset)/ reservered bits/ flags - advertised window size - urgent pointer - variable length options (+padding)",
        "original_sample_id": "smp0796q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1539q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the frame may control inexplicit acks.",
        "answer_feedback": "the response does not answer the requirement correctly. implicit acks is the description of piggybacking rather than a requirement.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the frames may contain implicit acks.",
        "original_sample_id": "smp1539q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1090q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning try has no loops. when a spanning tree with all routers is known then a board- or multicast generates a minimal amount of packet copy's. nexus state routing extension every is have to know the multicast tree and if it is a member of a multicast grouping or not. to achive this information about the multicast groupings are periodically broadcast together with the nexus state packages. each is can then build the multicast tree from these information. the tree is used to determine which path should be used.",
        "answer_feedback": "each is already knows whether it is a member of a multicast group or not. otherwise, nodes could not append their group status to the link-state packets. the remaining explanation is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a spanning try has no loops. when a spanning tree with all routers is known then a board- or multicast generates a minimal amount of packet copy's. link state routing extension every is have to know the multicast tree and if it is a member of a multicast group or not. to achive this information about the multicast groups are periodically broadcast together with the link state packages. each is can then build the multicast tree from these information. the tree is used to determine which path should be used.",
        "original_sample_id": "smp1090q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1479q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggyback does only make sense if the liquidator has also data at hand, beyond protocol overhead, to be sent back to the liquidator in time with the potential ack message. otherwise piggyback makes no sense. in this instance a simple ack can be sent, without piggyback. this scenario is only useful in bidirectional channel with data traffic in both directions.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking does only make sense if the receiver has also data at hand, beyond protocol overhead, to be sent back to the receiver in time with the potential ack message. otherwise piggybacking makes no sense. in this case a simple ack can be sent, without piggybacking. this scenario is only useful in bidirectional channel with data traffic in both directions.",
        "original_sample_id": "smp1479q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0352q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1:(a, c, before)(a, b, before)(a, d, before) hub 2:(b, a, drop) already received(b, c, drop) already received(b, e, before)(c, b, drop) already received(c, a, drop) already received(d, a, drop) already received(d, c, drop) already received(d, f, before) hub 3:(e, b, drop) already received(e, c, drop) already received(e, f, drop) already received(e, g, drop) already received(f, d, drop) already received(f, c, drop) already received(f, e, drop) already received(f, g, drop) already received(g, e, drop) already received(g, e, drop) already received(g, f, drop) already received(g, f, drop) already received(g, h, before)",
        "answer_feedback": "n  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur and reasoning needs to be provided. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:(a, c, forward)(a, b, forward)(a, d, forward)hop 2:(b, a, drop) already received(b, c, drop) already received(b, e, forward)(c, b, drop) already received(c, a, drop) already received(c, d, drop) already received(d, a, drop) already received(d, c, drop) already received(d, f, forward)hop 3:(e, b, drop) already received(e, c, drop) already received(e, f, drop) already received(e, g, drop) already received(f, d, drop) already received(f, c, drop) already received(f, e, drop) already received(f, g, drop) already receivedhop 4:(g, e, drop) already received(g, f, drop) already received(g, h, forward)",
        "original_sample_id": "smp0352q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1639q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 for legion\n127.255.255.255 for local net\n127.0.0.0 - 127.255.255.254 appropriate for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 for host\n127.255.255.255 for local network\n127.0.0.0 - 127.255.255.254 reserved for loopback",
        "original_sample_id": "smp1639q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0824q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp headers have more airfield than udp headers. tcp as additional airfield for: sequence numeral, acknowledgement numeral, hl/resv/flags, advertise windows size, urgent pointer and options",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the terms hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp headers have more fields than udp headers. tcp as additional fields for: sequence number, acknowledgement number, hl/resv/flags, advertised windows size, urgent pointer and options",
        "original_sample_id": "smp0824q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0350q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a,b,before) (a,c,before) (a,d,drop)-> c directly related to a, path to f too long hops 2; (b,e,before) (c,f,drop) -> e and d have already received the information, path to g too long hops 3: (e,g,before) hops 4: (g,h,drop) - last node of the system",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1: (a,b,forward)\n             (a,c,forward)\n             (a,d,drop)-> c directly connected to a, path to f too long\n             \nhop 2; (b,e,forward)\n             (c,f,drop) -> e and d already received the information, path to g too long\nhop 3: (e,g,forward)\nhop 4: (g,h,drop) - last node in the system",
        "original_sample_id": "smp0350q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0803q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "seq issue, ack issue, hl/resv/flagstone, selection are only in the tcp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the terms hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "seq number, ack number, hl/resv/flags, options are only in the tcp header.",
        "original_sample_id": "smp0803q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0231q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. step: queue: service of 10 packages: service of 10 packages 2. step: service of 9 packages: service of 10 packages 3. step: service of 9 packages: service of 9 packages 4. step: service of 9 packages: service of 9 packages and so on. if always arrives 9 packages per second and the server can serve a maximum of 10 packages per second, there will never be 10 packages in the queue except in the first step.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. step:\nqueue: 10 packets\nservice: 10 packets\n\n2. step:\nqueue: 9 packets\nservice: 10 packets\n\n3.step:\nqueue: 9 packets\nservice: 9 packets\n\n4. step:\nqueue: 9 packets\nservice: 9 packets\n\nand so on. if there will always arrive 9 packets per second and the server can serve maximum 10 packets per second, there will never be 10 packets in the queue except in the first step.",
        "original_sample_id": "smp0231q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0231q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. step: queue: service of 10 packages: service of 10 packages 2. step: service of 9 packages: service of 10 packages 3. step: service of 9 packages: service of 9 packages 4. step: service of 9 packages: service of 9 packages and so on. if always arrives 9 packages per second and the server can serve a maximum of 10 packages per second, there will never be 10 packages in the queue except in the first step.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. step:\nqueue: 10 packets\nservice: 10 packets\n\n2. step:\nqueue: 9 packets\nservice: 10 packets\n\n3.step:\nqueue: 9 packets\nservice: 9 packets\n\n4. step:\nqueue: 9 packets\nservice: 9 packets\n\nand so on. if there will always arrive 9 packets per second and the server can serve maximum 10 packets per second, there will never be 10 packets in the queue except in the first step.",
        "original_sample_id": "smp0231q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1086q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the properties of spanning tree ensure (with the discussed algorithm) that no cringle occur when we transfer multicast (1:n) or broadcast (1:all) messages.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the modification related to the link state algorithm for constructing a multicast spanning-tree is not provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the properties of spanning trees ensure (with the discussed algorithms) that no loops occur when we transfer multicast (1:n) or broadcast (1:all) messages.",
        "original_sample_id": "smp1086q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1685q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0xxx xxx.0000 0000.0000 0000.0000 0000 (network)0xxx xxx.111 1111.1111 1111.1111 (dissemination)0111 1111. xxxxxx xxxx. xxxxxx (127.x.x.x.x.x, loopback)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0xxx xxxx.0000 0000.0000 0000.0000 0000 (network)0xxx xxxx.1111 1111.1111 1111.1111 1111 (broadcast)0111 1111. xxxx xxxx. xxxx xxxx. xxxx xxxx (127.x.x.x , loopback)",
        "original_sample_id": "smp1685q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0349q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a, c, forward) (a, b, forward) (a, d, fall) d cannot advance packages further, as the distance is superior to the hop alternatives 2: (b, e, forward) (c, f, fall)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, c, forward)\n(a, b,  forward)\n(a, d, drop) => d cannot forward packets any further as the distance is higher than alternatives\nhop 2:\n(b, e, forward)\n(c, f, drop) => cannot forward due to high distance\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) => cannot forward because last node",
        "original_sample_id": "smp0349q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1635q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1635q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1635q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1635q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1486q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "framing may take unquestioning acks so both sides have to send framing",
        "answer_feedback": "the response answers the requirement partially because for both sides to send frames, the channel needs to be duplex. furthermore, in the absence of data for piggybacking, it is also possible to send separate acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "frames may contain implicit acks so both sides have to send frames",
        "original_sample_id": "smp1486q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1486q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "framing may contain implicit acks so both side have to transport framing",
        "answer_feedback": "the response answers the requirement partially because for both sides to send frames, the channel needs to be duplex. furthermore, in the absence of data for piggybacking, it is also possible to send separate acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "frames may contain implicit acks so both sides have to send frames",
        "original_sample_id": "smp1486q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1486q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "frames may carry implicit acks so both slope have to post frames",
        "answer_feedback": "the response answers the requirement partially because for both sides to send frames, the channel needs to be duplex. furthermore, in the absence of data for piggybacking, it is also possible to send separate acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "frames may contain implicit acks so both sides have to send frames",
        "original_sample_id": "smp1486q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1486q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "underframe may curb implicit acks so both position have to send underframe",
        "answer_feedback": "the response answers the requirement partially because for both sides to send frames, the channel needs to be duplex. furthermore, in the absence of data for piggybacking, it is also possible to send separate acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "frames may contain implicit acks so both sides have to send frames",
        "original_sample_id": "smp1486q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1486q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "framing may take implicit acks so both sides have to send framing",
        "answer_feedback": "the response answers the requirement partially because for both sides to send frames, the channel needs to be duplex. furthermore, in the absence of data for piggybacking, it is also possible to send separate acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "frames may contain implicit acks so both sides have to send frames",
        "original_sample_id": "smp1486q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0246q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "9 * 60 = 540 bundle arrive in 1 minute\n10 * 60 = 600 bundle can be processed in 1 minute\n\nbased on the effrontery that the bundle arrive uniformly distributed in the minute (i.e. 9 bundle per second) and we can process 10 bundle per second, this means that the scheme is busy in 90 % of the time with processing the bundle. in 10 % of the time the scheme has no bundle to process. \nsince the scheme can process more bundle in a second than we expect to arrive in a second, the scheme will be in a state with less than 10 bundle waiting in the queue for the whole time.",
        "answer_feedback": "the description to justify the system waiting time is missing in the response. additionally, the system does not stay in a less than 10 packets state for a whole minute, only 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "9 * 60 = 540 packets arrive in 1 minute\n10 * 60 = 600 packets can be processed in 1 minute\n\nbased on the assumption that the packets arrive uniformly distributed in the minute (i.e. 9 packets per second) and we can process 10 packets per second, this means that the system is busy in 90 % of the time with processing the packets. in 10 % of the time the system has no packets to process. \nsince the system can process more packets in a second than we expect to arrive in a second, the system will be in a state with less than 10 packets waiting in the queue for the whole time.",
        "original_sample_id": "smp0246q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0246q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "9 * 60 = 540 bundle arrive in 1 minute\n10 * 60 = 600 bundle can be processed in 1 minute\n\nbased on the supposal that the bundle arrive uniformly distributed in the minute (i.e. 9 bundle per second) and we can process 10 bundle per second, this means that the organisation is busy in 90 % of the time with processing the bundle. in 10 % of the time the organisation has no bundle to process. \nsince the organisation can process more bundle in a second than we expect to arrive in a second, the organisation will be in a state with less than 10 bundle waiting in the queue for the whole time.",
        "answer_feedback": "the description to justify the system waiting time is missing in the response. additionally, the system does not stay in a less than 10 packets state for a whole minute, only 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "9 * 60 = 540 packets arrive in 1 minute\n10 * 60 = 600 packets can be processed in 1 minute\n\nbased on the assumption that the packets arrive uniformly distributed in the minute (i.e. 9 packets per second) and we can process 10 packets per second, this means that the system is busy in 90 % of the time with processing the packets. in 10 % of the time the system has no packets to process. \nsince the system can process more packets in a second than we expect to arrive in a second, the system will be in a state with less than 10 packets waiting in the queue for the whole time.",
        "original_sample_id": "smp0246q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "An important feature of the fish distribution is that the probability of x taking a discrete value is independent of the previous values, i.e. the probability is independent of the past. Fish distribution is often used to model the arrival of packages over an interval. The arrival times of the package modelled by the fish distribution have an exponential distribution and constitute an independent process distributed identically. However, in practice, it has been shown that the arrival times of the package do not have exponential distribution, hence the error introduced by the modeling as a fish distribution is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in recitation it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug02smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in practice it has been express that the packet inter-arrival times do not have an exponential dispersion, hence the error infix by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug03smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "An important feature of the fish distribution is that the probability of x taking a discrete value is independent of the previous values, i.e. the probability is independent of the past. Fish distribution is often used to model the arrival of packages over an interval. The arrival times of the package modelled by the fish distribution have an exponential distribution and constitute an independent process distributed identically. However, in practice, it has been shown that the arrival times of the package do not have exponential distribution, hence the error introduced by the modeling as a fish distribution is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug04smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is sovereign upon the previous values i.e. the probability is sovereign of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and nominate an sovereign identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug05smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a distinct value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to mold arrival of packets during an interval. the packet arrival times molded by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by molding them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1023q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf: each sender has its own extension tree. a node receives a package. if you have reached the usual entry link, assume that the package has used the best route so far and forward over all borders (not including the incoming one). if the entries via another link will assume its duplicate and discard it (space tree). ensure a multicast loop-free forwarding as duplicates are discarded. rpf: works as rpf but with a specific selection of the outgoing links. optimizes the disadvantage of rpf forwarding over all borders. if the package arrives at the entry on which packages are sent for this station/source generally and the package uses the best route that sends packages only over appropriate borders, that is, selects the border from which packages arrive and from which they are redirected to the source in an inverted direction. also discards the purpose is the same as rpf, ensuring a free forwarding, but is more optimized and allows multiple shipping of the same package.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "rpf: each sender has its own spanning tree. a node receives a packet. if it has arrived at the usual entry link, it assumes the packet used the best route until now and resend over all edges (not including the incoming one). if it entries trough another link it will assume its a duplicate and discards it (spanning tree).  it ensures a loop-free forwarding of multicast packets as duplicates are discarded. rpf: it works like rpf but with a specific selection of the outgoing links. it optimizies the disadvantage of rpf of resending over all edges. if the packet arrived at the is entry over which the packets for this station/source are usually sent and the packet used the best route it forwards the packets only over suitable edges, i.e. it selects the the edge from which the packets arrived and from which they are then rerouted to the source in reversed direction. it also discards duplicates.  the purpose is the same as rpf, ensuring a loop free forwarding, but it is more optimized and doesn´t allow multiple sending of the same packet.",
        "original_sample_id": "smp1023q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1023q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf: each sender has its own extension tree. a node receives a package. if you have reached the usual entry link, assume that the package has used the best route so far and forward over all borders (not including the incoming one). if the entries via another link will assume its duplicate and discard it (space tree). ensure a multicast loop-free forwarding as duplicates are discarded. rpf: works as rpf but with a specific selection of the outgoing links. optimizes the disadvantage of rpf forwarding over all borders. if the package arrives at the entry on which packages are sent for this station/source generally and the package uses the best route that sends packages only over appropriate borders, that is, selects the border from which packages arrive and from which they are redirected to the source in an inverted direction. also discards the purpose is the same as rpf, ensuring a free forwarding, but is more optimized and allows multiple shipping of the same package.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "rpf: each sender has its own spanning tree. a node receives a packet. if it has arrived at the usual entry link, it assumes the packet used the best route until now and resend over all edges (not including the incoming one). if it entries trough another link it will assume its a duplicate and discards it (spanning tree).  it ensures a loop-free forwarding of multicast packets as duplicates are discarded. rpf: it works like rpf but with a specific selection of the outgoing links. it optimizies the disadvantage of rpf of resending over all edges. if the packet arrived at the is entry over which the packets for this station/source are usually sent and the packet used the best route it forwards the packets only over suitable edges, i.e. it selects the the edge from which the packets arrived and from which they are then rerouted to the source in reversed direction. it also discards duplicates.  the purpose is the same as rpf, ensuring a loop free forwarding, but it is more optimized and doesn´t allow multiple sending of the same packet.",
        "original_sample_id": "smp1023q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0366q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:\n(a,b, ahead)(a,c, ahead)(a,d, drop) => neither f nor c receive unicast packet via d\n\nskip 2:\n(b,e, ahead)(c,f, drop) => g does not receive unicast packet via f\n\nskip 3:\n(e, g, ahead)\n\nskip 4:\n(g, h, drop) => broadcast is finished",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b, forward)(a,c, forward)(a,d, drop) => neither f nor c receive unicast packets via d\n\nhop 2:\n(b,e, forward)(c,f, drop) => g does not receive unicast packets via f\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop) => broadcast is finished",
        "original_sample_id": "smp0366q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1020q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The objective of this relay routing algorithm is to reduce the amount of duplicates that go to the network while sending a relay package. Reverse route forwarding: a relay package will be forwarded at all edges (except the incoming border), only if the packet was received at the edge that would be used for a unicast package (faster/better route).This is to remove packages that come on a longer path. Reverse route relay: a forward packet will be forwarded only at the edges that are part of the best routes for unicast inverted to the sender.It is also true that a package is re-sent only if the package was received at the edge that would be used for a unicast package (faster/better route).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of these broadcast routing algorithm is to reduce the amount of duplicates going to the network while sending a broadcast packet. reverse path forwarding: a broadcast packet will be forwarded on all edges (except the incoming edge), only if the packet was received on the edge which would be used for a unicast packet (fastest/best route). this is to eliminate packets which are coming over a longer path. reverse path broadcast: a broadcast packet will be forwarded only on those edges which are part of the best routes for a reversed unicast to the sender. also it holds true that a packet is only forwarded if the packet was received on the edge which would be used for a unicast packet (fastest/best route).",
        "original_sample_id": "smp1020q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1020q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The objective of this relay routing algorithm is to reduce the amount of duplicates that go to the network while sending a relay package. Reverse route forwarding: a relay package will be forwarded at all edges (except the incoming border), only if the packet was received at the edge that would be used for a unicast package (faster/better route).This is to remove packages that come on a longer path. Reverse route relay: a forward packet will be forwarded only at the edges that are part of the best routes for unicast inverted to the sender.It is also true that a package is re-sent only if the package was received at the edge that would be used for a unicast package (faster/better route).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of these broadcast routing algorithm is to reduce the amount of duplicates going to the network while sending a broadcast packet. reverse path forwarding: a broadcast packet will be forwarded on all edges (except the incoming edge), only if the packet was received on the edge which would be used for a unicast packet (fastest/best route). this is to eliminate packets which are coming over a longer path. reverse path broadcast: a broadcast packet will be forwarded only on those edges which are part of the best routes for a reversed unicast to the sender. also it holds true that a packet is only forwarded if the packet was received on the edge which would be used for a unicast packet (fastest/best route).",
        "original_sample_id": "smp1020q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1088q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "This is favorable for transmission and multicasting because it limits the number of packages-copies and avoids loops. each is transmissions is local link status information periodically to all others is. the information is distributed in packets and contains the distance to neighbors as well as the information about multicast groups (each one knows which group it belongs to)! then each one is has all the link status information and calculates the multicast tree.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees allows to reach all other nodes of a network with a small subset of links. this is favorable for broadcasting and multicasting because it limits the number of packet-copies and prevents loops. each is broadcasts it’s local link state info periodically to all other is. the info is distributed in packets and contains the distance to the neighbors as well as the info on multicast groups (each is knows to which group it belongs to)! then each is has all the link state info and calculates the multicast tree.",
        "original_sample_id": "smp1088q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1088q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees allows to reach all other nodes of a network with a small subset of links. this is favorable for broadcasting and multicasting because it limits the number of packet-copies and prevents loops. each is broadcasts it’s local link state info periodically to all other is. the info is distributed in packets and contains the distance to the neighbors as well as the info on multicast radicals (each is knows to which radical it belong to)! then each is has all the link state info and calculates the multicast tree.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees allows to reach all other nodes of a network with a small subset of links. this is favorable for broadcasting and multicasting because it limits the number of packet-copies and prevents loops. each is broadcasts it’s local link state info periodically to all other is. the info is distributed in packets and contains the distance to the neighbors as well as the info on multicast groups (each is knows to which group it belongs to)! then each is has all the link state info and calculates the multicast tree.",
        "original_sample_id": "smp1088q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe datum from two side is about equal. the windowpane size should be smaller than a half of seq. number.",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a requirement is that we have a duplex connection and a cos or ccs. data from two sides is approximately equal.The size of the window must be less than half the number..",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a demand is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the windowpane size should be smaller than a half of seq. figure.",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a requirement is that we have a duplex connection and a cos or ccs. data from two sides is approximately equal.The size of the window must be less than half the number..",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe datum from two side is some equal. the windowpane size should be smaller than a half of seq. number.",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1661q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "for software: 0.0.0.0 - 0.255.255,255 used for local communications within a private network: 10.0.0 - 10.255,255,255 used for loopback addresses to the local host: 127.0.0 - 127.255,255,255 for the international shared public address space system for communications between a service provider: 100.64.0.0–100.127,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "for software: 0.0.0.0 - 0.255.255.255\nused for local communications within a private network: 10.0.0.0 - 10.255.255.255 \n\nused for loopback addresses to the local host: 127.0.0.0 - 127.255.255.255\n\nfor international system of public \n\nshared address space for communications between a service provider： 100.64.0.0–100.127.255.255",
        "original_sample_id": "smp1661q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can estimate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 mailboat is 1-pb. based on the 1 minute monitoring time we can get the consequence 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. accord to the limited fender size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. establish on the 1 minute monitoring time we can get the result 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s the average rate of arrival is 9 and the average rate of service is 10. depending on the limited size of buffer 10 we can calculate pb, which means the probability that the system is full. so the probability that there are less than 10 packages is 1-bp. based on the 1 minute monitoring time we can get the result 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1025q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The two principles work on the same basis: each router has the information on the path that he would use for a unicast transmission. the sender then starts to broadcast a package to all his connected neighbours. the neighbouring routers then determine, if the incoming package used the best route to reach it. the best route in this case, is the one that you would normally use in a unicast transmission. if the incoming package did not take the best route, it is rejected as it is most likely a copy. if he took the best route the router advances the package. at this point, the reverse route and the reverse transmission of the path differ from each other: rpf: if the package used the best route, the router returns the message to all the edges, without including the one from which the message comes. rpb: if the package used the best route, the router turns the message back to those edges that would be the best route.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. the purpose of reverse path forwarding and reverse path broadcast is not limited to multicasting but also used in broadcasting.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcasting is done, to find the shortest way to each recipient of a multicast message while minimizing the amount of copies sent in a network.  both principles work on the same foundation:  each router has the information which path it would use for a unicast transmission. the sender then starts to broadcast a package to all its connected neighbors. the neighboring routers then determine, whether the incoming package has used the best route to reach him. the best route in this case, is the one you would normally use in a unicast transmission.  if the incoming package has not taken the best route, it is discarded as it is most likely a copy.   if it has taken the best route the router forwards the package.  at this point reverse path forwarding and reverse path broadcasting differ from each other: rpf: if the package has used the best route, the router resends the message to all edges, not including the one from which the message came from.  rpb: if the package has used the best route, the router resends the message to those edges over which it would be the best route.",
        "original_sample_id": "smp1025q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1025q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The two principles work on the same basis: each router has the information on the path that he would use for a unicast transmission. the sender then starts to broadcast a package to all his connected neighbours. the neighbouring routers then determine, if the incoming package used the best route to reach it. the best route in this case, is the one that you would normally use in a unicast transmission. if the incoming package did not take the best route, it is rejected as it is most likely a copy. if he took the best route the router advances the package. at this point, the reverse route and the reverse transmission of the path differ from each other: rpf: if the package used the best route, the router returns the message to all the edges, without including the one from which the message comes. rpb: if the package used the best route, the router turns the message back to those edges that would be the best route.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. the purpose of reverse path forwarding and reverse path broadcast is not limited to multicasting but also used in broadcasting.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcasting is done, to find the shortest way to each recipient of a multicast message while minimizing the amount of copies sent in a network.  both principles work on the same foundation:  each router has the information which path it would use for a unicast transmission. the sender then starts to broadcast a package to all its connected neighbors. the neighboring routers then determine, whether the incoming package has used the best route to reach him. the best route in this case, is the one you would normally use in a unicast transmission.  if the incoming package has not taken the best route, it is discarded as it is most likely a copy.   if it has taken the best route the router forwards the package.  at this point reverse path forwarding and reverse path broadcasting differ from each other: rpf: if the package has used the best route, the router resends the message to all edges, not including the one from which the message came from.  rpb: if the package has used the best route, the router resends the message to those edges over which it would be the best route.",
        "original_sample_id": "smp1025q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1648q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 --> this host 127.(all) --> loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 --> this host\n127.(anything) --> loopback",
        "original_sample_id": "smp1648q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each sender has its own cross tree but is do not involve to know the cross trees each router has entropy which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own traverse tree but is do not need to know the traverse trees each router has information which path it would expend for (unicast)-packets becaexpend of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug02smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own cross tree but is do not demand to know the cross trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug03smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own cross tree but is do not need to fuck the cross trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug04smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own spanning tree but is do not need to bonk the spanning trees each router has information which way it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug05smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each sender has its own traverse tree but is do not want to screw the traverse trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug06smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each sender has its own sweep tree but is do not need to know the sweep tree each router has information which way it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug07smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own cross tree but is do not need to know the cross trees each router has information which path it would habituate for (unicast)-packets becahabituate of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1491q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the sender fender has to be large enough to keep all sent frames until the other party sends a frame and implicitly acknowledges the reception of these previous frames. besides, the forcible channel has to allow duplex communication.",
        "answer_feedback": "the response answers the piggybacking extension requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the sender buffer has to be large enough to keep all sent frames until the other party sends a frame and implicitly acknowledges the receipt of these previous frames. besides, the physical channel has to allow duplex communication.",
        "original_sample_id": "smp1491q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0790q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp: 1. Shipping port identification is optional 2. Package length is only 8 bytes 3. checksum is optional 4. no sequence and acknowledgement number tcp: 1. Shipping port and receiving port are mandatory 2. Package length can vary from 20 to 80 bytes 3. Checksum is mandatory 4. has sequence and acknowledgement number of receipt",
        "answer_feedback": "the header length not packet length of udp is 8 bytes, and that of tcp ranges from 20 to 60 bytes, not 80 bytes. the other three differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "udp:\n1. sender port identification is optional\n2. packet length is only 8 bytes\n3. checksum is optional\n4. no sequence and acknowledgement number\n\ntcp:\n1. sender port and receiver port are mandatory\n2. packet length can vary between 20 to 80 bytes\n3. checksum is mandatory\n4. has sequence and acknowledgement number",
        "original_sample_id": "smp0790q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0790q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp: 1. Shipping port identification is optional 2. Package length is only 8 bytes 3. checksum is optional 4. no sequence and acknowledgement number tcp: 1. Shipping port and receiving port are mandatory 2. Package length can vary from 20 to 80 bytes 3. Checksum is mandatory 4. has sequence and acknowledgement number of receipt",
        "answer_feedback": "the header length not packet length of udp is 8 bytes, and that of tcp ranges from 20 to 60 bytes, not 80 bytes. the other three differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "udp:\n1. sender port identification is optional\n2. packet length is only 8 bytes\n3. checksum is optional\n4. no sequence and acknowledgement number\n\ntcp:\n1. sender port and receiver port are mandatory\n2. packet length can vary between 20 to 80 bytes\n3. checksum is mandatory\n4. has sequence and acknowledgement number",
        "original_sample_id": "smp0790q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0790q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp: 1. Shipping port identification is optional 2. Package length is only 8 bytes 3. checksum is optional 4. no sequence and acknowledgement number tcp: 1. Shipping port and receiving port are mandatory 2. Package length can vary from 20 to 80 bytes 3. Checksum is mandatory 4. has sequence and acknowledgement number of receipt",
        "answer_feedback": "the header length not packet length of udp is 8 bytes, and that of tcp ranges from 20 to 60 bytes, not 80 bytes. the other three differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "udp:\n1. sender port identification is optional\n2. packet length is only 8 bytes\n3. checksum is optional\n4. no sequence and acknowledgement number\n\ntcp:\n1. sender port and receiver port are mandatory\n2. packet length can vary between 20 to 80 bytes\n3. checksum is mandatory\n4. has sequence and acknowledgement number",
        "original_sample_id": "smp0790q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0790q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp:\n1. sender embrasure identification is optional\n2. mailboat length is only 8 bytes\n3. checksum is optional\n4. no sequence and acknowledgement number\n\ntcp:\n1. sender embrasure and receiver embrasure are required\n2. mailboat length can vary between 20 to 80 bytes\n3. checksum is required\n4. has sequence and acknowledgement number",
        "answer_feedback": "the header length not packet length of udp is 8 bytes, and that of tcp ranges from 20 to 60 bytes, not 80 bytes. the other three differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "udp:\n1. sender port identification is optional\n2. packet length is only 8 bytes\n3. checksum is optional\n4. no sequence and acknowledgement number\n\ntcp:\n1. sender port and receiver port are mandatory\n2. packet length can vary between 20 to 80 bytes\n3. checksum is mandatory\n4. has sequence and acknowledgement number",
        "original_sample_id": "smp0790q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1651q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/8 10.00.0/8 100.64.0.0/10 127.0.0.0.8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n100.64.0.0/10\n127.0.0.0/8",
        "original_sample_id": "smp1651q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1499q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the communicating system must operate in full-duplex modality for using piggybacking in the slither window protocol.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the communication system must operate in full-duplex mode for using piggybacking in the sliding window protocol.",
        "original_sample_id": "smp1499q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1628q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 10.0.0 127.0.0.0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n10.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1628q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1628q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 10.0.0 127.0.0.0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n10.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1628q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1656q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 - 0.255.255.255 earmark for current host or meshwork\n\n10.0.0.0 - 10.255.255.255 earmark for individual (sub)net\n\n127.0.0.0 - 127.255.255.255 earmark for localhost (loopback)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 - 0.255.255.255 reserved for current host or network\n\n10.0.0.0 - 10.255.255.255 reserved for private (sub)net\n\n127.0.0.0 - 127.255.255.255 reserved for localhost (loopback)",
        "original_sample_id": "smp1656q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0776q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb's are not fair. client in the middle are more likely to achieve access to datum then outer client. so loveliness is the problem with dqdb's.",
        "answer_feedback": "the response is partially correct. stations located near the frame generator have a higher probability of reserving transmission rights than the middle stations. stations located in the middle may have a 50% chance of transmission rights reservation. the advantage/disadvantage depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve access to data then outer nodes. so fairness is the problem with dqdb's.",
        "original_sample_id": "smp0776q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0776q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb's are not honest. client in the middle are more likely to accomplish access to data then outer client. so honestness is the problem with dqdb's.",
        "answer_feedback": "the response is partially correct. stations located near the frame generator have a higher probability of reserving transmission rights than the middle stations. stations located in the middle may have a 50% chance of transmission rights reservation. the advantage/disadvantage depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve access to data then outer nodes. so fairness is the problem with dqdb's.",
        "original_sample_id": "smp0776q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0776q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb's are not fair. nodes in the midriff are more likely to achieve access to data then tabu nodes. so fairness is the trouble with dqdb's.",
        "answer_feedback": "the response is partially correct. stations located near the frame generator have a higher probability of reserving transmission rights than the middle stations. stations located in the middle may have a 50% chance of transmission rights reservation. the advantage/disadvantage depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve access to data then outer nodes. so fairness is the problem with dqdb's.",
        "original_sample_id": "smp0776q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0776q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve admission to datum then outer nodes. so candour is the problem with dqdb's.",
        "answer_feedback": "the response is partially correct. stations located near the frame generator have a higher probability of reserving transmission rights than the middle stations. stations located in the middle may have a 50% chance of transmission rights reservation. the advantage/disadvantage depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve access to data then outer nodes. so fairness is the problem with dqdb's.",
        "original_sample_id": "smp0776q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0776q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve entree to data then stunned nodes. so candor is the problem with dqdb's.",
        "answer_feedback": "the response is partially correct. stations located near the frame generator have a higher probability of reserving transmission rights than the middle stations. stations located in the middle may have a 50% chance of transmission rights reservation. the advantage/disadvantage depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "dqdb's are not fair. nodes in the middle are more likely to achieve access to data then outer nodes. so fairness is the problem with dqdb's.",
        "original_sample_id": "smp0776q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1040q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path program aim to reduce the number of mailboat copies in the network. in reverse path forwarding, a node forwards a mailboat if the mailboat used the entry over which the mailboats for the source would be sent. this means, if the mailboat used the best-known route, the node then forwards to all edges, except the incoming one.   in reverse path program, a node forwards a mailboat if the mailboat arrived at the is entry over which the mailboats would be sent to the source station (used the best-known route). if the mailboat arrived on the best-known route, the node forwards the mailboat to selected edges: the edges used to reroute on the reverse direction to the source. example of rpb: if a node a is not in the best-known route from b to c, then a will not forward a mailboat to b when the mailboat source is c.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms including their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast aim to reduce the number of packet copies in the network. in reverse path forwarding, a node forwards a packet if the packet used the entry over which the packets for the source would be sent. this means, if the packet used the best-known route, the node then forwards to all edges, except the incoming one.   in reverse path broadcast, a node forwards a packet if the packet arrived at the is entry over which the packets would be sent to the source station (used the best-known route). if the packet arrived on the best-known route, the node forwards the packet to selected edges: the edges used to reroute on the reverse direction to the source. example of rpb: if a node a is not in the best-known route from b to c, then a will not forward a packet to b when the packet source is c.",
        "original_sample_id": "smp1040q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1040q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path broadcast aim to reduce the issue of packet copies in the network. in reverse path forwarding, a knob forwards a packet if the packet used the entry over which the packets for the source would be sent. this means, if the packet used the best-known route, the knob then forwards to all border, except the incoming one.   in reverse path broadcast, a knob forwards a packet if the packet arrived at the is entry over which the packets would be sent to the source station (used the best-known route). if the packet arrived on the best-known route, the knob forwards the packet to selected border: the border used to reroute on the reverse direction to the source. example of rpb: if a knob a is not in the best-known route from b to c, then a will not forward a packet to b when the packet source is c.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms including their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast aim to reduce the number of packet copies in the network. in reverse path forwarding, a node forwards a packet if the packet used the entry over which the packets for the source would be sent. this means, if the packet used the best-known route, the node then forwards to all edges, except the incoming one.   in reverse path broadcast, a node forwards a packet if the packet arrived at the is entry over which the packets would be sent to the source station (used the best-known route). if the packet arrived on the best-known route, the node forwards the packet to selected edges: the edges used to reroute on the reverse direction to the source. example of rpb: if a node a is not in the best-known route from b to c, then a will not forward a packet to b when the packet source is c.",
        "original_sample_id": "smp1040q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1687q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 10.00.0",
        "answer_feedback": "missing loopback and ranges",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0\n10.0.0.0",
        "original_sample_id": "smp1687q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0814q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp header has the following battleground which are not part of the udp header: \n1. sequence number\n2. acknowledgement number\n3. promote window\n4. urgent arrow",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp header has the following fields which are not part of the udp header: \n1. sequence number\n2. acknowledgement number\n3. advertised window\n4. urgent pointer",
        "original_sample_id": "smp0814q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0370q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (a, b, forward) (a, c, forward) (a, d, drop) The package cannot be forwarded to the next node hop 2: (b, e, forward) (c, f, drop) The package cannot be forwarded to the next node hop 3: (e, g, forward) hop 4: (g, h, drop) < = the package cannot be forwarded to the next node",
        "answer_feedback": "the reasoning is not complete as it does not state why the packet is not forwarded.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= the packet can't be forwarded to next node\nhop 2:\n(b, e, forward)\n(c, f, drop) <= the packet can't be forwarded to next node\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= the packet can't be forwarded to next node",
        "original_sample_id": "smp0370q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1106q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The extension tree creates a subset of all subnets while including all routers. there are also no loops present in extension trees. in case of link status routing, the whole is sends packets containing distance to neighbors to all other nodes. after which a multicast tree is calculated locally through this information, it is decided where to transmit the packets and what route to take.",
        "answer_feedback": "the response correctly identifies the appealing property of a spanning tree for broadcast and multicast. the modification of the link state algorithm for constructing spanning trees does not explain how each node shares its multicast information with others by adding it to the link-state packet. this leads to each node having complete information to build a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning tree creates a subset of all the subnets while including all the routers. also there are no loops present in spanning trees. in case of link state routing, all the is sends packets containing distance to neighbours to all other nodes. after which the is locally calculates a multicast tree through this information, the is decides as to where to transmit the packets and which route should be taken.",
        "original_sample_id": "smp1106q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0211q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. determine the queue model (kendall notation) - medium arrival and service → arrival process and service distributed exponentially → a=b=m - single server → c=1 - tail length (system offers space for up to 10 \"customers\")→ d=10",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. determine queuing model (kendall's notation)\n- average arrival and service → exponentially distributed arrival and service process → a=b=m\n- single-server → c=1\n- queue length (system provides room for up to 10 \"customers\")→ d=10\n⇒ m/m/1/10\n\n2. calculate utilisation\n\narrival rate λ = 9 packets per second\nservice rate µ = 10 packets per second\n\nutilisation ρ = λ/µ = 9/10 = 0.9\n\n3. calculate probability of system being in requested state:\nthe requirement of having less than 10 packets in the queue is equivalent to the system not being blocked (full) because of d=n=10. since the distribution is memoryless and we've reached equilibrium, the probability that the system is in a certain state does not depend on the time.\nwe have a finite queue, so there is a finite set of not-blocking states plus one blocking state.\n\nas n=10, we need to calculate p[blocking] = p_n = p_10 = ( (1-ρ)/ρ^10 ) / ( 1-ρ^(10+1) ) = 0.05081.\nit follows that p[not blocking] = 1 - p[blocking] = 0.94919.\n\n4. calculate time of system being in required state (less than 10 packets):\nas we're monitoring the system for 60s after the system reaches equilibrium, we can expect the system to be in a state where it is not full in those 60 seconds with a probability of p[not blocking]. it follows that we can expect this state for 60s * p[not blocking] = 56.95 seconds.",
        "original_sample_id": "smp0211q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0211q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. determine the queue model (kendall notation) - medium arrival and service → arrival process and service distributed exponentially → a=b=m - single server → c=1 - tail length (system offers space for up to 10 \"customers\")→ d=10",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. determine queuing model (kendall's notation)\n- average arrival and service → exponentially distributed arrival and service process → a=b=m\n- single-server → c=1\n- queue length (system provides room for up to 10 \"customers\")→ d=10\n⇒ m/m/1/10\n\n2. calculate utilisation\n\narrival rate λ = 9 packets per second\nservice rate µ = 10 packets per second\n\nutilisation ρ = λ/µ = 9/10 = 0.9\n\n3. calculate probability of system being in requested state:\nthe requirement of having less than 10 packets in the queue is equivalent to the system not being blocked (full) because of d=n=10. since the distribution is memoryless and we've reached equilibrium, the probability that the system is in a certain state does not depend on the time.\nwe have a finite queue, so there is a finite set of not-blocking states plus one blocking state.\n\nas n=10, we need to calculate p[blocking] = p_n = p_10 = ( (1-ρ)/ρ^10 ) / ( 1-ρ^(10+1) ) = 0.05081.\nit follows that p[not blocking] = 1 - p[blocking] = 0.94919.\n\n4. calculate time of system being in required state (less than 10 packets):\nas we're monitoring the system for 60s after the system reaches equilibrium, we can expect the system to be in a state where it is not full in those 60 seconds with a probability of p[not blocking]. it follows that we can expect this state for 60s * p[not blocking] = 56.95 seconds.",
        "original_sample_id": "smp0211q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0923q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table within the span holds the mac adresses of the members in the system. based on this table and the destination adress, the span decides in the forwarding process to what port it passes the incoming packets on. in addition, the span checks all packets and forwards only correct ones. an other advantage is, that spans divide and stucture the meshwork (-> increases reliability). the span receives any frame on any of its lans so the span can update its initially empty table. this is called the learning phase: if it receives frames from a specific source adress on a specific lan, the span learns that this source adress can be reached over this lan and stores this entropy in the table. if there is no entry in the table yet, flooding is used.",
        "answer_feedback": "the table holds the station's address, lan/port, and the timestamp only for stations a packet has been received, not for all the system members. the stated benefit is incorrect as the question asked for the benefit derived from using the bridge table based forwarding, not merely about using bridges. the remaining response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the table within the bridge holds the mac adresses of the members in the system. based on this table and the destination adress, the bridge decides in the forwarding process to what port it passes the incoming packets on. in addition, the bridge checks all packets and forwards only correct ones. an other advantage is, that bridges divide and stucture the network (-> increases reliability). the bridge receives any frame on any of its lans so the bridge can update its initially empty table. this is called the learning phase: if it receives frames from a specific source adress on a specific lan, the bridge learns that this source adress can be reached over this lan and stores this information in the table. if there is no entry in the table yet, flooding is used.",
        "original_sample_id": "smp0923q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0881q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, let’s suppose we have a server that hosts voip(voice over ip) services. if the server had a high amount of arrivals* (of packets) in the previous separation, it is more probable to have a similar amount of arrivals in the upcoming separation as the calls in the previous separation are still ongoing(unless the call has ended). same goes for the other way around. if the previous separation did not have a lot of traffic coming through it is more probable that the upcoming separation also does not have a lot of traffic incoming(unless a lot of calls starts on the separation change). thus each separation has some sort of dependency to the previous one(s).\n\n* incoming packets of ongoing calls",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, let’s suppose we have a server that hosts voip(voice over ip) services. if the server had a high amount of arrivals* (of packets) in the previous interval, it is more likely to have a similar amount of arrivals in the upcoming interval as the calls in the previous interval are still ongoing(unless the call has ended). same goes for the other way around. if the previous interval did not have a lot of traffic coming through it is more likely that the upcoming interval also does not have a lot of traffic incoming(unless a lot of calls starts on the interval change). thus each interval has some sort of dependency to the previous one(s).\n\n* incoming packets of ongoing calls",
        "original_sample_id": "smp0881q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1017q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective is to ensure a free rotation of the multicast packages. Inverse return: when the package arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have sent the package on all the edges except the incoming edge. If this is not the case, we have excluded the package, because it is probably a double. Inverse forwarding: when the packet arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have checked whether the package used the best route so far. If this is the best route we have chosen the edge on which the packets arrived and from which they are redirected to the station. if this is not the best route contrary to rpf we have not sent the package on all the edges. when the packet did not arrive at the entrance we have excluded the package because it is probably a double.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types except that the purpose is not limited to only mutlicast but also used in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to ensure a loop-free forwarding of multicast packets. reverse path forwarding: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we resend the packet over all edges except the incoming edge. if thats not the case we discard the packe, because its probably a duplicate. reverse path broadcast: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we check if the packet used the best route until now. if its the best route we select the edge at which the packets arrived and from which they are then rerouted to the station. if its not the best route on the contrary to rpf we don't send the packet over all edges. when the packet didn't arrive at the is entry we discard the packet, because its probably a duplicate.",
        "original_sample_id": "smp1017q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1017q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective is to ensure a free rotation of the multicast packages. Inverse return: when the package arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have sent the package on all the edges except the incoming edge. If this is not the case, we have excluded the package, because it is probably a double. Inverse forwarding: when the packet arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have checked whether the package used the best route so far. If this is the best route we have chosen the edge on which the packets arrived and from which they are redirected to the station. if this is not the best route contrary to rpf we have not sent the package on all the edges. when the packet did not arrive at the entrance we have excluded the package because it is probably a double.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types except that the purpose is not limited to only mutlicast but also used in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to ensure a loop-free forwarding of multicast packets. reverse path forwarding: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we resend the packet over all edges except the incoming edge. if thats not the case we discard the packe, because its probably a duplicate. reverse path broadcast: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we check if the packet used the best route until now. if its the best route we select the edge at which the packets arrived and from which they are then rerouted to the station. if its not the best route on the contrary to rpf we don't send the packet over all edges. when the packet didn't arrive at the is entry we discard the packet, because its probably a duplicate.",
        "original_sample_id": "smp1017q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0360q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, onwards); (a, c, onwards); (a, d, onwards).\nhop 2:\n(b, e, onwards);  (b, c, pearl) from a to  c ,via b is not the unretentive; \n(c, b, pearl),from a to b ,via c is not the unretentive; (c, d, pearl), from a to d ,via c is not the unretentive; (c, e, pearl), from a to e ,via c is not the unretentive; \n(c, f,  onwards).  \n(d, c, pearl) ,from a to c ,via d is not the unretentive; (d, f, pearl) ,from a to f ,via d is not the unretentive.\nhop 3:\n(e, c, pearl), from a to c ,via e is not the unretentive; (e, f, pearl), from a to f ,via e is not the unretentive; (e, g, onwards).",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward); (a, c, forward); (a, d, forward).\nhop 2:\n(b, e, forward);  (b, c, drop) from a to  c ,via b is not the shortest; \n(c, b, drop),from a to b ,via c is not the shortest; (c, d, drop), from a to d ,via c is not the shortest; (c, e, drop), from a to e ,via c is not the shortest; \n(c, f,  forward).  \n(d, c, drop) ,from a to c ,via d is not the shortest; (d, f, drop) ,from a to f ,via d is not the shortest.\nhop 3:\n(e, c, drop), from a to c ,via e is not the shortest; (e, f, drop), from a to f ,via e is not the shortest; (e, g, forward).",
        "original_sample_id": "smp0360q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0838q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the network load varies. for exemplar look on time and day there may be more or less traffic (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of traffic: for exemplar some video streaming applications produce a bursty traffic, if they buffer the video to some extend (which means continous traffic load), pause after the buffer is full (no load), and then continue after a certain buffer threshold.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the network load varies. for example depending on time and day there may be more or less traffic (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of traffic: for example some video streaming applications produce a bursty traffic, if they buffer the video to some extend (which means continous traffic load), pause after the buffer is full (no load), and then continue after a certain buffer threshold.",
        "original_sample_id": "smp0838q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0838q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the network load varies. for example depending on time and day there may be more or less dealings (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of dealings: for example some television streaming applications produce a bursty dealings, if they buffer the television to some extend (which means continous dealings load), pause after the buffer is full (no load), and then uphold after a certain buffer threshold.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the network load varies. for example depending on time and day there may be more or less traffic (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of traffic: for example some video streaming applications produce a bursty traffic, if they buffer the video to some extend (which means continous traffic load), pause after the buffer is full (no load), and then continue after a certain buffer threshold.",
        "original_sample_id": "smp0838q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1536q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Therefore, instead of sending separate packages, ack packages can be tied to a frame. on the way back it has to be directed to which package is being directed with the ack. so it is necessary to have a duplex operation and a specifier indicating what/how many frames are recognized with the ack.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking is characterized by a duplex operation where both sides of the transmission can send data as well as ack packets. therefore, instead of sending separate packets, the ack packets can be tied to a frame. on the way back it has to be addressed which packet you are addressing with the ack.\nso it is required to have a duplex operation and a specifier who indicates which/how many frames get acknowledged with the ack",
        "original_sample_id": "smp1536q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0356q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a,b, go ahead)(a,c, go ahead)(a,d, fall) $ = d receives the package, but does not send it to c or f hop 2:(b,e, go ahead) (c,f, fall) $ = f receives the package, but does not send it hop 3:(e,g, go ahead) hop 4 (g,h, fall) $ = h receives the package, but does not forward it, since there is no other neighbor node (except g, but this received the package)",
        "answer_feedback": "the response needs to state why d or f does not forward the packet, the remaining part is correct.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop 1:\n(a,b, forward)(a,c, forward)(a,d, drop) <= d receives the packet, but doesn't forward it to c or f\n\nhop 2:(b,e, forward)(c,f, drop) <= f  receives the packet, but doesnt forward it\nhop 3:(e,g, forward)\nhop 4\n(g,h, drop) <= h  receives the packet, but doesn't forward it, since there is no other neighbor node left (except g, but this he received the packet)",
        "original_sample_id": "smp0356q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0816q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- udp admit the packet length in the cope while tcp doesnt - tcp admit a ack number in the cope, while udp doesnt - tcp admit additional tcp options in the cope, while udp doesnt have additional options (in the cope) - tcp admit 8 bite of flags, while udp doesnt",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- udp includes the packet length in the header while tcp doesnt - tcp includes a ack number in the header, while udp doesnt - tcp includes additional tcp options in the header, while udp doesnt have additional options (in the header) - tcp includes 8 bit of flags, while udp doesnt",
        "original_sample_id": "smp0816q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "not confirmed without connection: transmission of isolated and independent data units. confirmed without connection: receipt of data units must be recognised by the receiver. orientated connection: transmission of data units is carried out in free, predefined channels.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unsupport connectionless: transmission of insulate, independent data units. \nsupport connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined line.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "not confirmed without connection: transmission of isolated and independent data units. confirmed without connection: receipt of data units must be recognised by the receiver. orientated connection: transmission of data units is carried out in free, predefined channels.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed joiningless: transmission of isolated, sovereign data units. \nconfirmed joiningless: receipt of data units need to be acknowledged by receiver. \njoining oriented: transmission of data units is performed in free, pre-defined channels.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "not confirmed without connection: transmission of isolated and independent data units. confirmed without connection: receipt of data units must be recognised by the receiver. orientated connection: transmission of data units is carried out in free, predefined channels.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0652q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "not confirmed without connection: transmission of isolated and independent data units. confirmed without connection: receipt of data units must be recognised by the receiver. orientated connection: transmission of data units is carried out in free, predefined channels.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless: transmission of isolated, independent data units. \nconfirmed connectionless: receipt of data units needs to be acknowledged by receiver. \nconnection oriented: transmission of data units is performed in free, pre-defined channels.",
        "original_sample_id": "smp0652q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0828q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header is shorter than the tcp header. the udp header has the sender port, the receiving port, the package length and the check sum. the tcp header also has a sender port, the destination port, and the check sum, but it does not have a package length. it also has a sequence number, recognition number, data compensation, a \"reserved\" field, control windows, the urgent pointer and a choice field. in other words, both protocols make use of different types of headers to transmit their data. the udp headers contain information only about the required functions and therefore are 8 bytes in length. the tcp headers contain mandatory and optional features resulting in 20 bytes and 60 bytes (heading allows up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tap. tcp headers cannot guarantee the delivery of data and 60 bytes (heading allows up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tap. the tcp headers cannot guarantee the delivery of data and 60 bytes (heading up to 40 bytes for options).",
        "answer_feedback": "the response is correct, but apart from the differences between the tcp and udp headers, it also contains general differences between the two transport layer protocols, which were not required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header is shorter than the tcp header. the udp header has the sender port, receiver port, packet length, and checksum. the tcp header also has a sender port, destination port, and the checksum but doesnt have a packet length. it also has a sequence number, acknowledgment number, the data offset, a \"reserved\" field, control fields, receive windows, the urgent pointer, and a field for options. in other words, both protocols make use of different types of headers to transmit their data. udp headers contain information only about the necessary functions and are therefore 8 bytes in length. tcp headers contain both mandatory and optional features resulting in 20 bytes and 60 bytes (header allows for up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tcp. it cannot guarantee the delivery of the data, and the packets can get lost or corrupt. tcp, on the other hand, tracks and error-checks its streams of data and is therefore reliable. because udp has only limited functions and doesnt perform many features such as error correction, it is faster than tcp. further, tcp can handle flow control, whereas udp doesnt have the required option.",
        "original_sample_id": "smp0828q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0831q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp has has sequence issue, udp does not\n\nthere are acknowledgment issue in tcp \n\ntcp has a advertisemed win header\n\ntcp has a urgent arrow",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp has has sequence numbers, udp does not\n\nthere are acknowledgement numbers in tcp \n\ntcp has a advertisemed win header\n\ntcp has a urgent pointer",
        "original_sample_id": "smp0831q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0854q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the arriver are dependent from each other in terms of network state. for example, if a link go, the likelihood that the next bundle will not arrive is high if the last sent bundle also did not. reason for that is that in this case the link failure prevented the last bundle from arriving and it is likely that the next bundle will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the given example may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the arrivals are dependent from each other in terms of network state. for example, if a link fails, the likelihood that the next packet will not arrive is high if the last sent packet also did not. reason for that is that in this case the link failure prevented the last packet from arriving and it is likely that the next packet will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "original_sample_id": "smp0854q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0854q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the arrivals are dependent on each other in terms of network status. e.g., if a link fails, the probability that the next package will not arrive is high if the last package sent does not have it either. reason why in this case the link failure prevented the last package from arriving and it is likely that the next package will take the same route. therefore, it would probably also be abandoned at this failed link. even applies to the complete nodes buffers located on a road.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the given example may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the arrivals are dependent from each other in terms of network state. for example, if a link fails, the likelihood that the next packet will not arrive is high if the last sent packet also did not. reason for that is that in this case the link failure prevented the last packet from arriving and it is likely that the next packet will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "original_sample_id": "smp0854q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0344q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "Hops 1: (a, b, below) (a, c, below) (a, d, fall) shorter road to f is through c and c can be reached directly from hops 2: (c, f, fall) shorter road to e is through b and g through e (b, e, below) hops 3: (e, g, below) hops 4: (g, h, fall) < = one neighbour",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1: \n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= shortest path to f is via c and c can be reached directly from a\nhop 2:\n(c, f, drop) <= shortest path to e is via b and to g via e\n(b, e, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= only one neighbor",
        "original_sample_id": "smp0344q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0930q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "a bridge table holds the information about how to reach the specific station through attached lans\n\nif the bridge receives a frame on a attached lan, then it knows this lan can reach the generator station of this frame. if generator and terminus lans are the same,bridges will drop the frame. if they are different, frame will be rerouted to terminus lan. if it doesn't know the terminus lan, it will use flooding.\n\nbenefit: increase reliability:connect lans via various bridges in parallel.",
        "answer_feedback": "the response incorrectly mentions the benefit of using multiple transparent bridges but the question asked for the benefit of using bridging information in forwarding frames. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a bridge table holds the information about how to reach the specific station through connected lans\n\nif the bridge receives a frame on a connected lan, then it knows this lan can reach the source station of this frame. if source and destination lans are the same,bridges will drop the frame. if they are different, frame will be rerouted to destination lan. if it doesn't know the destination lan, it will use flooding.\n\nbenefit: increase reliability:connect lans via various bridges in parallel.",
        "original_sample_id": "smp0930q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0782q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "In an upp header, the use of checksum is optional, while in a tcp header it is necessary to checksum. upp headers contain package length, tcp headers do not. tcp headers contain sequence numbers so that packages can be sorted correctly. upp headers do not guarantee delivery in order. tcp headers containack numbers, to ensure delivery, udp does not guarantee delivery of packages.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in a udp header, use of checksum is optional, whereas in a tcp header checksum is required. udp headers contain packet length, tcp headers dont. tcp headers contain sequence numbers so that packets can be ordered correctly. udp headers dont guarantee delivery in order. tcp headers contain ack numbers, to ensure delivery, udp does not ensure delivery of packets.",
        "original_sample_id": "smp0782q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1676q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 10.0.0.8 100.64.0.0/10 127.0.0.0/8 (source: https://en.wikipedia.org/wiki/ reserved_ip_directions)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n100.64.0.0/10\n127.0.0.0/8\n\n(source: https://en.wikipedia.org/wiki/reserved_ip_addresses)",
        "original_sample_id": "smp1676q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1519q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it has to be a duplex surgery, that data and acks are sent in both directions between sender and receiver, and figure may comprise implicit acks.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "it has to be a duplex operation, that data and acks are sent in both directions between sender and receiver, and frames may contain implicit acks.",
        "original_sample_id": "smp1519q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1494q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "in order to be capable to use the piggybacking wing you need to make sure that you can broadcast data both ways at the same time via duplex.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in order to be able to use the piggybacking extension you need to make sure that you can send data both ways at the same time via duplex.",
        "original_sample_id": "smp1494q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1645q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 (default path, or this server)\n127.0.0.0 (loopback mapping)",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0 (default route, or this host)\n127.0.0.0 (loopback function)",
        "original_sample_id": "smp1645q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1645q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 (default road, or this legion)\n127.0.0.0 (loopback purpose)",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0 (default route, or this host)\n127.0.0.0 (loopback function)",
        "original_sample_id": "smp1645q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diam is the aloofness between two locations/nodes. when increasing the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug01smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision field diam is the distance between two locations/knob. when increasing the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug02smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to squinch.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug03smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the distance between two locations/nodes. when increasing the speed the maximal distance between two locations has to recoil.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug04smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/node. when increasing the speed the maximum distance between two locations has to cringe.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug05smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localisation/nodes. when increase the speed the maximum distance between two localisation has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug06smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision sphere diameter is the distance between two locations/node. when increasing the speed the maximal distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug07smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/nodes. when increasing the speed the maximal distance between two locations has to recoil.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug08smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two emplacement/nodes. when increasing the amphetamine the maximal distance between two emplacement has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug09smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the aloofness between two locations/nodes. when increasing the speed the maximal aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug10smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/thickening. when increasing the hurrying the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug11smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the space between two locations/nodes. when increasing the speed the maximum space between two locations has to cringe.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug12smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug13smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug14smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the distance between two locations/nodes. when increasing the upper the maximal distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug15smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the length between two locations/thickening. when increasing the speed the maximum length between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug16smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the space between two locations/nodes. when increase the speed the maximum space between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug17smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the space between two locations/nodes. when increasing the amphetamine the maximum space between two locations has to reduce.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug18smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two location/nodes. when increasing the swiftness the maximum distance between two location has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug19smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/nodes. when increasing the speed the maximal distance between two locations has to wither.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug20smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision land diam is the distance between two location/nodes. when increasing the speed the maximum distance between two location has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug21smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increasing the speed the maximum aloofness between two locations has to wither.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug22smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the aloofness between two locations/knob. when increasing the speed the maximal aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug23smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two locations/knob. when increase the swiftness the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug24smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision area diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug25smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug26smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to quail.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug27smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug28smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision orbit diameter is the space between two location/nodes. when increasing the speed the maximum space between two location has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug29smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug30smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two location/nodes. when increasing the swiftness the maximum distance between two location has to squinch.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug31smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localization/nodes. when increasing the speed the maximum distance between two localization has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug32smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug33smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localization/nodes. when increasing the speed the maximum distance between two localization has to wither.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug34smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug35smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision sphere diameter is the space between two locations/thickening. when increasing the speed the maximum space between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug36smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug37smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two fix/nodes. when increasing the speed the maximum aloofness between two fix has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug38smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the distance between two locations/thickening. when increasing the speed the maximal distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug39smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug40smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision orbit diameter is the distance between two localisation/nodes. when increasing the speed the maximum distance between two localisation has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug41smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the amphetamine the maximal distance between two locations has to contract.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug42smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision area diameter is the distance between two positioning/nodes. when increasing the speed the maximum distance between two positioning has to quail.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug43smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increasing the speeding the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug44smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the distance between two locations/nodes. when increase the velocity the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug45smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug46smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the aloofness between two locations/nodes. when increasing the upper the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug47smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to funk.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug48smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the distance between two position/nodes. when increasing the hurrying the maximum distance between two position has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug00smp0382q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:\n(a, b, frontwards)\n(a, c, frontwards)\n(a, d, drop) <= node d doesn't receive parcels to a\nhops 2:\n(b, e, frontwards)\n(c, f, drop) <= node f doesn't receive parcels to a\nhops 3:\n(e, g, frontwards)\nhops 4:\n(g, h, drop) <= no other nodes to send the parcel to",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= node d doesn't receive packets to a\nhop 2:\n(b, e, forward)\n(c, f, drop) <= node f doesn't receive packets to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= no other nodes to send the packet to",
        "original_sample_id": "smp0382q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0888q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, i do not think that this assumption is true, especially when we are monitoring a connection that is far from being congested.\nfor exercise, with a single download of some data, the probability of more mailboat arriving after the first packet is no longer independent, and when the expected bytes have been transmitted, the probability of further mailboat belonging to the download is not very likely.\nanother exercise is video streaming, where the video is transmitted in chunks and there are pauses between each chunk, the second packet of a chunk arrives with a higher probability, and after the chunk has been transmitted, there is a pause until the client requests another chunk, so again the reaching are not independent.\nin the exercises given above, the reaching of subsequent mailboat are not random and exponentially distributed, the mailboat arriving after the first packet are very likely to arrive consecutively, and as long as the download or video chunk is not completely received, the probability of getting further mailboat subsequent time intervals is higher than λδt and after the download or chunk has finished, it is lower than 1 - λδt.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, i do not think that this assumption is true, especially when we are monitoring a connection that is far from being congested.\nfor example, with a single download of some data, the probability of more packets arriving after the first packet is no longer independent, and when the expected bytes have been transmitted, the probability of further packets belonging to the download is not very likely.\nanother example is video streaming, where the video is transmitted in chunks and there are pauses between each chunk, the second packet of a chunk arrives with a higher probability, and after the chunk has been transmitted, there is a pause until the client requests another chunk, so again the arrivals are not independent.\nin the examples given above, the arrivals of subsequent packets are not random and exponentially distributed, the packets arriving after the first packet are very likely to arrive consecutively, and as long as the download or video chunk is not completely received, the probability of getting further packets subsequent time intervals is higher than λδt and after the download or chunk has finished, it is lower than 1 - λδt.",
        "original_sample_id": "smp0888q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0819q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp curb an additional head for the sequence number tcp curb an additional head for the acknowledgement number tcp curb an additional head for hl/resv/flagstone tcp curb an additional head for an urgent pointer",
        "answer_feedback": "the response states four differences correctly. however, abbreviations, such as hl and resv, should be introduced. moreover, instead of \"additional headers\" it should be \" additional fields are present\".",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp contains an additional header for the sequence number tcp contains an additional header for the acknowledgement number tcp contains an additional header for hl/resv/flags tcp contains an additional header for an urgent pointer",
        "original_sample_id": "smp0819q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1031q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf and rpb are algorithms used to reduce the number of duplicate and unnecessary bundles in flooding/broadcasting by inspecting the optimal unicast ways. in rpf, if an is receives a bundle from a source over which it would normally receive unicast bundles, it can assume the bundle has taken the optimal way so far, and it forwards it over all outbound edges.  if it did not come over the port unicast bundles normally would, then the is discards the bundle. in rpb, only specific outgoing embrasure are selected rather than all embrasure.  if an is receives a bundle from a source that it would normally receive bundles from, it will only forward the bundles on the outgoing embrasure for which it is on the optimal way from source to destination, rather than forwarding on all outgoing embrasure as in rpf.  the is knows whether it is on the optimal way by inspecting unicast bundles.  if the bundle did not come on a port from which the is would normally receive bundles, then the is can discard the message (as in rpf).",
        "answer_feedback": "the response incorrectly states that \"if an is receives a packet from a source over which it would normally 'receive' unicast packets\". instead, it should be \"if an is receives a packet from sender s over neighbor n and would usually send packets to s over n\". the same holds for rpb. also, both rpf and rpb exclude the link from which it receives the packet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "rpf and rpb are algorithms used to reduce the number of duplicate and unnecessary packets in flooding/broadcasting by inspecting the optimal unicast paths. in rpf, if an is receives a packet from a source over which it would normally receive unicast packets, it can assume the packet has taken the optimal path so far, and it forwards it over all outbound edges.  if it did not come over the port unicast packets normally would, then the is discards the packet. in rpb, only specific outgoing ports are selected rather than all ports.  if an is receives a packet from a source that it would normally receive packets from, it will only forward the packets on the outgoing ports for which it is on the optimal path from source to destination, rather than forwarding on all outgoing ports as in rpf.  the is knows whether it is on the optimal path by inspecting unicast packets.  if the packet did not come on a port from which the is would normally receive packets, then the is can discard the message (as in rpf).",
        "original_sample_id": "smp1031q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0863q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "it is not realistic because the amount of dealings is different at different times of the day. another example are polisher e.g. video cyclosis where several packets are send followed by a break until the next train of packets.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it is not realistic because the amount of traffic is different at different times of the day. another example are buffers e.g. video streaming where several packets are send followed by a break until the next train of packets.",
        "original_sample_id": "smp0863q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0863q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "it is not realistic because the amount of traffic is different at different times of the day. another example are the buffers for example video streaming where several packages are sent followed by a pause until the next package train.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it is not realistic because the amount of traffic is different at different times of the day. another example are buffers e.g. video streaming where several packets are send followed by a break until the next train of packets.",
        "original_sample_id": "smp0863q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0384q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (a,b,forward) (a,c,forward) (a,d,drop) because d will not receive any other packet from other nodes and knows that in itself it is not included in any other better path, so d will drop the package hop 2: (b,e,forward) (c,f,drop) because f will not receive any other packet from other nodes and knows that in itself it is not included in any other better path, so f will drop the package hop 3: (e,g,forward) hop 4: (g,h,drop)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1: \n\n(a,b,forward)\n(a,c,forward)\n(a,d, drop) => because d won't receive any other packets from other nodes and knows that itself is not included in any other best paths, so d will drop the packet\nhop 2:\n(b,e,forward)\n(c,f,drop) => because f won't receive any other packets from other nodes and knows that itself is not included in any other best paths, so f will drop the packet\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop) => because h has only one neighbor from which it got the message, therefore it does not forward the message",
        "original_sample_id": "smp0384q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1679q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/810.0.0.0/8100.64.0.0/10127.0.0.0.0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/810.0.0.0/8100.64.0.0/10127.0.0.0/8",
        "original_sample_id": "smp1679q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0150q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Manchester differential coding",
        "answer_feedback": "incorrect and no reasoning provided. the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential  manchester  encoding",
        "original_sample_id": "smp0150q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0150q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Manchester differential coding",
        "answer_feedback": "incorrect and no reasoning provided. the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential  manchester  encoding",
        "original_sample_id": "smp0150q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1056q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property: a cross tree has a route to each router without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. based on that information each is can locally calculate a cross tree for themselves.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property: a spanning tree has a route to each routers without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. based on that information each is can locally calculate a spanning tree for themselves.",
        "original_sample_id": "smp1056q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1056q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property: a traverse tree has a route to each router without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. found on that information each is can locally calculate a traverse tree for themselves.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property: a spanning tree has a route to each routers without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. based on that information each is can locally calculate a spanning tree for themselves.",
        "original_sample_id": "smp1056q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1696q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "127,00.0-127,255.255,255(1-126).0.0.0 (1-126).255,255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "127.0.0.0-127.255.255.255（1—126）.0.0.0\n（1—126）.255.255.255",
        "original_sample_id": "smp1696q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1012q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "- reverse itinerary forwarding: the main idea is here is that each sender has its own spanning tree, but the is do not need to know the spanning trees itself. _algorithm:_ 1. node b sends unicast mailboat to destination node s using the shortest route via the node a 2. node s sends braodcast mailboat to all nodes which are also forwared by a to b 3. since b also can get the braodcasted mailboat from other nodes, the unicast routing information is used to determine which information to keep: - if the broadcastet packet from s did not arrive via a, ignore it because we know that the itinerary via a is the shortest route - if the broadcastet mailboat arrived via a then keep the data because we know its the shortest route - reverse itinerary broadcast:  the main idea here is to just use the edges, in the broadcast step, at which the mailboat arrived and reroute it to the source instead of broadcasting to all and every nodes. this helps avoiding duplication. _algorithm:_ 1. node b sends unicast mailboat to node s via node a. where a inspects the mailboat and can learn the best itinerary and also the best itinerary in the reversed direction. furthermore, other connected nodes to b can learn that they never did receive a unicast itinerary from b to s, means they are not part of the itinerary.  2. now when s broadcasts the mailboat, just a fowards the mailboat to b. the other connected node to b will not forward the mailboat to b because it knows it is not part of the best route → the connection from that node to b is relieved. the node does foward the broadcast mailboat from s to other nodes though.",
        "answer_feedback": "the response is incomplete as it does not state the purpose of rpf which is also to reduce duplicates during broadcasting compared to flooding. the explanation of rpf and rpb is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.9,
        "original_answer": "- reverse path forwarding: the main idea is here is that each sender has its own spanning tree, but the is do not need to know the spanning trees itself. _algorithm:_ 1. node b sends unicast packets to destination node s using the shortest route via the node a 2. node s sends braodcast packets to all nodes which are also forwared by a to b 3. since b also can get the braodcasted packets from other nodes, the unicast routing information is used to determine which information to keep: - if the broadcastet packet from s did not arrive via a, ignore it because we know that the path via a is the shortest route - if the broadcastet packets arrived via a then keep the data because we know its the shortest route - reverse path broadcast:  the main idea here is to just use the edges, in the broadcast step, at which the packets arrived and reroute it to the source instead of broadcasting to all and every nodes. this helps avoiding duplicates. _algorithm:_ 1. node b sends unicast packets to node s via node a. where a inspects the packets and can learn the best path and also the best path in the reversed direction. furthermore, other connected nodes to b can learn that they never did receive a unicast path from b to s, means they are not part of the path.  2. now when s broadcasts the packets, just a fowards the packets to b. the other connected node to b will not forward the packets to b because it knows it is not part of the best route → the connection from that node to b is relieved. the node does foward the broadcast packets from s to other nodes though.",
        "original_sample_id": "smp1012q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0916q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa of a transparent bridge holds the source speech, the lan on which it received the frame and a timestamp to tell when the frame was received.the mesa consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridge, that a can be reached over lan1. this entry gets updated when another frame is received from the same source speech (a) or the the entry get’s purged because the mesa gets scanned periodically for old entries. if a frame is received at a bridge where the source and destination speech are equal, then the bridge will not forward the packet (drop it because the bridge is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridge has to use flooding. an reward could be, that the bridge only forwards packets if necessary (when source and destination speech are in different lan’s), except the mesa doesn’t contain the corresponding destination path, then flooding is required.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge holds the source address, the lan on which it received the frame and a timestamp to tell when the frame was received.the table consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridge, that a can be reached over lan1. this entry gets updated when another frame is received from the same source address (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a frame is received at a bridge where the source and destination address are equal, then the bridge will not forward the packet (drop it because the bridge is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridge has to use flooding. an advantage could be, that the bridge only forwards packets if necessary (when source and destination address are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "original_sample_id": "smp0916q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0916q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa of a transparent bridgework holds the source address, the lan on which it received the frame and a timestamp to tell when the frame was received.the mesa consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridgework, that a can be reached over lan1. this entry gets updated when another frame is received from the same source address (a) or the the entry get’s purged because the mesa gets scanned periodically for old entries. if a frame is received at a bridgework where the source and destination address are equal, then the bridgework will not forward the parcel (drop it because the bridgework is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridgework has to use flooding. an advantage could be, that the bridgework only forwards parcels if necessary (when source and destination address are in different lan’s), except the mesa doesn’t contain the corresponding destination path, then flooding is required.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge holds the source address, the lan on which it received the frame and a timestamp to tell when the frame was received.the table consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridge, that a can be reached over lan1. this entry gets updated when another frame is received from the same source address (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a frame is received at a bridge where the source and destination address are equal, then the bridge will not forward the packet (drop it because the bridge is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridge has to use flooding. an advantage could be, that the bridge only forwards packets if necessary (when source and destination address are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "original_sample_id": "smp0916q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0916q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent span holds the source reference, the lan on which it received the frame and a timestamp to tell when the frame was received.the table consist of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the span, that a can be reached over lan1. this entry gets updated when another frame is received from the same source reference (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a frame is received at a span where the source and destination reference are equal, then the span will not forward the packet (drop it because the span is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the span has to use flooding. an advantage could be, that the span only forwards packets if necessary (when source and destination reference are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge holds the source address, the lan on which it received the frame and a timestamp to tell when the frame was received.the table consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridge, that a can be reached over lan1. this entry gets updated when another frame is received from the same source address (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a frame is received at a bridge where the source and destination address are equal, then the bridge will not forward the packet (drop it because the bridge is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridge has to use flooding. an advantage could be, that the bridge only forwards packets if necessary (when source and destination address are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "original_sample_id": "smp0916q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0916q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent span holds the source address, the lan on which it received the figure and a timestamp to tell when the figure was received.the table consists of all the received figures of any connected lan, e.g. (a, lan1, timestamp) telling the span, that a can be reached over lan1. this entry gets updated when another figure is received from the same source address (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a figure is received at a span where the source and destination address are equal, then the span will not forward the packet (drop it because the span is not needed). if the source differs from the destination, then the figure gets rerouted to the destination lan. if the destination is not known so far, the span has to use flooding. an advantage could be, that the span only forwards packets if necessary (when source and destination address are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge holds the source address, the lan on which it received the frame and a timestamp to tell when the frame was received.the table consists of all the received frames of any connected lan, e.g. (a, lan1, timestamp) telling the bridge, that a can be reached over lan1. this entry gets updated when another frame is received from the same source address (a) or the the entry get’s purged because the table gets scanned periodically for old entries. if a frame is received at a bridge where the source and destination address are equal, then the bridge will not forward the packet (drop it because the bridge is not needed). if the source differs from the destination, then the frame gets rerouted to the destination lan. if the destination is not known so far, the bridge has to use flooding. an advantage could be, that the bridge only forwards packets if necessary (when source and destination address are in different lan’s), except the table doesn’t contain the corresponding destination path, then flooding is required.",
        "original_sample_id": "smp0916q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0843q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis does not hold for the real internet traffic because it has very strong assumptions: - it assumes that only one package can arrive at the same time in the defined time interval. it is not realistic because there may be many time intervals when 0 packages arrive and time intervals when more than one package arrives in the same time interval, for example depending on the time of day - the hypothesis of independence does not hold because in different time intervals the probability that a package (or packages) arrives will not always be the same as the Poisson process assumes - even the hypothesis that two or more packages arrive in a time interval is 0 unrealistic.",
        "answer_feedback": "the response correctly states that the independence assumption does not hold.  however, the explanation is incorrect as the poisson process requires independent inter-arrival times but not a constant inter-arrival rate parameter.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the assumption does not hold for real internet traffic because it has very strong assumptions:\n- it assumes that only one packet can arrive at the same time in the defined time interval. this is not realistic because there may be many time intervals then where 0 packets arrive and time intervals where more than one packet arrives in the same time interval e.g. depending on time of day\n- independence assumption does not hold because in different time intervals the probability that a packet (or packets) arrive will not always be the same like poisson process assumes\n- also the assumption that two or more packets arrive in one time interval is 0 is unrealistic.",
        "original_sample_id": "smp0843q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0843q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis does not hold for the real internet traffic because it has very strong assumptions: - it assumes that only one package can arrive at the same time in the defined time interval. it is not realistic because there may be many time intervals when 0 packages arrive and time intervals when more than one package arrives in the same time interval, for example depending on the time of day - the hypothesis of independence does not hold because in different time intervals the probability that a package (or packages) arrives will not always be the same as the Poisson process assumes - even the hypothesis that two or more packages arrive in a time interval is 0 unrealistic.",
        "answer_feedback": "the response correctly states that the independence assumption does not hold.  however, the explanation is incorrect as the poisson process requires independent inter-arrival times but not a constant inter-arrival rate parameter.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the assumption does not hold for real internet traffic because it has very strong assumptions:\n- it assumes that only one packet can arrive at the same time in the defined time interval. this is not realistic because there may be many time intervals then where 0 packets arrive and time intervals where more than one packet arrives in the same time interval e.g. depending on time of day\n- independence assumption does not hold because in different time intervals the probability that a packet (or packets) arrive will not always be the same like poisson process assumes\n- also the assumption that two or more packets arrive in one time interval is 0 is unrealistic.",
        "original_sample_id": "smp0843q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0840q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this effrontery does not halt for real internet traffic, since when we are watching a video, for example, we need to receive the packets, so we need the probability a packet to be delivered to be 1 and not 0. if we are not watching we need the probability to be 0. and a part from this when we are watching a video, we get a bunch of packets, then there is a higher probability that we receive also the next packets.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold for real internet traffic, since when we are watching a video, for example, we want to receive the packets, so we want the probability a packet to be delivered to be 1 and not 0. if we are not watching we want the probability to be 0. and a part from this when we are watching a video, we get a bunch of packets, then there is a higher probability that we receive also the next packets.",
        "original_sample_id": "smp0840q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0762q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the networks that use dqdb in metropolitan areas suffer a problem of equity due to the information of control of the network. the propagation delays become much longer than the time of transmission of a data segment. to address this problem, a procedure of speed control is used that only requires a minor modification to the structure of dqdb network.",
        "answer_feedback": "the response answer is partially correct because it identifies the fairness problem due to network control information and propagation delays. but the lack of fairness is based on station locations.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "networks that use dqdb in metropolitan areas suffer a fairness problem due to network control information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate control procedure is used that only requires a minor modification to dqdb network structure.",
        "original_sample_id": "smp0762q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0762q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "webs that use dqdb in metropolitan areas suffer a candour problem due to web ascendence information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate ascendence procedure is used that only requires a minor modification to dqdb web structure.",
        "answer_feedback": "the response answer is partially correct because it identifies the fairness problem due to network control information and propagation delays. but the lack of fairness is based on station locations.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "networks that use dqdb in metropolitan areas suffer a fairness problem due to network control information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate control procedure is used that only requires a minor modification to dqdb network structure.",
        "original_sample_id": "smp0762q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0762q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the networks that use dqdb in metropolitan areas suffer a problem of equity due to the information of control of the network. the propagation delays become much longer than the time of transmission of a data segment. to address this problem, a procedure of speed control is used that only requires a minor modification to the structure of dqdb network.",
        "answer_feedback": "the response answer is partially correct because it identifies the fairness problem due to network control information and propagation delays. but the lack of fairness is based on station locations.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "networks that use dqdb in metropolitan areas suffer a fairness problem due to network control information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate control procedure is used that only requires a minor modification to dqdb network structure.",
        "original_sample_id": "smp0762q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0762q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the networks that use dqdb in metropolitan areas suffer a problem of equity due to the information of control of the network. the propagation delays become much longer than the time of transmission of a data segment. to address this problem, a procedure of speed control is used that only requires a minor modification to the structure of dqdb network.",
        "answer_feedback": "the response answer is partially correct because it identifies the fairness problem due to network control information and propagation delays. but the lack of fairness is based on station locations.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "networks that use dqdb in metropolitan areas suffer a fairness problem due to network control information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate control procedure is used that only requires a minor modification to dqdb network structure.",
        "original_sample_id": "smp0762q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0762q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the networks that use dqdb in metropolitan areas suffer a problem of equity due to the information of control of the network. the propagation delays become much longer than the time of transmission of a data segment. to address this problem, a procedure of speed control is used that only requires a minor modification to the structure of dqdb network.",
        "answer_feedback": "the response answer is partially correct because it identifies the fairness problem due to network control information and propagation delays. but the lack of fairness is based on station locations.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "networks that use dqdb in metropolitan areas suffer a fairness problem due to network control information. propagation delays become much longer than the transmission time of a data segment. to tackle this problem, a rate control procedure is used that only requires a minor modification to dqdb network structure.",
        "original_sample_id": "smp0762q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1004q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path circularize are circularize routing algorithms. the purpose of them is that sending a packet to all destinations simultaneously while making full use of bandwidth and do not waste resources. 1. reverse pah forwarding when a circularize packet arrive at a router, the router checks to see if the packet arrive on the line that is normally used for sending packets from source to destination. if so, the very circularize packet used the best route until now and is therefore resend over all edges. if not, i.e. the packet did not use such route, it will be discarded like duplicate. 2. reverse path circularize when a packet arrive at the intermediate system, is checks to see if the packet arrive at the entry port over which the packets for this souces s are usually sent. if so then it continues checking to see if the packet used the best route until now. if this nested-if holds true, then select the edge at which the packets arrive and from which they are rerouted to source s. if it holds false, then do not send over all edges. otherwise, the arrive packet will be discarded as a likely duplicate.",
        "answer_feedback": "the stated purpose is incorrect as the response is not explicit about which resources and how their wastage is avoided. the explanation for rfb and rpb is correct except that in both algorithms, the packet is also not forwarded to the edge from which it was received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.7,
        "original_answer": "reverse path forwarding and reverse path broadcast are broadcast routing algorithms. the purpose of them is that sending a packet to all destinations simultaneously while making full use of bandwidth and do not waste resources. 1. reverse pah forwarding when a broadcast packet arrives at a router, the router checks to see if the packet arrived on the line that is normally used for sending packets from source to destination. if so, the very broadcast packet used the best route until now and is therefore resend over all edges. if not, i.e. the packet did not use such route, it will be discarded like duplicate. 2. reverse path broadcast when a packet arrives at the intermediate system, is checks to see if the packet arrived at the entry port over which the packets for this souces s are usually sent. if so then it continues checking to see if the packet used the best route until now. if this nested-if holds true, then select the edge at which the packets arrived and from which they are rerouted to source s. if it holds false, then do not send over all edges. otherwise, the arrived packet will be discarded as a likely duplicate.",
        "original_sample_id": "smp1004q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1671q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0,0,0,0,0,2552,255 10,0,0,055 10,255,255 100,64,0,0,05,100,127,255,255 127,0,0,0,07,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "original_sample_id": "smp1671q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1502q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the support must support the duplex operation and the receiver must have some data that it wants to return. If the support does not support the duplex operation, the receiver cannot return its data and the piggybacked recognition. even if the receiver does not have any data that it wants to send to the sender, it cannot piggyback the acks on anything.",
        "answer_feedback": "the response answers the underlying requirement correctly, namely the duplex communication. to overcome the lack of data to send a dedicated timer timeout can be used. after a timeout, an acknowledgment is sent separately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the medium has to support duplex operation and the receiver has to have some data that he wants to send back. if the medium does not support duplex operation, the receiver can not send his data and the piggybacked acknowledgement back. also if the receiver has no data that he wants to send to the sender, he can not piggyback the acks on anything.",
        "original_sample_id": "smp1502q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0142q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the slip window technique should be used in this scenario for these reasons:\n1) the mesh is often congested. the sw has unspoilt capability for dealing with that by unspoilt utilizing channels / generating more throughput.\n2) its a small mesh of 3 users meaning that increasing complexity (buffer demand) does not scale that much, neutralizing one of the main drawbacks of sw",
        "answer_feedback": "the provided response is not related to the type of encoding.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the sliding window technique should be used in this scenario for these reasons:\n1) the network is often congested. the sw has better capability for dealing with that by better utilizing channels / generating more throughput.\n2) its a small network of 3 users meaning that increasing complexity (buffer demand) does not scale that much, neutralizing one of the main drawbacks of sw",
        "original_sample_id": "smp0142q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0142q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the technique of the sliding window must be used in this scenario for these reasons: 1) the network is often crowded. the sw has a better ability to manage this using the best channels / generating more performance. 2) its small network 3 users means that the increasing complexity (bubble demand) does not evolve so much by neutralizing one of the main drawbacks of sw",
        "answer_feedback": "the provided response is not related to the type of encoding.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the sliding window technique should be used in this scenario for these reasons:\n1) the network is often congested. the sw has better capability for dealing with that by better utilizing channels / generating more throughput.\n2) its a small network of 3 users meaning that increasing complexity (buffer demand) does not scale that much, neutralizing one of the main drawbacks of sw",
        "original_sample_id": "smp0142q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1049q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the rearward forwarding each router has the information about which path it should use for unicast-packets.if the packet arriving at an is is not using the best route this packet will be handled as a duplicate therefore being fling. otherwise if the packet is using the best route , it will be resend over all edges (without including the incoming one) rearward path broadcast: this one is very similar to the rpf but less robust. the biggest difference is that the packet will be resent to the selected  edge at which the packets come and then they will be rerouted to source s (it will not be resent to all edges)",
        "answer_feedback": "the response is partially correct as it does not state the purpose of rpf and rpb which is to reduce redundant packets/duplicates during broadcasting. the remaining parts are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "the reverse forwarding each router has the information about which path it should use for unicast-packets.if the packet arriving at an is is not using the best route this packet will be handled as a duplicate therefore being discarded. otherwise if the packet is using the best route , it will be resend over all edges (without including the incoming one) reverse path broadcast: this one is very similar to the rpf but less robust. the biggest difference is that the packet will be resent to the selected  edge at which the packets arrived and then they will be rerouted to source s (it will not be resent to all edges)",
        "original_sample_id": "smp1049q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0924q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa holds information about which addresses are reachable through which lan. initialy the mesa is empty, so the bridge has to flood the data. during backward learning, if receiving a packet with an address a over lan l, the bridge will add the compounding (a, l) to the mesa, so it knows a can be reached over l. furthermore entries can be consort with an timestamp so old entries can be purged later. now if the bridge receives on the over side a packet with an destination address a, it knows from the previous saved mesa entry that a can be reached from l and forwards it to it.",
        "answer_feedback": "the response does not mention the benefit. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table holds information about which addresses are reachable through which lan. initialy the table is empty, so the bridge has to flood the data. during backward learning, if receiving a packet with an address a over lan l, the bridge will add the combination (a, l) to the table, so it knows a can be reached over l. furthermore entries can be associated with an timestamp so old entries can be purged later. now if the bridge receives on the over side a packet with an destination address a, it knows from the previous saved table entry that a can be reached from l and forwards it to it.",
        "original_sample_id": "smp0924q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0237q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "in this instance the scheme will be for the whole time in a state, in which there are less than 10 packets waiting in the queue, due to the fact that there are always more packets processed pro second than arriving.\nusage = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of packets in the scheme\nn =  usage / 1 - usage which gives = 9 packets\nwe can also calculate the probability, that the scheme is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a result. because the usage ist the same at every time, the probability that the scheme is full remains equally.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time as was done for p_10. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "in this case the system will be for the whole time in a state, in which there are less than 10 packets waiting in the queue, due to the fact that there are always more packets processed pro second than arriving.\nutilisation = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of packets in the system\nn =  utilisation / 1 - utilisation which gives = 9 packets\nwe can also calculate the probability, that the system is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a result. because the utilisation ist the same at every time, the probability that the system is full remains equally.",
        "original_sample_id": "smp0237q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0237q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "in this case the system will be for the whole time in a state, in which there are less than 10 mailboat waiting in the queue, due to the fact that there are always more mailboat processed pro second than arriving.\nutilisation = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of mailboat in the system\nn =  utilisation / 1 - utilisation which gives = 9 mailboat\nwe can also calculate the probability, that the system is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a outcome. because the utilisation ist the same at every time, the probability that the system is full remains equally.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time as was done for p_10. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "in this case the system will be for the whole time in a state, in which there are less than 10 packets waiting in the queue, due to the fact that there are always more packets processed pro second than arriving.\nutilisation = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of packets in the system\nn =  utilisation / 1 - utilisation which gives = 9 packets\nwe can also calculate the probability, that the system is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a result. because the utilisation ist the same at every time, the probability that the system is full remains equally.",
        "original_sample_id": "smp0237q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0324q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, c, forward)\n(a, b, forward)\n(a, d, forward)\nhop 2:\n(b, a, fall) already incur\n(b, c, fall) already incur\n(b, e, forward)\n(c, b, fall) already incur\n(c, a, fall) already incur\n(c, d, fall) already incur\n(d, a, fall) already incur\n(d, c, fall) already incur\n(d, f, forward)\nhop 3:\n(e, b, fall) already incur\n(e, c, fall) already incur\n(e, f, fall) already incur\n(e, g, fall) already incur\n(f, d, fall) already incur\n(f, c, fall) already incur\n(f, e, fall) already incur\n(f, g, fall) already incur\nhop 4:\n(g, e, fall) already incur\n(g, f, fall) already incur\n(g, h, forward)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, c, forward)\n(a, b, forward)\n(a, d, forward)\nhop 2:\n(b, a, drop) already received\n(b, c, drop) already received\n(b, e, forward)\n(c, b, drop) already received\n(c, a, drop) already received\n(c, d, drop) already received\n(d, a, drop) already received\n(d, c, drop) already received\n(d, f, forward)\nhop 3:\n(e, b, drop) already received\n(e, c, drop) already received\n(e, f, drop) already received\n(e, g, drop) already received\n(f, d, drop) already received\n(f, c, drop) already received\n(f, e, drop) already received\n(f, g, drop) already received\nhop 4:\n(g, e, drop) already received\n(g, f, drop) already received\n(g, h, forward)",
        "original_sample_id": "smp0324q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1010q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective of restarting the reverse route (rpf) and retransfering the reverse route (rpb) is to guarantee the most efficient way to re-send the information of any sender to any receiving terminal, thus providing the best possible loopless extension tree for each transmitting terminal. using the most efficient means rpf and rpb to reduce the number of packages required for broadcasting. in rpf each router must have information about the route he would use for unicast-packages. when a package arrives at the entrance, one will wonder whether the packages are also sent by that station for that source. Yes, then the package will use the best route so far and will be felt on all edges (except for revenue). Otherwise, the package does not use the best route and will throw itself. Therefore, the most efficient form is established, but rpf still requires re-allocation on all edges, which costs a great bandwidth capacity. in rpb is not re-placed on all edges.",
        "answer_feedback": "the response correctly answers all three parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) and reverse path broadcast (rpb) is to guarantee the most efficient way to forward information from any sender to any receiver terminal, thus providing the best possible loop-free spanning tree for each sender terminal. by using the most efficient way rpf and rpb reduce the number of packets needed for broadcasting. in rpf each router must have information which path it would use for unicast-packets. when a packet arrives at the is entry, it will be asked whether packets are normally also sent over this station for this source. if yes, then the packet will use the best route so far and will be resent over all edges (except the income one). if not, the packet does not use the best route and is discarded. therefore, the most efficient way is then established, but rpf always requires a resend over all edges, which costs a lot of bandwidth capacity.     in rpb is no resend over all edges. when the packet arrives at the is entry, it will be asked whether the packets are normally also sent over this station for this specific source. if yes the edge will be selected at which the packets arrived and from which they are then rerouted to the specific source (in reversed direction). if not, the packet gets discarded.",
        "original_sample_id": "smp1010q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1010q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective of restarting the reverse route (rpf) and retransfering the reverse route (rpb) is to guarantee the most efficient way to re-send the information of any sender to any receiving terminal, thus providing the best possible loopless extension tree for each transmitting terminal. using the most efficient means rpf and rpb to reduce the number of packages required for broadcasting. in rpf each router must have information about the route he would use for unicast-packages. when a package arrives at the entrance, one will wonder whether the packages are also sent by that station for that source. Yes, then the package will use the best route so far and will be felt on all edges (except for revenue). Otherwise, the package does not use the best route and will throw itself. Therefore, the most efficient form is established, but rpf still requires re-allocation on all edges, which costs a great bandwidth capacity. in rpb is not re-placed on all edges.",
        "answer_feedback": "the response correctly answers all three parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) and reverse path broadcast (rpb) is to guarantee the most efficient way to forward information from any sender to any receiver terminal, thus providing the best possible loop-free spanning tree for each sender terminal. by using the most efficient way rpf and rpb reduce the number of packets needed for broadcasting. in rpf each router must have information which path it would use for unicast-packets. when a packet arrives at the is entry, it will be asked whether packets are normally also sent over this station for this source. if yes, then the packet will use the best route so far and will be resent over all edges (except the income one). if not, the packet does not use the best route and is discarded. therefore, the most efficient way is then established, but rpf always requires a resend over all edges, which costs a lot of bandwidth capacity.     in rpb is no resend over all edges. when the packet arrives at the is entry, it will be asked whether the packets are normally also sent over this station for this specific source. if yes the edge will be selected at which the packets arrived and from which they are then rerouted to the specific source (in reversed direction). if not, the packet gets discarded.",
        "original_sample_id": "smp1010q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0785q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- tcp header more complex and larger than the udp header - optional udp source port, tcp required - no sequence number in udp header - no recognition number in udp header - no package length field in tcp header",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- tcp header more complex and bigger than the udp header\n- source port in udp optional, in tcp necessary\n- no sequence number in udp header\n- no acknowledgement number in udp header\n- no packet length field in tcp header",
        "original_sample_id": "smp0785q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1533q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "underframe can carry inexplicit acks",
        "answer_feedback": "the response is incorrect. in piggybacking, the acknowledgment may be implicit but that is not the requirement. the requirement is to have a separate field in the data frame for acknowledgment.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "frames can contain implicit acks",
        "original_sample_id": "smp1533q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1634q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 10.0.0 127.0.0.0",
        "answer_feedback": "the addresses have ranges: from 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n10.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1634q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1634q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 10.0.0 127.0.0.0",
        "answer_feedback": "the addresses have ranges: from 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n10.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1634q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1480q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "To do this, all participants must have a certain type of buffer, as well as a protocol on the waiting time schedule and maximum waiting time before sending a single rack if there is no outgoing data frame to fix theack.",
        "answer_feedback": "the response answers the underlying requirement correctly. the other point adds to the main requirement from the implementation and optimization point of view.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking requires a duplex communication, where both participants want to send and receive data frames, so that they both have the chance to bind their acknowledgement to the next outgoing data frame. to do so, all participants must have a certain  kind of buffer, as well as protocol about the timeout scheme and the maximum waiting time before sending out a single ack-frame if there is no outgoing data frame to attach the ack to.",
        "original_sample_id": "smp1480q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this web to encode bitstreams. this is because manchester and differential manchester encoding systems worry twice as much as bandwidth as the binary encoding system. so this in turn leads to the web being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this mesh to encode bitstreams. this is because manchester and differential manchester encoding scheme occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the mesh being choke.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encode needs to be used in this web to encode bitstreams. this is because manchester and differential manchester encode schemes occupy twice as much as bandwidth as the binary encode scheme. so this in turn result to the web being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding must be used in this network to encode bitstreams. This is because the encoding schemas sleeve and differential sleeve occupy twice as much bandwidth as the binary encoding schema.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this meshwork to encode bitstreams. this is because manchester and differential manchester encoding dodge occupy double as much as bandwidth as the binary encoding scheme. so this in turn leads to the meshwork being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding dodging occupy twice as much as bandwidth as the binary encoding scheme. so this in go extend to the network being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption needs to be used in this web to encode bitstreams. this is because manchester and differential manchester encryption schemes engross twice as much as bandwidth as the binary encryption scheme. so this in turn leads to the web being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encode needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encode schemes occupy twice as much as bandwidth as the binary encode scheme. so this in bend lead to the network being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug08smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption penury to be used in this meshwork to encode bitstreams. this is because manchester and differential manchester encryption schemes occupy twice as much as bandwidth as the binary encryption scheme. so this in turn leads to the meshwork being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1070q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "An important property of the trees that extend is that the trees that extend do not have any cycle. adding any edge to the tree will result in a cycle. therefore, a tree that extends is acyclic to the maximum. all are minimally connected. that means that the tree that extends will no longer be connected if a border is removed. the tree algorithm that extends ensures that there are no revolving packages undesirablely. identifies multiple routes converting topologies with redundant routes logically blocking certain paths in a tree topology without loops. all but one connection is blocked in switches with multiple connections to other switches. to build a tree that extends for multicasting outside of a link status routing, each one is aware of which group it belongs to but does not know which other group also. packets containing the distance to the neighbors and information about the multicast group to which it belongs. the package is sent by transmission to all the other nodes. based on that, each calculates the multicast tree and determines the outgoing lines on which packages have to transmit.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "an important property of spanning trees is that spanning trees do not have any cycles. adding any edge to the tree will result in a cycle. so, a spanning tree is maximally acyclic. they are all minimally connected. that means that the spanning tree will no longer be connected if one edge is eliminated. the spanning tree algorithm ensures that there are no undesirably rotating packets. it identifies multiple paths by converting topologies with redundant paths by logically blocking certain paths into a tree topology with no loops. all but one connection is blocked on the switches with multiple connections to other switches. to construct a spanning tree for multicasting out of a link-state routing, each is knows which group it belongs to but doesn't know which other is belongs to the group as well. the is sends packets that contain the distance to neighbors and the information on which multicast group it belongs to. the packet is sent by broadcast to all other nodes. based on that, each is calculates the multicast tree and determines the outgoing lines on which the packets have to be transmitted.",
        "original_sample_id": "smp1070q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1070q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an important property of sweep trees is that sweep trees do not have any cycles. adding any edge to the tree will result in a cycle. so, a sweep tree is maximally acyclic. they are all minimally connected. that means that the sweep tree will no longer be connected if one edge is eliminated. the sweep tree algorithm ensures that there are no undesirably rotating packets. it identifies multiple paths by converting topology with redundant paths by logically blocking certain paths into a tree topology with no loops. all but one connection is blocked on the switches with multiple connections to other switches. to construct a sweep tree for multicasting out of a link-state routing, each is knows which group it belongs to but doesn't know which other is belongs to the group as well. the is sends packets that check the distance to neighbors and the information on which multicast group it belongs to. the packet is sent by broadcast to all other nodes. based on that, each is calculates the multicast tree and determines the outgoing lines on which the packets have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "an important property of spanning trees is that spanning trees do not have any cycles. adding any edge to the tree will result in a cycle. so, a spanning tree is maximally acyclic. they are all minimally connected. that means that the spanning tree will no longer be connected if one edge is eliminated. the spanning tree algorithm ensures that there are no undesirably rotating packets. it identifies multiple paths by converting topologies with redundant paths by logically blocking certain paths into a tree topology with no loops. all but one connection is blocked on the switches with multiple connections to other switches. to construct a spanning tree for multicasting out of a link-state routing, each is knows which group it belongs to but doesn't know which other is belongs to the group as well. the is sends packets that contain the distance to neighbors and the information on which multicast group it belongs to. the packet is sent by broadcast to all other nodes. based on that, each is calculates the multicast tree and determines the outgoing lines on which the packets have to be transmitted.",
        "original_sample_id": "smp1070q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the guileless bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the web. that means the guileless bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the guileless bridge floods the web with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the web.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the filmy bridge receives every frame of each connected side. the bridge board holds the information about which components are attached to the network. that entail the filmy bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the filmy bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the crystalline bridge receives every figure of each connected side. the bridge table holds the information about which components are attached to the network. that means the crystalline bridge receives from the component a a figure which has the information \"a can be reached over lan l.\" in the forwarding process, the crystalline bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent bridge receives each frame on each connected side. the bridge table contains information about the components that are connected to the network. which means that the transparent bridge receives from the component a frame that has the information \"can be reached on the lan l.\" in the turning process, the transparent bridge floods the network with this information, so that other bridges also have information about the component a. a benefit of flooding is that it uses the shortest path of the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug04smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the guileless bridge receives every frame of each connected side. the bridge table holds the information about which parts are bind to the network. that means the guileless bridge receives from the part a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the guileless bridge floods the network with this information, so that other bridges also have the information about part a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug05smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the limpid bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the limpid bridge receives from the component a a frame which has the information \"a can be strain over lan l.\" in the forwarding process, the limpid bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug06smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent nosepiece receives every frame of each connected side. the nosepiece table agree the information about which components are attached to the network. that means the transparent nosepiece receives from the component a a frame which has the information \"a can be strain over lan l.\" in the forwarding process, the transparent nosepiece floods the network with this information, so that other nosepieces also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug07smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every frame of each connected side. the span table holds the entropy about which components are attached to the network. that means the transparent span receives from the component a a frame which has the entropy \"a can be pass over lan l.\" in the forwarding process, the transparent span floods the network with this entropy, so that other spans also have the entropy about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug08smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent bridge receives each frame on each connected side. the bridge table contains information about the components that are connected to the network. which means that the transparent bridge receives from the component a frame that has the information \"can be reached on the lan l.\" in the turning process, the transparent bridge floods the network with this information, so that other bridges also have information about the component a. a benefit of flooding is that it uses the shortest path of the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug09smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the gauzy bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the gauzy bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the gauzy bridge floods the network with this information, so that other bridges also have the information about component a. a welfare of flooding is that it uses the brusk path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug10smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every frame of each connected side. the span table holds the information about which components are attached to the meshing. that means the transparent span receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent span floods the meshing with this information, so that other spans also have the information about component a. a benefit of flooding is that it uses the shortest path in the meshing.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug11smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every physique of each connected side. the span table holds the information about which factors are attached to the network. that means the transparent span receives from the factor a a physique which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent span floods the network with this information, so that other spans also have the information about factor a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0373q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:de a:(a, b, before)(a, c, before)(a, d, fall) // d is not on the unicast path from c to a and f to a. hops 2:de b:(b, e, before)de c:(c, f, fall) // f is not on the unicast path from d, e or g to a hops 3:de e:(e, g, before) hops 4:de g:(g, h, fall) // h is not connected to other nodes (except the receiver node)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:from a:(a, b, forward)(a, c, forward)(a, d, drop) // d is not on unicast path from c to a and f to a.\nhop 2:from b:(b, e, forward)from c:(c, f, drop) // f is not on unicast path from d, e or g to a\nhop 3:from e:(e, g, forward)\nhop 4:from g:(g, h, drop) // h is not connected to further nodes (except the receiving node)",
        "original_sample_id": "smp0373q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0868q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it is not maintained for real Internet traffic.The amount of traffic normally varies throughout the day.Internet traffic is also often broken, so when a package was shipped, more packets with a very short interarrival time will follow for the duration of the explosion.When the explosion is over, for example, because a video data buffer is full, the interarrival time can be much longer than during the explosion.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, it does not hold for real internet traffic. the amount of traffic normally varies throughout the day. internet traffic is also often bursty, so when a packet got sent, more packets with a very short interarrival time will follow for the duration of the burst. when the burst is over, e.g. because a video data buffer is full, the interarrival time can be much higher than during the burst.",
        "original_sample_id": "smp0868q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow mastery on transport level\n\nrecognition mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-room handshake protocol\n+ ds\n- \n\nflow command on transport layer\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncurrent mastery on rapture layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on shipping level\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug04smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-manner handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug05smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncatamenia control on transferral bed\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug06smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on exaltation level\n\nreference mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug07smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on shipping stratum\n\nmention mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug08smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncatamenia control on exaltation bed\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug09smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-agency handshake protocol\n+ ds\n- \n\nmenses control on raptus layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug10smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflowing control on rapture layer\n\ncredit mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug11smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-fashion handshake protocol\n+ ds\n- \n\ncatamenia control on transport stratum\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug12smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow ascendence on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug13smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on transport stratum\n\nquotation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug14smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on shipping bed\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug15smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-room handshake protocol\n+ ds\n- \n\nflow control on transport stratum\n\nquotation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug16smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow controller on transport bed\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug17smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-fashion handshake protocol\n+ ds\n- \n\nmenstruum control on transportation layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug18smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nperiod control on transport layer\n\nrecognition mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug19smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow ascendency on raptus layer\n\ncredit mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug20smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-mode handshake protocol\n+ ds\n- \n\nmenstruum controller on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug21smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncurrent control on transportation layer\n\nrecognition mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug22smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nperiod control on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug23smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on transport level\n\ncite mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0323q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, pearl): d knows that f and c don't receive unicast packets via d\nhop 2:\n(b, e, forward)\n(c, f, pearl): f knows that e, g and d don't receive unicast packets via f.\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, pearl): h received the packet from the only nexus attach to it and can't send it anywhere.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop): d knows that f and c don't receive unicast packets via d\nhop 2:\n(b, e, forward)\n(c, f, drop): f knows that e, g and d don't receive unicast packets via f.\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop): h received the packet from the only link attached to it and can't send it anywhere.",
        "original_sample_id": "smp0323q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1014q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The inverted road shuttle ensures a free loop rotation for multicast multicast packets in multicast routing, in addition to avoiding the replacement of IP addresses on a unicat routing. It works by returning the packet away from the sources to move along the distribution tree and preventing routing loops. Retransmission of inverted routes works at the reception of a multicast package, then a router records the original address of the package and the port in which the package arrives.",
        "answer_feedback": "the response is partially correct. the purpose for only rpf is stated and is also not in the context of the broadcast. the explanation for rpf  and rpb is not complete as the response does not explain how packets are forwarded and based on what information.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.1,
        "original_answer": "reverse path forwarding ensures a loop-free forwarding for multicast packets in multicast routing moreover, it prevents ip address spoofing in a unicast routing. it works by forwarding the packet away from the sources to make progress along the distribution tree and prevents routing loops.  reverse path broadcast works by receiving a multicast packet, then a router records the source address of the packet and the port the packet arrives on.",
        "original_sample_id": "smp1014q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1620q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0 to 127.255,255,255",
        "answer_feedback": "not all addresses in class a are reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "1.0.0.0 up to 127.255.255.255",
        "original_sample_id": "smp1620q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1075q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning tree ensures that all members of the network/radical are reached by using as less links as possible.  link state is modified by the entropy of which is belongs to which radical. so every is knows that it belongs to a certain radical and distributes this entropy in addition to the existing link state distribution packets. based on this entropy, every is can calculate a spanning tree for each radical.",
        "answer_feedback": "though spanning trees have a minimal number of links, the primary reason for them being used in the multicast and broadcast is an avoidance of unnecessary duplicates by removing loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a spanning tree ensures that all members of the network/group are reached by using as less links as possible.  link state is modified by the information of which is belongs to which group. so every is knows that it belongs to a certain group and distributes this information in addition to the existing link state distribution packets. based on this information, every is can calculate a spanning tree for each group.",
        "original_sample_id": "smp1075q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the modest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it demand for the modest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug01smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest bundle is at least 64 bytes, the maximum collision domain diam is calculated by the time it takes for the smallest bundle to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diam is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug02smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 byte, the maximum collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 time.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug03smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the humble package is at least 64 bytes, the maximal collision domain diameter is calculated by the time it takes for the humble package to travel at a sealed speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug04smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest software is at least 64 bytes, the maximum hit sphere diameter is calculated by the time it takes for the smallest software to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit sphere diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug05smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 bytes, the maximal collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increase 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug06smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest parcel is at least 64 bytes, the maximum hit demesne diameter is calculated by the time it takes for the smallest parcel to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit demesne diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug07smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 byte, the maximum collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug08smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the lowly package is at least 64 byte, the maximum collision sphere diameter is calculated by the time it takes for the lowly package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision sphere diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug09smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest package is at least 64 bytes, the maximum collision arena diam is calculated by the time it takes for the smallest package to travel at a sealed speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision arena diam is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug10smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "Since the smallest package is at least 64 bytes, the maximum collision field diameter is calculated by the time it takes to travel at a certain speed. Therefore, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while at 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s., the collision field diameter is therefore increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug11smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "Since the smallest package is at least 64 bytes, the maximum collision field diameter is calculated by the time it takes to travel at a certain speed. Therefore, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while at 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s., the collision field diameter is therefore increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug12smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest software is at least 64 bytes, the maximum hit domain diameter is calculated by the time it takes for the smallest software to travel at a sure speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug13smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest package is at least 64 bytes, the maximum hit domain diam is calculated by the sentence it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit domain diam is increased 100 sentences.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug14smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest parcel is at least 64 bytes, the maximum collision domain diameter is calculated by the time it deal for the smallest parcel to locomote at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug15smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest bundle is at least 64 byte, the maximum collision domain diameter is calculated by the time it takes for the smallest bundle to go at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug16smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest parcel is at least 64 bytes, the maximum collision domain diam is calculated by the time it takes for the smallest parcel to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diam is increase 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug17smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest packet is at least 64 byte, the maximum collision orbit diameter is calculated by the time it takes for the smallest packet to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision orbit diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug18smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest bundle is at least 64 bytes, the maximum hit domain diameter is direct by the time it takes for the smallest bundle to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug19smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the modest package is at least 64 bytes, the maximum collision domain diameter is forecast by the time it takes for the modest package to travel at a sure speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug20smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest package is at least 64 bytes, the maximum hit field diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit field diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug21smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest packet is at least 64 byte, the maximum collision domain diameter is calculated by the clip it takes for the smallest packet to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 clips.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug22smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "Since the smallest package is at least 64 bytes, the maximum collision field diameter is calculated by the time it takes to travel at a certain speed. Therefore, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while at 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s., the collision field diameter is therefore increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug23smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the belittled package is at least 64 bytes, the maximum hit domain diameter is calculated by the time it takes for the belittled package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the hit domain diameter is increase 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug00smp0362q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b, forrard)(a,c, forrard)(a,d, forrard)\nhop 2:\n(b,e,forrard)(b,c,drop) <= b is not on unicast course from c to a(c,b,drop) <= c is not on unicast course from b to a(c,e,drop) <= c is not on unicast course from e to a(c,f,forrard) (c,d,drop) <= c is not on unicast course from d to a(d,c, drop) <= d is not on unicast course from c to a(d,f,drop) <= d is not on unicast course from f to a\nhop 3:\n(e,f, drop) <= e is not on unicast course from f to a(e,g,forrard)(f,e, drop) <= f is not on unicast course from e to a(f,g,drop) <= f is not on unicast course from g to a\nhop 4:\n(g,h,forrard)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,b, forward)(a,c, forward)(a,d, forward)\nhop 2:\n(b,e,forward)(b,c,drop) <= b is not on unicast path from c to a(c,b,drop) <= c is not on unicast path from b to a(c,e,drop) <= c is not on unicast path from e to a(c,f,forward) (c,d,drop) <= c is not on unicast path from d to a(d,c, drop) <= d is not on unicast path from c to a(d,f,drop) <= d is not on unicast path from f to a\nhop 3:\n(e,f, drop) <= e is not on unicast path from f to a(e,g,forward)(f,e, drop) <= f is not on unicast path from e to a(f,g,drop) <= f is not on unicast path from g to a\nhop 4:\n(g,h,forward)",
        "original_sample_id": "smp0362q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1045q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse route forwarding - for sending unicast packages - if the package arrived on the usually sent station, let's suspect that the package used the best route. now it will forward it over all borders, otherwise the package will be discarded reverse route retransmission - it's like reverse route forwarding, but it won't be resented over all borders. it will select the border where the packages arrived and from which they then redirect to the source",
        "answer_feedback": "the response does not state the purpose of rpf and rpb. the rpf explanation is partially correct as the packet should not only arrive at the usual station, it should follow the same route the station would have taken to send a unicast packet to the sender/broadcast source. the rpb explanation is also not complete as it does not describe how best routes are selected for a node, namely through the unicast routing algorithm (e.g. link state) or observing previous unicast traffic.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.4,
        "original_answer": "reverse path forwarding - for sending unicast packets - if the packet arrived over the usually sent station, we will assumpt that the packet used the best route. now it will resend it over all edges, else the packet will be discarded reverse path broadcast - is like reverse path forwarding, but it won't be resent over all edges. it will select the edge at which the packets arrived and from which they are then rerouted to source",
        "original_sample_id": "smp1045q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0891q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "1. What information does the table contain? There is a destination direction and a lan exit line of each frame that reaches a bridge. 2. How is the table changed during the learning phase backwards? as mentioned in the conference, the bridges operate in promiscuo mode, so that the bridges see each frame sent into one of their lans. Looking at the original direction, they can tell which machine is accessible in which lan. 3. How is the table used in the rotation process? When a frame arrives at a bridge, the bridge must decide to abandon it or return it. Looking at the direction of destination of such a frame in a hash table stored on the bridge, you can decide to move away or redeploy it. The table can list each possible destination and tell which exit line belongs to that frame. Therefore, this frame will be transmitted. 4. What is a benefit of this? increases the reliability of the network.",
        "answer_feedback": "the stated benefit is not correct as flooding is more reliable than selective forwarding. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.  what information the table holds? there are destination address and lan output line of each frame that arrives at a bridge. 2. how is the table modified during the backwards learning phase? as mentioned in the lecture, the bridges operate in promiscuous mode, so the bridges see every frame sent on any of their lans. by looking at the source address, they can tell which machine is accessible on which lan. 3. how is the table used in the forwarding process? when a frame arrives at a bridge, the bridge must decide whether to discard or forward it. by looking up the destination address of such frame in a hash table stored in the bridge, it can decide discarding or forwarding. the table can list each possible destination and tell which output line this frame belongs on. accordingly, this frame will be forwarded. 4. what is one benefit of that? it increases the reliability of network.",
        "original_sample_id": "smp0891q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0457q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary tsaps that are unique for each connection. + It is not necessary to store additional information - the process server address method is not possible, as the server is reached by a well-known tsap 2. identify each connection individually by sequence number + solves the problem - the final systems must be able to store sequence number 3. identify each pods by not reset the sequence number for a long time. + solve the problem - wider bandwidth and memory usage",
        "answer_feedback": "solves the problem is not an advantage, it is the purpose. apart from it, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. use temporary tsaps that are unique to each connection.\n+ no additional information needs to be stored\n- process server addressing method not possible, as the server is reached via a well-known tsap\n\n2. identify each connection individually by sequence number \n+ solves the problem \n- endsystems need to be able to store sequence number\n\n3. identify each puds by not resetting sequence number for a long time.\n+ solves the problem\n- higher bandwidth and memory usage",
        "original_sample_id": "smp0457q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0457q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary tsaps that are unique to each connection.\n+ no additional information needs to be stored\n- process server addressing method not possible, as the server is reached via a well-known tsap\n\n2. identify each connection individually by episode number \n+ lick the trouble \n- endsystems need to be able to store episode number\n\n3. identify each puds by not resetting episode number for a long time.\n+ lick the trouble\n- higher bandwidth and memory usage",
        "answer_feedback": "solves the problem is not an advantage, it is the purpose. apart from it, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. use temporary tsaps that are unique to each connection.\n+ no additional information needs to be stored\n- process server addressing method not possible, as the server is reached via a well-known tsap\n\n2. identify each connection individually by sequence number \n+ solves the problem \n- endsystems need to be able to store sequence number\n\n3. identify each puds by not resetting sequence number for a long time.\n+ solves the problem\n- higher bandwidth and memory usage",
        "original_sample_id": "smp0457q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0457q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary tsaps that are unique to each association.\n+ no additional information needs to be stored\n- process waiter addressing method not possible, as the waiter is reached via a well-known tsap\n\n2. identify each association individually by sequence figure \n+ solves the problem \n- endsystems need to be able to store sequence figure\n\n3. identify each puds by not resetting sequence figure for a long time.\n+ solves the problem\n- higher bandwidth and memory usage",
        "answer_feedback": "solves the problem is not an advantage, it is the purpose. apart from it, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. use temporary tsaps that are unique to each connection.\n+ no additional information needs to be stored\n- process server addressing method not possible, as the server is reached via a well-known tsap\n\n2. identify each connection individually by sequence number \n+ solves the problem \n- endsystems need to be able to store sequence number\n\n3. identify each puds by not resetting sequence number for a long time.\n+ solves the problem\n- higher bandwidth and memory usage",
        "original_sample_id": "smp0457q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0457q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary tsaps that are unique for each connection. + It is not necessary to store additional information - the process server address method is not possible, as the server is reached by a well-known tsap 2. identify each connection individually by sequence number + solves the problem - the final systems must be able to store sequence number 3. identify each pods by not reset the sequence number for a long time. + solve the problem - wider bandwidth and memory usage",
        "answer_feedback": "solves the problem is not an advantage, it is the purpose. apart from it, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. use temporary tsaps that are unique to each connection.\n+ no additional information needs to be stored\n- process server addressing method not possible, as the server is reached via a well-known tsap\n\n2. identify each connection individually by sequence number \n+ solves the problem \n- endsystems need to be able to store sequence number\n\n3. identify each puds by not resetting sequence number for a long time.\n+ solves the problem\n- higher bandwidth and memory usage",
        "original_sample_id": "smp0457q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1683q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127).0.0 (0-127).255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0\n(0-127).255.255.255",
        "original_sample_id": "smp1683q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1683q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127).0.0 (0-127).255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0\n(0-127).255.255.255",
        "original_sample_id": "smp1683q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1029q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf and rpb are routing algorithms that use trees that cover, without each node having to know the whole tree. Inverse return: the basic principle is flooding, but not all incoming packets are sent again, but only those that have come from the shortest route. The shortest path is determined by recalling where (where it comes from) the packets that this sender usually comes from. Reverse retransflation: improvement in rpf not only by ignoring packages based on the incoming link, but also by putting packets back into the shortest outgoing connection. The shortest outgoing connection is the connection where the packets destined for the current source normally arrive.",
        "answer_feedback": "the stated purpose is not correct as the objective achieved by using a spanning tree i.e. avoiding loops/duplicates needs to be provided. the explanation for rpf and rpb is correct except that packets are also not forwarded to the node from which they were received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "rpf and rpb are routing algorithms which use spanning trees, without each node having to know the whole tree. reverse path forwarding:  basic principle is flooding, but not all incoming packets are sent out again, but only the ones that came from the shortest path. the shortest path is determined by remembering where (from which is) packets this sender usually come from. reverse path broadcasting: improves on rpf by not only ignoring packets based on the incoming link, but also only forwarding packets on the shortest outgoing connection. the shortest outgoing connection is the connection where packets destined for the current source normally arrive on.",
        "original_sample_id": "smp1029q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1100q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a sweep tree is delineate as an undirected graph where every node in the network can be reached without having any routing loops. hence sweep trees are appealing for broad as well as multicasting due to the efficient transmission to the desired nodes in the network without having packets circling around (no routing loops). the link country routing protocol needs to be expanded by information on multicast groups of the intermediate systems (is). every is needs to know which multicast groups it belongs to but not (initially) how many other is are in the same group as well. all is periodically send link country packets that include the distance to their neighbours as well as the information of their multicast group via broadcast to all the other nodes on the network. finally each is can calculate a multicast tree as well as the outgoing lines on which packets have to be transmitted.",
        "answer_feedback": "the explanation behind using a spanning tree for multicast and broadcast is partially correct because though the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a spanning tree is defined as an undirected graph where every node in the network can be reached without having any routing loops. hence spanning trees are appealing for broad as well as multicasting due to the efficient transmission to the desired nodes in the network without having packets circling around (no routing loops). the link state routing protocol needs to be expanded by information on multicast groups of the intermediate systems (is). every is needs to know which multicast groups it belongs to but not (initially) how many other is are in the same group as well. all is periodically send link state packets that include the distance to their neighbours as well as the information of their multicast group via broadcast to all the other nodes on the network. finally each is can calculate a multicast tree as well as the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1100q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0876q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for the real cyberspace, as traffic in the real cyberspace often occurs in burst rather than as random bundles send at an abitrary time. for example, when loading one file (webpage, video, etc.), there are several consecutive bundles issued, and the likelihood that there is another bundle immediately after another one has been received is therefore much eminent as the propability of one bundle arriving after a longer interval of no arriving bundles.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, this assumption does not hold for the real internet, as traffic in the real internet often occurs in burst rather than as random packets send at an abitrary time. for example, when loading one file (webpage, video, etc.), there are several consecutive packets issued, and the likelihood that there is another packet immediately after another one has been received is therefore much higher as the propability of one packet arriving after a longer interval of no arriving packets.",
        "original_sample_id": "smp0876q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1084q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "These paths are unicast. This property can be used to define a range tree, which contains everything that participates in a multicast group. If a wide/multicast is then sent to one of the nodes, it will distribute the data to all the other nodes in the range tree. These range trees can be calculated with the routing of the link state use the best path (the shortest, the smallest delay, the highest bandwidth, etc.) specific for data transfer. For multicast, the participating nodes all have the same tree of reach (perhaps also other trees) so that it does not matter to which the multicast node is sent, it will always reach each node in the group. for scattering, this range tree simply includes each node in the network.",
        "answer_feedback": "the response is partially correct because it lacks how the link-state routing can be modified to construct the multicast tree. to calculate the spanning trees, you also have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees are individual for every is and are initially not known to other is.  they represent a subnetwork, with one fixed path from this is to every other node in this subnet. these paths are unicast paths. this property can be used to define a spanning tree, which contains all is that participate in a multicast group. if a broad/multicast is then sent to one of the nodes, it will distribute the data to every other node in the spanning tree. these spanning trees can be calculated with link state routing use the best path (shortest, smallest delay, highest bandwidth etc.) specific for data transfer. for multicast, the participating nodes all have the same spanning tree (maybe also other trees) so it does not matter to which node the multicast is sent, it will always reach every node in the group. for broadcasting, this spanning tree simply includes every node in the network.",
        "original_sample_id": "smp1084q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis of independent fish arrivals has been justified by the assertion that the aggregation of many independent and distributed renewal processes identically tends to the fish process when the number increases. fish processes are conventional in the traffic application scenarios that include a large number of independent traffic flows. the theoretical context behind the use comes from the palm theorem (arrowsmith et al. 2015). it indicates that under appropriate but light conditions, a large number of multiplexed fluxes approach a fish process as the number of flows increases. still, individual rates decrease to maintain the aggregate rate constant. but, the aggregation of traffic should not always lead to a fish process.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis of independent fish arrivals has been justified by the assertion that the aggregation of many independent and distributed renewal processes identically tends to the fish process when the number increases. fish processes are conventional in the traffic application scenarios that include a large number of independent traffic flows. the theoretical context behind the use comes from the palm theorem (arrowsmith et al. 2015). it indicates that under appropriate but light conditions, a large number of multiplexed fluxes approach a fish process as the number of flows increases. still, individual rates decrease to maintain the aggregate rate constant. but, the aggregation of traffic should not always lead to a fish process.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug02smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis of independent fish arrivals has been justified by the assertion that the aggregation of many independent and distributed renewal processes identically tends to the fish process when the number increases. fish processes are conventional in the traffic application scenarios that include a large number of independent traffic flows. the theoretical context behind the use comes from the palm theorem (arrowsmith et al. 2015). it indicates that under appropriate but light conditions, a large number of multiplexed fluxes approach a fish process as the number of flows increases. still, individual rates decrease to maintain the aggregate rate constant. but, the aggregation of traffic should not always lead to a fish process.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug03smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically propagate renewal summonses tend to poisson summons when the number increases.\n\npoisson summonses are conventional in dealings application scenarios that include a large number of independent dealings streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson summons as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, dealings aggregation need not always result in a poisson summons. so it holds if the above-mentioned criteria apply.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug04smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis of independent fish arrivals has been justified by the assertion that the aggregation of many independent and distributed renewal processes identically tends to the fish process when the number increases. fish processes are conventional in the traffic application scenarios that include a large number of independent traffic flows. the theoretical context behind the use comes from the palm theorem (arrowsmith et al. 2015). it indicates that under appropriate but light conditions, a large number of multiplexed fluxes approach a fish process as the number of flows increases. still, individual rates decrease to maintain the aggregate rate constant. but, the aggregation of traffic should not always lead to a fish process.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug05smp0879q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption of independent poisson arrivals has been justified by claiming that the assembling of many independent and identically distributed reclamation processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic watercourse. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed watercourse approach a poisson process as the number of watercourse grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic assembling need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "answer_feedback": "the response does not provide an explicit \"yes\" or \"no\". it instead states another underlying condition when the poisson process will hold, without concluding whether it holds for the real internet.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the assumption of independent poisson arrivals has been justified by claiming that the aggregation of many independent and identically distributed renewal processes tend to poisson process when the number increases.\n\npoisson processes are conventional in traffic application scenarios that include a large number of independent traffic streams. the theoretical background behind the usage comes from palm's theorem (arrowsmith et al. 2015). it states that under suitable but mild conditions, such a large number of multiplexed streams approach a poisson process as the number of streams grows. still, the individual rates decrease to keep the aggregate rate constant. but, traffic aggregation need not always result in a poisson process. so it holds if the above-mentioned criteria apply.",
        "original_sample_id": "smp0879q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0353q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\na,b,forward\na,c,forward\na,d,forward\nhop 2:\nb,c,swing <- shortest course is directly to a\nb,e,forward\nc,b,swing <- shortest course is directly to a\nc,d,swing <- shortest course is directly to a\nc,e,swing <- course via b is brusk\nc,f,forward\nd,c,swing <- shortest course is directly to a\nd,f,swing <- course via c is brusk\n\nhop 3:\ne,c,swing <- c directly to a is brusk\ne,f,swing <- course via c is brusk\ne,g,forward\nf,d,swing <- d directly to a is brusk\nf,e,swing <- course via b is brusk\nf,g,swing -> course via e is brusk\n\nhop 4:\ng,h, swing <- no further nodes.",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\na,b,forward\na,c,forward\na,d,forward\nhop 2:\nb,c,drop <- shortest path is directly to a\nb,e,forward\nc,b,drop <- shortest path is directly to a\nc,d,drop <- shortest path is directly to a\nc,e,drop <- path via b is shorter\nc,f,forward\nd,c,drop <- shortest path is directly to a\nd,f,drop <- path via c is shorter\n\nhop 3:\ne,c,drop <- c directly to a is shorter\ne,f,drop <- path via c is shorter\ne,g,forward\nf,d,drop <- d directly to a is shorter\nf,e,drop <- path via b is shorter\nf,g,drop -> path via e is shorter\n\nhop 4:\ng,h, drop <- no further nodes.",
        "original_sample_id": "smp0353q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0774q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "circularise queue treble buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantage. there is no fair allocation of the bandwidth between stations.",
        "answer_feedback": "the response answer is partially correct. it correctly identifies the problem in dqdb but does not explain why stations have an advantage/disadvantage while reserving transmission rights. the reservation depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "distributed queue dual buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "original_sample_id": "smp0774q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0774q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "one station has to book on one bus and send on the other. in some situations the stations have advantages and disadvantages. there is not a fair distribution of bandwidth between the stations.",
        "answer_feedback": "the response answer is partially correct. it correctly identifies the problem in dqdb but does not explain why stations have an advantage/disadvantage while reserving transmission rights. the reservation depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "distributed queue dual buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "original_sample_id": "smp0774q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0774q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "distributed queue dual buses has the problem of bonnieness. a station has to reserve on one bus and send on the other. in some situations stations have reward and disadvantage. there is no bonnie allocation of the bandwidth between stations.",
        "answer_feedback": "the response answer is partially correct. it correctly identifies the problem in dqdb but does not explain why stations have an advantage/disadvantage while reserving transmission rights. the reservation depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "distributed queue dual buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "original_sample_id": "smp0774q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0774q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "distributed queue dual jalopy has the problem of fairness. a station has to reserve on one heap and send on the other. in some situations stations have advantages and disadvantages. there is no fair parcelling of the bandwidth between stations.",
        "answer_feedback": "the response answer is partially correct. it correctly identifies the problem in dqdb but does not explain why stations have an advantage/disadvantage while reserving transmission rights. the reservation depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "distributed queue dual buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "original_sample_id": "smp0774q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0774q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "distributed queue threefold buses has the problem of candor. a station has to reserve on one bus and send on the other. in some situation stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "answer_feedback": "the response answer is partially correct. it correctly identifies the problem in dqdb but does not explain why stations have an advantage/disadvantage while reserving transmission rights. the reservation depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "distributed queue dual buses has the problem of fairness. a station has to reserve on one bus and send on the other. in some situations stations have advantages and disadvantages. there is no fair allocation of the bandwidth between stations.",
        "original_sample_id": "smp0774q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0461q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsaps: limiting the life of packages: a network monitoring switch: advantage: network monitoring switches facilitate the centralization of network traffic monitoring in the noc drawback: network monitoring switches take a simple concept, passive network valve, and make it an expensive and complex device that requires configuration and management.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service need to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17,
        "original_answer": "throw-away tsaps:\nrestrict packet life time:\na network monitoring switch:\nadvantage: network monitoring switches facilitate centralizing network traffic monitoring in the noc.\ndisadvantage: network monitoring switches take a simple concept, the passive network tap, and make it an expensive, complex device that requires configuration and management.",
        "original_sample_id": "smp0461q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0461q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsaps: limiting the life of packages: a network monitoring switch: advantage: network monitoring switches facilitate the centralization of network traffic monitoring in the noc drawback: network monitoring switches take a simple concept, passive network valve, and make it an expensive and complex device that requires configuration and management.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service need to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17,
        "original_answer": "throw-away tsaps:\nrestrict packet life time:\na network monitoring switch:\nadvantage: network monitoring switches facilitate centralizing network traffic monitoring in the noc.\ndisadvantage: network monitoring switches take a simple concept, the passive network tap, and make it an expensive, complex device that requires configuration and management.",
        "original_sample_id": "smp0461q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0461q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "throw-away tsaps:\nrestrict packet life time:\na web monitoring switch:\nreward: web monitoring change facilitate centralizing web traffic monitoring in the noc.\ndisreward: web monitoring change take a simple concept, the passive web tap, and make it an expensive, complex device that requires configuration and management.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service need to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17,
        "original_answer": "throw-away tsaps:\nrestrict packet life time:\na network monitoring switch:\nadvantage: network monitoring switches facilitate centralizing network traffic monitoring in the noc.\ndisadvantage: network monitoring switches take a simple concept, the passive network tap, and make it an expensive, complex device that requires configuration and management.",
        "original_sample_id": "smp0461q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0461q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "throw-away tsaps:\nrestrict packet life time:\na meshwork monitoring shift:\nadvantage: meshwork monitoring shiftes facilitate centralizing meshwork traffic monitoring in the noc.\ndisadvantage: meshwork monitoring shiftes take a simple concept, the passive meshwork tap, and make it an expensive, complex device that involve configuration and management.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service need to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17,
        "original_answer": "throw-away tsaps:\nrestrict packet life time:\na network monitoring switch:\nadvantage: network monitoring switches facilitate centralizing network traffic monitoring in the noc.\ndisadvantage: network monitoring switches take a simple concept, the passive network tap, and make it an expensive, complex device that requires configuration and management.",
        "original_sample_id": "smp0461q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug05smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug06smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug07smp0733q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "There is a problem of equity with dqdbs, where all nodes are allowed to transmit at a certain speed, but when a node is given an offer rate below the permitted limit, this node transmits at the lowest rate while others remain at the maximum permitted rate. This is called rate-controlled equity.",
        "answer_feedback": "the response is incorrect because it identifies the problem of \"fairness\" in the wrong context. \"rate controlled fairness\" is a way to overcome the problem of fairness, when stations at different positions are forced to have the same rate irrespective of their position in the bus, not a problem itself.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there is a fairness problem with dqdbs, where all nodes are allowed to transmit at a certain rate, but when a node is given an offered rate less than the allowed limit, that node transmits at the lower rate while others continue at the maximum allowed rate. this is called rate controlled fairness.",
        "original_sample_id": "smp0733q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0433q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps\n- vantage: solves duplicate problem\n- disvantage: can't adress process servers\n\n2. identify connections individually\n\n- vantage: solves duplicate problem\n- disvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- vantage: high reiteration sentence \n- disvantage: eminent usage of bandwoth and memory",
        "answer_feedback": "removes duplicate is the purpose behind using the method not the advantage. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0433q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0433q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps - advantage: solves the problem in double - disadvantage: you cannot direct the process servers 2. identify the connections individually - advantage: solves the problem in double - disadvantage: endsystems must be able to store this information 3. identify pdus ididially - advantage: high repetition time - disadvantage: increased use of bandwoth and memory",
        "answer_feedback": "removes duplicate is the purpose behind using the method not the advantage. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0433q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0433q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps\n- vantage: solves twin problem\n- disvantage: can't adress process servers\n\n2. identify association individually\n\n- vantage: solves twin problem\n- disvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- vantage: high reiteration time \n- disvantage: higher usage of bandwoth and memory",
        "answer_feedback": "removes duplicate is the purpose behind using the method not the advantage. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0433q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0433q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps\n- vantage: solves duplicate problem\n- disvantage: can't adress summons servers\n\n2. identify connections individually\n\n- vantage: solves duplicate problem\n- disvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- vantage: high reiteration time \n- disvantage: gamey usage of bandwoth and memory",
        "answer_feedback": "removes duplicate is the purpose behind using the method not the advantage. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0433q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1112q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The minimum calibration trees represent the minimum (shortest/lowest cost) connection of all nodes in the network. This is particularly useful for broadcasting/multicasting because we want to transmit packages to several destinations with minimal effort. Assuming that each node has information about the multicast groups to which it belongs, the lsr routing can be extended by including information from the mutlicast group in the periodic broadcasts of link-state packets.",
        "answer_feedback": "spanning trees do not necessarily contain the shortest path between all nodes, only the minimal number of edges. the unique paths between each node minimize the number of duplicates needed. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "minimal spanning trees represent the minimal (shortest/ lowest cost) connection of all nodes in the network. this is especially useful for broadcast/ multicast as we want to transmit packets to multiple destination with minimal effort. assuming that each node has information on the multicast groups it belongs to, lsr routing can be extended by including the mutlicast group information in the periodical link state packet broadcasts. based on this information received from every other node on the network, each node can calculate its own mutlicast tree to determine the routes, via which packets should be distributed.",
        "original_sample_id": "smp1112q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0209q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first, we have to calculate the probability where there are exactly 10 mailboat in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the meter (one minute, or 60 seconds) the system being in a state which there are exactly 10 mailboat waiting in the queue. the amount of this meter should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never outgo 10, then other than 10 mailboat waiting in the buffer, the system will have less than 10 mailboat waiting, and the amount of meter for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first, we have to calculate the probability where there are exactly 10 packets in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the time (one minute, or 60 seconds) the system being in a state which there are exactly 10 packets waiting in the queue. the amount of this time should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 packets waiting in the buffer, the system will have less than 10 packets waiting, and the amount of time for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "original_sample_id": "smp0209q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0209q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first, we have to calculate the probability where there are exactly 10 mailboat in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the land of the system for exactly one minute, then 5.0813731% of the clip (one minute, or 60 seconds) the system being in a land which there are exactly 10 mailboat waiting in the queue. the amount of this clip should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 mailboat waiting in the buffer, the system will have less than 10 mailboat waiting, and the amount of clip for this land would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first, we have to calculate the probability where there are exactly 10 packets in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the time (one minute, or 60 seconds) the system being in a state which there are exactly 10 packets waiting in the queue. the amount of this time should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 packets waiting in the buffer, the system will have less than 10 packets waiting, and the amount of time for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "original_sample_id": "smp0209q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0875q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process that is used to model packet arrivals is not very realistic for real Internet traffic. if packet arrivals are considered for a longer period (through day and night, or through before and after the black Friday period, ...), there will certainly be some intervals with a lot of sequels (on the 1st day or during the black Friday promotion) or a lot of sequels (on the 1st day or before and after the promotion). the other scenario could be possible when considering the arrivals of video transmission packages, with the help of the streaming buffer, the package will arrive continuously for a period of time (when the sequence player prefetches the data and stores them in his own buffer). After that, when the amount of damped data is sufficient, the sequence reader stops from prefetching data then the packet arrivals will cease continuously until the player continues the prefetching process again. Thus, the actual Internet traffic depends to a large extent on the hours of the day and the applications.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the poisson process which is used to model the packet arrivals does not hold very realistically for the real internet traffic. if the packet arrivals are considered over a longer period of time (through day and night, or through the before and after the black friday period, …), there will definitely be some intervals with many consecutive on (1 – during the day or during the black friday promotion) or many consecutive off (0 – during the night time or before and after the promotion). the other scenario could be possible is when the packet arrivals of the video stream is considered, with the help of the streaming buffer, the packet will arrive continually for a period of time (when the stream player prefetches the data and store them in its own buffer). after that, when the amount of buffered data is enough, the stream player stops prefetching data then the packet arrivals are continually off until the player continues the prefetching process again. so, the real internet traffic heavily depends on the times of day and the applications.",
        "original_sample_id": "smp0875q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0875q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process that is used to model packet arrivals is not very realistic for real Internet traffic. if packet arrivals are considered for a longer period (through day and night, or through before and after the black Friday period, ...), there will certainly be some intervals with a lot of sequels (on the 1st day or during the black Friday promotion) or a lot of sequels (on the 1st day or before and after the promotion). the other scenario could be possible when considering the arrivals of video transmission packages, with the help of the streaming buffer, the package will arrive continuously for a period of time (when the sequence player prefetches the data and stores them in his own buffer). After that, when the amount of damped data is sufficient, the sequence reader stops from prefetching data then the packet arrivals will cease continuously until the player continues the prefetching process again. Thus, the actual Internet traffic depends to a large extent on the hours of the day and the applications.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the poisson process which is used to model the packet arrivals does not hold very realistically for the real internet traffic. if the packet arrivals are considered over a longer period of time (through day and night, or through the before and after the black friday period, …), there will definitely be some intervals with many consecutive on (1 – during the day or during the black friday promotion) or many consecutive off (0 – during the night time or before and after the promotion). the other scenario could be possible is when the packet arrivals of the video stream is considered, with the help of the streaming buffer, the packet will arrive continually for a period of time (when the stream player prefetches the data and store them in its own buffer). after that, when the amount of buffered data is enough, the stream player stops prefetching data then the packet arrivals are continually off until the player continues the prefetching process again. so, the real internet traffic heavily depends on the times of day and the applications.",
        "original_sample_id": "smp0875q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1039q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the main purpose of both rearward path forwarding and rearward path broadcast is router initiating broadcast and to reduce copies of bundles in the network. for rearward path forwarding each sender has its own spanning tree but the is do not need to know the spanning tree hence each router has information which path it would use for (unicast)-bundles. each is checks whether a bundle arrived at the is entry port over which the bundles for this station are usually sent. if so we can assume that the best route is used so far and we can continue charge over all edges except the incoming one. if not, discard the package. rearward path broadcast is like rearward path forwarding with specific selection of the outgoing links (instead of recharge over all edges). rearward path broadcast can learn by bundles failing to appear that it is not located on the unicast path and also learn by inspecting the unicast bundles that it is located on the unicast path from destination to sender which helps to get rid of even more copies in the network compared to rearward path forwarding.",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the main purpose of both reverse path forwarding and reverse path broadcast is router initiating broadcast and to reduce copies of packets in the network. for reverse path forwarding each sender has its own spanning tree but the is do not need to know the spanning tree hence each router has information which path it would use for (unicast)-packets. each is checks whether a packet arrived at the is entry port over which the packets for this station are usually sent. if so we can assume that the best route is used so far and we can continue sending over all edges except the incoming one. if not, discard the package. reverse path broadcast is like reverse path forwarding with specific selection of the outgoing links (instead of resending over all edges). reverse path broadcast can learn by packets failing to appear that it is not located on the unicast path and also learn by inspecting the unicast packets that it is located on the unicast path from destination to sender which helps to get rid of even more copies in the network compared to reverse path forwarding.",
        "original_sample_id": "smp1039q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1039q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The main objective of reverse route forwarding and reverse route retransmission is to initiate router retransmission and reduce packet copies on the network. for reverse route forwarding each sender has its own forwarding tree, but it is not necessary to know the forwarding tree, so each router has information about the route it would use for packets (unicast). each one checks if a packet arrived at the input port is the input port on which the packets are usually sent for this station. if we can assume that the best route is used up to now and we can continue to send through all borders except the incoming one. if not, discard the packet. the reverse route retransmission is like re-shipment of inverse routes with a specific selection of outgoing links (instead of forwarding over all borders). the reverse route retransmission can learn by packets that do not appear on the unicat route and also learn by means of the unicat packets inspection that is found in the unicast route from the destination to the sender more copies that help to get rid.",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the main purpose of both reverse path forwarding and reverse path broadcast is router initiating broadcast and to reduce copies of packets in the network. for reverse path forwarding each sender has its own spanning tree but the is do not need to know the spanning tree hence each router has information which path it would use for (unicast)-packets. each is checks whether a packet arrived at the is entry port over which the packets for this station are usually sent. if so we can assume that the best route is used so far and we can continue sending over all edges except the incoming one. if not, discard the package. reverse path broadcast is like reverse path forwarding with specific selection of the outgoing links (instead of resending over all edges). reverse path broadcast can learn by packets failing to appear that it is not located on the unicast path and also learn by inspecting the unicast packets that it is located on the unicast path from destination to sender which helps to get rid of even more copies in the network compared to reverse path forwarding.",
        "original_sample_id": "smp1039q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1653q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0 to 127.255,255,255",
        "answer_feedback": "not all addresses in class a are reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "1.0.0.0 to 127.255.255.255",
        "original_sample_id": "smp1653q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0896q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the span manages a table that includes the information on which output line of the span which station is colligate.\ninitially, the table is empty, so flooding is used to reach the unknown stations. when the span receives frames, it takes the source information combined with the input line it received the frame on. these pieces of information are used to create a table entry.\nif a frame was received from a station, the span knows on which output line to redirect frames to this already known stations, but if the source equals the finish, the frame is dropped.\nthe benefit of this behaviour is that the spans are not visible to other components; this simplifies the network for the other components.",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge manages a table that includes the information on which output line of the bridge which station is connected.\ninitially, the table is empty, so flooding is used to reach the unknown stations. when the bridge receives frames, it takes the source information combined with the input line it received the frame on. these pieces of information are used to create a table entry.\nif a frame was received from a station, the bridge knows on which output line to redirect frames to this already known stations, but if the source equals the destination, the frame is dropped.\nthe benefit of this behaviour is that the bridges are not visible to other components; this simplifies the network for the other components.",
        "original_sample_id": "smp0896q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1489q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "- the requirement for the extension of pig includes the recognition \"ack.\" - contains the sequence-number ack'seq.no) and confirms the frame (seq.no). - here, the ack recognition can be implicitly given by the frames.",
        "answer_feedback": "the response answers the requirement incorrectly. the response states what happens in piggybacking/flow control in general, but a duplex channel is required for it to work.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "- the requirement for the piggybacking extension includes the acknowledgment \"ack\".\n- it contains the sequence-number ack(seq.no) and confirms the frame(seq.no). \n- here, the acknowledgment ack can be given by the frames implicitly.",
        "original_sample_id": "smp1489q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0818q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the most obvious difference between the two headings is the length. while the udp cope consists of 8 bytes (64 bits), the tcp cope has a minimum length of 20 bytes (without options). furthermore, it is possible to append options in the tcp cope, which increases the length of the cope. the additional bytes of the tcp cope length are for the sequence number, acknowledge number, hl/resv/flags, advertised win, urgent pointer and the options. this additional information cannot be found in the udp cope, in particular there is no possibility for options besides the compulsory function of the cope. another difference between the two copes is that the checksum field in the udp cope is optional while the checksum field in the tcp cope is mandatory. the transmitter port ( udp ) and source port ( tcp ) fields behave in the same way. for tcp, a source port is essential for establishing a connection, while the transmitter port for udp only has to be used if a response is expected.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the most obvious difference between the two headings is the length. while the udp header consists of 8 bytes (64 bits), the tcp header has a minimum length of 20 bytes (without options). furthermore, it is possible to append options in the tcp header, which increases the length of the header. the additional bytes of the tcp header length are for the sequence number, acknowledge number, hl/resv/flags, advertised win, urgent pointer and the options. this additional information cannot be found in the udp header, in particular there is no possibility for options besides the compulsory function of the header. another difference between the two headers is that the checksum field in the udp header is optional while the checksum field in the tcp header is mandatory. the sender port ( udp ) and source port ( tcp ) fields behave in the same way. for tcp, a source port is indispensable for establishing a connection, while the sender port for udp only has to be used if a response is expected.",
        "original_sample_id": "smp0818q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0341q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:\n(a, b, onward)\n(a, c, onward)\n(a, d, onward)\n\nskip 2:\n(b, e, onward)\n(c,f, onward)\n\nskip 3:\n(e, g, onward)\n\nskip 4:\n(g, h, drop) <= because h has only one neighbor from which it got the message, h does not onward the message and drop it.",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.5 for reasoning (a,d, drop), (c, f, drop) ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\n(b, e, forward)\n(c,f, forward)\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop) <= because h has only one neighbor from which it got the message, h does not forward the message and drop it.",
        "original_sample_id": "smp0341q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0739q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "there are mainly two problems with distributed queue double motorbus:\n1.there is loveliness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "answer_feedback": "the response answer is partially correct as it identifies the fairness problem in terms of propagation delays and throughput deterioration. however,the fairness problem is based on station location instead.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are mainly two problems with distributed queue dual buses:\n1.there is fairness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "original_sample_id": "smp0739q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0739q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "there are mainly two problems with distributed queue dual charabanc:\n1.there is comeliness problem which is due to propagation delays.\n2.throughput worsening problem with dqdb networks.",
        "answer_feedback": "the response answer is partially correct as it identifies the fairness problem in terms of propagation delays and throughput deterioration. however,the fairness problem is based on station location instead.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are mainly two problems with distributed queue dual buses:\n1.there is fairness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "original_sample_id": "smp0739q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0739q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "there are mainly two troubles with distributed queue treble buses:\n1.there is fairness trouble which is due to propagation holdup.\n2.throughput deterioration trouble with dqdb networks.",
        "answer_feedback": "the response answer is partially correct as it identifies the fairness problem in terms of propagation delays and throughput deterioration. however,the fairness problem is based on station location instead.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are mainly two problems with distributed queue dual buses:\n1.there is fairness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "original_sample_id": "smp0739q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0739q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "there are mainly two jobs with distributed queue duple buses:\n1.there is blondness job which is due to propagation delays.\n2.throughput deterioration job with dqdb networks.",
        "answer_feedback": "the response answer is partially correct as it identifies the fairness problem in terms of propagation delays and throughput deterioration. however,the fairness problem is based on station location instead.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are mainly two problems with distributed queue dual buses:\n1.there is fairness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "original_sample_id": "smp0739q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0739q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "there are chiefly two jobs with distributed queue dual buses:\n1.there is fairness job which is due to propagation delays.\n2.throughput impairment job with dqdb networks.",
        "answer_feedback": "the response answer is partially correct as it identifies the fairness problem in terms of propagation delays and throughput deterioration. however,the fairness problem is based on station location instead.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are mainly two problems with distributed queue dual buses:\n1.there is fairness problem which is due to propagation delays.\n2.throughput deterioration problem with dqdb networks.",
        "original_sample_id": "smp0739q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0837q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no. typically users dont use internet overhaul continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in realism bundle may depend on other bundle e.g. with tcp traffic.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like non-continuous internet use over the day. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no. typically users dont use internet services continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "original_sample_id": "smp0837q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0837q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no. typically applyrs dont apply internet services continuesly throughout the whole day (and nighttime), but in relatively short bursts. so this framework would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like non-continuous internet use over the day. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no. typically users dont use internet services continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "original_sample_id": "smp0837q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0337q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,forward)\nhop 2:\n(b,c,dip) <= already bewilder packet\n(b,e,forward)\n(c,b,dip) <= already bewilder packet\n(c,e,dip) <= not shortest path\n(c,d,dip) <= already bewilder packet\n(c,f,foward)\n(d,c,dip) <= already bewilder packet\n(d,f,dip) <= not shortest path\nhop 3:\n(e,b,dip) <= already bewilder packet\n(e,c,dip) <= already bewilder packet\n(e,f,dip) <= already bewilder packet\n(e,g,forward)\n\n(f,d,dip) <= already bewilder packet\n(f,e,dip) <= already bewilder packet\n(f,c,dip) <= already bewilder packet\n(f,g,dip) <= not shortest path\nhop 4:\n(g,e,dip) <= already bewilder packet\n(g,f,dip) <= already bewilder packet\n(g,h,forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,forward)\nhop 2:\n(b,c,drop) <= already got packet\n(b,e,forward)\n(c,b,drop) <= already got packet\n(c,e,drop) <= not shortest path\n(c,d,drop) <= already got packet\n(c,f,foward)\n(d,c,drop) <= already got packet\n(d,f,drop) <= not shortest path\nhop 3:\n(e,b,drop) <= already got packet\n(e,c,drop) <= already got packet\n(e,f,drop) <= already got packet\n(e,g,forward)\n\n(f,d,drop) <= already got packet\n(f,e,drop) <= already got packet\n(f,c,drop) <= already got packet\n(f,g,drop) <= not shortest path\nhop 4:\n(g,e,drop) <= already got packet\n(g,f,drop) <= already got packet\n(g,h,forward)",
        "original_sample_id": "smp0337q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1697q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 bis 0.255.255,255 sind standard-path (host) 127.0.0 bis 127.255,255,255 loop",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 bis 0.255.255.255 sind standard-route (host)\n127.0.0.0 bis 127.255.255.255 loopback",
        "original_sample_id": "smp1697q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0908q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the associations between stations and lans. for every received soma, an concord table entry with the soma’s origin address and the lan it was received from, is created. if the origin and destination lans of a received soma are identical it gets dropped, otherwise the soma is rerouted to the destination lan. if the destination is unknown the bridge floods all other lans. a benefit of that is that the bridge is not visible as such for other components of the network, hence the term transparent, what simplifies them.",
        "answer_feedback": "the stated benefit is related to the transparent bridge but the question asked for the benefit of using bridge table information which is to reduce duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table holds the associations between stations and lans. for every received frame, an according table entry with the frame’s source address and the lan it was received from, is created. if the source and destination lans of a received frame are identical it gets dropped, otherwise the frame is rerouted to the destination lan. if the destination is unknown the bridge floods all other lans. a benefit of that is that the bridge is not visible as such for other components of the network, hence the term transparent, what simplifies them.",
        "original_sample_id": "smp0908q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0898q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds no data intitially i.e. it is empty. during backward learning, the nosepiece works in promiscuous mode to receive any frame on any of its lans. then. the nosepiece receives frames with source address q on lan l. q can be reached over l, and the nosepiece produce table entry accordingly.  the table is used to learn about the new devices that are plugged into the network. the advantage is that this can dilute overall network congestion.",
        "answer_feedback": "the table information is used to perform selective forwarding instead of flooding, which is not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table holds no data intitially i.e. it is empty. during backward learning, the bridge works in promiscuous mode to receive any frame on any of its lans. then. the bridge receives frames with source address q on lan l. q can be reached over l, and the bridge creates table entry accordingly.  the table is used to learn about the new devices that are plugged into the network. the advantage is that this can reduce overall network congestion.",
        "original_sample_id": "smp0898q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1518q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the next successiveness-number and the next ack-successiveness-number to be expected must be given or computable. furthermore, the data physique have to consist of an ack discipline.",
        "answer_feedback": "the response answers the requirement correctly as a separate acknowledgment field is a must for piggybacking. the other points are more related to window sliding in general.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the next sequence-number and the next ack-sequence-number to be expected must be given or computable. furthermore, the data frames have to consist of an ack field.",
        "original_sample_id": "smp1518q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1018q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "If this is the case, there is no transfer to avoid loops. Inverse path routing (also referred to as reverse path flooding) (rpf) is a variation of the method tree. Each sender has its range tree. Other nodes do not have to know the range tree. the hypothesis is that each router knows which path he would use for packages. The rpf algorithm checks if a packet has arrived at the port of entry on which the packets of this station are usually also sent. If yes, then the algorithm assumes that the packet has gone the best path until a node reaches it first by the shortest route, everything that does not need to use the best route.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and broadcast are methods for broadcast routing. they enable improved flooding: it is checked whether a copy of a data unit has been received. if this is the case, no forwarding takes place to avoid loops. reverse path forwarding (also called reverse path flooding) (rpf) is a variation of the method spanning tree. each sender has its spanning tree. the other nodes don't have to know the spanning tree. the assumption is that each router knows which path it would use for packets.  the rpf algorithm checks whether a packet arrived at the is entry port over which the packets for this station are usually also sent. if yes, then the algorithm assumes the packet went the best path until now and resends the packet to all edges but the incoming one. if not, it assumes that the packet is a duplicate and didn't use the best route. this duplicate is then not forwarded but discarded. the significant advantage of this algorithm is its simple implementation. if a node assumes that a packet will reach it first by the shortest route, all that needs to be done is to ensure that a receiver can detect duplicates. as soon as a duplicate is received, it is assumed that the shortest route did not receive the packet, and it is not forwarded. the disadvantage of this method is that some nodes receive the packet unnecessarily several times. the reverse path broadcast (rpb) is like rpf but with a specific selection of outgoing links. after the first check, the algorithm checks if the packet used the best route until then. if yes, it selects the edge at which the packets arrived and from which they are then rerouted to source s. if not, it won't send over all edges. reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path concerning the interface on which the multicast packets are received but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to decide about forwarding, the routers must be informed about the shortest paths.",
        "original_sample_id": "smp1018q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1018q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "If this is the case, there is no transfer to avoid loops. Inverse path routing (also referred to as reverse path flooding) (rpf) is a variation of the method tree. Each sender has its range tree. Other nodes do not have to know the range tree. the hypothesis is that each router knows which path he would use for packages. The rpf algorithm checks if a packet has arrived at the port of entry on which the packets of this station are usually also sent. If yes, then the algorithm assumes that the packet has gone the best path until a node reaches it first by the shortest route, everything that does not need to use the best route.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and broadcast are methods for broadcast routing. they enable improved flooding: it is checked whether a copy of a data unit has been received. if this is the case, no forwarding takes place to avoid loops. reverse path forwarding (also called reverse path flooding) (rpf) is a variation of the method spanning tree. each sender has its spanning tree. the other nodes don't have to know the spanning tree. the assumption is that each router knows which path it would use for packets.  the rpf algorithm checks whether a packet arrived at the is entry port over which the packets for this station are usually also sent. if yes, then the algorithm assumes the packet went the best path until now and resends the packet to all edges but the incoming one. if not, it assumes that the packet is a duplicate and didn't use the best route. this duplicate is then not forwarded but discarded. the significant advantage of this algorithm is its simple implementation. if a node assumes that a packet will reach it first by the shortest route, all that needs to be done is to ensure that a receiver can detect duplicates. as soon as a duplicate is received, it is assumed that the shortest route did not receive the packet, and it is not forwarded. the disadvantage of this method is that some nodes receive the packet unnecessarily several times. the reverse path broadcast (rpb) is like rpf but with a specific selection of outgoing links. after the first check, the algorithm checks if the packet used the best route until then. if yes, it selects the edge at which the packets arrived and from which they are then rerouted to source s. if not, it won't send over all edges. reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path concerning the interface on which the multicast packets are received but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to decide about forwarding, the routers must be informed about the shortest paths.",
        "original_sample_id": "smp1018q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1501q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "1. the receiver is supposed to wait inadequate than the sender’s timeout period, otherwise, the build will be resent by the sender.\n2. a fresh build should arrives quickly enough, so that the ack could be piggybacked onto it, otherwise, only the current build would be acknowledged.",
        "answer_feedback": "both stated points are correct independently and imply a duplex connection too.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. the receiver is supposed to wait shorter than the sender’s timeout period, otherwise, the frame will be resent by the sender.\n2. a new frame should arrives quickly enough, so that the ack could be piggybacked onto it, otherwise, only the current frame would be acknowledged.",
        "original_sample_id": "smp1501q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding, because it has a good use of bandwidth, which can solve the traffic problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding, because it has a good use of bandwidth, which can solve the traffic problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding, because it has a good use of bandwidth, which can solve the traffic problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding, because it has a good use of bandwidth, which can solve the traffic problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encryption,because it has salutary employment of the bandwidth ,which can solve traffic problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encryption,because it has good utilization of the bandwidth ,which can lick dealings problem.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encryption,because it has full utilization of the bandwidth ,which can solve traffic job.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encryption,because it has good utilization of the bandwidth ,which can solve dealings job.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug08smp0165q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encryption,because it has dear utilization of the bandwidth ,which can solve traffic job.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "bianry encoding,because it has good utilization of the bandwidth ,which can solve traffic problem.",
        "original_sample_id": "smp0165q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are unite at least one other, all client can be reached. constructing a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are relate at least one other, all client can be reached. constructing a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug02smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are connected at least one other, all client can be reached. constructing a span tree: first measuring the distance to the neighbors, organize your package(send the distance), all client do the calculation which aloofness are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug03smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all guest are connected at least one other, all guest can be reached. constructing a cross tree: first measuring the space to the neighbors, organize your package(send the space), all guest do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug04smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are connected at least one other, all client can be reached. retrace a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug05smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all nodes are join at least one other, all nodes can be reached. constructing a spanning tree: first measuring the aloofness to the neighbors, orchestrate your package(send the aloofness), all nodes do the calculation which aloofnesss are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0346q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1: (a,b,forward) (a,c,forward) (a,d,drop) f does not receive unicast packages by d so that d does not transmit a message from a to f hop 2: (b,e,forward) (c,f,drop) g does not receive unicast packages per f so that f does not transmit a message from a to g hop 3: (e,g,forward) hop 4: (g,h,drop) h only has a neighbour to get the message",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop) f doesn't receive unicast packets by d so d won't forward a message from a to f\nhop 2:\n(b,e,forward)\n(c,f,drop) g doesn't receive unicast packets by f so f won't forward a message from a to g\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop) h has only one neighbour to get the message",
        "original_sample_id": "smp0346q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1677q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 refer to the current meshwork\n10.0.0.0/8 is a individual meshwork range\n127.0.0.0/8 is used for localhost as loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8 refers to the current network\n10.0.0.0/8 is a private network range\n127.0.0.0/8 is used for localhost as loopback",
        "original_sample_id": "smp1677q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1096q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "If there are no loops, duplicates cannot be produced. Link status packages need to be extended by information about multicast groups. in lsr each has complete information about network status. with this information each node can calculate its own multicast tree.",
        "answer_feedback": "the response correctly identifies the appealing property of a spanning tree for broadcast and multicast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees have no loops, that makes them interesting for broad- and multicasts. if there are no loops, no duplicates can occur.  the link state packets need to be extended by the information on multicast groups. in lsr each is has complete information about the network state. with this information each node can calculate its own multicast spanning tree.",
        "original_sample_id": "smp1096q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1096q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees have no loops, that makes them interesting for broad- and multicasts. if there are no loops, no duplicates can happen.  the link state packets need to be extended by the entropy on multicast groups. in lsr each is has complete entropy about the network state. with this entropy each node can calculate its own multicast sweep tree.",
        "answer_feedback": "the response correctly identifies the appealing property of a spanning tree for broadcast and multicast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees have no loops, that makes them interesting for broad- and multicasts. if there are no loops, no duplicates can occur.  the link state packets need to be extended by the information on multicast groups. in lsr each is has complete information about the network state. with this information each node can calculate its own multicast spanning tree.",
        "original_sample_id": "smp1096q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0855q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This hypothesis is not supported for real Internet traffic. time intervals are very small, while Internet traffic (for example, starting to see a video of youtube where the buffer is filled.) can have a long duration. therefore the probability of arrival of packages, in the time band directly after a time band with the arrival of packages is larger, than in the time band where your predecessor did not have any packet arrivals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold for real internet traffic. time intervals are very small, while internet traffic (for example start watching a youtube video where the buffer is filled.) may have a long duration. therefore the probability of packet arrival, in the timeslot directly after a timeslot with packet arrival is higher, than in the timeslot where its predecessor had no packet arrival.",
        "original_sample_id": "smp0855q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1504q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Therefore, the media has to provide a duplex operation. If the sender expects a response containing data, the response itself can be seen as an implicit recognition.",
        "answer_feedback": "the response answers the underlying requirement correctly. however, by implicit acknowledgment, one implies a data frame received as a response from the receiver contains an acknowledgment of previously sent packet/packets.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking only makes sense in a two-way communication with both participants sending data packets to each other. therefore, the communication medium has to provide duplex operation.\nif the sender expects an answer which contains data the answer itself can be seen as an implicit acknowledgement.",
        "original_sample_id": "smp1504q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1617q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "x.0.0.0, x.255.255, wobei x eine zahl zwischen 0 und 127 ist.",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "x.0.0.0, x.255.255.255, wobei x eine zahl zwischen 0 und 127 ist.",
        "original_sample_id": "smp1617q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1617q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "x.0.0.0, x.255.255, wobei x eine zahl zwischen 0 und 127 ist.",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "x.0.0.0, x.255.255.255, wobei x eine zahl zwischen 0 und 127 ist.",
        "original_sample_id": "smp1617q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0127q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Manchester encoding",
        "answer_feedback": "incorrect and no reasoning provided. the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "manchester encoding",
        "original_sample_id": "smp0127q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0127q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Manchester encoding",
        "answer_feedback": "incorrect and no reasoning provided. the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "manchester encoding",
        "original_sample_id": "smp0127q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1686q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0 - 127.255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0\n127.0.0.0 – 127.255.255.255",
        "original_sample_id": "smp1686q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0226q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "supposition: a is the rate of arrival of the package, b is the rate of service of the package on average, c = a / b step 1. the size buffer is 10, which is finished and. depending on the rate of arrival of the package and the rate of service of the package on average, it is clear that a = 9, b = 10, c = a / b = 0.9. step 2. it is necessary to calculate the time in one minute that there are less than 10 packages, so n = 10. step 3. calculate by blocking the probability that the system is full. apply the parameters we get pb is about 0.05. step 4. because the observation lasts exactly one minute, this means the probability that the system is full is 0.05, that is three seconds ago that the system is in a state where there are less than 10 packages in the queue.",
        "answer_feedback": "the response states the number of seconds where the system has 10 packets waiting in the queue while the question requirement is to calculate the number of seconds where the system has less than 10 packets.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "assumption: a is packet arrival rate, b is packet served rate on average, c = a / b\nstep 1. the buffer of size is 10, which is finite and. according to the packet arrival rate and packet served rate on average, it is clear that a = 9, b = 10, c = a / b = 0.9.\nstep 2. it is required to calculate time in one minute that there are less than 10 packets, therefore n = 10.\nstep 3. calculate by blocking probability we could know the probability that the system is full. apply the parameters we get pb is approximately 0.05.\nstep 4. because the observation lasts for exactly one minute, it means the probability that the system is full is 0.05, i.e. that there are three seconds that the system is in a state in which there are less less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0226q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0226q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "presumptuousness: a is mailboat reaching rate, b is mailboat served rate on average, c = a / b\nstep 1. the buffer of size is 10, which is finite and. according to the mailboat reaching rate and mailboat served rate on average, it is clear that a = 9, b = 10, c = a / b = 0.9.\nstep 2. it is required to calculate time in one minute that there are less than 10 mailboats, therefore n = 10.\nstep 3. calculate by blocking probability we could know the probability that the system is full. apply the parameters we get pb is approximately 0.05.\nstep 4. because the observation lasts for exactly one minute, it means the probability that the system is full is 0.05, i.e. that there are three seconds that the system is in a state in which there are less less than 10 mailboats waiting in the queue.",
        "answer_feedback": "the response states the number of seconds where the system has 10 packets waiting in the queue while the question requirement is to calculate the number of seconds where the system has less than 10 packets.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "assumption: a is packet arrival rate, b is packet served rate on average, c = a / b\nstep 1. the buffer of size is 10, which is finite and. according to the packet arrival rate and packet served rate on average, it is clear that a = 9, b = 10, c = a / b = 0.9.\nstep 2. it is required to calculate time in one minute that there are less than 10 packets, therefore n = 10.\nstep 3. calculate by blocking probability we could know the probability that the system is full. apply the parameters we get pb is approximately 0.05.\nstep 4. because the observation lasts for exactly one minute, it means the probability that the system is full is 0.05, i.e. that there are three seconds that the system is in a state in which there are less less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0226q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0226q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "supposition: a is the rate of arrival of the package, b is the rate of service of the package on average, c = a / b step 1. the size buffer is 10, which is finished and. depending on the rate of arrival of the package and the rate of service of the package on average, it is clear that a = 9, b = 10, c = a / b = 0.9. step 2. it is necessary to calculate the time in one minute that there are less than 10 packages, so n = 10. step 3. calculate by blocking the probability that the system is full. apply the parameters we get pb is about 0.05. step 4. because the observation lasts exactly one minute, this means the probability that the system is full is 0.05, that is three seconds ago that the system is in a state where there are less than 10 packages in the queue.",
        "answer_feedback": "the response states the number of seconds where the system has 10 packets waiting in the queue while the question requirement is to calculate the number of seconds where the system has less than 10 packets.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "assumption: a is packet arrival rate, b is packet served rate on average, c = a / b\nstep 1. the buffer of size is 10, which is finite and. according to the packet arrival rate and packet served rate on average, it is clear that a = 9, b = 10, c = a / b = 0.9.\nstep 2. it is required to calculate time in one minute that there are less than 10 packets, therefore n = 10.\nstep 3. calculate by blocking probability we could know the probability that the system is full. apply the parameters we get pb is approximately 0.05.\nstep 4. because the observation lasts for exactly one minute, it means the probability that the system is full is 0.05, i.e. that there are three seconds that the system is in a state in which there are less less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0226q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process is based on probabilities based on packages that arrive at random, based on t indepedent. each interval is independent of the previous intervals, so that the arrivals are memory-free. the same situation is for Internet. here we have the server/client application, web server, streaming clients that have different and random arrivals of packages that can be modelled as fish process.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the poisson outgrowth is found on probabilities found on randomly arriving packets, found on t indepedent.\nevery separation is independent to the previous separations, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson outgrowth.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug02smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process is based on probabilities based on packages that arrive at random, based on t indepedent. each interval is independent of the previous intervals, so that the arrivals are memory-free. the same situation is for Internet. here we have the server/client application, web server, streaming clients that have different and random arrivals of packages that can be modelled as fish process.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug03smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process is based on probabilities based on packages that arrive at random, based on t indepedent. each interval is independent of the previous intervals, so that the arrivals are memory-free. the same situation is for Internet. here we have the server/client application, web server, streaming clients that have different and random arrivals of packages that can be modelled as fish process.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug04smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process is based on probabilities based on packages that arrive at random, based on t indepedent. each interval is independent of the previous intervals, so that the arrivals are memory-free. the same situation is for Internet. here we have the server/client application, web server, streaming clients that have different and random arrivals of packages that can be modelled as fish process.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug05smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the fish process is based on probabilities based on packages that arrive at random, based on t indepedent. each interval is independent of the previous intervals, so that the arrivals are memory-free. the same situation is for Internet. here we have the server/client application, web server, streaming clients that have different and random arrivals of packages that can be modelled as fish process.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0892q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds entries to what terminus can be reached over which path. it is created empty. in the backwards learning process the nosepiece receives any data from any of its networks and safes that the sender can be reached over that path it sent the data. the table has a decision procedure, where it etiher drops a frame, sends it to the terminus or has to flood the whole network because it doesnt fuck where the terminus is. the table essentially holds a spanning tree, which has the benefit of having only the needed paths saved in it.",
        "answer_feedback": "the response correctly describes how transparent bridges build their bridge table. however, the stated benefit is incorrect. the spanning tree is used only when multiple bridges are used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table holds entries to what destination can be reached over which path. it is created empty. in the backwards learning process the bridge receives any data from any of its networks and safes that the sender can be reached over that path it sent the data. the table has a decision procedure, where it etiher drops a frame, sends it to the destination or has to flood the whole network because it doesnt know where the destination is. the table essentially holds a spanning tree, which has the benefit of having only the needed paths saved in it.",
        "original_sample_id": "smp0892q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0933q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "a bridge table humps through which lan connected to itself can reach the specific station. if the bridge receives a shape on a connected lan, it will hump this lan can be used to get to the source station of this shape. if source and destination lans are very, bridges will drop the shape, if they are different, shape is rerouted to destination lan. if bridge doesn’t hump the destination, it will use flooding. benefit: increase reliability, connect lans via various bridges in parallell.",
        "answer_feedback": "the response incorrectly mentions the benefit of using multiple transparent bridges but the question asked for the benefit of using bridging information in forwarding frames. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a bridge table knows through which lan connected to itself can reach the specific station. if the bridge receives a frame on a connected lan, it will know this lan can be used to get to the source station of this frame. if source and destination lans are identical, bridges will drop the frame, if they are different, frame is rerouted to destination lan. if bridge doesn’t know the destination, it will use flooding. benefit: increase reliability, connect lans via various bridges in parallell.",
        "original_sample_id": "smp0933q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1024q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the inverse path is a variation of the tree of the span. each sender has his tree of span won. so if a node revives something from one of his links, he checks the source address(example :a) and compares to his own table, if he would send something to one: wold i uses the same link for that? if that's the case, the node knows that this is the optimal link for this direction. →sumption package has used the best rout so far→resend to all the edges next to the incoming. if this is not the case →sumption package this is not the optimal route →discard the package because it is probably a useless duplicate.",
        "answer_feedback": "the response does not state the purpose for both. the assumption behind them is that the packet used the best route\nuntil now for sending unicast packets to the broadcast source. the remaining explanation for rpf and rpb is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "reverse path forwarding is a variation of the spanning tree.\n\neach sender has its won spanning tree. so if a node revives something from one of its links it checks the source adress( example :a) and compares with its own table, if it would send something to a: wold i use the same link for that ?\n\nif that is the case the node knows that this is the optimal link for this direction.\n\n→assumtion package used the best rout until now→resend to all edges beside the incoming one.\nif that is not the case →assumtion this is not the optimal route →discard the package because it is likely a unnecessary duplicate. \nreverse path broadcasting is similar. but instead of sending it everywhere, after coming from the optimal rout, you send it only to the link that you would use to get to this destination.\nassumtion for both systems is that everything is working correct and everyone knows the directions the need to send",
        "original_sample_id": "smp1024q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1114q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend allow to model nodes, store and update information about nearby intermediate stations (s) and to determine and calculate wide and multicast routes on the march. link routing of the state to build a multicasting extension tree - allowing all intermediate stations (s) to send regularly connecting state packets to neighbours and multicast groups. using transmission to and from others, each one is calculated its multicast tree, which can be used to determine outgoing lines or new routes on which packets can be transmitted.",
        "answer_feedback": "though the stated information about a spanning tree may be true in certain cases, it is not the main reason why a spanning tree is used in the multicast and broadcast algorithm. the correct property is the absence of loops, thereby reducing unnecessary duplicates. the description of modification related to the link state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees make it convenient to model nodes, store and update information about neighboring intermediate stations (is) and determine and compute broad and multicast routes on the go. link state routing to construct a spanning tree for multicasting - by allowing all intermediate stations (is) to send link state packets about neighbors and multicast groups periodically. using broadcast to and from others, each is calculates its multicast tree, which can be used to determine outgoing lines or new routes on which packets can be transmitted.",
        "original_sample_id": "smp1114q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0391q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1: (a,c,forward) (a,b,forward) (a,d,forward) hop2: (b,e,forward) (c,f,forward) (c,d,drop)-> a package cannot be redirected (d,f,drop)-> a package cannot be redirected hop3: (e,g,forward) (e,f,forward) (f,g,drop) -> a package cannot be redirected hop4: (g,h,drop) -> a package cannot be redirected 7 packages",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. one need to provide the reason why the packet is not forwarded or dropped.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.5,
        "original_answer": "hop1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop2:\n(b,e,forward)\n(c,f,forward)\n(c,d,drop )-> a packet can't be forwarded \n(d,f,drop)-> a packet can't be forwarded \nhop3:\n(e,g,forward)\n(e,f,forward)\n(f,g,drop) -> a packet can't be forwarded \nhop4:\n(g,h,drop) -> a packet can't be forwarded \n\n7packets",
        "original_sample_id": "smp0391q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0800q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "recognition number (ack number) = tcp uses this to send checks of received packets. sequence number = tcp uses this to keep the sequence in the transmissions as well as to identify lost packages urgent pointer (tcp) = point that some data is very urgent in a segment sender port in udp is optional, while in tcp the sender and receiver port is required. moreover udp and tcp use different port numbers",
        "answer_feedback": "the response correctly identifies and states the four differences between tcp and udp headers. the port numbers are more of a general dissimilarity of tcp and udp.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "acknowledgement number (ack. no.) = tcp uses this to send verifications of received packets. sequence number = tcp uses this to maintain the sequence in the transmissions as well as for identifying lost packets urgent pointer (tcp) = point that some data is very urgent in a segment sender port in udp is optional, while in tcp the sender and receiver port is required. moreover udp and tcp use different port numbers",
        "original_sample_id": "smp0800q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the added probabilities of 0,1,..,9 mailboat waiting in the queue, we can just calculate the probability that 10 mailboat are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate equilibrium equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this lead in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the lend probabilities of 0,1,..,9 packets look in the queue, we can just calculate the probability that 10 packets are look in the queue (=fender is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite fender of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the added probabilities of 0,1,..,9 package waiting in the queue, we can just calculate the probability that 10 package are waiting in the queue (=pilot is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate counterpoise equation. since we have a finite pilot of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0225q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first we need to calculate the forget probability (prob. that the scheme is full) with n=10 and rho = 9/10. this results in a forget probability of 0,05. \n\ngiven the forget probability we can calculate the probability that the scheme is not full. therefore we use 1 - forget probability and get 0,95. if we procreate this probability with 60 seconds the scheme is 57 seconds in a state in which there are less than 10 packets waiting.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first we need to calculate the blocking probability (prob. that the system is full) with n=10 and rho = 9/10. this results in a blocking probability of 0,05. \n\ngiven the blocking probability we can calculate the probability that the system is not full. therefore we use 1 - blocking probability and get 0,95. if we multiply this probability with 60 seconds the system is 57 seconds in a state in which there are less than 10 packets waiting.",
        "original_sample_id": "smp0225q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0225q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first we need to calculate the blocking chance (prob. that the organisation is full) with n=10 and rho = 9/10. this results in a blocking chance of 0,05. \n\ngiven the blocking chance we can calculate the chance that the organisation is not full. therefore we expend 1 - blocking chance and get 0,95. if we multiply this chance with 60 seconds the organisation is 57 seconds in a state in which there are less than 10 packets waiting.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first we need to calculate the blocking probability (prob. that the system is full) with n=10 and rho = 9/10. this results in a blocking probability of 0,05. \n\ngiven the blocking probability we can calculate the probability that the system is not full. therefore we use 1 - blocking probability and get 0,95. if we multiply this probability with 60 seconds the system is 57 seconds in a state in which there are less than 10 packets waiting.",
        "original_sample_id": "smp0225q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1527q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "- need a reckoninger \n- because if receiver have no frame to transmit, the transmitter will never get an ack for his transmited frames\n- so when a frame is received, the receiver have no frame to transmit and the reckoning is ended, the receiver transmit a ack",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. the stated-point is more of an optimizing technique rather than a requirement.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "- need a counter \n- because if receiver have no frame to send, the sender will never get an ack for his sended frames\n- so when a frame is received, the receiver have no frame to send and the count is ended, the receiver send a ack",
        "original_sample_id": "smp1527q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0845q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption does not hold for the real internet traffic.\ndatum packets are often sent in bursts or packet trains, especially in applications such as watercourseing. therefore, over a gamy time scale the probability of multiple arrivals of datum packets one after another is high and no longer independent from one another. on the flip side, the chance that no arrival happens in an interval deltat is gamy, if there has not been an arrival in the previous interval. \nin watercourseing for instance, multiple datum packets are sent in bursts and buffered at the receiver to reliably guarantee a steady video watercourse.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold for the real internet traffic.\ndata packets are often sent in bursts or packet trains, especially in applications such as streaming. therefore, over a higher time scale the probability of multiple arrivals of data packets one after another is high and no longer independent from one another. on the flip side, the chance that no arrival happens in an interval deltat is higher, if there has not been an arrival in the previous interval. \nin streaming for instance, multiple data packets are sent in bursts and buffered at the receiver to reliably guarantee a steady video stream.",
        "original_sample_id": "smp0845q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0934q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table in a transparent bridge contains the information on which the exit line of a station z can be reached and the chronometers of when the last frame entry of a station has been received. the table operates in promiscuous mode, which means that it receives any frame of one of its connected lans and records the information on which the lan a station has sent its data. the table is also scanned periodically and purified from all the old entries. during the return process, if the incoming source lan and the lan destination of its table are identical, the frame is dropped, if the incoming source lan and the lan destination of its table differ the frame is rerouted according to its table and if the lan destination is unknown, the frame is flooded at each connected exit line. the advantages of this type of return process are high speed, that the bridge itself is not visible to the rest of the network, which simplifies other components of the network and finally that the bridges are not affected by a different network topology.",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge table in a transparent bridge holds the information over which output line a station z can be reached and the timestamps of when the last frame entry from a station has been received. \nthe bridge works in promiscuous mode, which means that it receives any frame from any of its connected lans and saves the information over which lan a station has sent its data. \nthe table is also scanned periodically and purged of any old entries. \nduring the forwarding process, if the incoming source lan and destination lan from its table are identical, the frame is dropped, if the incoming source lan and destination lan from its table differ the frame is rerouted according to its table and if the destination lan is unknown the frame is flooded to every connected output line. \nthe advantages of this kind of forwarding process are high speed, that the bridge itself is not visible to the rest of the network, which simplifies other components of the network and lastly that the bridges are not affected by a different network topology.",
        "original_sample_id": "smp0934q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0897q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa contains the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new mesa entry is add. in the forwarding process, the bridge receives a frame with a destination address, it looks up the mesa and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's mesa, flooding between the network can be reduced/avoided.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table contains the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new table entry is added. in the forwarding process, the bridge receives a frame with a destination address, it looks up the table and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's table, flooding between the networks can be reduced/avoided.",
        "original_sample_id": "smp0897q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0897q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa carry the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new mesa entry is added. in the forwarding appendage, the bridge receives a frame with a destination address, it looks up the mesa and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's mesa, flooding between the networks can be reduced/avoided.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table contains the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new table entry is added. in the forwarding process, the bridge receives a frame with a destination address, it looks up the table and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's table, flooding between the networks can be reduced/avoided.",
        "original_sample_id": "smp0897q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0897q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the different stations with knowledge in which they are located. the bridges receive a frame with the direction of origin q in lan l and you then know that the station q can be reached on lan l. a new entry of table is added. in the turning process, the bridge receives a frame with a direction of destination, looks up the table and can return the package to the correct lan. a benefit of this technique is that after the entrance exists on the bridge table, the floods between the networks can be reduced/avoided.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table contains the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new table entry is added. in the forwarding process, the bridge receives a frame with a destination address, it looks up the table and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's table, flooding between the networks can be reduced/avoided.",
        "original_sample_id": "smp0897q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0897q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the different stations with knowledge in which they are located. the bridges receive a frame with the direction of origin q in lan l and you then know that the station q can be reached on lan l. a new entry of table is added. in the turning process, the bridge receives a frame with a direction of destination, looks up the table and can return the package to the correct lan. a benefit of this technique is that after the entrance exists on the bridge table, the floods between the networks can be reduced/avoided.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table contains the different stations with knowledge in which lan they are located. the bridges receive a frame with the source address q on lan l and then knows, that station q can be reached over lan l. a new table entry is added. in the forwarding process, the bridge receives a frame with a destination address, it looks up the table and can forward the package into the correct lan. a benefit of this technique is, that after the entry exists in the bridge's table, flooding between the networks can be reduced/avoided.",
        "original_sample_id": "smp0897q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1027q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse itinerary forwarding (rpf) and  reverse itinerary broadcasting (rpb) are techniques used for multi- and broadcast communication. their purpose is to reduce network load in comparison to more rudimentary approaches for broadcast routing like flooding, by utilizing the information each is can gain from looking at unicast routing itinerarys and therefore only forward mailboats which are on the best route so far.   in reverse itinerary forwarding, each sender maintains its own spanning tree derived from information gathered during normal unicast operation. if a unicast mailboat from a to c passes a router b frequently, b knows that it is on the shortest itinerary from a to c and reverse. if, on the other hand, a router d never sees any unicast mailboats from a to c, or reverse, it knows, that it is not on a shortest itinerary. this information is then used when a flooding mailboat from a or c (sender) arrives at either c or d (is). only if the is is on the shortest itinerary, it forwards the mailboat.   reverse itinerary broadcasting is an improvement of reverse itinerary forwarding. not only does it evaluate the shortest itinerary according to the is entry port, where it get the multicast mailboats like rpf does, but also influences how the mailboats are then forwarded to the outgoing edges. in contrast to rpf, which just sends the mailboat over all edges except the incoming one if the mailboat has arrived at the is entry port over which the mailboats for this station are usually sent, i.e. the best route, rpb attempts to send the mailboat only over suitable edges. namely those edges, from which it usually receives unicast mailboats in the reverse direction, because that indicates the best possible route.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) and  reverse path broadcasting (rpb) are techniques used for multi- and broadcast communication. their purpose is to reduce network load in comparison to more rudimentary approaches for broadcast routing like flooding, by utilizing the information each is can gain from looking at unicast routing paths and therefore only forward packets which are on the best route so far.   in reverse path forwarding, each sender maintains its own spanning tree derived from information gathered during normal unicast operation. if a unicast packet from a to c passes a router b frequently, b knows that it is on the shortest path from a to c and reverse. if, on the other hand, a router d never sees any unicast packets from a to c, or reverse, it knows, that it is not on a shortest path. this information is then used when a flooding packet from a or c (sender) arrives at either c or d (is). only if the is is on the shortest path, it forwards the packet.   reverse path broadcasting is an improvement of reverse path forwarding. not only does it evaluate the shortest path according to the is entry port, where it received the multicast packets like rpf does, but also influences how the packets are then forwarded to the outgoing edges. in contrast to rpf, which just sends the packet over all edges except the incoming one if the packet has arrived at the is entry port over which the packets for this station are usually sent, i.e. the best route, rpb attempts to send the packet only over suitable edges. namely those edges, from which it usually receives unicast packets in the reverse direction, because that indicates the best possible route.",
        "original_sample_id": "smp1027q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1027q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Inverse transmission is an improvement of the reverse path. Not only does the shortest path be evaluated according to the input method, but it also receives the input package, which is the one that sends the input package, but it is the one that sends the input package. Inverse transmission is an improvement of the inverse path. Not only does the shortest path be evaluated according to the input method, but also the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the input package, the reversion package, the retransmission package, the retransmission package, is an improvement of the inverse way.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) and  reverse path broadcasting (rpb) are techniques used for multi- and broadcast communication. their purpose is to reduce network load in comparison to more rudimentary approaches for broadcast routing like flooding, by utilizing the information each is can gain from looking at unicast routing paths and therefore only forward packets which are on the best route so far.   in reverse path forwarding, each sender maintains its own spanning tree derived from information gathered during normal unicast operation. if a unicast packet from a to c passes a router b frequently, b knows that it is on the shortest path from a to c and reverse. if, on the other hand, a router d never sees any unicast packets from a to c, or reverse, it knows, that it is not on a shortest path. this information is then used when a flooding packet from a or c (sender) arrives at either c or d (is). only if the is is on the shortest path, it forwards the packet.   reverse path broadcasting is an improvement of reverse path forwarding. not only does it evaluate the shortest path according to the is entry port, where it received the multicast packets like rpf does, but also influences how the packets are then forwarded to the outgoing edges. in contrast to rpf, which just sends the packet over all edges except the incoming one if the packet has arrived at the is entry port over which the packets for this station are usually sent, i.e. the best route, rpb attempts to send the packet only over suitable edges. namely those edges, from which it usually receives unicast packets in the reverse direction, because that indicates the best possible route.",
        "original_sample_id": "smp1027q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0220q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the organization is in 10 mailboat wait state. \n60s - 3.05s = 56.95 seconds",
        "answer_feedback": "the response correctly calculates the non-blocking time but it does not state why we are following the stated steps, i.e. why p_10 was calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the system is in 10 packet waiting state. \n60s - 3.05s = 56.95 seconds",
        "original_sample_id": "smp0220q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0220q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the organization is in 10 parcel waiting country. \n60s - 3.05s = 56.95 seconds",
        "answer_feedback": "the response correctly calculates the non-blocking time but it does not state why we are following the stated steps, i.e. why p_10 was calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the system is in 10 packet waiting state. \n60s - 3.05s = 56.95 seconds",
        "original_sample_id": "smp0220q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0220q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the organisation is in 10 bundle waiting land. \n60s - 3.05s = 56.95 seconds",
        "answer_feedback": "the response correctly calculates the non-blocking time but it does not state why we are following the stated steps, i.e. why p_10 was calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "p_10 = ((1-0.9)*0.9^10) / (1-0.9^(10+1)) * 60s = 3.05s the system is in 10 packet waiting state. \n60s - 3.05s = 56.95 seconds",
        "original_sample_id": "smp0220q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0895q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the deck table stores, which accessible lan connects which parameter. it is empty at the beginning and is filled when the packets arrive at the deck. if the bridge receives a packet on a lan, it checks the source ip. now it knows, that this computer is accessible via this specific lan and stores the information in the deck table. the return process implements 3 different decisions based on the incoming packet, target ip and information in the deck table: 1. destination lan unknown target -> packet distributed 2. destination lan== source lan -> drop-down package 3. destination lan is known and different from source lan -> packet advanced to destination lan",
        "answer_feedback": "the response correctly specifies the fields in the bridging table, how the table is modified during backward learning and used for selective forwarding. the response, however, does not mention the benefit of selective forwarding derived from using the bridging table.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge table stores, which accessible lan connects which endpoint. it is empty at first and is filled when packets arrive at the bridge. if the bridge receives a packet over one lan, it checks the source ip. now it knows, that this computer is reachable via this specific lan and stores the information in the bridge table.\nthe forwarding process implements 3 different decision based on the incoming packet, the target ip and the information in the bridge table:\n1. destination lan of target unknown -> broadcast packet\n2. destination lan == source lan -> drop packet\n3. destination lan is known and different from source lan\n    -> forward packet to destination lan",
        "original_sample_id": "smp0895q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unsustain connectionless service\n- sustain connectionless service\n- connection-oriented service\n\nthe difference betweed sustain and unsustain connectionless service is, that with the sustain variant, the receiver sends an acknowledgement to the transmitter, after he receives a correct frame. this way the transmitter experience if he has to resend a frame. in the unsustain variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where transmitter and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that transmitter and receiver can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unconfirmed associationless service\n- confirmed associationless service\n- association-oriented service\n\nthe difference betweed confirmed and unconfirmed associationless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the associationless and association-oriented services is, that with the association-oriented variant, there are three phases of communication. first the association phase where sender and receiver get ready, then the data transfer phase, where the literal data is transferred and then a disassociation phase, so that sender and receiver can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unconfirmed associationless avail\n- confirmed associationless avail\n- association-oriented avail\n\nthe difference betweed confirmed and unconfirmed associationless avail is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, flesh can get lost.\n\nthe difference between the associationless and association-oriented avails is, that with the association-oriented variant, there are three phases of communication. first the association phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disassociation phase, so that sender and receiver can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- service without connection confirmed - service without connection confirmed - service oriented to the connection the difference between the service without connection confirmed and the service without connection not confirmed is, that with the variant confirmed, the receiver sends a acknowledgement of receipt to the sender, after receiving a correct frame. in this way the sender knows if it has to forward a frame. in the variant not confirmed, the frames can be lost. the difference between the services without connection and oriented to the connection is, that with the variant oriented to the connection, there are three phases of communication. first the phase of connection where the sender and the receiver are prepared, then the phase of data transfer, where the actual data are transferred and then a phase of disconnection, so that the sender and the receiver can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unconfirmed joiningless service\n- confirmed joiningless service\n- joining-orientate service\n\nthe difference betweed confirmed and unconfirmed joiningless service is, that with the confirmed variant, the recipient sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the joiningless and joining-orientate services is, that with the joining-orientate variant, there are three phases of communication. first the joining phase where sender and recipient get ready, then the data transfer phase, where the actual data is transferred and then a disjoining phase, so that sender and recipient can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0702q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unaffirm connectionless service\n- affirm connectionless service\n- connection-oriented service\n\nthe difference betweed affirm and unaffirm connectionless service is, that with the affirm variant, the receiver sends an acknowledgement to the transmitter, after he receives a correct frame. this way the transmitter knows if he has to resend a frame. in the unaffirm variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where transmitter and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that transmitter and receiver can agree to end the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first difference is about acknowledgements and the second difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe difference betweed confirmed and unconfirmed connectionless service is, that with the confirmed variant, the receiver sends an acknowledgement to the sender, after he receives a correct frame. this way the sender knows if he has to resend a frame. in the unconfirmed variant, frames can get lost.\n\nthe difference between the connectionless and connection-oriented services is, that with the connection-oriented variant, there are three phases of communication. first the connection phase where sender and receiver get ready, then the data transfer phase, where the actual data is transferred and then a disconnection phase, so that sender and receiver can agree to end the communication.",
        "original_sample_id": "smp0702q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0859q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption is not 100% applicable due to the fact that there are packages that depend on each other as tcp packages.In this case, to establish a tcp connection, the specific packages have to be sent, which are strictly dependent on each other.If we have a tcp connection, which starts at t time and ends at t+n time, there are some packages in this time period, which are dependent on each other.",
        "answer_feedback": "indeed, the assumption doesn’t hold for real internet traffic. however, the explanation is incorrect because many packets may arrive at a queue so that a specific tcp connection will likely not significantly influence the arrival probabilities.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "this assumption is not 100% applicable due to the fact, that there are packets which are dependent on each other like tcp packets. in this case, in order to estabilish a tcp connection, pecific packets have to be sent, which are strict dependent on each other. if we have a tcp connection, which starts at time t and ends at time t+n, there are some packets in this time period, which are dependent on each other.",
        "original_sample_id": "smp0859q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0859q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption is not 100% applicable due to the fact that there are packages that depend on each other as tcp packages.In this case, to establish a tcp connection, the specific packages have to be sent, which are strictly dependent on each other.If we have a tcp connection, which starts at t time and ends at t+n time, there are some packages in this time period, which are dependent on each other.",
        "answer_feedback": "indeed, the assumption doesn’t hold for real internet traffic. however, the explanation is incorrect because many packets may arrive at a queue so that a specific tcp connection will likely not significantly influence the arrival probabilities.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "this assumption is not 100% applicable due to the fact, that there are packets which are dependent on each other like tcp packets. in this case, in order to estabilish a tcp connection, pecific packets have to be sent, which are strict dependent on each other. if we have a tcp connection, which starts at time t and ends at time t+n, there are some packets in this time period, which are dependent on each other.",
        "original_sample_id": "smp0859q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1514q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for the piggybacking extension the transmitter and receiver must mail datum at the same time. so it needs a full duplex operation to mail the datum.",
        "answer_feedback": "the response answers the underlying requirement correctly. however, sending data at the same time is not a must.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "for the piggybacking extension the sender and receiver must send data at the same time. so it needs a full duplex operation to send the data.",
        "original_sample_id": "smp1514q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0358q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(b, a, onwards)\n(c, a, onwards)\n\nhop 2:\n(e, c, drop) <= going over c to a is not on the ripe course from e to a\n\n(f, d, drop) <= going over d to a is not on the ripe course from f to a\n(e, b, onwards)\n(f, c, onwards)\n\nhop 3:\n\n(g, e, onwards)\n(g, f, drop) <= going over f to a is not on the ripe course from g to a\n\n\n\n\nhop 4:\n(h, g, onwards)",
        "answer_feedback": "the notation is (sender, receiver, forward/drop), not (receiver, sender, forward/drop). (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.3,
        "original_answer": "hop 1:\n(b, a, forward)\n(c, a, forward)\n\nhop 2:\n(e, c, drop) <= going over c to a is not on the best path from e to a\n\n(f, d, drop) <= going over d to a is not on the best path from f to a\n(e, b, forward)\n(f, c, forward)\n\nhop 3:\n\n(g, e, forward)\n(g, f, drop) <= going over f to a is not on the best path from g to a\n\n\n\n\nhop 4:\n(h, g, forward)",
        "original_sample_id": "smp0358q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1632q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 for legion\n127.255.255.255 for local meshing\n127.0.0.0 - 127.255.255.254 reserve for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 for host\n127.255.255.255 for local network\n127.0.0.0 - 127.255.255.254 reserved for loopback",
        "original_sample_id": "smp1632q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0903q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa entranceway each hold a timestamp, the address of the sender, and the lan from which it came. if a bridge receives a frame it looks up its mesa if the the address address is in there. if it is, it sends the frame to the appropriate lan, otherwise it uses flooding (therefore sending the frame to every network despite the one from the sender). to accomodate network changes, old entranceway are purged from the mesa after a couple of minutes a machine didnt send something.",
        "answer_feedback": "the response does not mention how these entries are learned in the backward learning process and what is the benefit derived from using the bridge table in selective forwarding. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the table entries each hold a timestamp, the address of the sender, and the lan from which it came. if a bridge receives a frame it looks up its table if the the destination address is in there. if it is, it sends the frame to the appropriate lan, otherwise it uses flooding (therefore sending the frame to every network despite the one from the sender). to accomodate network changes, old entries are purged from the table after a couple of minutes a machine didnt send something.",
        "original_sample_id": "smp0903q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1664q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "all directions between 10.0.0.0 and 10.255.255.255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "every addresses between \n10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1664q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1664q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "all directions between 10.0.0.0 and 10.255.255.255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "every addresses between \n10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1664q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0917q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information which the stations are accessible on which the lans attached. in the learning phase back the bridge receives frames from any lan and stores the source information from which it comes, to use it for future transmission when this address is used as a destination. these table entries are used to transmit incoming frames only to the lan on which the destination is accessible. or do not do so at all if it already comes from this lan. the advantage is that the frames do not need to be flooded to all the lans attached and the table can be updated with each incoming frame. (no additional routing mechanism required)",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the information which stations are reachable over which of the attached lans.\nin the backwards learning phase the bridge receives frames from any lan and stores the source information from which lan it is coming from, to use it for future forwarding when this address is used as destination.\nthis table entries are used to forward incoming frames only to the lan over which the destination is reachable. or do not forward it at all if it is already coming from this lan.\nthe benefit is that frames do not need to be flooded to all attached lans and the table can be updated with every incoming frame.(no additional routing mechanism needed)",
        "original_sample_id": "smp0917q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0917q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information which the stations are accessible on which the lans attached. in the learning phase back the bridge receives frames from any lan and stores the source information from which it comes, to use it for future transmission when this address is used as a destination. these table entries are used to transmit incoming frames only to the lan on which the destination is accessible. or do not do so at all if it already comes from this lan. the advantage is that the frames do not need to be flooded to all the lans attached and the table can be updated with each incoming frame. (no additional routing mechanism required)",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the information which stations are reachable over which of the attached lans.\nin the backwards learning phase the bridge receives frames from any lan and stores the source information from which lan it is coming from, to use it for future forwarding when this address is used as destination.\nthis table entries are used to forward incoming frames only to the lan over which the destination is reachable. or do not forward it at all if it is already coming from this lan.\nthe benefit is that frames do not need to be flooded to all attached lans and the table can be updated with every incoming frame.(no additional routing mechanism needed)",
        "original_sample_id": "smp0917q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0917q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information which the stations are accessible on which the lans attached. in the learning phase back the bridge receives frames from any lan and stores the source information from which it comes, to use it for future transmission when this address is used as a destination. these table entries are used to transmit incoming frames only to the lan on which the destination is accessible. or do not do so at all if it already comes from this lan. the advantage is that the frames do not need to be flooded to all the lans attached and the table can be updated with each incoming frame. (no additional routing mechanism required)",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the information which stations are reachable over which of the attached lans.\nin the backwards learning phase the bridge receives frames from any lan and stores the source information from which lan it is coming from, to use it for future forwarding when this address is used as destination.\nthis table entries are used to forward incoming frames only to the lan over which the destination is reachable. or do not forward it at all if it is already coming from this lan.\nthe benefit is that frames do not need to be flooded to all attached lans and the table can be updated with every incoming frame.(no additional routing mechanism needed)",
        "original_sample_id": "smp0917q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0917q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the information which stations are approachable over which of the attached lans.\nin the backwards learning phase the nosepiece receives frames from any lan and stores the source information from which lan it is coming from, to use it for future forwarding when this address is used as destination.\nthis table entries are used to forward incoming frames only to the lan over which the destination is approachable. or do not forward it at all if it is already coming from this lan.\nthe benefit is that frames do not need to be flooded to all attached lans and the table can be updated with every incoming frame.(no extra routing mechanism needed)",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the information which stations are reachable over which of the attached lans.\nin the backwards learning phase the bridge receives frames from any lan and stores the source information from which lan it is coming from, to use it for future forwarding when this address is used as destination.\nthis table entries are used to forward incoming frames only to the lan over which the destination is reachable. or do not forward it at all if it is already coming from this lan.\nthe benefit is that frames do not need to be flooded to all attached lans and the table can be updated with every incoming frame.(no additional routing mechanism needed)",
        "original_sample_id": "smp0917q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0883q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it does not. in the real Internet traffic, there are gusts / peaks with a large quantity of packages delivered simultaneously. These peak phases are likely to last more than a time interval (for example, if an application requires a large amount of data), so that arrivals in a time interval and arrivals in the previous / next interval are interdependent and therefore not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, it does not. in real internet traffic, there are bursts / peaks with a high amount of packages delivered simultaneously. these peak phases are likely to last more than only one time interval (e.g. if an application requests a lot of data), so the arrivals in one time interval and the arrivals in the previous / next interval are correlated and therefore not independent.",
        "original_sample_id": "smp0883q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1013q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpb is a rpf modification. in rpf each is to decide whether to forward an incoming package through all outgoing links based on information if the package arrived on the link that is normally used to send unicat packages to the source. in rpb this decision is also made but, the package is only forwarded on specific links, in the reverse form the packages are normally forwarded in unicat communications. rpb reduces the duplicates more than rpf, but also becomes less reliable.",
        "answer_feedback": "in both algorithms, the packet is also not forwarded to the edge from which it was received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.9,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are both routing algorithms for broadcasting. they both try to reduce the duplicates in comparison to flooding, by implicitly building a spanning tree. rpb is a modification of rpf. in rpf each is decides whether it forwards an incoming packet via all outgoing links based on the information if the packet arrived over the link that is usually used to send unicast packets to the source. in rpb this decision is also made but, the packet is then only forwarded on specific links, in the reverse way packages are forwarded normally in unicast communications. rpb reduces duplicates more than rpf, but also becomes less reliable.",
        "original_sample_id": "smp1013q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1053q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of reverse path forwarding (rpf) is the prevention of grummet in a network when a multicast is sent from a guest. it works in the way that each guest has the knowledge about which guest it would use for sending a unicast mailboat due to unicast routing algorithms. when a multicast mailboat arrives at a guest’s entry port, the guest would forward the mailboat to all other guests (except for the one where the mailboat arrived) only if the guest would also use this very guest for sending the incoming mailboats to its source. otherwise, the mailboat is discarded because it is most likely a duplicate. the purpose of reverse path broadcast is to send a broadcast over the network without the occurrence of grummet. it works in a similar way like rpf but here, a receiving guest doesn’t forward the mailboat to all other guests. a receiving guest instead only forwards the mailboat to the guest it would also send a unicast mailboat to.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. rpf avoids loops not only in multicast but also in the broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) is the prevention of loops in a network when a multicast is sent from a node. it works in the way that each node has the knowledge about which node it would use for sending a unicast packet due to unicast routing algorithms. when a multicast packet arrives at a node’s entry port, the node would forward the packet to all other nodes (except for the one where the packet arrived) only if the node would also use this very node for sending the incoming packets to its source. otherwise, the packet is discarded because it is most likely a duplicate. the purpose of reverse path broadcast is to send a broadcast over the network without the occurrence of loops. it works in a similar way like rpf but here, a receiving node doesn’t forward the packet to all other nodes. a receiving node instead only forwards the packet to the node it would also send a unicast packet to.",
        "original_sample_id": "smp1053q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1053q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of rearward path forwarding (rpf) is the prevention of loops in a web when a multicast is sent from a thickening. it works in the way that each thickening has the knowledge about which thickening it would use for sending a unicast packet due to unicast routing algorithms. when a multicast packet arrives at a thickening’s entry port, the thickening would forward the packet to all other thickenings (except for the one where the packet arrived) only if the thickening would also use this very thickening for sending the incoming packets to its source. otherwise, the packet is discarded because it is most likely a duplicate. the purpose of rearward path broadcast is to send a broadcast over the web without the occurrence of loops. it works in a similar way like rpf but here, a receiving thickening doesn’t forward the packet to all other thickenings. a receiving thickening instead only forwards the packet to the thickening it would also send a unicast packet to.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. rpf avoids loops not only in multicast but also in the broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) is the prevention of loops in a network when a multicast is sent from a node. it works in the way that each node has the knowledge about which node it would use for sending a unicast packet due to unicast routing algorithms. when a multicast packet arrives at a node’s entry port, the node would forward the packet to all other nodes (except for the one where the packet arrived) only if the node would also use this very node for sending the incoming packets to its source. otherwise, the packet is discarded because it is most likely a duplicate. the purpose of reverse path broadcast is to send a broadcast over the network without the occurrence of loops. it works in a similar way like rpf but here, a receiving node doesn’t forward the packet to all other nodes. a receiving node instead only forwards the packet to the node it would also send a unicast packet to.",
        "original_sample_id": "smp1053q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1622q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 bis 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 bis 10.255.255.255",
        "original_sample_id": "smp1622q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1622q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 bis 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 bis 10.255.255.255",
        "original_sample_id": "smp1622q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1650q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0, 127.255.255.255",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0, 127.255.255.255",
        "original_sample_id": "smp1650q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0784q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "• udp lintel (8 bytes) is humble than the tcp lintel (20 bytes) • tcp lintel can comprise optional informations, udp lintel cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "answer_feedback": "the response correctly states three differences, but the fourth difference regarding length is partially correct as the tcp header length varies from 20 to 60 bytes. additionally, the third difference regarding connection maintenance is slightly unclear, and a more specific term or the field's names should be used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "• udp header (8 bytes) is smaller than the tcp header (20 bytes) • tcp header can contain optional informations, udp header cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "original_sample_id": "smp0784q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0784q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "• udp lintel (8 byte) is modest than the tcp lintel (20 byte) • tcp lintel can contain optional informations, udp lintel cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "answer_feedback": "the response correctly states three differences, but the fourth difference regarding length is partially correct as the tcp header length varies from 20 to 60 bytes. additionally, the third difference regarding connection maintenance is slightly unclear, and a more specific term or the field's names should be used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "• udp header (8 bytes) is smaller than the tcp header (20 bytes) • tcp header can contain optional informations, udp header cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "original_sample_id": "smp0784q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0784q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "• the udp header (8 bytes) is smaller than the tcp header (20 bytes) • the tcp header can contain optional information, the udp header song • the tcp has fields for the maintenance of the connection, the udp does not do so because its offline • the tcp has aack and sequence number, the udp does not because it does not provide reliable transport",
        "answer_feedback": "the response correctly states three differences, but the fourth difference regarding length is partially correct as the tcp header length varies from 20 to 60 bytes. additionally, the third difference regarding connection maintenance is slightly unclear, and a more specific term or the field's names should be used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "• udp header (8 bytes) is smaller than the tcp header (20 bytes) • tcp header can contain optional informations, udp header cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "original_sample_id": "smp0784q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0784q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "• the udp header (8 bytes) is smaller than the tcp header (20 bytes) • the tcp header can contain optional information, the udp header song • the tcp has fields for the maintenance of the connection, the udp does not do so because its offline • the tcp has aack and sequence number, the udp does not because it does not provide reliable transport",
        "answer_feedback": "the response correctly states three differences, but the fourth difference regarding length is partially correct as the tcp header length varies from 20 to 60 bytes. additionally, the third difference regarding connection maintenance is slightly unclear, and a more specific term or the field's names should be used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "• udp header (8 bytes) is smaller than the tcp header (20 bytes) • tcp header can contain optional informations, udp header cant • tcp has fields for connection maintenance, udp doesnt because its connectionless • tcp has a ack and sequence number, udp doesnt because it doesnt provide reliable transport",
        "original_sample_id": "smp0784q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1073q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the tree that extends is especially interesting for the width and multicasting because it has all the network without any loop, which reduces traffic, which is very important especially for the width and multicasting due to the high load of the network. link state routing can be used to produce the trees that extend in that way, which measure the distances of all the neighbors, which are then distributed to all the other nodes. once each node has all the information about all the delays between them, all can calculate the trees that spread optimally for themselves.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast. the explanation for modifying the link-state algorithm is incomplete because, firstly, there is no mention of how the packets are expanded to contain additional multicast information. and secondly, each node has information about the network topology and multicast-group in the end, not about delays as stated in the response.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the spanning tree is espescially interesting for broad and multicasting because it has the whole network without any loop, that reduces traffic, which is very important espescially for broad and multicasting because of the high network load. link state routing can be used to produce the spanning trees in that way, that you measure the distances of all the neighbours, which you then distribute to all other nodes. once every node has all the information about all the delays between them, they can all calculate the optimale spanning trees for themselfs.",
        "original_sample_id": "smp1073q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0821q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. there are sequence numbers in tcp lintel, in udp there are not sequence numbers. 2. there are acknownledgement numbers in tcp lintel, while in udp dont. 3. udp lintel do not have urgent arrow, but tcp lintel have such thing. 4. udp lintel do not contain various kinds of flags, tcp lintel have flags.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. there are sequence numbers in tcp headers, in udp there are not sequence numbers. 2. there are acknownledgement numbers in tcp headers, while in udp dont. 3. udp headers do not have urgent pointer, but tcp headers have such thing. 4. udp headers do not contain various kinds of flags, tcp headers have flags.",
        "original_sample_id": "smp0821q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1047q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding: if a knob receives a packet which it should forward further, it determines, if the packet transmitter is in the direction of the incoming packet. if yes, the packet is on the best route and is sent via all other edges except the incoming. otherwise, it's ignored, because it's moste likely a duplicate. reverse path broadcast behaves similar in selecting if the packet should be forward. but, instead of sending it to all other knobs, it does not forward the packets to another knob, if it knows that it is not on the best route for this given source and destination.",
        "answer_feedback": "the response correctly explains rpb. the purpose of rpf and rpb to reduce duplicates in the network while broadcasting is missing. the explanation of rpf is partially correct as \"being in the direction of the incoming packet\" does not mean it is on the best route. each node has a routing table stemming from unicast routing algorithms to check whether it would send a packet to the source using the incoming link.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "reverse path forwarding: if a node receives a packet which it should forward further, it determines, if the packet sender is in the direction of the incoming packet. if yes, the packet is on the best route and is sent via all other edges except the incoming. otherwise, it's ignored, because it's moste likely a duplicate. reverse path broadcast behaves similar in selecting if the packet should be forwarded. but, instead of sending it to all other nodes, it does not forward the packets to another node, if it knows that it is not on the best route for this given source and destination.",
        "original_sample_id": "smp1047q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1672q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.* 127.*",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.*\n127.*",
        "original_sample_id": "smp1672q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0866q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption is too strong for real internet traffic. the probability that you get another mailboat after you received one is much eminent as e.g. video applications might fetch the next seconds of the video into the local buffer which causes a number of mailboats. after buffering a segment of the video, there is no traffic until the next video segment is fetched which again causes more traffic. furthermore, circumstances like the time of the daytime influence the traffic in different ways.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, this assumption is too strong for real internet traffic. the probability that you get another packet after you received one is much higher as e.g. video applications might fetch the next seconds of the video into the local buffer which causes a number of packets. after buffering a segment of the video, there is no traffic until the next video segment is fetched which again causes more traffic. furthermore, circumstances like the time of the day influence the traffic in different ways.",
        "original_sample_id": "smp0866q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1505q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "duplex operation must be supported. that signify sending datum from both sides should be possible. and each side is able to encounter datum also.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "duplex operation must be supported. that means sending data from both sides should be possible. and each side is able to receive data also.",
        "original_sample_id": "smp1505q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1498q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking requires a two way datum communication between two parties (a and b). this essential exists, because instead of both parties immediately sending acknowledgement-frames to each other when\nthey recieve a datum-mailboat, they include the acknowledgement in the next datum-mailboats header. this means that, when a sends a datum-mailboat to b, b has to answer at some time with datum to fulfill the\nessential for an acknowledgement.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking requires a two way data communication between two parties (a and b). this requirement exists, because instead of both parties immediately sending acknowledgement-frames to each other when\nthey recieve a data-packet, they include the acknowledgement in the next data-packets header. this means that, when a sends a data-packet to b, b has to answer at some time with data to fulfill the\nrequirement for an acknowledgement.",
        "original_sample_id": "smp1498q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0244q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this can be calculated by using the blocking chance which is the chance for that the arrangement is full (slide 31 in script).  for the given arrangement this result in a chance of 0.05 using n=10 and lambda=9 and µ=10 as parameters. so the inverse chance saying that the arrangement has less than 10 packets in the waiting queue is 1-0.05=0.95. \nas a result of this we anticipate the arrangement to be for 0.95*60s=57s in the state \"not full\".",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this can be calculated by using the blocking probability which is the probability for that the system is full (slide 31 in script).  for the given system this result in a probability of 0.05 using n=10 and lambda=9 and µ=10 as parameters. so the inverse probability saying that the system has less than 10 packets in the waiting queue is 1-0.05=0.95. \nas a result of this we expect the system to be for 0.95*60s=57s in the state \"not full\".",
        "original_sample_id": "smp0244q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0244q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this can be calculated by using the kibosh probability which is the probability for that the scheme is full (slide 31 in script).  for the hand scheme this result in a probability of 0.05 using n=10 and lambda=9 and µ=10 as parameters. so the inverse probability saying that the scheme has less than 10 packets in the waiting queue is 1-0.05=0.95. \nas a result of this we expect the scheme to be for 0.95*60s=57s in the state \"not full\".",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this can be calculated by using the blocking probability which is the probability for that the system is full (slide 31 in script).  for the given system this result in a probability of 0.05 using n=10 and lambda=9 and µ=10 as parameters. so the inverse probability saying that the system has less than 10 packets in the waiting queue is 1-0.05=0.95. \nas a result of this we expect the system to be for 0.95*60s=57s in the state \"not full\".",
        "original_sample_id": "smp0244q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1637q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 Factual address 10.0.0.0/8 private network 127.0.0/8 rear loop",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8 dummy address\n10.0.0.0/8 private network\n127.0.0.0/8 loopback",
        "original_sample_id": "smp1637q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1082q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "A tree that expands can optimize the routes through a network by avoiding loops. the property of what needs to be optimized can be varied. e.g.: distance, traffic, smaller hops, etc. for a wide and multiple diffusion, it is very attractive, because it is possible to optimize a tree to minimize the copies sent through the network. multicasting a group of nodes connect in small groups. the objective for multicasting is to find a tree that extends connects the routers of a local multicast group. this we can a specific tree, as in \"shared tree\" or specific extension trees of the sender, as in \"source-based trees.\" the procedure of routing the state of the link already built large trees to use for unicasting. during the distribution of the information that each has gathered about its neighbours (phase 4), the information extends on information about multicast groups. each one can adjust its routing tables accordingly to optimize multicasting to specific local multicast groups.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree can optimize routes through a network while avoiding loops. the property of what has to be optimized can be varied. for instance: distance, traffic, fewest hops etc. for broad- and multicasting this is very appealing as it is possible to optimize a tree to minimize copies sent through the network.  in multicasting a group of nodes are connected into small groups. the goal for multicasting is to find a spanning tree connecting the routers of a local multicast group. this can we one specific tree, such as in \"shared tree\" or sender specific spannign trees, such as in the \"source-based trees\".  the link state routing procedure already builds up spanning trees to use for unicasting. during the distribution of the information that every is has gathered about its neighbors (phase 4), the information is expanded by the information on the multicast groups. each is can then adjust its routing tables accordingly to optimize multicasting to specific local multicast groups.",
        "original_sample_id": "smp1082q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1082q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "A tree that expands can optimize the routes through a network by avoiding loops. the property of what needs to be optimized can be varied. e.g.: distance, traffic, smaller hops, etc. for a wide and multiple diffusion, it is very attractive, because it is possible to optimize a tree to minimize the copies sent through the network. multicasting a group of nodes connect in small groups. the objective for multicasting is to find a tree that extends connects the routers of a local multicast group. this we can a specific tree, as in \"shared tree\" or specific extension trees of the sender, as in \"source-based trees.\" the procedure of routing the state of the link already built large trees to use for unicasting. during the distribution of the information that each has gathered about its neighbours (phase 4), the information extends on information about multicast groups. each one can adjust its routing tables accordingly to optimize multicasting to specific local multicast groups.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree can optimize routes through a network while avoiding loops. the property of what has to be optimized can be varied. for instance: distance, traffic, fewest hops etc. for broad- and multicasting this is very appealing as it is possible to optimize a tree to minimize copies sent through the network.  in multicasting a group of nodes are connected into small groups. the goal for multicasting is to find a spanning tree connecting the routers of a local multicast group. this can we one specific tree, such as in \"shared tree\" or sender specific spannign trees, such as in the \"source-based trees\".  the link state routing procedure already builds up spanning trees to use for unicasting. during the distribution of the information that every is has gathered about its neighbors (phase 4), the information is expanded by the information on the multicast groups. each is can then adjust its routing tables accordingly to optimize multicasting to specific local multicast groups.",
        "original_sample_id": "smp1082q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0336q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, forward)\nhop 2:\n(b, e, forward)(c, f, forward)\nhop 3:\n(e, g, forward)(g, h, forward)\n\nin rpb, in contrast to rbf, no mailboat are dropt (optimally), because mailboat are only sent on the brusk route to each destination",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop) ). incorrect hop (-0.25p): hop 3 (e, g, forward)hop 4 (g, h, drop)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, forward)\nhop 2:\n(b, e, forward)(c, f, forward)\nhop 3:\n(e, g, forward)(g, h, forward)\n\nin rpb, in contrast to rbf, no packets are dropt (optimally), because packets are only sent on the shortest paths to each destination",
        "original_sample_id": "smp0336q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0684q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- non-confirmed service to this layer you can send a layer of data and you as a sender will not be able to check, if the data unit has arrived. this means that data loss is possible. (the top layer must check if the data is corrupted) - service confirmed when a receiver receives data it sends an acknowledgement of receipt to the sender to let him know that it has arrived. if after a certain period of time the receiver did not send the acknowledgement of receipt, the sender will retransmit the data - service oriented connection needs a communication in 3 phases: 1. connection: the sender sends a connection request and the receiver answers to confirm the connection 2. data transfer: several data can be transferred between the other 3. disconnection: the disconnection must be requested and recognized by the two communication partners to disconnect",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme between them, the first two services' difference is about acknowledgements and the third service's difference is about how a connection is established.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "- unconfirmed conn.less service\nat this layer you can send a data layer and you as a sender will not be able to check, if the data unit arrived. that means loss of data is possible. (upper layer have to check if the data is corrupted)\n\n- confirmed conn.less service\nwhen a receiver gets data it send an acknowledgement back to the sender to let it know it arrived. if after a certain time frame the receiver did not send the acknowledgement, the sender will retransmit the data \n\n- connection-oriented service\nneeds a 3-phased communication:\n1. connection: sender sends a connect request and receiver responses to confirm the connection\n2. data transfer: multiple data can be transfered between each other \n3. disconnection: the disconection must be requested and acknowledged from both communication partners to disconnect",
        "original_sample_id": "smp0684q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0718q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem with dqdb is paleness.\nthe question is how everybody can get the same probable to get access to datum.",
        "answer_feedback": "the response correctly identifies the problem in dqdb but it lacks an explanation for it. the fairness of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem with dqdb is fairness.\nthe question is how everybody can get the same likely to get access to data.",
        "original_sample_id": "smp0718q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0718q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the job with dqdb is fairness.\nthe question is how everybody can get the same likely to get entree to datum.",
        "answer_feedback": "the response correctly identifies the problem in dqdb but it lacks an explanation for it. the fairness of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem with dqdb is fairness.\nthe question is how everybody can get the same likely to get access to data.",
        "original_sample_id": "smp0718q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0718q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the trouble with dqdb is fairness.\nthe interrogation is how everybody can get the same likely to get approach to data.",
        "answer_feedback": "the response correctly identifies the problem in dqdb but it lacks an explanation for it. the fairness of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem with dqdb is fairness.\nthe question is how everybody can get the same likely to get access to data.",
        "original_sample_id": "smp0718q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0718q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem with dqdb is fairness.\nthe interrogation is how everybody can get the same probable to get admission to data.",
        "answer_feedback": "the response correctly identifies the problem in dqdb but it lacks an explanation for it. the fairness of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem with dqdb is fairness.\nthe question is how everybody can get the same likely to get access to data.",
        "original_sample_id": "smp0718q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0718q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the trouble with dqdb is fairness.\nthe query is how everybody can get the same likely to get access to datum.",
        "answer_feedback": "the response correctly identifies the problem in dqdb but it lacks an explanation for it. the fairness of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem with dqdb is fairness.\nthe question is how everybody can get the same likely to get access to data.",
        "original_sample_id": "smp0718q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "A useful property for the multicasting/widening of the extension tree for a given node is that it not only specifies the optimal path of the other nodes to this node, but also the optimal routes from this node to the other nodes. Link status routing can be used to build multicast extension trees by first running the link status routing procedure to obtain the extension tree for a given x node.This extension tree could already be used as the multicast extension tree for the x node, but it can be optimized by removing all edges that are not part of any route between two nodes of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "A useful property for the multicasting/widening of the extension tree for a given node is that it not only specifies the optimal path of the other nodes to this node, but also the optimal routes from this node to the other nodes. Link status routing can be used to build multicast extension trees by first running the link status routing procedure to obtain the extension tree for a given x node.This extension tree could already be used as the multicast extension tree for the x node, but it can be optimized by removing all edges that are not part of any route between two nodes of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug02smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a utile property for broad-/multicasting of the spanning tree for a certain guest is that it does not only qualify the optimal path from the other guests to this guest, but also the optimal paths from this guest to the other guests. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain guest x. this spanning tree could already be used as the multicast spanning tree for guest x, but it can be optimized by removing all edges that are not part of any path between any two guests of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug03smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a useful property for broad-/multicasting of the spanning tree for a certain guest is that it does not only specify the optimal course from the other guests to this guest, but also the optimal courses from this guest to the other guests. link state routing can be used to construct multicast spanning trees by first campaign the link state routing procedure to get the spanning tree for a certain guest x. this spanning tree could already be used as the multicast spanning tree for guest x, but it can be optimized by removing all edges that are not part of any course between any two guests of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug04smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "A useful property for the multicasting/widening of the extension tree for a given node is that it not only specifies the optimal path of the other nodes to this node, but also the optimal routes from this node to the other nodes. Link status routing can be used to build multicast extension trees by first running the link status routing procedure to obtain the extension tree for a given x node.This extension tree could already be used as the multicast extension tree for the x node, but it can be optimized by removing all edges that are not part of any route between two nodes of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug05smp1089q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a utile dimension for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimum path from the other nodes to this node, but also the optimum paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "answer_feedback": "what makes spanning trees desirable for multicast and broadcast is the absence of loops and, thus, minimizing unnecessary duplicates.  the response is missing how the multicast group information is distributed to all nodes. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "a useful property for broad-/multicasting of the spanning tree for a certain node is that it does not only specify the optimal path from the other nodes to this node, but also the optimal paths from this node to the other nodes. link state routing can be used to construct multicast spanning trees by first running the link state routing procedure to get the spanning tree for a certain node x. this spanning tree could already be used as the multicast spanning tree for node x, but it can be optimized by removing all edges that are not part of any path between any two nodes of the multicast group.",
        "original_sample_id": "smp1089q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1482q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the transfer of information should be possible in both directions. an efficient approach is to use a complete duplex circuit. plus, an additional field for recognitions should be added to the data frame.",
        "answer_feedback": "the response correctly identifies both the requirements for piggybacking.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the transfer of information must be possible in both directions. an efficient approach is to use a full-duplex circuit. furthermore, an additional field for acknowledgements must be added to the data frame.",
        "original_sample_id": "smp1482q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0805q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- header size: udp header size is 8 bytes. tcp has 20 bytes\n\n- udp has no menstruum control. tcp does.\n\n- udp has no error control, so you can loose packets (due to corruption, loss, duoplication, reordering). tcp in the other paw has error control and you will get the correct and ordered byte sequence  \n\n- udp is a connectionless service. tcp creates a logical oddment-to-oddment connection",
        "answer_feedback": "the first point is partially correct as the tcp header length is not fixed, it varies from 20 to 60 bytes. the remaining three points are not relevant as they mention the difference between the tcp and udp protocols and not the headers.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.12,
        "original_answer": "- header size: udp header size is 8 bytes. tcp has 20 bytes\n\n- udp has no flow control. tcp does.\n\n- udp has no error control, so you can loose packets (due to corruption, loss, duoplication, reordering). tcp in the other hand has error control and you will get the correct and ordered byte sequence  \n\n- udp is a connectionless service. tcp creates a logical end-to-end connection",
        "original_sample_id": "smp0805q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0805q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- header size: header size udp is 8 bytes. tcp has 20 bytes - udp has no flow control. tcp has no error control. - udp has no error control, so you can lose packages (due to corruption, loss, duplication, rearrangement). tcp in the other hand has error control and you will get the correct and ordered bytes sequence - udp is a offline service. tcp creates a logical connection from end to end.",
        "answer_feedback": "the first point is partially correct as the tcp header length is not fixed, it varies from 20 to 60 bytes. the remaining three points are not relevant as they mention the difference between the tcp and udp protocols and not the headers.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.12,
        "original_answer": "- header size: udp header size is 8 bytes. tcp has 20 bytes\n\n- udp has no flow control. tcp does.\n\n- udp has no error control, so you can loose packets (due to corruption, loss, duoplication, reordering). tcp in the other hand has error control and you will get the correct and ordered byte sequence  \n\n- udp is a connectionless service. tcp creates a logical end-to-end connection",
        "original_sample_id": "smp0805q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0805q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- header size: header size udp is 8 bytes. tcp has 20 bytes - udp has no flow control. tcp has no error control. - udp has no error control, so you can lose packages (due to corruption, loss, duplication, rearrangement). tcp in the other hand has error control and you will get the correct and ordered bytes sequence - udp is a offline service. tcp creates a logical connection from end to end.",
        "answer_feedback": "the first point is partially correct as the tcp header length is not fixed, it varies from 20 to 60 bytes. the remaining three points are not relevant as they mention the difference between the tcp and udp protocols and not the headers.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.12,
        "original_answer": "- header size: udp header size is 8 bytes. tcp has 20 bytes\n\n- udp has no flow control. tcp does.\n\n- udp has no error control, so you can loose packets (due to corruption, loss, duoplication, reordering). tcp in the other hand has error control and you will get the correct and ordered byte sequence  \n\n- udp is a connectionless service. tcp creates a logical end-to-end connection",
        "original_sample_id": "smp0805q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0805q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- header size: header size udp is 8 bytes. tcp has 20 bytes - udp has no flow control. tcp has no error control. - udp has no error control, so you can lose packages (due to corruption, loss, duplication, rearrangement). tcp in the other hand has error control and you will get the correct and ordered bytes sequence - udp is a offline service. tcp creates a logical connection from end to end.",
        "answer_feedback": "the first point is partially correct as the tcp header length is not fixed, it varies from 20 to 60 bytes. the remaining three points are not relevant as they mention the difference between the tcp and udp protocols and not the headers.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.12,
        "original_answer": "- header size: udp header size is 8 bytes. tcp has 20 bytes\n\n- udp has no flow control. tcp does.\n\n- udp has no error control, so you can loose packets (due to corruption, loss, duoplication, reordering). tcp in the other hand has error control and you will get the correct and ordered byte sequence  \n\n- udp is a connectionless service. tcp creates a logical end-to-end connection",
        "original_sample_id": "smp0805q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0375q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a, b, forward) (a, c, forward) (a, d) hops 2: (b, e, forward) (b, c, fall) < = b is not on the optimal road of c a (c, b, fall) < = c is not on the optimal road of b a (c, e, fall) < = c is not on the optimal road of a (c, d, fall) < = c is not on the optimal road of d a (c, f, fall) < = d is not on the optimal road of c a (e, f, fall) < = e is not on the optimal road of f a (e, g, advance) (f, d, fall) < = e is not on the optimal road of c a (e, f, fall) < and is not on the optimal road of f a (f, f), f g is not on the optimal road of f a (f, d, d, fall)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\n(b, e, forward)\n(b, c, drop) <= b is not on optimal route from c to a\n(c, b, drop) <= c is not on optimal route from b to a\n(c, e, drop) <= c is not on optimal route from e to a\n(c, d, drop) <= c is not on optimal route from d to a\n(c, f, forward)\n(d, c, drop) <= d is not on optimal route from c to a\n(d, f, drop) <= d is not on optimal route from f to a\n\nhop 3:\n(e, c, drop) <= e is not on optimal route from c to a\n(e, f, drop) <= e is not on optimal route from f to a\n(e, g, forward)\n(f, d, drop) <= f is not on optimal route from d to a\n(f, g, drop) <= f is not on optimal route from g to a\n\nhop 4:\n(g, f, drop) <= g is not on optimal route from f to a\n(g, h, forward)",
        "original_sample_id": "smp0375q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1641q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "networks 0.0.0.0 - 0.255.255.255 and 127.0.0.0 - 127.255.255.255 are reserved.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "the networks\n\n0.0.0.0 - 0.255.255.255and127.0.0.0 - 127.255.255.255\n\nare reserved.",
        "original_sample_id": "smp1641q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1636q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "127,0.0.0 to 127,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "127.0.0.0 to 127.255.255.255",
        "original_sample_id": "smp1636q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1699q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1699q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1699q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1699q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0861q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "when considering real cyberspace traffic, it is unreasonable to simulate that the individual arrivals are independent from each other. whether packets are arriving or not is based not on independent instances, but on usage. for example, if someone was stream or downloading something on the cyberspace then the chance of packets arriving within that time frame is extremely high, and that probability is dependent on cyberspace usage.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "when considering real internet traffic, it is unreasonable to assume that the individual arrivals are independent from each other. whether packets are arriving or not is based not on independent instances, but on usage. for example, if someone was streaming or downloading something on the internet then the chance of packets arriving within that time frame is extremely high, and that probability is dependent on internet usage.",
        "original_sample_id": "smp0861q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0216q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buff in the task is finite. it follows from the balance equation that the land probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can calculate a probability of 0,95. it follows that the system is for about 57s in a land where less than 10 mailboat are in the queue",
        "answer_feedback": "it is not stated whether the calculated probability is blocking or non-blocking and how the time is calculated from that, only the correct non-blocking time is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the buffer in the task is finite. it follows from the balance equation that the state probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can calculate a probability of 0,95. it follows that the system is for about 57s in a state where less than 10 packets are in the queue",
        "original_sample_id": "smp0216q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0216q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer in the task is finite. it follows from the rest equation that the land probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can calculate a probability of 0,95. it follows that the system is for about 57s in a land where less than 10 mailboat are in the queue",
        "answer_feedback": "it is not stated whether the calculated probability is blocking or non-blocking and how the time is calculated from that, only the correct non-blocking time is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the buffer in the task is finite. it follows from the balance equation that the state probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can calculate a probability of 0,95. it follows that the system is for about 57s in a state where less than 10 packets are in the queue",
        "original_sample_id": "smp0216q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0216q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer in the task is finite. it follows from the balance equation that the dos probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can cipher a probability of 0,95. it follows that the system is for about 57s in a dos where less than 10 mailboat are in the queue",
        "answer_feedback": "it is not stated whether the calculated probability is blocking or non-blocking and how the time is calculated from that, only the correct non-blocking time is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the buffer in the task is finite. it follows from the balance equation that the state probability must be lambda divided by my. in this case the result is 0,9. \nwith using the normalization condition and the formula for the system throughput, we can calculate a probability of 0,95. it follows that the system is for about 57s in a state where less than 10 packets are in the queue",
        "original_sample_id": "smp0216q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0913q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge board holds information over which lan a source address can be reached (note with a timestamp for dropping old entries). the board is modified when the bridge receives a frame from any connected lan. the containing source address can be reached over the sending lan so the board is updated. entries can be used to determine the destination lan when incur a frame. if no entry is available for an address flooding is used and therefore the benefit of using the board is to avoid unnecessary usage of the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds information over which lan a source address can be reached (marked with a timestamp for dropping old entries). the table is modified when the bridge receives a frame from any connected lan. the containing source address can be reached over the sending lan so the table is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "original_sample_id": "smp0913q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0913q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the span table holds information over which lan a source address can be attain (marked with a timestamp for dropping old entries). the table is modified when the span receives a frame from any link lan. the containing source address can be attain over the sending lan so the table is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds information over which lan a source address can be reached (marked with a timestamp for dropping old entries). the table is modified when the bridge receives a frame from any connected lan. the containing source address can be reached over the sending lan so the table is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "original_sample_id": "smp0913q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0913q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge board holds information over which lan a source address can be reached (marked with a timestamp for dropping old entries). the board is modified when the bridge receives a frame from any connect lan. the containing source address can be reached over the sending lan so the board is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is uncommitted for an address flooding is used and therefore the benefit of using the board is to avoid unnecessary usage of the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds information over which lan a source address can be reached (marked with a timestamp for dropping old entries). the table is modified when the bridge receives a frame from any connected lan. the containing source address can be reached over the sending lan so the table is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "original_sample_id": "smp0913q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0913q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the span table holds information over which lan a source address can be reached (marked with a timestamp for dropping old entrance). the table is modified when the span receives a frame from any connected lan. the containing source address can be reached over the sending lan so the table is updated. entrance can be used to determine the destination lan when obtain a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds information over which lan a source address can be reached (marked with a timestamp for dropping old entries). the table is modified when the bridge receives a frame from any connected lan. the containing source address can be reached over the sending lan so the table is updated. entries can be used to determine the destination lan when receiving a frame. if no entry is available for an address flooding is used and therefore the benefit of using the table is to avoid unnecessary usage of the network.",
        "original_sample_id": "smp0913q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0234q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "for the 1 minute time interval we have to calculate the set of probability of number of packages in the queue with each new state of arrival of packages and packet processed from the queue. with increasing rate of arrival the queue will be more complete until it reaches n = 10, after which the fall of packages occurs, and consequently the rate of arrival decreases. thus the p changing state from p0 to p10. with rate of arrival reduces the number of packages processed from the queue and the size of the queue decreases by p10 until the point rate increases again.",
        "answer_feedback": "yes, it is correct that “blocking probability” needs to be calculated, but neither the calculation steps, probability nor the time is mentioned in the response..",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "for the time interval of 1 minute we have to do the calculation of set of probabilities of number of packets in the queue with every new state of packet arrival and packet processed from the queue. with increasing arrival rate the queue will get more full until it reaches n = 10, after which packet dropping occurs, and consequently the arrival rate decreases. so this way  the p changing from state of p0 till p10. with reduced arrival rate the more packets get processed from the queue and the queue size decreases from p10 until the point arrival rate increases again. so we need to check for the “blocking probability” and “expected number of customers in the system” in order to determine the number of seconds the queue is not full or less than 10 packets in the waiting queue.",
        "original_sample_id": "smp0234q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0234q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "for the 1 minute time interval we have to calculate the set of probability of number of packages in the queue with each new state of arrival of packages and packet processed from the queue. with increasing rate of arrival the queue will be more complete until it reaches n = 10, after which the fall of packages occurs, and consequently the rate of arrival decreases. thus the p changing state from p0 to p10. with rate of arrival reduces the number of packages processed from the queue and the size of the queue decreases by p10 until the point rate increases again.",
        "answer_feedback": "yes, it is correct that “blocking probability” needs to be calculated, but neither the calculation steps, probability nor the time is mentioned in the response..",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "for the time interval of 1 minute we have to do the calculation of set of probabilities of number of packets in the queue with every new state of packet arrival and packet processed from the queue. with increasing arrival rate the queue will get more full until it reaches n = 10, after which packet dropping occurs, and consequently the arrival rate decreases. so this way  the p changing from state of p0 till p10. with reduced arrival rate the more packets get processed from the queue and the queue size decreases from p10 until the point arrival rate increases again. so we need to check for the “blocking probability” and “expected number of customers in the system” in order to determine the number of seconds the queue is not full or less than 10 packets in the waiting queue.",
        "original_sample_id": "smp0234q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1682q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0 127.255,255,255 first and last reserved address.",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0\n127.255.255.255\nfirst and last address are reserved.",
        "original_sample_id": "smp1682q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0249q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "adopt a fifo queue, and adopt that the parcels arrive and are processed continuously with equal time distribution for each parcel within the second:\nservice time: u = 10 parcels/second => x1 = 1/10s\narrival rate = 9 parcels/second => arrival time = every 1/9s\nbuffer = 10 parcels\n\nsince the service time is smaller than the parcel arrival time for each parcel, and the number of parcels arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more parcels in it, hence, the queue always has less than 10 parcels in it.",
        "answer_feedback": "the response is incorrect because it is purely based on assumptions. additionally, the arrival and service rates are not constant and vary with time, so the stated argument of the queue never containing 10 packets for an entire minute is invalid.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "assuming a fifo queue, and assuming that the packets arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 packets/second => x1 = 1/10s\narrival rate = 9 packets/second => arrival time = every 1/9s\nbuffer = 10 packets\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of packets arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more packets in it, hence, the queue always has less than 10 packets in it.",
        "original_sample_id": "smp0249q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0249q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "assuming a fifo queue, and assuming that the bundle arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 bundle/second => x1 = 1/10s\narrival rate = 9 bundle/second => arrival time = every 1/9s\nbuffer = 10 bundle\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of bundle arriving per second is smaller than the queue's buffer size, we can simulate that in the entire minute, the queue never contains 10 or more bundle in it, hence, the queue always has less than 10 bundle in it.",
        "answer_feedback": "the response is incorrect because it is purely based on assumptions. additionally, the arrival and service rates are not constant and vary with time, so the stated argument of the queue never containing 10 packets for an entire minute is invalid.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "assuming a fifo queue, and assuming that the packets arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 packets/second => x1 = 1/10s\narrival rate = 9 packets/second => arrival time = every 1/9s\nbuffer = 10 packets\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of packets arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more packets in it, hence, the queue always has less than 10 packets in it.",
        "original_sample_id": "smp0249q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0812q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header is longer than the udp header and has a variable length which is set in the hl champaign. it also has sequence and acknowledgement number champaigns as well as flags used to ensure reliability in terms of avoiding packet losses, keeping packet order and detecting duplicates. the flags are also used to manage connections. furthermore, the tcp header’s advertised window champaign holds the initial size of the congestion window used for congestion control. the urgent pointer champaign of the tcp header is only used when the urg flag is set in order to assure the receiver that data located at a specific offset is to be read firstly. the options champaign may be used to provide functions that are not defined within the normal tcp protocol head. eventually there are 6 unused reserved bits in the resv champaign.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header is longer than the udp header and has a variable length which is set in the hl field. it also has sequence and acknowledgement number fields as well as flags used to ensure reliability in terms of avoiding packet losses, keeping packet order and detecting duplicates. the flags are also used to manage connections. furthermore, the tcp header’s advertised window field holds the initial size of the congestion window used for congestion control. the urgent pointer field of the tcp header is only used when the urg flag is set in order to tell the receiver that data located at a specific offset is to be read firstly. the options field may be used to provide functions that are not defined within the normal tcp protocol head. finally there are 6 unused reserved bits in the resv field.",
        "original_sample_id": "smp0812q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1655q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0000 0000 0000 0000 0000 0000 0000 (network)0xxx xxxx.1111 1111 1111 1111 1111 1111 (transmission)127. x . x . x (return)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0xxx xxxx.0000 0000. 0000 0000. 0000 0000. 0000 0000 (network)0xxx xxxx.1111 1111. 1111 1111. 1111 1111. 1111 1111 (broadcast)127. x . x . x (loop back)",
        "original_sample_id": "smp1655q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, pearl) c is not located on the unicast path from b to a\n           (c, d, pearl) c is not located on the unicast path from d to a\n           (c, e, pearl) c is not located on the unicast path from e to a\n           (d, f, pearl) d is not located on the unicast path from f to a\n           (f, g, pearl) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, cliff) c is not located on the unicast path from b to a\n           (c, d, cliff) c is not located on the unicast path from d to a\n           (c, e, cliff) c is not located on the unicast path from e to a\n           (d, f, cliff) d is not located on the unicast path from f to a\n           (f, g, cliff) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug02smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1c, a, forwards)  (d, a, forwards)  (b, a, forwards)  (e, b, forwards)  (g, e, forwards)\n           (h,g,forwards)   (f,c,forwards)\n           (c, b, drib) c is not located on the unicast path from b to a\n           (c, d, drib) c is not located on the unicast path from d to a\n           (c, e, drib) c is not located on the unicast path from e to a\n           (d, f, drib) d is not located on the unicast path from f to a\n           (f, g, drib) f is not located on the unicast path from g to a\nskip 2e, a, forwards) (f, a, forwards)\nskip 3g, a, forwards)     \nskip 4h, a, forwards)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug03smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, drop) c is not located on the unicast course from b to a\n           (c, d, drop) c is not located on the unicast course from d to a\n           (c, e, drop) c is not located on the unicast course from e to a\n           (d, f, drop) d is not located on the unicast course from f to a\n           (f, g, drop) f is not located on the unicast course from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug04smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, drop) c is not situate on the unicast course from b to a\n           (c, d, drop) c is not situate on the unicast course from d to a\n           (c, e, drop) c is not situate on the unicast course from e to a\n           (d, f, drop) d is not situate on the unicast course from f to a\n           (f, g, drop) f is not situate on the unicast course from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug05smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, pearl) c is not located on the unicast path from b to a\n           (c, d, pearl) c is not located on the unicast path from d to a\n           (c, e, pearl) c is not located on the unicast path from e to a\n           (d, f, pearl) d is not located on the unicast path from f to a\n           (f, g, pearl) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug06smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1c, a, fore)  (d, a, fore)  (b, a, fore)  (e, b, fore)  (g, e, fore)\n           (h,g,fore)   (f,c,fore)\n           (c, b, drop) c is not located on the unicast way from b to a\n           (c, d, drop) c is not located on the unicast way from d to a\n           (c, e, drop) c is not located on the unicast way from e to a\n           (d, f, drop) d is not located on the unicast way from f to a\n           (f, g, drop) f is not located on the unicast way from g to a\nskip 2e, a, fore) (f, a, fore)\nskip 3g, a, fore)     \nskip 4h, a, fore)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug07smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrad)  (d, a, forrad)  (b, a, forrad)  (e, b, forrad)  (g, e, forrad)\n           (h,g,forrad)   (f,c,forrad)\n           (c, b, cliff) c is not located on the unicast itinerary from b to a\n           (c, d, cliff) c is not located on the unicast itinerary from d to a\n           (c, e, cliff) c is not located on the unicast itinerary from e to a\n           (d, f, cliff) d is not located on the unicast itinerary from f to a\n           (f, g, cliff) f is not located on the unicast itinerary from g to a\nhop 2e, a, forrad) (f, a, forrad)\nhop 3g, a, forrad)     \nhop 4h, a, forrad)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0887q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the reaching are not independt for real internet traffic, because they can influence one another.\ne.g if a request is transport, the probabillity of a next message (the response) is more probable.",
        "answer_feedback": "the response is partially correct because the question requirement is to identify whether the arrivals at a node depend on previous arrivals at the same node. therefore, the explanation that the arrival at a node depends on the outgoing packets is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the arrivals are not independt for real internet traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more likely.",
        "original_sample_id": "smp0887q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0887q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the arrivals are not independt for genuine cyberspace traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more probable.",
        "answer_feedback": "the response is partially correct because the question requirement is to identify whether the arrivals at a node depend on previous arrivals at the same node. therefore, the explanation that the arrival at a node depends on the outgoing packets is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the arrivals are not independt for real internet traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more likely.",
        "original_sample_id": "smp0887q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0802q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp cope is only 64 bits long and does – in contrast to the tcp cope – not contain a sequence routine, an reference routine, an advertisement window nor space for optional information.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header is only 64 bits long and does – in contrast to the tcp header – not contain a sequence number, an acknowledgment number, an advertisement window nor space for optional information.",
        "original_sample_id": "smp0802q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1035q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the two are techniques to perform broadcast or multicast without chargeing parcels in circles. \n\nin principles, both look at the is entry port of incoming parcel: does it came from the entry which part of the best itinerary, if the itineraryr wants to charge himself a message to the source? if the answer is no, the itineraryr will drop the paket.\n\nif the answer is yes, rpf and rpb differ: rpf charge the parcel to all the other egdes while rpb selects only the edge at which the parcels arrived and from which they are then reitineraryd to the source.",
        "answer_feedback": "the response is partially correct because it explains both rpf and rpb but the incoming and outgoing packet references are unclear.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "the two are techniques to perform broadcast or multicast without sending packets in circles. \n\nin principles, both look at the is entry port of incoming packet: does it came from the entry which part of the best route, if the router wants to send himself a message to the source? if the answer is no, the router will drop the paket.\n\nif the answer is yes, rpf and rpb differ: rpf send the packet to all the other egdes while rpb selects only the edge at which the packets arrived and from which they are then rerouted to the source.",
        "original_sample_id": "smp1035q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1500q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the requirement is that the communication channel has to operate in full duplex way so that the liquidator could commit both acknowledgement and data at the same go.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the requirement is that the communication channel has to operate in full duplex mode so that the receiver could send both acknowledgement and data at the same go.",
        "original_sample_id": "smp1500q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1692q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0,0,0,0,0,2552,255 10,0,0,055 10,255,255 100,64,0,0,05,100,127,255,255 127,0,0,0,07,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "original_sample_id": "smp1692q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0792q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is simple in the means of transport protocol. it is without connection, oriented towards messages and unreliable. udp, we have a sender and receiving port, a package length a sum of control and data. there is no flow control and no error control. the data can be sent very quickly, since the netwrk. for tcp, we have the sequence number, the recognition number, flags and urgent pointer, which allows multiplex/multiplex (difference 1), error control (difference 2), extreme to extreme flow control (difference 3), connection configuration (difference 4) and congestion prevention (difference 5), which is not all given with udp. so tcp is reliable, but tcp is also more complicated, tcp requires more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for much more transmitted data, as for streaming. (tcp, smp, smp, smp, smp)",
        "answer_feedback": "the differences marked (1-5) in the response are general tcp and udp protocol differences and are not specific to the headers. since the answer additionally mentions four header differences, it is partially correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "udp is simple in means of transport protocol. it is connectionless, message-oriented and not reliable. udp, we have a sender and receiver port, packet length a checksum and data. there is no flow control and no error control. data can be sent very fast, as the it is allowed by the netowrk. for tcp, we have sequence number, acknowledgment number, flags, and urgent pointer, which allows multiplex/demultiplex (difference 1), error control (difference 2), end-to-end flow control( difference 3), connection setup (difference 4) and congestion avoidance (difference 5), which is all not given with udp. so tcp is reliable, but tcp is also more complicated, tcp demands more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for a lot more of data to be transmitted, like for streaming.  (tcp is applied for ftp, telnet, smtp and the www(http))",
        "original_sample_id": "smp0792q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0792q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is simple in the means of transport protocol. it is without connection, oriented towards messages and unreliable. udp, we have a sender and receiving port, a package length a sum of control and data. there is no flow control and no error control. the data can be sent very quickly, since the netwrk. for tcp, we have the sequence number, the recognition number, flags and urgent pointer, which allows multiplex/multiplex (difference 1), error control (difference 2), extreme to extreme flow control (difference 3), connection configuration (difference 4) and congestion prevention (difference 5), which is not all given with udp. so tcp is reliable, but tcp is also more complicated, tcp requires more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for much more transmitted data, as for streaming. (tcp, smp, smp, smp, smp)",
        "answer_feedback": "the differences marked (1-5) in the response are general tcp and udp protocol differences and are not specific to the headers. since the answer additionally mentions four header differences, it is partially correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "udp is simple in means of transport protocol. it is connectionless, message-oriented and not reliable. udp, we have a sender and receiver port, packet length a checksum and data. there is no flow control and no error control. data can be sent very fast, as the it is allowed by the netowrk. for tcp, we have sequence number, acknowledgment number, flags, and urgent pointer, which allows multiplex/demultiplex (difference 1), error control (difference 2), end-to-end flow control( difference 3), connection setup (difference 4) and congestion avoidance (difference 5), which is all not given with udp. so tcp is reliable, but tcp is also more complicated, tcp demands more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for a lot more of data to be transmitted, like for streaming.  (tcp is applied for ftp, telnet, smtp and the www(http))",
        "original_sample_id": "smp0792q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0792q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is simple in the means of transport protocol. it is without connection, oriented towards messages and unreliable. udp, we have a sender and receiving port, a package length a sum of control and data. there is no flow control and no error control. the data can be sent very quickly, since the netwrk. for tcp, we have the sequence number, the recognition number, flags and urgent pointer, which allows multiplex/multiplex (difference 1), error control (difference 2), extreme to extreme flow control (difference 3), connection configuration (difference 4) and congestion prevention (difference 5), which is not all given with udp. so tcp is reliable, but tcp is also more complicated, tcp requires more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for much more transmitted data, as for streaming. (tcp, smp, smp, smp, smp)",
        "answer_feedback": "the differences marked (1-5) in the response are general tcp and udp protocol differences and are not specific to the headers. since the answer additionally mentions four header differences, it is partially correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "udp is simple in means of transport protocol. it is connectionless, message-oriented and not reliable. udp, we have a sender and receiver port, packet length a checksum and data. there is no flow control and no error control. data can be sent very fast, as the it is allowed by the netowrk. for tcp, we have sequence number, acknowledgment number, flags, and urgent pointer, which allows multiplex/demultiplex (difference 1), error control (difference 2), end-to-end flow control( difference 3), connection setup (difference 4) and congestion avoidance (difference 5), which is all not given with udp. so tcp is reliable, but tcp is also more complicated, tcp demands more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for a lot more of data to be transmitted, like for streaming.  (tcp is applied for ftp, telnet, smtp and the www(http))",
        "original_sample_id": "smp0792q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0792q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is simple in the means of transport protocol. it is without connection, oriented towards messages and unreliable. udp, we have a sender and receiving port, a package length a sum of control and data. there is no flow control and no error control. the data can be sent very quickly, since the netwrk. for tcp, we have the sequence number, the recognition number, flags and urgent pointer, which allows multiplex/multiplex (difference 1), error control (difference 2), extreme to extreme flow control (difference 3), connection configuration (difference 4) and congestion prevention (difference 5), which is not all given with udp. so tcp is reliable, but tcp is also more complicated, tcp requires more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for much more transmitted data, as for streaming. (tcp, smp, smp, smp, smp)",
        "answer_feedback": "the differences marked (1-5) in the response are general tcp and udp protocol differences and are not specific to the headers. since the answer additionally mentions four header differences, it is partially correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "udp is simple in means of transport protocol. it is connectionless, message-oriented and not reliable. udp, we have a sender and receiver port, packet length a checksum and data. there is no flow control and no error control. data can be sent very fast, as the it is allowed by the netowrk. for tcp, we have sequence number, acknowledgment number, flags, and urgent pointer, which allows multiplex/demultiplex (difference 1), error control (difference 2), end-to-end flow control( difference 3), connection setup (difference 4) and congestion avoidance (difference 5), which is all not given with udp. so tcp is reliable, but tcp is also more complicated, tcp demands more resources compared to udp and tcp is not as fast as udp. udp is faster and can be used for a lot more of data to be transmitted, like for streaming.  (tcp is applied for ftp, telnet, smtp and the www(http))",
        "original_sample_id": "smp0792q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0215q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "there should be all the sentence less than 10 packet because we get only 9 packet and serve 10 packet. ^^",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time (60 seconds) is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there should be all the time less than 10 packets because we receive only 9 packets and serve 10 packets. ^^",
        "original_sample_id": "smp0215q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0215q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "there should be all the clip less than 10 packet because we meet only 9 packet and serve 10 packet. ^^",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time (60 seconds) is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "there should be all the time less than 10 packets because we receive only 9 packets and serve 10 packets. ^^",
        "original_sample_id": "smp0215q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0799q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp header arrest only the sender embrasure, receiver embrasure, packet length, checksum.tcp and udp same headers have sender embrasure, receiver embrasure and checksum, more information than udp, e.g. sequence bit, acknowledgment bit, hl/resv/flags, advertised window.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp header contains only the sender port, receiver port, packet length, checksum.tcp and udp same headers have sender port, receiver port and checksum, more information than udp, e.g. sequence number, acknowledgment number, hl/resv/flags, advertised window.",
        "original_sample_id": "smp0799q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1107q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the attractive property of an extension tree formed from a network/graphic is the fact that all nodes are at least connected (i.e. they do not include loops). If the connections have also been selected in such a way that the most favourable edge weights have been used to build the tree (i.e. the shortest path), then the minimum extension tree represents even the optimal connection of all the other nodes. This means that the east does not unnecessarily load with messages during a wide/multicast. for everything to be known from multicast trees, the link state packets can be expanded with information about multicast groups. the line with destination and distance is expanded by the column indicating the adhesion of the destination multicast group. Since these packets are distributed to all nodes by diffusion, it is able to calculate the multicast tree for a given multicast group independently once you have the information fully available locally to determine the outgoing lines to send/remit packets.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the appealing property of a spanning tree formed from a network/graph is the fact that all nodes are minimally connected (i.e. no loops are included). if the connections were also selected in such a way that the most favourable edge weights were used for building the tree (i.e. shortest path), the then so-called minimal spanning tree even represents the optimal connection of all other nodes. this means that the is are not unnecessarily charged with messages during a broad-/multicast.  in order that all is know the multicast trees, the link state packages can be extended with information about the multicast groups. the row with destination and distance is expanded by the column indicating the multicast group membership of the destination. since these packages are distributed to all nodes by broadcast, the is can calculate the multicast tree for a certain multicast group independently once it has the information completely available locally to determine the outgoing lines for sending/forwarding the packages.",
        "original_sample_id": "smp1107q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1107q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the attractive property of an extension tree formed from a network/graphic is the fact that all nodes are at least connected (i.e. they do not include loops). If the connections have also been selected in such a way that the most favourable edge weights have been used to build the tree (i.e. the shortest path), then the minimum extension tree represents even the optimal connection of all the other nodes. This means that the east does not unnecessarily load with messages during a wide/multicast. for everything to be known from multicast trees, the link state packets can be expanded with information about multicast groups. the line with destination and distance is expanded by the column indicating the adhesion of the destination multicast group. Since these packets are distributed to all nodes by diffusion, it is able to calculate the multicast tree for a given multicast group independently once you have the information fully available locally to determine the outgoing lines to send/remit packets.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the appealing property of a spanning tree formed from a network/graph is the fact that all nodes are minimally connected (i.e. no loops are included). if the connections were also selected in such a way that the most favourable edge weights were used for building the tree (i.e. shortest path), the then so-called minimal spanning tree even represents the optimal connection of all other nodes. this means that the is are not unnecessarily charged with messages during a broad-/multicast.  in order that all is know the multicast trees, the link state packages can be extended with information about the multicast groups. the row with destination and distance is expanded by the column indicating the multicast group membership of the destination. since these packages are distributed to all nodes by broadcast, the is can calculate the multicast tree for a certain multicast group independently once it has the information completely available locally to determine the outgoing lines for sending/forwarding the packages.",
        "original_sample_id": "smp1107q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1002q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding purpose: broadcasting methods with reduction of duplicates reverse path forwarding working: each sender has an own spanning tree but is does not know them. packet arrives at is → check the port (is it the usual one for sending the packages for this station)  yes → (seems like best route) → resend over all edges no → (appears not to be the best route → duplicate) → drop package reverse path broadcast purpose: like rpf but not use all edges instead only suitable ones  reverse path broadcast working: check entry port the same way as in rpf  yes → check if best route until now? - yes → select arriving and rerouting (for packages) edge and send in opposite direction via this way  - no  → do not send over all edges (as it would be in rpf) no → discard (similar to rpf)",
        "original_sample_id": "smp1002q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1002q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding purpose: broadcasting methods with reduction of duplicates reverse path forwarding working: each sender has an own spanning tree but is does not know them. packet arrives at is → check the port (is it the usual one for sending the packages for this station)  yes → (seems like best route) → resend over all edges no → (appears not to be the best route → duplicate) → drop package reverse path broadcast purpose: like rpf but not use all edges instead only suitable ones  reverse path broadcast working: check entry port the same way as in rpf  yes → check if best route until now? - yes → select arriving and rerouting (for packages) edge and send in opposite direction via this way  - no  → do not send over all edges (as it would be in rpf) no → discard (similar to rpf)",
        "original_sample_id": "smp1002q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp cope contain a checksum, while udp cope have no error control. tcp cope have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp cope contain an advertised window to avoid the sender overmaster the receiver while udp has no means of stream control in their cope.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp cope incorporate a checksum, while udp cope have no error control. tcp cope have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp cope incorporate an advertised window to avoid the sender overwhelming the receiver while udp has no mean of flow control in their cope.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "The tcp headers contain a control sum, while the udp headers do not have an error control. The tcp headers have recognition numbers to ensure reliable communications while udp does not have an ack process. The tcp headers contain an announced window to prevent the sender from overwriting the receiver while udp has no means of flow control in their headers.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp head arrest a checksum, while udp head have no error control. tcp head have acknowledgement numbers to ensure reliable communications while udp has no ack appendage.\ntcp head arrest an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their head.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0904q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent spans contains the stations and the corresponding lan the station is in. the spans learn over which span they have to send data to reach certain stations. they qualify the entries if they receive a frame from a source address that is not yet in the table. the transparent spans adapt to the changes in topology by updating the board. (e.g. after a certain time)",
        "answer_feedback": "the response correctly states the information contained in the bridge table. it does not mention how the bridge learns, i.e. by inspecting incoming packets, and how this is used in selective forwarding.  the correct benefit is that there is less traffic because of selective forwarding, not just topological change adaption.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the table of a transparent bridges contains the stations and the corresponding lan the station is in. the bridges learn over which bridge they have to send data to reach certain stations. they modify the entries if they receive a frame from a source address that is not yet in the table. the transparent bridges adapt to the changes in topology by updating the tables. (e.g. after a certain time)",
        "original_sample_id": "smp0904q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0374q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1: (a,b,forward) (a,c,forward) (a,d,drop) <= d knows no other \"better\" route to send hops 2: (b,e,forward) (c,f,drop) <= f knows no other \"better\" route to send hops 3: (e,g,forward) hops 4: (g,h,drop) <= h receives the package but does not need to pass it on to anyone else, because it has no other neighbours",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop) <= d doesn't know any other \"best\" route to send the packet\n\nhop 2:\n(b,e,forward)\n(c,f,drop) <= f doesn't know any other \"best\" route to send the packet\n\nhop 3:\n(e,g,forward)\n\nhop 4:\n(g,h,drop) <= h receives the packet but doesn't need to forward it to anyone else, because it has no other neighbors",
        "original_sample_id": "smp0374q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0334q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: \n(a, b, fore)(a, c, fore)\n(a, d, fore)\nhop 2:\n(b, e, fore)\n(b, c, cliff) <= (a, c) is myopic\n(c, b, cliff) <= (a, b) is myopic\n(c, e, cliff) <= (a, b, e) is myopic\n(c, f, fore)\n(c, d, cliff) <= (a, d) is myopic\n(d, c, cliff) <= (a, c) is myopic\n(d, f, cliff) <= (a, c, f) is myopic\nhop 3:\n(e, c, cliff) <= (a, c) is myopic\n(e, f, cliff) <= (a, c, f) is myopic\n(e, g, fore)\n(f, d, cliff) <= (a, d) is myopic\n(f, e, cliff) <= (a, b , e) is myopic\n(f, g, cliff) <= (a, b, e, g) is myopic\n(g, f, cliff) <= (a, c, f) is myopic\n(g, h, fore)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1: \n(a, b, forward)(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(b, c, drop) <= (a, c) is shorter\n(c, b, drop) <= (a, b) is shorter\n(c, e, drop) <= (a, b, e) is shorter\n(c, f, forward)\n(c, d, drop) <= (a, d) is shorter\n(d, c, drop) <= (a, c) is shorter\n(d, f, drop) <= (a, c, f) is shorter\nhop 3:\n(e, c, drop) <= (a, c) is shorter\n(e, f, drop) <= (a, c, f) is shorter\n(e, g, forward)\n(f, d, drop) <= (a, d) is shorter\n(f, e, drop) <= (a, b , e) is shorter\n(f, g, drop) <= (a, b, e, g) is shorter\n(g, f, drop) <= (a, c, f) is shorter\n(g, h, forward)",
        "original_sample_id": "smp0334q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1059q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend are attractive for wide diffusion and multicasting due to their efficient form of route search algorithm. it adds a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link status routing (lsr) to use with extension tree: all is to have to know the multicast tree. the is sends the liaison status packets periodically with its distance to the neighbors and information about its multicast group and transmits it to all others. then, each one is calculated a multicast tree from the available information. based on the multicast tree built the output line is determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing to broad- and multicasting because of its efficient way of path-finding algorithm. it aggregates a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link state routing (lsr) to use with spanning tree: all is have to know the multicast tree. the is sends the link-state packets periodically with its distance to neighbors and information about its multicast group and broadcasts it to all others. afterward, each is calculates a multicast tree from the available information received. based on the built multicast tree the is determines the outgoing line.",
        "original_sample_id": "smp1059q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1059q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend are attractive for wide diffusion and multicasting due to their efficient form of route search algorithm. it adds a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link status routing (lsr) to use with extension tree: all is to have to know the multicast tree. the is sends the liaison status packets periodically with its distance to the neighbors and information about its multicast group and transmits it to all others. then, each one is calculated a multicast tree from the available information. based on the multicast tree built the output line is determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing to broad- and multicasting because of its efficient way of path-finding algorithm. it aggregates a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link state routing (lsr) to use with spanning tree: all is have to know the multicast tree. the is sends the link-state packets periodically with its distance to neighbors and information about its multicast group and broadcasts it to all others. afterward, each is calculates a multicast tree from the available information received. based on the built multicast tree the is determines the outgoing line.",
        "original_sample_id": "smp1059q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0915q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "nosepiece table: transparent nosepieces manage a nosepiece table which contains entropy in the format station -> lan (output line) for the forwarding process. the table is initially empty so flooding is the consequence. the backward learning phase helps to fill the table with entryway e.g. if a nosepiece receives a frame from station s on lan l the nosepiece creates a new entry s -> l which means that the station s can be reached over lan l. forwarding process: transparent nosepieces implement the following decision procedure: a) frame with unknown destination is received -> action: flood the network b) source and destination lans of the frame is identical -> drop the frame c) source and destination lan differ -> send frame to destination lan since the nosepiece table forms the basis for the decision procedure this has a positive impact on the network performance",
        "answer_feedback": "the stated benefit derived from using the bridge table is not clear on what or how the network performance improves. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "bridge table: transparent bridges manage a bridge table which contains information in the format station -> lan (output line) for the forwarding process. the table is initially empty so flooding is the consequence. the backward learning phase helps to fill the table with entries e.g. if a bridge receives a frame from station s on lan l the bridge creates a new entry s -> l which means that the station s can be reached over lan l. forwarding process: transparent bridges implement the following decision procedure: a) frame with unknown destination is received -> action: flood the network b) source and destination lans of the frame is identical -> drop the frame c) source and destination lan differ -> send frame to destination lan since the bridge table forms the basis for the decision procedure this has a positive impact on the network performance",
        "original_sample_id": "smp0915q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0224q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "rho = 9/10 p(#p=10) = 0.0508 p(#p less than 10) = 0.9492 t(#p less than 10) = 0.9492 * 60s = 56,952s in 57 seconds of 60 seconds, there are less than 10 packages in the tail.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "rho = 9/10\np(#p=10) = 0.0508\np(#p less than 10) = 0.9492\n\nt(#p less than 10) =  0.9492 * 60s = 56.952s \n\nin 57sec of 60sec there are less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0224q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0224q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "rho = 9/10 p(#p=10) = 0.0508 p(#p less than 10) = 0.9492 t(#p less than 10) = 0.9492 * 60s = 56,952s in 57 seconds of 60 seconds, there are less than 10 packages in the tail.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "rho = 9/10\np(#p=10) = 0.0508\np(#p less than 10) = 0.9492\n\nt(#p less than 10) =  0.9492 * 60s = 56.952s \n\nin 57sec of 60sec there are less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0224q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0332q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: [a, b, above] [a, c, above] [a, d, below]hop 2:(b, e, below] [c, f, below]hop 3:(e, g, above)hop 4:(g, h, below]",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop) ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7,
        "original_answer": "hop 1:(a, b, forward)(a, c, forward)(a, d, forward)hop 2:(b, e, forward)(c, f, forward)hop 3:(e, g, forward)hop 4:(g, h, forward)",
        "original_sample_id": "smp0332q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1509q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking can be only used with duplex operation. the receiver of the datum to be acknowledged has to send datum in the diametrical direction in club that the acknowledgement can be \"piggybacked\" with the transmitted datum.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking can be only used with duplex operation. the receiver of the data to be acknowledged has to send data in the opposite direction in order that the acknowledgement can be \"piggybacked\" with the transmitted data.",
        "original_sample_id": "smp1509q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1649q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 -> for this horde00000000.xxxxxxxx.xxxxxxxx.xxxxxxxx -> a horde at this net\n127.255.255.255 -> broadcast on local net\n0xxxxxxx.11111111.11111111.11111111 -> broadcast on distant net\n127.x.x.x -> loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 -> for this host00000000.xxxxxxxx.xxxxxxxx.xxxxxxxx -> a host at this network\n127.255.255.255 -> broadcast on local network\n0xxxxxxx.11111111.11111111.11111111 -> broadcast on distant network\n127.x.x.x -> loopback",
        "original_sample_id": "smp1649q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0834q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp headers have a episode routine, an acknowledgement routine, an advertised window and an extra options section.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp headers have a sequence number, an acknowledgement number, an advertised window and an additional options section.",
        "original_sample_id": "smp0834q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1485q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "The roggybacking needs a duplex connection.It is often used in a sliding window protocol for better use of available channel bandwidth.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking needs a duplex connection.it is often used in a sliding window protocol for better use of the available channel bandwidth.",
        "original_sample_id": "smp1485q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0248q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe chance, that the scheme is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the scheme is _not_ full about 94.92% of the meter, resulting in about 56.952 seconds.",
        "answer_feedback": "the response does not explicitly state how the probability is multiplied with the time frame. additionally, the number of expected seconds or the probability is rounded incorrectly. the correct value is 56.952 instead of 56.96 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe probability, that the system is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the system is _not_ full about 94.92% of the time, resulting in about 56.952 seconds.",
        "original_sample_id": "smp0248q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0248q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe chance, that the organisation is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the organisation is _not_ full about 94.92% of the time, ensue in about 56.952 seconds.",
        "answer_feedback": "the response does not explicitly state how the probability is multiplied with the time frame. additionally, the number of expected seconds or the probability is rounded incorrectly. the correct value is 56.952 instead of 56.96 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe probability, that the system is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the system is _not_ full about 94.92% of the time, resulting in about 56.952 seconds.",
        "original_sample_id": "smp0248q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0248q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe probability, that the organisation is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the organisation is _not_ full about 94.92% of the clip, lead in about 56.952 seconds.",
        "answer_feedback": "the response does not explicitly state how the probability is multiplied with the time frame. additionally, the number of expected seconds or the probability is rounded incorrectly. the correct value is 56.952 instead of 56.96 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "lambda = 9/sec\nmu = 10/sec\ntherefore rho = 9/10 = 0.9\nthe probability, that the system is full: p_b = (1-rho)*rho^n/(1-rho^(n+1)) = 0.0508 (approx.)\n\ntherefore, the system is _not_ full about 94.92% of the time, resulting in about 56.952 seconds.",
        "original_sample_id": "smp0248q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0902q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains information on to which lan the span should forrad incoming packets depending on its destination. since the span works in promiscuous mode, it receives any frame from any of its lans. if it is receiving a frame on lan l from author address q, it knows that q is reachable from l and it therefore can store that information in the table, so next time, when it has to forrad a frame with destination address of q, it can forrad it to l. each entry is associated with a timestamp, making sure that old entries are purged, making the span adapt easily to changes in the topology.",
        "answer_feedback": "the correct benefit is that there is less traffic because of selective forwarding, not just topological change adaption. the remaining response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table contains information on to which lan the bridge should forward incoming packets depending on its destination. since the bridge works in promiscuous mode, it receives any frame from any of its lans. if it is receiving a frame on lan l from source address q, it knows that q is reachable from l and it therefore can store that information in the table, so next time, when it has to forward a frame with destination address of q, it can forward it to l. each entry is associated with a timestamp, making sure that old entries are purged, making the bridge adapt easily to changes in the topology.",
        "original_sample_id": "smp0902q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0390q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "Hops 1: (a, b, before)(a, c, before) (a, d, before) hops 2: (b, e, before)(c, f, before) hops 3: (e, g, before) hops 4: (g, h, before) hops",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop) ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7,
        "original_answer": "hop 1:\n(a, b, forward)(a, c, forward) (a, d, forward)\nhop 2:\n(b, e, forward)(c, f, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, forward)",
        "original_sample_id": "smp0390q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0853q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption is not maintained in real Internet traffic. in real Internet traffic packages arrive in bursts and for longer periods of time there are phases with more or less traffic. so the probability of arrival of a package is higher if the packages arrived at the previous intervals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, this assumption does not hold in the real internet traffic. in the real internet traffic packets arrive in bursts and over longer time periods there are phases with more or with less traffic. so the probability for the arrival of a packet is higher in δt if packets arrived in the previous intervals.",
        "original_sample_id": "smp0853q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1513q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "something needs to be sent in one centering, to be able to send some data back with the ack. it is basically using the default operation of mail the ack to also send some additional data back to the sender, instead of mail a new bod.",
        "answer_feedback": "the response is incorrect because it implies that the presence of data on both sides is necessary for acknowledgments to be sendable. however, one can also send pure acknowledgments when no data is available for a specific time.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "something needs to be sent in one direction, to be able to send some data back with the ack. it is basically using the default operation of sending the ack to also send some additional data back to the sender, instead of sending a new frame.",
        "original_sample_id": "smp1513q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0877q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not because Internet traffic is usually ruined which means that there is more than one package by data transmission. e.g., if you open a video on the Internet, the website sends a part of the video to fill a buffer for several seconds, so wait for the user to see a few seconds of the video and then fill it with the next part of the video. while it sends these parts, each time interval is not really independent of the previous one because the packages are too small to send the buffer data into a single package.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no because internet traffic is normally bursty which means that there are more than one packet per data transmission. for example if you open a video in the internet the webpage sends some part of the video to fill a buffer for several seconds, then waits until the user has watch some seconds of the video and then fills the buffer with the next part of the video. while sending these parts, each time interval is not really independent of the one before because the packets are too small to send the buffer data in one single packet.",
        "original_sample_id": "smp0877q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1532q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the datum link bed of one station must get a new packet from the upper bed by the end of the timeout interval",
        "answer_feedback": "the response is incorrect because even if it fails to get a packet from the upper layer, it can send the acknowledgment independently without piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the data link layer of one station must get a new packet from the upper layer by the end of the timeout interval",
        "original_sample_id": "smp1532q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0201q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the arrangement is not full, so there are less than 10 packets wait in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the arrangement being in a state with less than 10 packets wait in the queue if the arrangement is monitored for one minute after equipoise has been reached",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the system is not full, so there are less than 10 packets waiting in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 packets waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "original_sample_id": "smp0201q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0201q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. calculate the blocking chance for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this chance from one in club to get the chance that the system is not full, so there are less than 10 mailboat waiting in the queue\n\n3. multiply the last chance with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 mailboat waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the system is not full, so there are less than 10 packets waiting in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 packets waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "original_sample_id": "smp0201q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1076q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees have no cycles. * we add the additional dimension group to every link country mailboat indicating which group the sending is belongs to.",
        "answer_feedback": "while the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops. additionally, how the multicast information is used by every node to construct a multicast spanning tree is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees have no cycles. * we add the additional attribute group to every link state packet indicating which group the sending is belongs to.",
        "original_sample_id": "smp1076q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1643q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "these addresses have a range: so not only 127.0.0.0, but 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1643q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1643q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "these addresses have a range: so not only 127.0.0.0, but 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1643q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1007q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "- purpose: avoid loop formation and duplicate on the network in case we are dealing with multicast or retransmission. - reverse route forwarding: the packet forwarding depends on the reverse path of the package. if b sends so s through a, and b knows that this is the optimal path (by inspection). in contrast, if s wants to send to b, then it sends through many nodes (for example through a and via x). as a result, many duplicate packages will arrive at destination b. but b will only accept packages that follow the optimal route (the previous reverse route, through a) and discard all other packages (via x). - reverse route retransmission: use the same example above. this strategy can even prevent network congestion, in which the intermediate node (the x node) does not resend the package at all, if you know that it is not on the unicat route of s a b. so less unnecessary packages are being resending, more bandwidth can have the network.",
        "answer_feedback": "the explanation of rpb does not specify on which links a node will forward packets and how being on the best path is determined by inspecting unicast traffic. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "- purpose: to avoid loop formation and duplicate in the network in case we're dealing with multicast or broadcast. - reverse path forwarding: forwarding of the packet depends on the reverse path of the packet. if b sends so s via a, and and b knows that this is the optimal path( by inspection). in contrast, if s wants to send to b, then it sends via many nodes(for example via a and via x). as the result, many duplicate packet will reach to destination b. but b will only accept the packets that follows the optimal path(the previous reverse path, via a) and discard all others packet(via x). -reverse path broadcast: use the same example above. this strategy can even prevent the network from congestion, in which the intermediate node(the x node) doesn't forwarding the packet at all, if it knows that it's not on the uni-cast path from s to b. so the less the unnecessary packets is being forwarded, the more bandwidth the network can have.",
        "original_sample_id": "smp1007q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0926q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The table is modified by listening to all the frames of the connected lans and by updating that the sending station of the frame can be reached above the lan on which the frame was received. the table is then used to route the received frames only to the lan where the table indicates the destination of the frame is located (or deposit it if this lan is the same as the one where the package was received). This reduces the amount of frames compared to flooding them to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table includes information about which stations can be reached over which lan connected to the bridge. the table is modified by listening to all frames of the connected lans and updating that the sending station of the frame can be reached over the lan the frame has been received on. the table is then used to forward received frames only to the lan where the table says the destination of the frame is located (or drop it if this lan ist the same as the one where the packet was received on). this reduces the amount of frames compared to flooding them to all connected lans.",
        "original_sample_id": "smp0926q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0926q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the span table includes information about which stations can be attain over which lan connected to the span. the table is modified by listening to all frames of the connected lans and updating that the sending station of the frame can be attain over the lan the frame has been incur on. the table is then used to forward incur frames only to the lan where the table says the destination of the frame is located (or drop it if this lan ist the same as the one where the packet was incur on). this reduces the amount of frames compared to flooding them to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table includes information about which stations can be reached over which lan connected to the bridge. the table is modified by listening to all frames of the connected lans and updating that the sending station of the frame can be reached over the lan the frame has been received on. the table is then used to forward received frames only to the lan where the table says the destination of the frame is located (or drop it if this lan ist the same as the one where the packet was received on). this reduces the amount of frames compared to flooding them to all connected lans.",
        "original_sample_id": "smp0926q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0926q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The table is modified by listening to all the frames of the connected lans and by updating that the sending station of the frame can be reached above the lan on which the frame was received. the table is then used to route the received frames only to the lan where the table indicates the destination of the frame is located (or deposit it if this lan is the same as the one where the package was received). This reduces the amount of frames compared to flooding them to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table includes information about which stations can be reached over which lan connected to the bridge. the table is modified by listening to all frames of the connected lans and updating that the sending station of the frame can be reached over the lan the frame has been received on. the table is then used to forward received frames only to the lan where the table says the destination of the frame is located (or drop it if this lan ist the same as the one where the packet was received on). this reduces the amount of frames compared to flooding them to all connected lans.",
        "original_sample_id": "smp0926q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0926q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table includes information about which stations can be reached over which lan connected to the bridge. the table is modified by listening to all somas of the connected lans and updating that the sending station of the soma can be reached over the lan the soma has been meet on. the table is then used to forward meet somas only to the lan where the table says the destination of the soma is located (or drop it if this lan ist the same as the one where the packet was meet on). this reduces the amount of somas compared to flooding them to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table includes information about which stations can be reached over which lan connected to the bridge. the table is modified by listening to all frames of the connected lans and updating that the sending station of the frame can be reached over the lan the frame has been received on. the table is then used to forward received frames only to the lan where the table says the destination of the frame is located (or drop it if this lan ist the same as the one where the packet was received on). this reduces the amount of frames compared to flooding them to all connected lans.",
        "original_sample_id": "smp0926q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1506q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there should be duplex communication in between transmitter and receiver such that acknowledgement meant for transmitter gets appended to data form from receiver (which now roleplay as transmitter) which is being sent to transmitter (which now roleplay as receiver) and this process also works vice versa.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "there should be duplex communication in between sender and receiver such that acknowledgement meant for sender gets appended to data frame from receiver (which now acts as sender) which is being sent to sender (which now acts as receiver) and this process also works vice versa.",
        "original_sample_id": "smp1506q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1674q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.255-10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.255-10.255.255.255",
        "original_sample_id": "smp1674q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1674q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.255-10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.255-10.255.255.255",
        "original_sample_id": "smp1674q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0339q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, pearl) <== d is not on the adept path from c or f to a\nhop 2:\n(b, e, forward)(c, f, pearl) <== f is not on the adept path from g (or d) to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, pearl) <== h has no other neighbour than g",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, drop) <== d is not on the best path from c or f to a\nhop 2:\n(b, e, forward)(c, f, drop) <== f is not on the best path from g (or d) to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <== h has no other neighbor than g",
        "original_sample_id": "smp0339q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0999q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "these are methods of broadcast routing which do not waste the bandwidth or generate too many duplicates and are a variation of the spanning tree. in reverse path forwarding every sender has its own spanning tree but the is don't need to knwo them. it is considered that each router has entropy about which path it would use for packets. if a packet arrives at the is entry point it checks if this is the point over which they are usually sent. if this is the vitrine, it is assumed that the packet used the best route until now and is therefore resend over all sharpnesss excluding the incoming one. if this is not the vitrine and the packet arrived not over the best route, the packet is discarded. in reverse path broadcast the outgoing links are selected. first it will be checked if the packet arrived at the is entry over which the packets for this station are usually sent. if not, the packet is most likely a duplicate and will be discarded. if yes, it is checked if the packet has used the best route until now. if this is the vitrine, the sharpness at which the packets arrived and from which they are then rerouted to the source is selected for sending (in reverse direction). if this is not the vitrine, the packet is not send over all sharpnesss (so not like in reverse path forwarding).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "these are methods of broadcast routing which do not waste the bandwidth or generate too many duplicates and are a variation of the spanning tree. in reverse path forwarding every sender has its own spanning tree but the is don't need to knwo them. it is considered that each router has information about which path it would use for packets. if a packet arrives at the is entry point it checks if this is the point over which they are usually sent. if this is the case, it is assumed that the packet used the best route until now and is therefore resend over all edges excluding the incoming one. if this is not the case and the packet arrived not over the best route, the packet is discarded. in reverse path broadcast the outgoing links are selected. first it will be checked if the packet arrived at the is entry over which the packets for this station are usually sent. if not, the packet is most likely a duplicate and will be discarded. if yes, it is checked if the packet has used the best route until now. if this is the case, the edge at which the packets arrived and from which they are then rerouted to the source is selected for sending (in reverse direction). if this is not the case, the packet is not send over all edges (so not like in reverse path forwarding).",
        "original_sample_id": "smp0999q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp0999q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "these are methods of broadcast routing which do not waste the bandwidth or generate too many duplicates and are a variation of the spanning tree. in reverse path forwarding every sender has its own spanning tree but the is don't need to knwo them. it is considered that each router has information about which path it would use for mailboats. if a mailboat arrives at the is entry point it checks if this is the point over which they are usually sent. if this is the case, it is seize that the mailboat used the best route until now and is therefore resend over all edges excluding the incoming one. if this is not the case and the mailboat arrived not over the best route, the mailboat is discarded. in reverse path broadcast the outgoing link are selected. first it will be checked if the mailboat arrived at the is entry over which the mailboats for this station are usually sent. if not, the mailboat is most likely a duplicate and will be discarded. if yes, it is checked if the mailboat has used the best route until now. if this is the case, the edge at which the mailboats arrived and from which they are then rerouted to the source is selected for sending (in reverse direction). if this is not the case, the mailboat is not send over all edges (so not like in reverse path forwarding).",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "these are methods of broadcast routing which do not waste the bandwidth or generate too many duplicates and are a variation of the spanning tree. in reverse path forwarding every sender has its own spanning tree but the is don't need to knwo them. it is considered that each router has information about which path it would use for packets. if a packet arrives at the is entry point it checks if this is the point over which they are usually sent. if this is the case, it is assumed that the packet used the best route until now and is therefore resend over all edges excluding the incoming one. if this is not the case and the packet arrived not over the best route, the packet is discarded. in reverse path broadcast the outgoing links are selected. first it will be checked if the packet arrived at the is entry over which the packets for this station are usually sent. if not, the packet is most likely a duplicate and will be discarded. if yes, it is checked if the packet has used the best route until now. if this is the case, the edge at which the packets arrived and from which they are then rerouted to the source is selected for sending (in reverse direction). if this is not the case, the packet is not send over all edges (so not like in reverse path forwarding).",
        "original_sample_id": "smp0999q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0844q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "for real internet dealings, the assumption of inhooked comers for each time unit does not hold truth, as there are packets in sequence that belong to each other and make the comer of more packets of the same type more probable (bursty dealings). a good example for this hooked comer of packets is streaming a movie - there is a sequence of similar packets arriving until the receiving buffer is full, so we cannot speak about indepedent comer of the packets.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "for real internet traffic, the assumption of independent arrivals for each time unit does not hold truth, as there are packets in sequence that belong to each other and make the arrival of more packets of the same type more probable (bursty traffic). a good example for this dependent arrival of packets is streaming a movie - there is a sequence of similar packets arriving until the receiving buffer is full, so we cannot speak about indepedent arrival of the packets.",
        "original_sample_id": "smp0844q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0240q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "it is to be expected, that close to every second the queue, there are less than 10 packets. because first, the server only has a buffer size of 10, so there is not more than 10 packets in the queue possible, they would get discarded instead. second, the assist pace is higher than the arrival pace, contribute to a tendency, that the system should not be full for too long. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "answer_feedback": "the response is partially correct because the probability calculation step is explained correctly, but the probability of the system not being full is 94.92% instead of 98%, and the time is 56.9512 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "it is to be expected, that close to every second the queue, there are less than 10 packets. because first, the server only has a buffer size of 10, so there is not more than 10 packets in the queue possible, they would get discarded instead. second, the serving rate is higher than the arrival rate, leading to a tendency, that the system should not be full for too long. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "original_sample_id": "smp0240q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0240q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "It is to be expected, that almost every second the queue, there are less than 10 packages. because first, the server has only a buffer size of 10, so there are no more than 10 packages in the possible queue, they would be rejected instead. Then, the service rate is higher than the rate of arrival, leading to a trend, that the system should not be full for too long. we can calculate the probability explicitly, adding all the p_i for i = 1, ..., 9 and get a result of 98%, which for one minute is about 59 seconds of that.",
        "answer_feedback": "the response is partially correct because the probability calculation step is explained correctly, but the probability of the system not being full is 94.92% instead of 98%, and the time is 56.9512 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "it is to be expected, that close to every second the queue, there are less than 10 packets. because first, the server only has a buffer size of 10, so there is not more than 10 packets in the queue possible, they would get discarded instead. second, the serving rate is higher than the arrival rate, leading to a tendency, that the system should not be full for too long. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "original_sample_id": "smp0240q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0240q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "it is to be expected, that close to every second the queue, there are less than 10 mailboat. because first, the server only has a buffer size of 10, so there is not more than 10 mailboat in the queue possible, they would get discarded instead. second, the serving rate is higher than the arrival rate, leading to a disposition, that the system should not be full for too retentive. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "answer_feedback": "the response is partially correct because the probability calculation step is explained correctly, but the probability of the system not being full is 94.92% instead of 98%, and the time is 56.9512 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "it is to be expected, that close to every second the queue, there are less than 10 packets. because first, the server only has a buffer size of 10, so there is not more than 10 packets in the queue possible, they would get discarded instead. second, the serving rate is higher than the arrival rate, leading to a tendency, that the system should not be full for too long. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "original_sample_id": "smp0240q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1493q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the framing moderate inexplicit acks, duplex operation.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the frames contain implicit acks, duplex operation.",
        "original_sample_id": "smp1493q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0817q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the sender identification in udp is optional -in tcp there is an options field where you can add extra information in the lintel, this means that the tcp lintel does not have a fixed length compared to the udp lintel -the use of the checksum in udp is also optional -since tcp is connection-oriented, the tcp lintel has a lot of control flags that udp doesnt postulate. for example the syn and fin flag for establishing and releasing a connection. -the tcp lintel uses sequence numbers in order to sort packages in lawsuit they do not arrive in the correct order.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "-the sender identification in udp is optional -in tcp there is an options field where you can add extra information in the header, this means that the tcp header does not have a fixed length compared to the udp header -the use of the checksum in udp is also optional -since tcp is connection-oriented, the tcp header has a lot of control flags that udp doesnt need. for example the syn and fin flag for establishing and releasing a connection. -the tcp header uses sequence numbers in order to sort packages in case they do not arrive in the correct order.",
        "original_sample_id": "smp0817q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0932q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table contains stations and the lans they belong to. at first this table is empty. every metre the bridge sees a frame from a certain station over a lan, it can associate that station with the lan and add them to the table. in the promotion process the bridge looks up the lans of the source and the destination in the bridge table, drops the frame if they are identical, routes it to the right lan if they differ and sends it to all directions (flooding) if the destination lan is unsung. advantage: connected stations do not have to be aware of the bridge and can send frames independently of the lan where the receiver is, while the bridge handles the transmission if necessary.",
        "answer_feedback": "frames can indeed be transmitted independently of the lan, but that is not the main advantage. the bridge table benefits are less duplication, less congestion, and better bandwidth usage than flooding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge table contains stations and the lans they belong to. at first this table is empty. every time the bridge sees a frame from a certain station over a lan, it can associate that station with the lan and add them to the table. in the forwarding process the bridge looks up the lans of the source and the destination in the bridge table, drops the frame if they are identical, routes it to the right lan if they differ and sends it to all directions (flooding) if the destination lan is unknown. advantage: connected stations do not have to be aware of the bridge and can send frames independently of the lan where the receiver is, while the bridge handles the transmission if necessary.",
        "original_sample_id": "smp0932q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0222q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "size buffer=10\narrival=9/sec\nserved=10/sec\n\nso utilization= 9/10=0.9\nto calculate forget \n\np_10=((1-p)/p^10)/(1-p^(10+1))\n= 0.050\nso to find chance of non forget\n=1-p_10\n=0.95\n\nclip required= approx 57 sec. =60*0.95",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "size buffer=10\narrival=9/sec\nserved=10/sec\n\nso utilization= 9/10=0.9\nto calculate blocking \n\np_10=((1-p)/p^10)/(1-p^(10+1))\n= 0.050\nso to find probability of non blocking\n=1-p_10\n=0.95\n\ntime required= approx 57 sec. =60*0.95",
        "original_sample_id": "smp0222q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0222q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "size buffer=10\narrival=9/sec\nserved=10/sec\n\nso utilization= 9/10=0.9\nto calculate bar \n\np_10=((1-p)/p^10)/(1-p^(10+1))\n= 0.050\nso to find chance of non bar\n=1-p_10\n=0.95\n\ntime required= approx 57 sec. =60*0.95",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "size buffer=10\narrival=9/sec\nserved=10/sec\n\nso utilization= 9/10=0.9\nto calculate blocking \n\np_10=((1-p)/p^10)/(1-p^(10+1))\n= 0.050\nso to find probability of non blocking\n=1-p_10\n=0.95\n\ntime required= approx 57 sec. =60*0.95",
        "original_sample_id": "smp0222q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0371q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:(a, b, forward)(a, c, forward)(a, d, drop) <= is d wird dice nachricht nicht mehr weiterleiten, da kein weiterer node dicesen aluminum besten vorgänger besitzt \nskip 2:(b, e, forward)(c, f, drop) <= is f wird dice nachricht nicht mehr weiterleiten, da kein weiterer node dicesen aluminum besten vorgänger besitzt\nskip 3:(e, g, fordward)\nskip 4:(g, h, drop) <= is h besitzt nur dicesen einen nachbarn, daher wird dice nachricht nicht mehr weitergeleitet",
        "answer_feedback": "die response ist richtig.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:(a, b, forward)(a, c, forward)(a, d, drop) <= is d wird die nachricht nicht mehr weiterleiten, da kein weiterer node diesen als besten vorgänger besitzt \nhop 2:(b, e, forward)(c, f, drop) <= is f wird die nachricht nicht mehr weiterleiten, da kein weiterer node diesen als besten vorgänger besitzt\nhop 3:(e, g, fordward)\nhop 4:(g, h, drop) <= is h besitzt nur diesen einen nachbarn, daher wird die nachricht nicht mehr weitergeleitet",
        "original_sample_id": "smp0371q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0221q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "m/m/1/10 queue: locking probability = 0.0508 -> probability less than 10 packages = 0.9492, probability times 60 seconds: 56.9512 s -> the system is expected to be in a state with less than 10 packages for 56 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation. note that 56.95 rounds off to 57 seconds, not 56.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "m/m/1/10 queue: blocking probability = 0.0508 -> probability less then 10 packets = 0.9492, probability times 60 seconds: 56.9512 s -> it is expected that the system is in a state with less than 10 packets for 56 seconds.",
        "original_sample_id": "smp0221q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0221q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "m/m/1/10 queue: locking probability = 0.0508 -> probability less than 10 packages = 0.9492, probability times 60 seconds: 56.9512 s -> the system is expected to be in a state with less than 10 packages for 56 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation. note that 56.95 rounds off to 57 seconds, not 56.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "m/m/1/10 queue: blocking probability = 0.0508 -> probability less then 10 packets = 0.9492, probability times 60 seconds: 56.9512 s -> it is expected that the system is in a state with less than 10 packets for 56 seconds.",
        "original_sample_id": "smp0221q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0221q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "m/m/1/10 queue: blocking chance = 0.0508 -> chance less then 10 parcel = 0.9492, chance times 60 seconds: 56.9512 s -> it is expected that the system is in a nation with less than 10 parcel for 56 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation. note that 56.95 rounds off to 57 seconds, not 56.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "m/m/1/10 queue: blocking probability = 0.0508 -> probability less then 10 packets = 0.9492, probability times 60 seconds: 56.9512 s -> it is expected that the system is in a state with less than 10 packets for 56 seconds.",
        "original_sample_id": "smp0221q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1021q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf and rpb are used to reduce traffic when sending broadcast messages. rpf: they only send incoming transmission packages if they arrive by the best link (usually used link for licast) to the source. rpb: the nodes look at the packets to see if they are on the unicast path from one node to another. If they receive a transmission package, they only return them to nodes that use them on the path for a unicast package.",
        "answer_feedback": "the response is partially correct as in rpf, the node forwards the packet instead of \"resending\" it. in both algorithms, the packet is also not forwarded to the edge from which it was received. the other parts are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "rpf and rpb are used to reduce traffic when sending broadcast messages. rpf: only resend incoming broadcast packets if they came over the best link (link usually used for unicast) to the source. rpb: nodes look at packets to find out, if they are on the unicast path from one node to another. if they receive a broadcast packet, they only forward them to nodes that use them on the path for a unicast packet.",
        "original_sample_id": "smp1021q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0365q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:\n(a, b, forrader)\n(a, c, forrader)\n(a, d, bead): because d recognize that f and c won't receive packets via d.\n\nskip 2:\n(b, e, forrader)\n(c, f, bead): because f recognize that e,d and g won't receive packets via f.\n\nskip 3:\n(e, g, forrader)\n\nskip 4:\n(g, h, bead): because h can only receive packets via g.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop): because d recognize that f and c won't receive packets via d.\n\nhop 2:\n(b, e, forward)\n(c, f, drop): because f recognize that e,d and g won't receive packets via f.\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop): because h can only receive packets via g.",
        "original_sample_id": "smp0365q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1055q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "traverse tree is a subset of subnets including all routers which does not comprise loops, and thus there are no duplicates in broad- and multicasting using a traverse tree. to modify link state routing to construct a traverse tree, all is have to send link state packets peridodically, which is expanded by entropy on multicast groups. then, each is calculates a multicast tree, and based on the entropy about this tree, is determines the outgoing lines on which packets have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is a subset of subnets including all routers which does not contain loops, and thus there are no duplicates in broad- and multicasting using a spanning tree. to modify link state routing to construct a spanning tree, all is have to send link state packets peridodically, which is expanded by information on multicast groups. then, each is calculates a multicast tree, and based on the information about this tree, is determines the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1055q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1055q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning tree is a subset of subnets including all routers which does not contain loops, and thus there are no duplicates in broad- and multicasting using a spanning tree. to modify link land routing to retrace a spanning tree, all is have to send link land packets peridodically, which is expanded by information on multicast groups. then, each is calculates a multicast tree, and based on the information about this tree, is determines the outgoing lines on which packets have to be convey.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is a subset of subnets including all routers which does not contain loops, and thus there are no duplicates in broad- and multicasting using a spanning tree. to modify link state routing to construct a spanning tree, all is have to send link state packets peridodically, which is expanded by information on multicast groups. then, each is calculates a multicast tree, and based on the information about this tree, is determines the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1055q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0931q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent spans hold table information between destination and lan interface.span table initially empty and then flooding befall on every line. learning process: backward learning the span works in promiscuous mode: 1.receives any frame on any of its lans. 2.when span receives skeleton with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "transparent bridges hold table information between destination and lan interface.bridge table initially empty and then flooding happens on every line. learning process: backward learning the bridge works in promiscuous mode: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "original_sample_id": "smp0931q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0931q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "gauzy bridges hold table information between destination and lan interface.bridge table initially empty and then flooding happens on every line. learning process: backwards learning the bridge works in promiscuous style: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "transparent bridges hold table information between destination and lan interface.bridge table initially empty and then flooding happens on every line. learning process: backward learning the bridge works in promiscuous mode: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "original_sample_id": "smp0931q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0931q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent spans harbour table information between destination and lan interface.span table initially empty and then flooding happens on every line. learning process: backward learning the span works in promiscuous mode: 1.receives any frame on any of its lans. 2.when span receives frames with source destination q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "transparent bridges hold table information between destination and lan interface.bridge table initially empty and then flooding happens on every line. learning process: backward learning the bridge works in promiscuous mode: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "original_sample_id": "smp0931q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0931q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges hold board information between destination and lan interface.bridge board initially empty and then flooding happens on every line. encyclopaedism outgrowth: backward encyclopaedism the bridge works in promiscuous mode: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create board entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "transparent bridges hold table information between destination and lan interface.bridge table initially empty and then flooding happens on every line. learning process: backward learning the bridge works in promiscuous mode: 1.receives any frame on any of its lans. 2.when bridge receives frames with source address q on lan l the q can be reached over l and create table entry accordingly selective forwarding is done. benefits: they have less congestion and less packet loss and duplication.",
        "original_sample_id": "smp0931q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0343q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1: (a, b, before) (a, c, before) (a, d, fall) <= d no longer has connections that have its shortest route through hub 2: (b, e, before) (c, f, fall) <= f no longer has connections that have its shortest route through f hub 3: (e, g, before) hub 4: (g, h, fall) <= h no longer has connections that have its shortest route through h",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= d has no more connections that have its shortest path through d\nhop 2:\n(b, e, forward)\n(c, f, drop) <= f has no more connections that have its shortest path through f\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= h has no more connections that have its shortest path through h",
        "original_sample_id": "smp0343q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0847q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no because in the model the bundle arrivals have a probability to incur or not to incur a bundle. for example, overnight no bundles have to be incurd and delta(t) must be all the time 0. and while streaming a film multiple bundles have to be incurd and delta(t) must be 1 all the time. additionally, for films, bundles get incur via a stream buffer with more bundles in a row and so the arrivals are not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no because in the model the packet arrivals have a probability to receive or not to receive a packet. for example, overnight no packets have to be received and delta(t) must be all the time 0. and while streaming a movie multiple packets have to be received and delta(t) must be 1 all the time. additionally, for movies, packets get receive via a stream buffer with more packets in a row and so the arrivals are not independent.",
        "original_sample_id": "smp0847q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0997q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose is to allow transmission without storing much more for each is like an extension tree or to remember past packages, while reducing the amount of copies of packages. rpf when you receive a transmission massage from the sender only returns it, if it comes from a station that is used to send unicast messages a s. this assumes that you have learned over time that the next season is the best to take, when it is sent to s and this cellar when a package goes otherwise. if the transmission message is received from another station is supposed to be a duplicate. rpb rpf rpf to not transmit to all available stations once a message has been received on the right station. in rpb you learn which nearby stations are on a good route to s and the message is sent only to those. if for example the station has never received a message of b that goes to s only not to send a transmission message to b assuming that b receives your message from another better route.",
        "answer_feedback": "the response correctly explains rpf and rpb algorithms and their purpose. please note that is have routing tables that store past packet information to decide the best route.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to allow broadcast without storing a much additional for every is like a spanning tree or remember past packages while also reducing the amount of package copies. rpf when an is receives a broadcast massage from sender s it only forwards it, if it comes from a station the is would use to send unicast messages to s. this assumes that the is has learned over time which next station is the best one to take, when sending to s and that this hold when a package goes the other way. if the broadcast message is received from an other station the is assumes this is a douplicate. rpb refines rpf by not broadcasting to all available stations once a message has been received over the right station. in rpb the is learns which neighboring stations are on a good path to s and the message is send only to those. if for example station a has never received a message from b that goes to s than a does not send a broadcast message to b assuming that b gets its message from another “better“ route.",
        "original_sample_id": "smp0997q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp0997q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose is to allow transmission without storing much more for each is like an extension tree or to remember past packages, while reducing the amount of copies of packages. rpf when you receive a transmission massage from the sender only returns it, if it comes from a station that is used to send unicast messages a s. this assumes that you have learned over time that the next season is the best to take, when it is sent to s and this cellar when a package goes otherwise. if the transmission message is received from another station is supposed to be a duplicate. rpb rpf rpf to not transmit to all available stations once a message has been received on the right station. in rpb you learn which nearby stations are on a good route to s and the message is sent only to those. if for example the station has never received a message of b that goes to s only not to send a transmission message to b assuming that b receives your message from another better route.",
        "answer_feedback": "the response correctly explains rpf and rpb algorithms and their purpose. please note that is have routing tables that store past packet information to decide the best route.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to allow broadcast without storing a much additional for every is like a spanning tree or remember past packages while also reducing the amount of package copies. rpf when an is receives a broadcast massage from sender s it only forwards it, if it comes from a station the is would use to send unicast messages to s. this assumes that the is has learned over time which next station is the best one to take, when sending to s and that this hold when a package goes the other way. if the broadcast message is received from an other station the is assumes this is a douplicate. rpb refines rpf by not broadcasting to all available stations once a message has been received over the right station. in rpb the is learns which neighboring stations are on a good path to s and the message is send only to those. if for example station a has never received a message from b that goes to s than a does not send a broadcast message to b assuming that b gets its message from another “better“ route.",
        "original_sample_id": "smp0997q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the datum and ackknowledgements are tied together and post to poster and receiver and vice versa.\ntherefore you need to address which part of datum and acknowledgement you post by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the datum number and the acknowledgement number.\notherwise there wouldn't be an assigment which datum and ackknowledgement is post or post back between poster and receiver,\nwhen datum and ack are tied together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the datum and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of datum and acknowledgement you send by expressing form(x,y), f.e. form (1,0) or form (1,2) .\nin brackets there is the datum numeral and the acknowledgement numeral.\notherwise there wouldn't be an assigment which datum and ackknowledgement is send or send back between sender and receiver,\nwhen datum and ack are tied together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the datum and ackknowledgements are marry together and send to sender and receiver and vice versa.\ntherefore you postulate to address which part of datum and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the datum number and the acknowledgement number.\notherwise there wouldn't be an assigment which datum and ackknowledgement is send or send back between sender and receiver,\nwhen datum and ack are marry together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the datum and ackknowledgements are marry together and post to poster and receiver and vice versa.\ntherefore you need to address which part of datum and acknowledgement you post by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the datum number and the acknowledgement number.\notherwise there wouldn't be an assigment which datum and ackknowledgement is post or post back between poster and receiver,\nwhen datum and ack are marry together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the data and ackknowledgements are tied together and broadcast to broadcaster and receiver and vice versa.\ntherefore you need to address which part of data and recognition you broadcast by expressing anatomy(x,y), f.e. anatomy (1,0) or anatomy (1,2) .\nin brackets there is the data number and the recognition number.\notherwise there wouldn't be an assigment which data and ackknowledgement is broadcast or broadcast back between broadcaster and receiver,\nwhen data and ack are tied together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0998q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "these both methods are able to realize the broadcast routing upon a network.   reverse itinerary forwarding (rpf):  a sender broadcasts to all stations on the network. when a mailboat arrived at an is, the is will check if this itinerary is the one which is usually used to communicate with the sender or not. if yes, the is is able to resend the mailboat to all stations except the incoming one. if not, the is will discard the mailboat. reverse itinerary broadcast (rpb): it is almost like a improved version of rpf. if the mailboat reaches the is entry over which the mailboats for this station/source s are usually also sent and the mailboat has used the best route until now, select the edge at which the mailboat arrives, and then reroute it from that edge to the source s (reverse) , if no mailboat has not used the best route until now, do not send over all edges (without incoming edges), i.e., not as in the reverse itinerary forwarding (rpf). if the mailboat does not reach the is entry port, then the mailboat is discarded (the most likely twinned).",
        "answer_feedback": "the stated purpose is missing the goal of minimizing the number of duplicate packets during broadcasting. additionally, the description of rpb is slightly incorrect regarding discarding the packet if it \"does not reach the is entry port\". instead, the packet is discarded if it has not arrived at the is entry, over which packets for this station/source are usually sent.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "these both methods are able to realize the broadcast routing upon a network.   reverse path forwarding (rpf):  a sender broadcasts to all stations on the network. when a packet arrived at an is, the is will check if this path is the one which is usually used to communicate with the sender or not. if yes, the is is able to resend the packet to all stations except the incoming one. if not, the is will discard the packet. reverse path broadcast (rpb): it is almost like a improved version of rpf. if the packet reaches the is entry over which the packets for this station/source s are usually also sent and the packet has used the best route until now, select the edge at which the packet arrives, and then reroute it from that edge to the source s (reverse) , if no packet has not used the best route until now, do not send over all edges (without incoming edges), i.e., not as in the reverse path forwarding (rpf). if the packet does not reach the is entry port, then the packet is discarded (the most likely duplicate).",
        "original_sample_id": "smp0998q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0872q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "may not always contain for actual Internet traffic, because the receiver accepts a package or does not depend on the data packet transmission protocol. For example, the protocol requires that packages need to be received in a certain order, at this time, the time interval is not independent.",
        "answer_feedback": "though the assumption does not hold for the real internet, the reason behind this is the bursty nature of internet traffic. the arrival of a packet at a node is not dependent on whether it is accepted, buffered or dropped at a node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it can’t always hold for real internet traffic, because receiver accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time interval is not independent.",
        "original_sample_id": "smp0872q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0872q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "it can’t always hold for real internet dealings, because recipient accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time separation is not independent.",
        "answer_feedback": "though the assumption does not hold for the real internet, the reason behind this is the bursty nature of internet traffic. the arrival of a packet at a node is not dependent on whether it is accepted, buffered or dropped at a node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it can’t always hold for real internet traffic, because receiver accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time interval is not independent.",
        "original_sample_id": "smp0872q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0440q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "The sequence number indicates the exact position of the transmitted package. If the packets arrive this way, the router can match the packets, avoiding retransmission. However, this field is only 32 bits in size, which limits the unique numbers. In order to send more, a concept called \"wrap around\" is used, which requires calculation time and therefore slows down the transmission. The package id identifies the duplicates and drops them, but you have to remember the packages that have already arrived. The time of the field determines the maximum time that a packet can travel. After this time a packet of the network falls. If the messages have to travel a long distance, they will fall and will never be able to arrive.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be addressed.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "the sequence number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this field is only 32 bits in size, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicates and drops them but memory is needed to remember packets that already arrived.\nthe field time-to-live determines the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "original_sample_id": "smp0440q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0440q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "The sequence number indicates the exact position of the transmitted package. If the packets arrive this way, the router can match the packets, avoiding retransmission. However, this field is only 32 bits in size, which limits the unique numbers. In order to send more, a concept called \"wrap around\" is used, which requires calculation time and therefore slows down the transmission. The package id identifies the duplicates and drops them, but you have to remember the packages that have already arrived. The time of the field determines the maximum time that a packet can travel. After this time a packet of the network falls. If the messages have to travel a long distance, they will fall and will never be able to arrive.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be addressed.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "the sequence number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this field is only 32 bits in size, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicates and drops them but memory is needed to remember packets that already arrived.\nthe field time-to-live determines the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "original_sample_id": "smp0440q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0440q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "the episode number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this field is only 32 bits in sizing, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicates and drops them but memory is needed to remember packets that already arrived.\nthe field time-to-live regulate the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be addressed.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "the sequence number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this field is only 32 bits in size, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicates and drops them but memory is needed to remember packets that already arrived.\nthe field time-to-live determines the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "original_sample_id": "smp0440q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0440q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "the sequence number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this champaign is only 32 bits in size, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicate and drops them but memory is needed to think packets that already arrived.\nthe champaign time-to-live determines the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be addressed.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "the sequence number indicates the exact position of the transmitted packet. if packets arrive asynchronously, the router can match packets, preventing retransmission. on the other hand, this field is only 32 bits in size, which limits unique numbers. in order to still be able to send more, a concept called \"wrap around\" is used, which requires calculation time and thus slows down the transmission. \nthe packet id identifies duplicates and drops them but memory is needed to remember packets that already arrived.\nthe field time-to-live determines the max time a packet can travel. after that time a packet is dropped from the network. if messages have to travel a long distance, they will be dropped and will never be able to arrive.",
        "original_sample_id": "smp0440q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0202q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "calculate the probability of blocking (the probability that, the tail is full). Then, subtract this from 1 to get the probability that the tail is not filled. and then multiply this probability by 1 minute, to get the expected number of seconds the tail is not filled in this minute of monitoring. p_b = 0.0508 (form see slide 31) 1-p_b = 0.9492 60s * 0.9492 = 56.9512s it is expected that there are less than 10 packages waiting on the tail for almost 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you calculate the blocking probability (the probability that, the queue is full). you then subtract this from 1 to get the probability, that the queue is not full. and then multiply this probability with 1 minute, to get the expected number of seconds the queue is not full in this one minute of monitoring.\np_b = 0.0508       (formular see slide 31)\n1-p_b = 0.9492\n60s * 0.9492 = 56,9512s\nit is expected that there will be less than 10 packets waiting in the queue for nearly 57 seconds.",
        "original_sample_id": "smp0202q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0202q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "calculate the probability of blocking (the probability that, the tail is full). Then, subtract this from 1 to get the probability that the tail is not filled. and then multiply this probability by 1 minute, to get the expected number of seconds the tail is not filled in this minute of monitoring. p_b = 0.0508 (form see slide 31) 1-p_b = 0.9492 60s * 0.9492 = 56.9512s it is expected that there are less than 10 packages waiting on the tail for almost 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you calculate the blocking probability (the probability that, the queue is full). you then subtract this from 1 to get the probability, that the queue is not full. and then multiply this probability with 1 minute, to get the expected number of seconds the queue is not full in this one minute of monitoring.\np_b = 0.0508       (formular see slide 31)\n1-p_b = 0.9492\n60s * 0.9492 = 56,9512s\nit is expected that there will be less than 10 packets waiting in the queue for nearly 57 seconds.",
        "original_sample_id": "smp0202q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1508q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "- you ask a full-duplex connection\n- both sides have to be capable to act as sender and liquidator\n- the liquidator asks some data to send back along with the acknowledgement",
        "answer_feedback": "the response answers the underlying requirement correctly. apart from duplex communication other points also hold true but in absence of data, separate or explicit acknowledgment can also be sent by using a timeout timer.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- you need a full-duplex connection\n- both sides have to be able to act as sender and receiver\n- the receiver needs some data to send back along with the acknowledgement",
        "original_sample_id": "smp1508q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0807q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "[1] tcp cope contains acknowledgement number but udp cope does not.\n[2] tcp cope contains sequence number but udp cope does not.\n[3] tcp cope contains advertisement window but udp cope does not.\n[4] tcp cope contains urgent arrow but udp cope does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "[1] tcp header contains acknowledgement number but udp header does not.\n[2] tcp header contains sequence number but udp header does not.\n[3] tcp header contains advertisement window but udp header does not.\n[4] tcp header contains urgent pointer but udp header does not.",
        "original_sample_id": "smp0807q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1512q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "In addition, this requires two sequence numbers, one for each direction of transmission as it has a sliding window on both sides to send and to receive.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you need to have duplex operation. furthermore, this requires two sequence numbers, one for each transmission direction since you have a sliding window on both sides for sending and for receiving.",
        "original_sample_id": "smp1512q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0995q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of reverse path forwarding is that the intermediate systems (is) do not need to know the spanning trees. instead, each sender has its own spanning tree. when a parcel arrives at an is it checks whether this parcel arrived at the entry port over which the parcels for this sender are usually also sent, signify that no other parcel from the same sender arriving at the is has used a better route so far. if this is the vitrine, the incoming parcel is forwarded over all edges except from the incoming one. if not, the parcel gets discarded since it is not using the best route and most likely is a duplicate. the purpose of reverse path broadcast is to prevent the resending over all edges as it is the vitrine with reverse path forwarding and instead only forward the parcels over suitable edges. when a parcel arrives at an is, it also checks whether the parcel used the best route until now like above. the difference is that in this vitrine only the edge, at which the parcels which are rerouted to the sender, arrive, is selected for forwarding the incoming parcel. key point is that path information gained by inspecting unicast parcels is leveraged at each is to prevent unnecessary transmissions.",
        "answer_feedback": "the response correctly explains the rpf and rpb broadcasting algorithms. however, the purpose of both is to minimize the number of duplicate packets when broadcasting instead of eliminating the need for spanning trees.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "the purpose of reverse path forwarding is that the intermediate systems (is) do not need to know the spanning trees. instead, each sender has its own spanning tree. when a packet arrives at an is it checks whether this packet arrived at the entry port over which the packets for this sender are usually also sent, meaning that no other packet from the same sender arriving at the is has used a better route so far. if this is the case, the incoming packet is forwarded over all edges except from the incoming one. if not, the packet gets discarded since it is not using the best route and most likely is a duplicate. the purpose of reverse path broadcast is to prevent the resending over all edges as it is the case with reverse path forwarding and instead only forward the packets over suitable edges. when a packet arrives at an is, it also checks whether the packet used the best route until now like above. the difference is that in this case only the edge, at which the packets which are rerouted to the sender, arrive, is selected for forwarding the incoming packet. key point is that path information gained by inspecting unicast packets is leveraged at each is to prevent unnecessary transmissions.",
        "original_sample_id": "smp0995q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1526q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this elongation the receiver uses the acknowledgement of a frame to send datum back to the sender in the ack-frame. the sender then acknowledges this datum and sends with this acknowledgement his datum in one frame. so each infection consists of only one frame and this includes the ack for a certain frame and new datum.\nthis decreases the traffic significantly.",
        "answer_feedback": "the response answers the underlying requirement correctly. the \"use of confirmed connectionless service\" is not the only way to implement it, so it is an incorrect requirement.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a frame to send data back to the sender in the ack-frame. the sender then acknowledges this data and sends with this acknowledgement his data in one frame. so each transmission consists of only one frame and this includes the ack for a certain frame and new data.\nthis decreases the traffic significantly.",
        "original_sample_id": "smp1526q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1526q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a inning to send datum back to the transmitter in the ack-inning. the transmitter then acknowledges this datum and sends with this acknowledgement his datum in one inning. so each transmission consists of only one inning and this includes the ack for a certain inning and new datum.\nthis decreases the traffic significantly.",
        "answer_feedback": "the response answers the underlying requirement correctly. the \"use of confirmed connectionless service\" is not the only way to implement it, so it is an incorrect requirement.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a frame to send data back to the sender in the ack-frame. the sender then acknowledges this data and sends with this acknowledgement his data in one frame. so each transmission consists of only one frame and this includes the ack for a certain frame and new data.\nthis decreases the traffic significantly.",
        "original_sample_id": "smp1526q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1526q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it requires duplex operation and the role of confirmed connectionless service.\nin this extension the receiver roles the acknowledgement of a skeleton to send data back to the sender in the ack-skeleton. the sender then acknowledges this data and sends with this acknowledgement his data in one skeleton. so each contagion consists of only one skeleton and this includes the ack for a certain skeleton and new data.\nthis decreases the traffic significantly.",
        "answer_feedback": "the response answers the underlying requirement correctly. the \"use of confirmed connectionless service\" is not the only way to implement it, so it is an incorrect requirement.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a frame to send data back to the sender in the ack-frame. the sender then acknowledges this data and sends with this acknowledgement his data in one frame. so each transmission consists of only one frame and this includes the ack for a certain frame and new data.\nthis decreases the traffic significantly.",
        "original_sample_id": "smp1526q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1526q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a anatomy to send datum back to the sender in the ack-anatomy. the sender then acknowledges this datum and sends with this acknowledgement his datum in one anatomy. so each transmission consists of only one anatomy and this includes the ack for a certain anatomy and new datum.\nthis decreases the traffic significantly.",
        "answer_feedback": "the response answers the underlying requirement correctly. the \"use of confirmed connectionless service\" is not the only way to implement it, so it is an incorrect requirement.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a frame to send data back to the sender in the ack-frame. the sender then acknowledges this data and sends with this acknowledgement his data in one frame. so each transmission consists of only one frame and this includes the ack for a certain frame and new data.\nthis decreases the traffic significantly.",
        "original_sample_id": "smp1526q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1526q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a flesh to send datum back to the sender in the ack-flesh. the sender then acknowledges this datum and sends with this acknowledgement his datum in one flesh. so each transmission consists of only one flesh and this includes the ack for a certain flesh and new datum.\nthis decreases the dealings significantly.",
        "answer_feedback": "the response answers the underlying requirement correctly. the \"use of confirmed connectionless service\" is not the only way to implement it, so it is an incorrect requirement.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it requires duplex operation and the use of confirmed connectionless service.\nin this extension the receiver uses the acknowledgement of a frame to send data back to the sender in the ack-frame. the sender then acknowledges this data and sends with this acknowledgement his data in one frame. so each transmission consists of only one frame and this includes the ack for a certain frame and new data.\nthis decreases the traffic significantly.",
        "original_sample_id": "smp1526q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1062q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "extension tree is attractive for transmission and multicasting because it allows all nodes to be reached, without loops and with a minimum number of copies of packets. in order to use link state routing to build the extension tree, all intermediate systems would periodically issue link state packages, which contain the distance to their neighbors, expanded with information about multicast groups. then, each node would recalculate the best route to the other nodes and determine the outgoing lines, in which packages have to be transmitted.",
        "answer_feedback": "the response correctly states the spanning-tree property and explanation regarding the link state routing modification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is appealing for broadcast and multicasting because it allows for all nodes to be reached, without loops and with a minimum number of packet copies. in order to use link state routing to build the spanning tree, all intermediate systems would broadcast periodically link state packets, containing the distance to their neighbours, expanded with the informations on multicast groups. then, each node would recalculate the best route to the other nodes and determining the outgoing lines, on which packets have to be transmitted.",
        "original_sample_id": "smp1062q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1062q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "extension tree is attractive for transmission and multicasting because it allows all nodes to be reached, without loops and with a minimum number of copies of packets. in order to use link state routing to build the extension tree, all intermediate systems would periodically issue link state packages, which contain the distance to their neighbors, expanded with information about multicast groups. then, each node would recalculate the best route to the other nodes and determine the outgoing lines, in which packages have to be transmitted.",
        "answer_feedback": "the response correctly states the spanning-tree property and explanation regarding the link state routing modification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is appealing for broadcast and multicasting because it allows for all nodes to be reached, without loops and with a minimum number of packet copies. in order to use link state routing to build the spanning tree, all intermediate systems would broadcast periodically link state packets, containing the distance to their neighbours, expanded with the informations on multicast groups. then, each node would recalculate the best route to the other nodes and determining the outgoing lines, on which packets have to be transmitted.",
        "original_sample_id": "smp1062q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1646q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0-126.255,255,255",
        "answer_feedback": "not every address in class a is reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "1.0.0.0-126.255.255.255",
        "original_sample_id": "smp1646q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1072q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Trees that extend have no loops, which could be a problem for routing algorithms, also only a minimum number of copies are required. First, neighbors' addresses are determined and the distance is calculated. for multicast, receiver groups are considered when c calculation paths",
        "answer_feedback": "the response is partially correct because it lacks the link-state routing modification. to calculate the spanning trees for multicasting, you also have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees don't have loops, which might be a problem for routing algorithms, also only a minimal amount of copies are required. first, adresses of neighbours are determined and the distance is calculated. for multicast, receiving groups are considered whenc calculating routes",
        "original_sample_id": "smp1072q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0376q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "for the given scenario there will be no packages fallen, because each one is only forward to his neighbor if they are on the unique path of that neighbor a. in this case this results in a de-facto tree that spans without loops: hop 1: (a, b, forward) (a, c, forward) (a, d, forward) hop 2: (b, e, forward) (c, f, forward) hop 3: (e, g, forward) hop 4: (g, h, forward)",
        "answer_feedback": "as stated in the question \"list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. \" and if the packets is not forwarded, reasoning needs to be provided for the same. example (a, d, drop) reason: remaining neighbors c and f do not use d as the next hop to get to a",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7,
        "original_answer": "for the given scenario there will be no dropped packets, because every is only forwards to their neighbor if they are on the unicast path from that neighbor to a. in this case this results in a de-facto spanning tree with no loops:\nhop 1:\n(a, b, forward)(a, c, forward)(a, d, forward)\nhop 2:\n(b, e, forward)(c, f, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, forward)",
        "original_sample_id": "smp0376q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1667q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - addresses in this occlusion refer to source hosts on \"this\" network.  (for software)\n10.0.0.0/8 - this occlusion is set aside for use in private meshwork.\n4.0.0.0/8 - this occlusion is set aside for assignments to the outside system of public data meshwork.\n24.0.0.0/8 - this occlusion was allocated in early 1996 for use in provisioning ip service over cable television systems. \n39.0.0.0/8 - this occlusion was used in the \"class a subnet experiment\" that commenced in may 1995.\n127.0.0.0/8 - this occlusion is assigned for use as the internet host loopback address.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8 - addresses in this block refer to source hosts on \"this\" network.  (for software)\n10.0.0.0/8 - this block is set aside for use in private networks.\n4.0.0.0/8 - this block is set aside for assignments to the international system of public data networks.\n24.0.0.0/8 - this block was allocated in early 1996 for use in provisioning ip service over cable television systems. \n39.0.0.0/8 - this block was used in the \"class a subnet experiment\" that commenced in may 1995.\n127.0.0.0/8 - this block is assigned for use as the internet host loopback address.",
        "original_sample_id": "smp1667q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1673q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0: dummy destination\n10.0.0.0: individual meshing\n127.0.0.0: loopback",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0: dummy address\n10.0.0.0: private network\n127.0.0.0: loopback",
        "original_sample_id": "smp1673q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1673q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0: dummy reference\n10.0.0.0: secret meshing\n127.0.0.0: loopback",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0: dummy address\n10.0.0.0: private network\n127.0.0.0: loopback",
        "original_sample_id": "smp1673q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0822q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp lintel includes - a sequence number, - an acknowledgement number and - an advertised window field not present in the udp-lintel. the udp lintel includes - a packet duration field not present in the tcp-lintel.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header includes - a sequence number, - an acknowledgement number and - an advertised window field not present in the udp-header. the udp header includes - a packet length field not present in the tcp-header.",
        "original_sample_id": "smp0822q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0230q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p = 9/10 = 0.9. packets = client.\nhinder probability -> probability that 10 client are in the scheme = (1-p)p^10/(1-p^11)  -> 0.05\nthe probability that the scheme is full/blocked/ has teen client is 5% the other 95% represents that the scheme has less than 10 client.\nso in the interval 60 seconds, we expect less than 10 client for about 60s*0,95 = 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "p = 9/10 = 0.9. packets = customers.\nblocking probability -> probability that 10 customers are in the system = (1-p)p^10/(1-p^11)  -> 0.05\nthe probability that the system is full/blocked/ has teen customers is 5% the other 95% represents that the system has less than 10 customers.\nso in the interval 60 seconds, we expect less than 10 customers for about 60s*0,95 = 57 seconds.",
        "original_sample_id": "smp0230q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0230q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p = 9/10 = 0.9. parcel = customers.\nblock probability -> probability that 10 customers are in the organization = (1-p)p^10/(1-p^11)  -> 0.05\nthe probability that the organization is full/blocked/ has teen customers is 5% the other 95% represents that the organization has less than 10 customers.\nso in the interval 60 seconds, we expect less than 10 customers for about 60s*0,95 = 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "p = 9/10 = 0.9. packets = customers.\nblocking probability -> probability that 10 customers are in the system = (1-p)p^10/(1-p^11)  -> 0.05\nthe probability that the system is full/blocked/ has teen customers is 5% the other 95% represents that the system has less than 10 customers.\nso in the interval 60 seconds, we expect less than 10 customers for about 60s*0,95 = 57 seconds.",
        "original_sample_id": "smp0230q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0914q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "First the deck table is empty . during the learning process the bridge receives any frame in one of its lans. if you receive a frame in lan 1 with an original direction q, the bridge has learned that q can be reached on l and has created a table entry with this information. while the return of the table is scanned periodically and the old entries are purged if there is no update for a certain time to recognize if the position of the system has changed.",
        "answer_feedback": "the response correctly describes how transparent bridges build their bridge table and what information they contain. how this information is later used in forwarding packets selectively and the benefit derived from it is not mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "initially the bridge table is empty . during the learning process the bridge receives any frame on any of its lans. if a frame on lan 1 with a source address q is received, the bridge learned that q can be reached over l and created a table entry with this information. while forwarding the table is scanned periodically and old entries are purged if theres no update for some time to recognize if the position of the system has changed.",
        "original_sample_id": "smp0914q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0326q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:\n(a, b, forward)(a, c, forward)(a, d, cliff) d is not on unicast course of a-f, and not on the course a-c\n\nskip 2:\n(b, e, forward)(c, f, cliff) f is not on unicast course a-e / a-g\n\nskip 3:\n(e, g, forward)\n\nskip 4:\n(g, h, cliff) no neighbours available",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, drop) d is not on unicast path of a-f, and not on the path a-c\n\nhop 2:\n(b, e, forward)(c, f, drop) f is not on unicast path a-e / a-g\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop) no neighbours available",
        "original_sample_id": "smp0326q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0857q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "in general, the assumption does not hold. with streaming service for example, it is highly likely, that one bundle is followed by another one. \ntherefore, the probability of an arrival in any time gash is dependent on the previous one.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in general, the assumption does not hold. with streaming services for example, it is highly likely, that one packet is followed by another one. \ntherefore, the probability of an arrival in any time slice is dependent on the previous one.",
        "original_sample_id": "smp0857q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1515q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "slither window protocol send more than one frame at a time therefore using the bandwith of the communication groove. piggybacking means whenever a getr wants to send data, he will always send his data with ack. using this mechanism the bandwith of the groove can be used more efficiently. piggybacking only works if a the connection is duplex and the getr buffer is big enough to get data paket and ack in one package.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "sliding window protocol send more than one frame at a time therefore using the bandwith of the communication channel. piggybacking means whenever a receiver wants to send data, he will always send his data with ack. using this mechanism the bandwith of the channel can be used more efficiently. piggybacking only works if a the connection is duplex and the receiver buffer is big enough to receive data paket and ack in one package.",
        "original_sample_id": "smp1515q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0212q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "stimulant rate  =9, overhaul rate  =10 → the utilization stimulant rate/overhaul rate = 9/10= 0.9 so the utilization is 90%. \nthe probability the buffer is full p10 = p(10 client in the buffer)= p^10 x p0. \np0= 1-p/(1-p^10+1) = 0,1457. p10= 0.9^10 x 0,1457= 0,05081.\np( less than 10 client in the buffer)= 1-0,05081= 0,94919.\nthe number of seconds in the minute where there are less than 10 packets = 0,94919*60= 56,9514 second",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "input rate  =9, service rate  =10 → the utilization input rate/service rate = 9/10= 0.9 so the utilization is 90%. \nthe probability the buffer is full p10 = p(10 customers in the buffer)= p^10 x p0. \np0= 1-p/(1-p^10+1) = 0,1457. p10= 0.9^10 x 0,1457= 0,05081.\np( less than 10 customers in the buffer)= 1-0,05081= 0,94919.\nthe number of seconds in the minute where there are less than 10 packets = 0,94919*60= 56,9514 second",
        "original_sample_id": "smp0212q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0212q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "input rate  =9, service rate  =10 → the usage input rate/service rate = 9/10= 0.9 so the usage is 90%. \nthe probability the fender is full p10 = p(10 customers in the fender)= p^10 x p0. \np0= 1-p/(1-p^10+1) = 0,1457. p10= 0.9^10 x 0,1457= 0,05081.\np( less than 10 customers in the fender)= 1-0,05081= 0,94919.\nthe number of seconds in the mo where there are less than 10 packets = 0,94919*60= 56,9514 second",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "input rate  =9, service rate  =10 → the utilization input rate/service rate = 9/10= 0.9 so the utilization is 90%. \nthe probability the buffer is full p10 = p(10 customers in the buffer)= p^10 x p0. \np0= 1-p/(1-p^10+1) = 0,1457. p10= 0.9^10 x 0,1457= 0,05081.\np( less than 10 customers in the buffer)= 1-0,05081= 0,94919.\nthe number of seconds in the minute where there are less than 10 packets = 0,94919*60= 56,9514 second",
        "original_sample_id": "smp0212q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1619q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "the reserved addresses are: 10.0.0.0 - 10.255,255,255,255 and 127.0.0 - 127.255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "the reserved addresses are:\n10.0.0.0 - 10.255.255.255.255 and 127.0.0.0 - 127.255.255.255",
        "original_sample_id": "smp1619q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1698q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 - 0.255.255,255 current network 127.0.0.0 - 127.255,255,255 loopback addresses",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 - 0.255.255.255  current network\n127.0.0.0 - 127.255.255.255 loopback addresses",
        "original_sample_id": "smp1698q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1105q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a tree that extends contains only one path (most likely the shortest) each to all nodes of a given node. generate a tree that extends for multicasting, by using link status routing. 1. It is all to send link status packets periodically to all others through transmissions, containing information about the distance to their neighbors and information about multicast groups. 2. each is to calculate a multicast tree from the now available locally and complete status information. 3. It is to determine the outgoing lines in which packages have to be transmitted, based on information about the multicast tree. also, all outgoing links are removed, which do not connect group members to the node.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree contains only one (most likely the shortest) route each to all nodes from a certain node. generating a spanning tree for multicasting, by the use of link-state routing. 1. all is send link-state packets periodically to all the others by broadcasts, containing information about the distance to its neighbours and information on multicast groups. 2. each is calculates a multicast tree from the now locally available and complete state information. 3. the is determines the outgoing lines on which packets have to be transmitted, based on the information about the multicast tree. also, all outgoing links are removed, that do not connect group members to the node.",
        "original_sample_id": "smp1105q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1105q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a tree that extends contains only one path (most likely the shortest) each to all nodes of a given node. generate a tree that extends for multicasting, by using link status routing. 1. It is all to send link status packets periodically to all others through transmissions, containing information about the distance to their neighbors and information about multicast groups. 2. each is to calculate a multicast tree from the now available locally and complete status information. 3. It is to determine the outgoing lines in which packages have to be transmitted, based on information about the multicast tree. also, all outgoing links are removed, which do not connect group members to the node.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree contains only one (most likely the shortest) route each to all nodes from a certain node. generating a spanning tree for multicasting, by the use of link-state routing. 1. all is send link-state packets periodically to all the others by broadcasts, containing information about the distance to its neighbours and information on multicast groups. 2. each is calculates a multicast tree from the now locally available and complete state information. 3. the is determines the outgoing lines on which packets have to be transmitted, based on the information about the multicast tree. also, all outgoing links are removed, that do not connect group members to the node.",
        "original_sample_id": "smp1105q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1531q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the requirements for using the piggybacking extension of the sliding window protocol are a full duplex network, data that needs to be sent from the sender to the liquidator and vice versa, and a dedicated timeout timekeeper on both sides.\n\nthe full duplex network is needed so that data and acknowledgements can be transferred in both directions. data on both sides that is ready to be transferred is needed in order to allow acknowledgments to be piggybacked (otherwise acknowledgements would at some point be sent without being piggybacked). a dedicated timeout timekeeper on both sides is needed to optimize the summons. as a result, the liquidator and sender know at which point to send their acknowledgment separately to minimize the excess amount of waiting time for a data packet.",
        "answer_feedback": "the response answers the underlying requirement correctly. also optimizing the process of piggybacking by using a timeout timer is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the requirements for using the piggybacking extension of the sliding window protocol are a full duplex network, data that needs to be sent from the sender to the receiver and vice versa, and a dedicated timeout timer on both sides.\n\nthe full duplex network is needed so that data and acknowledgements can be transferred in both directions. data on both sides that is ready to be transferred is needed in order to allow acknowledgments to be piggybacked (otherwise acknowledgements would at some point be sent without being piggybacked). a dedicated timeout timer on both sides is needed to optimize the process. as a result, the receiver and sender know at which point to send their acknowledgment separately to minimize the excess amount of waiting time for a data packet.",
        "original_sample_id": "smp1531q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0873q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a bundle was encounter or not. but for exemplar, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where bundles are arriving.",
        "answer_feedback": "the response points out that packets are received continuously while streaming, but in reality, they are received in bursts. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a packet was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packets are arriving.",
        "original_sample_id": "smp0873q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0873q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the premiss realistically. the poisson process implies that for every interval delta t there is a propability wich say if a package was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packages are arriving.",
        "answer_feedback": "the response points out that packets are received continuously while streaming, but in reality, they are received in bursts. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a packet was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packets are arriving.",
        "original_sample_id": "smp0873q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10\narrival pace = 9 mailboat/sec\nprocessing pace = 10 mailboat/sec\nu = arrival pace/processing pace = 9/10 = 0.9\n\nthe chance of being less 10 mailboat (p(less 10)) in the buffer is the chance of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 mailboat in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 mailboat in the queue.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10\narrival rate = 9 parcel/sec\nprocessing rate = 10 parcel/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 parcel (p(less 10)) in the fender is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 parcel in the fender.\nsince n=10 we believe a queue model with a finite fender, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 parcel in the queue.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10 arrival rate = 9 packets/seg processing rate = 10 packets/seg u = arrival/processing rate = 9/10 = 0.9 the probability of being less than 10 packets (p{min 10) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer because n = 10 we consider a tail model with a finished buffer, so that in this case pn = ((1-u)(u^n))/(1-(u^n+1)) so, p{min 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94, because t=1min = 60seg 60seg * 0.94 = 56.4 sec, the system is expected to have less than 10 packets in the queue for 56.4 sec.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1061q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "in a tree that extends, all nodes are connected. to modify the link state routing to build a tree that extends we need to determine the adjacent direction is, then measure the distance to the neighbor is, organize the local link state information into a package, distribute information to everything is, and calculate the path based on the information of everything is.",
        "answer_feedback": "while all nodes are connected in a spanning tree,  what makes it desirable for use in multicast and broadcast is the absence of loops which reduces unnecessary duplicates.  the response only describes the classic link-state algorithm without mentioning any details on how the packet is expanded with multicast group information and how it is used to construct a  multicast spanning tree by each node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "on a spanning tree, all nodes are connected. to modify the link-state routing to construct a spanning tree we need to determine the address of adjacent is, then measure the distance to neighbor is, organize local link-state information in a packet, distribute information towards all is, and calculate the route based on the information of all is.",
        "original_sample_id": "smp1061q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless avail: transmitter commit independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless avail: transmitter commit independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented avail: before any frames will be sent, transmitter and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledge connectionless servicing: sender sends independet data soma without waiting for an acknowledgement from the receiver.\nacknowledge connectionless servicing: sender sends independet data soma which are individually acknowledge by the receiver.\nacknowledge connection-oriented servicing: before any soma will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming soma.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unrecognize connectionless service: sender sends independet data form without waiting for an acknowledgement from the receiver.\nrecognize connectionless service: sender sends independet data form which are individually recognize by the receiver.\nrecognize connection-oriented service: before any form will be sent, sender and receiver establish a connection between each other. the receiver recognize then incoming form.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognised offline service: the sender sends independent data frames without waiting for an acknowledgement of receipt.Recognised offline service: the sender sends independent data frames that are individually recognized by the receiver.Recognised connection-oriented service: before frames are sent, the sender and the receiver establish a connection with each other.The receiver recognizes the incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unnotice associationless avail: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nnotice associationless avail: sender sends independet data frames which are individually notice by the receiver.\nnotice association-oriented avail: before any frames will be sent, sender and receiver establish a association between each other. the receiver acknowledges then incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognised offline service: the sender sends independent data frames without waiting for an acknowledgement of receipt.Recognised offline service: the sender sends independent data frames that are individually recognized by the receiver.Recognised connection-oriented service: before frames are sent, the sender and the receiver establish a connection with each other.The receiver recognizes the incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0361q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1:(a,b,forward),(a,c,forward),(a,d,forward) hop 2:(b,e,forward),(c,f,forward) hop 3:(e,g,forward), hop 4:(g,h,forward) no package is filed because rpb does not send packages that do not follow the best path to the source node",
        "answer_feedback": "the packets which are not forwarded to other nodes by a node a will be considered dropped by that node in the context of the question. so (a,d, drop) should be shown ideally. as stated in the question, one has  to also provide the  reason when  message is not forwarded or dropped by a node. (a,d, drop) and (c,f,drop) : reason(-0.5p)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop1:(a,b,forward), (a,c,forward), (a,d,forward)\nhop 2:(b,e,forward), (c,f,forward)\nhop 3: (e,g,forward), \nhop 4: (g,h,forward)\nno packets are dropped because rpb does not send packets that don't follow the best path to the source node",
        "original_sample_id": "smp0361q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1630q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 give computer 127.0.0.0 loopback 10.0.0 locale kommunikation in privatm netzwerk",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0 dieser computer\n127.0.0.0 loopback\n10.0.0.0 locale kommunikation in privatem netzwerk",
        "original_sample_id": "smp1630q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1630q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 give computer 127.0.0.0 loopback 10.0.0 locale kommunikation in privatm netzwerk",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0 dieser computer\n127.0.0.0 loopback\n10.0.0.0 locale kommunikation in privatem netzwerk",
        "original_sample_id": "smp1630q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1497q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "underframe may arrest unquestioning acks",
        "answer_feedback": "the response does not identify the underlying requirement of duplex operation. implicit acknowledgment is a result of piggybacking rather than a prerequisite.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "frames may contain implicit acks",
        "original_sample_id": "smp1497q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendence -cease to cease flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and pullulate",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -fault control -end to end catamenia control udp: -connectionless -no catamenia control -no fault control or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error command -end to end course command udp: -connectionless -no course command -no error command or retransmission -maybe used with broadcast/multicast and stream",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascstopance -stop to stop flow ascstopance udp: -connectionless -no flow ascstopance -no error ascstopance or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug04smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error restraint -end to end menstruum restraint udp: -connectionless -no menstruum restraint -no error restraint or retransmission -maybe used with broadcast/multicast and swarm",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug05smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no wrongdoing ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug06smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug07smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendancy -end to end period ascendancy udp: -connectionless -no period ascendancy -no error ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug08smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end course ascendency udp: -connectionless -no course ascendency -no error ascendency or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug09smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascterminateence -terminate to terminate feed ascterminateence udp: -connectionless -no feed ascterminateence -no error ascterminateence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug10smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end menses ascendency udp: -connectionless -no menses ascendency -no error ascendency or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug11smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end current ascendency udp: -connectionless -no current ascendency -no error ascendency or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug12smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing mastery -finish to finish flow mastery udp: -connectionless -no flow mastery -no wrongdoing mastery or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug13smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error restraint -end to end menstruum restraint udp: -connectionless -no menstruum restraint -no error restraint or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug14smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error command -end to end period command udp: -connectionless -no period command -no error command or retransmission -maybe used with broadcast/multicast and teem",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug15smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug16smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendancy -end to end course ascendancy udp: -connectionless -no course ascendancy -no error ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug17smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendance -end to end flow ascendance udp: -connectionless -no flow ascendance -no wrongdoing ascendance or retransmission -maybe used with broadcast/multicast and pour",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug18smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -fault ascendancy -end to end feed ascendancy udp: -connectionless -no feed ascendancy -no fault ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug19smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error mastery -finish to finish flux mastery udp: -connectionless -no flux mastery -no error mastery or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug20smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendence -end to end flux ascendence udp: -connectionless -no flux ascendence -no error ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug21smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendance -terminate to terminate flow ascendance udp: -connectionless -no flow ascendance -no wrongdoing ascendance or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug22smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug23smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -mistake ascendance -end to end flow ascendance udp: -connectionless -no flow ascendance -no mistake ascendance or retransmission -maybe used with broadcast/multicast and pour",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0836q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is a fast, unreliable, unconnected and message-oriented transport protocol... which has no flow or error control. but can be used with broadcasting/multicasting and streaming. udp is mainly ip with a short transport header. the udp header format contains: 1. sender port: an optional 16 bit identification of the sender. when used, but when not used, it will be (000000000000000000000). 2. receiver port: it is the receiver identification and it is also 16 bits. 3. package length: it is in bytes (including the udp header). the minimum length is 8 (byte), i.e. the header without data. 4. checksum: from the header (not the package) and data for error detection.",
        "answer_feedback": "the response is correct, but apart from the differences between the tcp and udp headers, it also contains general differences between the two transport layer protocols, which were not required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is a fast and simple, unreliable, connectionless, and message-oriented transport protocol. that has no flow or error control. but may be used with broadcast/multicast and streaming.\nudp is mostly ip with a short transport header. the udp header format contains: \n1. sender port: an optional 16 bit sender identification. when used the response may be sent there, but when not used it will be (0000000000000000).\n2. receiver port: it is receiver identification and it's also 16 bit. \n3. packet length: it is in bytes (including udp header). the minimum length is 8 (byte), i.e., header without data.\n4. checksum: of the header (not the packet) and data for error detection. use of checksum optional.\n\ntcp is a connection-oriented and reliable bidirectional in-order end-to-end byte stream (socket: sock_stream) transport protocol. the connections in tcp established and torn down. there are multiplexing and demultiplexing ports at both ends. and tcp provides error control (users see correct, ordered byte sequences), end-to-end flow control (avoid overwhelming the machines at either end), and also provides congestion avoidance (avoid creating traffic jams within the network).\nthe tcp header format same as the udp header format contains source and destination ports (sender and receiver ports in udp) which are 16 bit each, and it contains checksum like the udp. but it is more complicated than the udp and it contains:\n1. sequence number. \n2. acknowledgment number (ack. no.). \n3. hl/resv/flags. \n4. advertised window.\n5. urgent pointer. \n6. and it can contain some other options…",
        "original_sample_id": "smp0836q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1477q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "both parties might charge datum simultaneously with implicit acks, therefore a full-duplex channel is need.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both parties might send data simultaneously with implicit acks, therefore a full-duplex channel is needed.",
        "original_sample_id": "smp1477q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1642q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 for boniface\n127.255.255.255 for broadcast\n127.0.0.0 to 127.255.255.255 are earmark as loopback address",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 for host\n127.255.255.255 for broadcast\n127.0.0.0 to 127.255.255.255 are reserved as loopback addresses",
        "original_sample_id": "smp1642q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1091q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees are appealing for broad- and multicasting because they include all routers without any loops, thus providing effective route. to construct a multicast sweep tree, each router has to provide additional information on multicast groups when sending information to neighbours, so each is can then calculate a sweep tree for multicasting.",
        "answer_feedback": "the response is partially correct because the link-state routing modification description lacks how the full network topology and multicast group information is distributed to all nodes. only once the network topology along with multicast group information of all nodes is available locally, can a node calculate a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees are appealing for broad- and multicasting because they include all routers without any loops, thus providing efficient paths. to construct a multicast spanning tree, each router has to provide additional information on multicast groups when sending information to neighbours, so each is can then calculate a spanning tree for multicasting.",
        "original_sample_id": "smp1091q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0829q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number: to uniquely identify each tcp package, udp does not have this header recognition number: to recognize that the package with the previous sequence number has been transmitted correctly, and it is expected that the next package. tcp has this while udp does not have. window size announced: the remaining size of the reception buffer used in the tcp flow control. udp does not have this functionality. urgent pointer: used to indicate the priority to process data in tcp, while udp treats all packages with the best effort mode without any specific priority and command.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "sequence number: to uniquely identify each tcp packet, udp does not have this header \n\nacknowledgement number: to acknowledge that the packet with the previous sequence number has been successfully transmitted, and the next packet is expected. tcp has this one while udp does not. \n\nadvertised window size: the remaining size of receiving buffer used in flow control by tcp. udp does not have this functionality. \n\nurgent pointer: is used to indicate the priority to process data in tcp, while udp treats all packets with the best effort manner without any specific priority and order.",
        "original_sample_id": "smp0829q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1633q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.x.x.x -> host or meshwork reference\n127.0.0.1 - 127.255.255.254 -> loopback  \nx.0.0.0 -> gateway (in all types of meshworks)\nn.255.255.255 -> broadcast (in all types of meshworks)here: n is meshwork reference\nx means number between 0 and 255.\nfor class a meshworks the first digit must be zero",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.x.x.x -> host or network address\n127.0.0.1 - 127.255.255.254 -> loopback  \nx.0.0.0 -> gateway (in all types of networks)\nn.255.255.255 -> broadcast (in all types of networks)here: n is network address\nx means number between 0 and 255.\nfor class a networks the first digit must be zero",
        "original_sample_id": "smp1633q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0942q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa have the mac addresses and it works like a routing mesa to transfer the information, in other words, the bridges manage mesa of post to lan (output).\n\nduring the backwards learning, bridge operates in promiscuous mode and receives any frame on any of its lan in this mode, bridge checks source address and lan, then add into the mesa. for example, bridge receives a frame with source address x on lan l, then bridge knows that x can be reached over l then creates or updates mesa entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with source address x (known destination) should be sent on lan l by using this mesa since this mesa indicates to which lan a frame with source address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the mac addresses and it works like a routing table to transfer the information, in other words, the bridges manage table of station to lan (output).\n\nduring the backwards learning, bridge operates in promiscuous mode and receives any frame on any of its lan in this mode, bridge checks source address and lan, then add into the table. for example, bridge receives a frame with source address x on lan l, then bridge knows that x can be reached over l then creates or updates table entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with source address x (known destination) should be sent on lan l by using this table since this table indicates to which lan a frame with source address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "original_sample_id": "smp0942q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0942q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa holds the mac addresses and it works like a routing mesa to transfer the information, in other words, the bridges manage mesa of station to lan (output).\n\nduring the backwards learning, bridge operates in loose mode and receives any frame on any of its lan in this mode, bridge checks beginning address and lan, then add into the mesa. for example, bridge receives a frame with beginning address x on lan l, then bridge knows that x can be reached over l then creates or updates mesa entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with beginning address x (known destination) should be sent on lan l by using this mesa since this mesa indicates to which lan a frame with beginning address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the mac addresses and it works like a routing table to transfer the information, in other words, the bridges manage table of station to lan (output).\n\nduring the backwards learning, bridge operates in promiscuous mode and receives any frame on any of its lan in this mode, bridge checks source address and lan, then add into the table. for example, bridge receives a frame with source address x on lan l, then bridge knows that x can be reached over l then creates or updates table entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with source address x (known destination) should be sent on lan l by using this table since this table indicates to which lan a frame with source address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "original_sample_id": "smp0942q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0942q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the mac addresses and it works like a routing table to transfer the information, in other words, the spans manage table of station to lan (output).\n\nduring the backwards learning, span operates in promiscuous mode and receives any framing on any of its lan in this mode, span checks source address and lan, then add into the table. for example, span receives a framing with source address x on lan l, then span knows that x can be reached over l then creates or updates table entry in its forwarding database. \n\nin the forwarding process, using the last example, then every framing with source address x (known destination) should be sent on lan l by using this table since this table indicates to which lan a framing with source address should be directed otherwise the framing is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent span reduces the traffic seen on each individual segment and improves network response time, and spans simplify other component since the spans are not visible in the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the mac addresses and it works like a routing table to transfer the information, in other words, the bridges manage table of station to lan (output).\n\nduring the backwards learning, bridge operates in promiscuous mode and receives any frame on any of its lan in this mode, bridge checks source address and lan, then add into the table. for example, bridge receives a frame with source address x on lan l, then bridge knows that x can be reached over l then creates or updates table entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with source address x (known destination) should be sent on lan l by using this table since this table indicates to which lan a frame with source address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "original_sample_id": "smp0942q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0942q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the mac directions and functions as a routing table to transfer the information, i.e., the bridges manage the station table to lan (output). during the learning backwards, the bridge operates in promiscuo mode and receives any array in one of its lan in this mode, the original direction of the bridge checks and lan, and then is added to the table. e.g., the bridge receives a frame with the direction of origin x in lan, then the bridge knows that x can be reached on it creates or updates the input of the table in its ironing database. in the ironing process, using the last example, then each image with the direction of origin x (known destination) must be sent in lan l using this table because this table indicates at which a frame with the direction of origin must be directed otherwise the frame is flooded at all ports except the port entering in this situation. in this situation, a benefit is that the transparent bridge reduces the traffic seen in each individual segment and improves the response time of the network, and the bridges are not visible since the bridges are not.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table holds the mac addresses and it works like a routing table to transfer the information, in other words, the bridges manage table of station to lan (output).\n\nduring the backwards learning, bridge operates in promiscuous mode and receives any frame on any of its lan in this mode, bridge checks source address and lan, then add into the table. for example, bridge receives a frame with source address x on lan l, then bridge knows that x can be reached over l then creates or updates table entry in its forwarding database. \n\nin the forwarding process, using the last example, then every frame with source address x (known destination) should be sent on lan l by using this table since this table indicates to which lan a frame with source address should be directed otherwise the frame is flooded to all ports except the inbound port.\n\nin this situation, one benefit is that transparent bridge reduces the traffic seen on each individual segment and improves network response time, and bridges simplify other component since the bridges are not visible in the network.",
        "original_sample_id": "smp0942q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1008q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the techniques ensure a free loop rotation of multicast packages. reverse-path-forwarding: a node that receives a package of node b on the same line as the node to send its packages to b, thinks that the packages have taken the shortest path, and distribute it to all the other neighbors. if the package is received on another route, the package will be discarded.",
        "answer_feedback": "the purpose of rpf and rpb is not just limited to multicast but also broadcast. rpf's explanation is correct, please note the packet is not forwarded to the edge from which it was received. no explanation for rpb is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the techniques ensure a loop-free forwarding of multicast packets. reverse-path-forwarding: a node that receives a package of node b on the same line as node a would send his packages to b, thinks that the packages took the shortest way, and will distribute it to all other neighbors. if the package is received on another path, package will be discarded.",
        "original_sample_id": "smp1008q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0862q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption is not supported for real Internet traffic because people usually use their connection in some time frames (e.g. watching netflix) and then it is not used for some time (e.g. while sleeping) regularly. if there is a first package more generally follow after that. so the time slot after a package has a higher probability of containing also a package.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption doesn't hold for real internet traffic because people usually use their connection in some time frames (for example watching netflix) an then don't use ist fore some time (for example while sleeping) regularly.if there is a first packet more usually follow after that. so the time slot after a packet has a higher probability to also contain a packet.",
        "original_sample_id": "smp0862q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0228q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "We have a lambda arrival rate = 9 packages per second, and a mu service rate = 10 packages per second. therefore, our system utilization is ro = lambda/mu = 9/10. since we start monitoring the system when it reaches balance, we can use the equilibrium equations to calculate the odds for each state. we take the equation for the probability p_n, that the system is in state n = 10, which means that there are 10 packages in the waiting queue, and with n = 10, which means that the buffer size of the waiting queue is 10. the equation for p_10 is therefore p_10 = ((1-ro)*ro^10) / (1-ro^11) = 0.0508 now the probability of having less than 10 packets in the waiting queue is (1 - p_10), since the normalization condition produces that the sum of all the odds for the states is equal to 1, and we can have in the majority of 10 packages in the waiting queue due to the size of the seconds 10.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we have an arrival rate lambda = 9 packets per second, and a service rate mu = 10 packets per second. therefore, our system utilization is \nro = lambda/mu = 9/10.\nsince we start monitoring the system when it reaches equilibrium, we can use the balance equations to calculate the probabilities for each state. we take the equation for the probability p_n, that the system is in state n = 10, meaning there are 10 packets in the waiting queue, and with n = 10, meaning the buffer size of the waiting queue is 10.\nthe equation for p_10 is therefore\np_10 = ((1-ro)*ro^10) / (1-ro^11) = 0.0508\nnow the probability of having less than 10 packets is (1 - p_10), since the normalization condition yields that the sum of all probabilities for the states equals 1, and we can have at most 10 packets in the waiting queue because of the buffer size 10.\ntherefore, we expect that the fraction of the time, in which we are in state p_10, is (p_10 * t), with t being the examined total time. on the other hand, we expect that the fraction of the time, in which we are not in state p_10, meaning we have less than 10 packets in the waiting queue, is ((1 - p_10) * t).\nsince we monitor the system for 60 seconds, we have t = 60s.\nwith the last term we get the result \n((1 - p_10) * 60s) = 56.9512s\ntherefore, we expect the system to have less than 10 packets in the waiting queue for approximately 56.9512 seconds of the total 60 seconds.",
        "original_sample_id": "smp0228q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0228q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "We have a lambda arrival rate = 9 packages per second, and a mu service rate = 10 packages per second. therefore, our system utilization is ro = lambda/mu = 9/10. since we start monitoring the system when it reaches balance, we can use the equilibrium equations to calculate the odds for each state. we take the equation for the probability p_n, that the system is in state n = 10, which means that there are 10 packages in the waiting queue, and with n = 10, which means that the buffer size of the waiting queue is 10. the equation for p_10 is therefore p_10 = ((1-ro)*ro^10) / (1-ro^11) = 0.0508 now the probability of having less than 10 packets in the waiting queue is (1 - p_10), since the normalization condition produces that the sum of all the odds for the states is equal to 1, and we can have in the majority of 10 packages in the waiting queue due to the size of the seconds 10.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we have an arrival rate lambda = 9 packets per second, and a service rate mu = 10 packets per second. therefore, our system utilization is \nro = lambda/mu = 9/10.\nsince we start monitoring the system when it reaches equilibrium, we can use the balance equations to calculate the probabilities for each state. we take the equation for the probability p_n, that the system is in state n = 10, meaning there are 10 packets in the waiting queue, and with n = 10, meaning the buffer size of the waiting queue is 10.\nthe equation for p_10 is therefore\np_10 = ((1-ro)*ro^10) / (1-ro^11) = 0.0508\nnow the probability of having less than 10 packets is (1 - p_10), since the normalization condition yields that the sum of all probabilities for the states equals 1, and we can have at most 10 packets in the waiting queue because of the buffer size 10.\ntherefore, we expect that the fraction of the time, in which we are in state p_10, is (p_10 * t), with t being the examined total time. on the other hand, we expect that the fraction of the time, in which we are not in state p_10, meaning we have less than 10 packets in the waiting queue, is ((1 - p_10) * t).\nsince we monitor the system for 60 seconds, we have t = 60s.\nwith the last term we get the result \n((1 - p_10) * 60s) = 56.9512s\ntherefore, we expect the system to have less than 10 packets in the waiting queue for approximately 56.9512 seconds of the total 60 seconds.",
        "original_sample_id": "smp0228q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0247q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "we have to calculate the probability for 10 mailboat being in the organization (more than 10 mailboat is not possible due to the buffer size). the counter-probability to that is the probability for having less than 10 mailboat inside the queue/organization at any given time.  \nif we now multiply this probability with the number of seconds we are monitoring the organization for (60s), we get the average/bear number of seconds the organization has less than 10 mailboat in total.\n\np10 is the probability of 10 mailboat being in the organization, it is calculated using lambda=9, mu=10, n=10 and n=10, p10=0.051.\nthe probability for the organization having less than 10 mailboat is 1-p10, and therefore the number of seconds the organization has less than 10 mailboat (out of 60 seconds) is (1-p10)*60s, which is about 56.95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we have to calculate the probability for 10 packets being in the system (more than 10 packets is not possible due to the buffer size). the counter-probability to that is the probability for having less than 10 packets inside the queue/system at any given time.  \nif we now multiply this probability with the number of seconds we are monitoring the system for (60s), we get the average/expected number of seconds the system has less than 10 packets in total.\n\np10 is the probability of 10 packets being in the system, it is calculated using lambda=9, mu=10, n=10 and n=10, p10=0.051.\nthe probability for the system having less than 10 packets is 1-p10, and therefore the number of seconds the system has less than 10 packets (out of 60 seconds) is (1-p10)*60s, which is about 56.95 seconds.",
        "original_sample_id": "smp0247q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0247q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "we have to calculate the probability for 10 packets being in the arrangement (more than 10 packets is not possible due to the fender size). the counter-probability to that is the probability for having less than 10 packets inside the queue/arrangement at any given time.  \nif we now multiply this probability with the figure of seconds we are monitoring the arrangement for (60s), we get the average/expected figure of seconds the arrangement has less than 10 packets in total.\n\np10 is the probability of 10 packets being in the arrangement, it is calculated using lambda=9, mu=10, n=10 and n=10, p10=0.051.\nthe probability for the arrangement having less than 10 packets is 1-p10, and therefore the figure of seconds the arrangement has less than 10 packets (out of 60 seconds) is (1-p10)*60s, which is about 56.95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we have to calculate the probability for 10 packets being in the system (more than 10 packets is not possible due to the buffer size). the counter-probability to that is the probability for having less than 10 packets inside the queue/system at any given time.  \nif we now multiply this probability with the number of seconds we are monitoring the system for (60s), we get the average/expected number of seconds the system has less than 10 packets in total.\n\np10 is the probability of 10 packets being in the system, it is calculated using lambda=9, mu=10, n=10 and n=10, p10=0.051.\nthe probability for the system having less than 10 packets is 1-p10, and therefore the number of seconds the system has less than 10 packets (out of 60 seconds) is (1-p10)*60s, which is about 56.95 seconds.",
        "original_sample_id": "smp0247q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0423q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use tsaps (point of access to the transport service), which are valid only for a connection+ - not always applicable because the server is reached via a designated/known tsap. 2. identify connections individually via sequence numbers+ - the final system must be able to store the suite 3. identify pdus individually+ - higher use of bandwidth and memory.",
        "answer_feedback": "advantages are not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "1. use tsaps (transport service access point), that are only valid for one connection+ - not always applicable because the server is reached via a designated/known tsap.\n\n2. identify connections individually via sequence numbers+ - endsystem needs to be capable of storing the seqno\n\n3. identify pdus individually+ - higher usage of bandwidth and memory.",
        "original_sample_id": "smp0423q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0423q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use tsaps (point of access to the transport service), which are valid only for a connection+ - not always applicable because the server is reached via a designated/known tsap. 2. identify connections individually via sequence numbers+ - the final system must be able to store the suite 3. identify pdus individually+ - higher use of bandwidth and memory.",
        "answer_feedback": "advantages are not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "1. use tsaps (transport service access point), that are only valid for one connection+ - not always applicable because the server is reached via a designated/known tsap.\n\n2. identify connections individually via sequence numbers+ - endsystem needs to be capable of storing the seqno\n\n3. identify pdus individually+ - higher usage of bandwidth and memory.",
        "original_sample_id": "smp0423q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0423q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use tsaps (point of access to the transport service), which are valid only for a connection+ - not always applicable because the server is reached via a designated/known tsap. 2. identify connections individually via sequence numbers+ - the final system must be able to store the suite 3. identify pdus individually+ - higher use of bandwidth and memory.",
        "answer_feedback": "advantages are not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "1. use tsaps (transport service access point), that are only valid for one connection+ - not always applicable because the server is reached via a designated/known tsap.\n\n2. identify connections individually via sequence numbers+ - endsystem needs to be capable of storing the seqno\n\n3. identify pdus individually+ - higher usage of bandwidth and memory.",
        "original_sample_id": "smp0423q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0423q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. habituate tsaps (rapture service access point), that are only valid for one connection+ - not always applicable becahabituate the waiter is reached via a designated/known tsap.\n\n2. identify connections individually via sequence numbers+ - endsystem needs to be capable of storing the seqno\n\n3. identify pdus individually+ - higher usage of bandwidth and memory.",
        "answer_feedback": "advantages are not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "1. use tsaps (transport service access point), that are only valid for one connection+ - not always applicable because the server is reached via a designated/known tsap.\n\n2. identify connections individually via sequence numbers+ - endsystem needs to be capable of storing the seqno\n\n3. identify pdus individually+ - higher usage of bandwidth and memory.",
        "original_sample_id": "smp0423q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an unreliable bit stream. it is the most basic type of transfer overhaul, without sequence errors.\nl2 overhaul is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical joining is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration direction.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an undependable bit stream. it is the most basic type of transfer overhaul, without sequence errors.\nl2 overhaul is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow mastery, error mastery and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 help is an unreliable bit stream. it is the most basic type of transferral help, without sequence errors.\nl2 help is a reliable and efficient datum transferral between two adjacent stations. transferral could occur between more than 2 stations, but a physical connection is required.\nl2 functions is datum transferral via frames with flow control, error control and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an unreliable bit stream. it is the most basic type of conveyance overhaul, without episode errors.\nl2 overhaul is a reliable and efficient data conveyance between two adjacent stations. conveyance could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data conveyance via frames with flow control, error control and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug06smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug07smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1638q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 - 0.255,255,255 127.0,0 - 127.255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 - 0.255.255.255\n127.0.0.0 - 127.255.255.255",
        "original_sample_id": "smp1638q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less avail: reception of data whole acknowledged.\n2.unconfirmed conn.less avail:transmission of isolated , independent whole.\n3.connection-oriented avail: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data unit acknowledged.\n2.unconfirmed conn.less overhaul:transmission of apart , independent unit.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data units acknowledged.\n2.unconfirmed conn.less overhaul:transmission of apart , independent units.\n3.connection-orient overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data units acknowledged.\n2.unconfirmed conn.less overhaul:transmission of isolated , sovereign units.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less avail: receipt of data whole acknowledged.\n2.unconfirmed conn.less avail:transmission of isolated , independent whole.\n3.connection-oriented avail: connection over fault free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of datum whole acknowledged.\n2.unconfirmed conn.less overhaul:transmission of isolated , independent whole.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1094q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an extension tree is a tree structure with only one active path, which connects any two nodes (i.e. there are no loops in the routing table).This avoids duplicate packages (reduces network load) and also helps maintain less routing information. to modify the link status routing to build an extension tree for multicasting first determines the adjacent address is. then measures the distance to “the directly adjacent is”. after that, organizes the local link status information into a package. and distributes the information to everything is. finally, calculates the ideal extension tree based on the information of everything is.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the provided information for modifying link state to construct a multicast spanning group is not complete as only the basic link-state algorithm is mentioned, it also needs to include how multicast group information is shared with other nodes.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a spanning tree is a tree structure with only one active path, that connects any two nodes (i.e. there are no loops in the routing table). this avoids duplicate packets (reduces the network load) and it also helps to maintain less routing information.  to modify link state routing to construct a spanning tree for multicasting first it determines the address of adjacent is. then it measures the distance to “the directly adjacent is”. after that, it organizes the local link-state information in a packet. and it distributes the information to all is. finally, it calculates the ideal spanning tree based on the information of all is.",
        "original_sample_id": "smp1094q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1525q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "if you use pingbacking in the protocol of the sliding window, the receiver waits for a certain period of time to attach the sequence number and the next sequence number of ack to the next table. for this, the additional delay time must be taken into account and the sender must be informed of the fact, which probably there are no independent ack frames transmitted. also, the sender must attach the ack to the data itself.",
        "answer_feedback": "the response does not identify the underlying requirement for piggybacking. the above points are related to the implementation of piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "if you use piggbacking on the sliding window protocol, \nthe receiver waits for a given time period to attach the sequence number\nand the next ack-sequence number to the next frame.\n\nin order to do that, additional time delay has to be considered and the \nsender has to be informed about the fact, that there are probably no \nstandalone ack frames transmitted. also, the sender has to attach the \nack to the data himself.",
        "original_sample_id": "smp1525q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0327q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a, b, forward) (a, c, forward) (a, d, gout) - there is a better way for hops f. 2: (b, e, forward) (c, f, gout) - there is a better way for hops g. 3: (e, g, forward) hops 4: (g, h, gout)",
        "answer_feedback": "the response is correct , but also need to provide reason for (g, h, drop).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.9,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) - there's a better path to f.\n\nhop 2:\n(b, e, forward)\n(c, f, drop) - there's a better path to g.\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop)",
        "original_sample_id": "smp0327q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1052q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "* * the inverse path of transfer (rpf) and diffusion is a technique that ensures the transfer without loop of multicast packages * the inverse path of diffusion (rpb) is an improved version of the rpf * rpf: * upon receipt of a multicast package, a router records the source address of the package and the port arrives on * if the shortest path of the router back to source is through the port the packet arrived on, the router passes the packet to all ports except that the packet arrived on * if no, the router rejects the package * * rpb: * algorithm as rpf, just with an improved selection of outgoing links * everything is inspecting the unicast packages and learning on the unicast paths - whether they are located on a certain unicast path or not * if the node receives a package from the station x to z and is not on the unicast path between x and z it does not return the data to z instead it sends it on different nodes on which it is located on the unicast path * this addition to the connections",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. rpf avoids loops not only in multicast but also in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "* * reverse path forwarding (rpf) and broadcast is a technique that’s ensures loop-free forwarding of multicast packets * reverse path broadcasting (rpb) is an improved version of the rpf * rpf: * upon receipt of a multicast packet, a router saves the source address of the packet and the port the packet arrives on * if the shortest path from the router back to the source is through the port the packet arrived on, the router forwards the packet to all ports except the one the packet arrived on * if not, the router discards the packet * * rpb: * algorithm like rpf, just with improved selection of the outgoing links * all is inspect unicast packets and learn about the unicast paths - whether they are located on a certain unicast path or not * if the node y receives a packet from station x to z and is not on the unicast path between x and z it does not resend the data to z instead it sends it over different nodes on which y is located on the unicast path * this addition to the rpf relieves some connections",
        "original_sample_id": "smp1052q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1052q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "* * the inverse path of transfer (rpf) and diffusion is a technique that ensures the transfer without loop of multicast packages * the inverse path of diffusion (rpb) is an improved version of the rpf * rpf: * upon receipt of a multicast package, a router records the source address of the package and the port arrives on * if the shortest path of the router back to source is through the port the packet arrived on, the router passes the packet to all ports except that the packet arrived on * if no, the router rejects the package * * rpb: * algorithm as rpf, just with an improved selection of outgoing links * everything is inspecting the unicast packages and learning on the unicast paths - whether they are located on a certain unicast path or not * if the node receives a package from the station x to z and is not on the unicast path between x and z it does not return the data to z instead it sends it on different nodes on which it is located on the unicast path * this addition to the connections",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. rpf avoids loops not only in multicast but also in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "* * reverse path forwarding (rpf) and broadcast is a technique that’s ensures loop-free forwarding of multicast packets * reverse path broadcasting (rpb) is an improved version of the rpf * rpf: * upon receipt of a multicast packet, a router saves the source address of the packet and the port the packet arrives on * if the shortest path from the router back to the source is through the port the packet arrived on, the router forwards the packet to all ports except the one the packet arrived on * if not, the router discards the packet * * rpb: * algorithm like rpf, just with improved selection of the outgoing links * all is inspect unicast packets and learn about the unicast paths - whether they are located on a certain unicast path or not * if the node y receives a packet from station x to z and is not on the unicast path between x and z it does not resend the data to z instead it sends it over different nodes on which y is located on the unicast path * this addition to the rpf relieves some connections",
        "original_sample_id": "smp1052q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0379q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "packages that are not forwarded to the is they came from are not listed here. (e.g. (e, b, drop))\n\nskip 1:\n(a,b, forward)\n(a,c, forward)\n\n(a,d, forward)\nskip 2:\n\n(b,e, forward)\n(b, c, drop) <= b screw that it is not located on the unicast path to a from c, therefore it does not forward the bundle.\n\n\n(c, b, drop) <= c screw that it is not located on the unicast path to a from b, therefore it does not forwardthe bundle.\n\n\n\n(c, d, drop) <= c screw that it is not located on the unicast path to a from d, therefore it does not forwardthe bundle.\n(c, e, drop) <= c screw that it is not located on the unicast path to a from e, therefore it does not forwardthe bundle.\n\n\n\n(c, f, forward)\n(d, c drop) <= d screw that it is not located on the unicast path to a from c, therefore it does not forward the bundle.\n(d, f, drop) <= d screw that it is not located on the unicast path to a from c, therefore it does not forward bundle.\n\nskip 3:\n(e, g, forward)\n(e, f, drop) <= e screw that it is not located on the unicast path to a from f, therefore it does not forward bundle.\n(e, c, drop) <= e screw that it is not located on the unicast path to a from c, therefore it does not forward bundle.\n\n\n(f, e, drop) <= f screw that it is not located on the unicast path to a from e, therefore it does not forward bundle.\n\n(f, g, drop) <= f screw that it is not located on the unicast path to a from g, therefore it does not forward bundle.\n(f, d, drop) <= f screw that it is not located on the unicast path to a from d, therefore it does not forward bundle.\n\nskip 4:\n(g, h, forward)\n(g, f, drop) <= g screw that it is not located on the unicast path to a from f therefore it does not forward bundle.",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "packages that are not forwarded to the is they came from are not listed here. (e.g. (e, b, drop))\n\nhop 1:\n(a,b, forward)\n(a,c, forward)\n\n(a,d, forward)\nhop 2:\n\n(b,e, forward)\n(b, c, drop) <= b knows that it is not located on the unicast path to a from c, therefore it does not forward the packet.\n\n\n(c, b, drop) <= c knows that it is not located on the unicast path to a from b, therefore it does not forwardthe packet.\n\n\n\n(c, d, drop) <= c knows that it is not located on the unicast path to a from d, therefore it does not forwardthe packet.\n(c, e, drop) <= c knows that it is not located on the unicast path to a from e, therefore it does not forwardthe packet.\n\n\n\n(c, f, forward)\n(d, c drop) <= d knows that it is not located on the unicast path to a from c, therefore it does not forward the packet.\n(d, f, drop) <= d knows that it is not located on the unicast path to a from c, therefore it does not forward packet.\n\nhop 3:\n(e, g, forward)\n(e, f, drop) <= e knows that it is not located on the unicast path to a from f, therefore it does not forward packet.\n(e, c, drop) <= e knows that it is not located on the unicast path to a from c, therefore it does not forward packet.\n\n\n(f, e, drop) <= f knows that it is not located on the unicast path to a from e, therefore it does not forward packet.\n\n(f, g, drop) <= f knows that it is not located on the unicast path to a from g, therefore it does not forward packet.\n(f, d, drop) <= f knows that it is not located on the unicast path to a from d, therefore it does not forward packet.\n\nhop 4:\n(g, h, forward)\n(g, f, drop) <= g knows that it is not located on the unicast path to a from f therefore it does not forward packet.",
        "original_sample_id": "smp0379q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1681q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0 - 127).0.0.0/8 -> appropriate for the network\n(0 - 127).255.255.255/8 -> appropriate for programme",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0 - 127).0.0.0/8 -> reserved for the network\n(0 - 127).255.255.255/8 -> reserved for broadcast",
        "original_sample_id": "smp1681q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1681q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0 - 127).0.0.0/8 -> book for the web\n(0 - 127).255.255.255/8 -> book for broadcast",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0 - 127).0.0.0/8 -> reserved for the network\n(0 - 127).255.255.255/8 -> reserved for broadcast",
        "original_sample_id": "smp1681q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer size is 10, so only nation where not less than 10 mailboat in the queue is nation 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich entail ca 5 % of the time the system is in the nation 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer size is 10, so only country where not less than 10 packets in the queue is country 10.\nthis is according to slide 31 the probability that the organisation is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the clip the organisation is in the country 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the cowcatcher size is 10, so only province where not less than 10 packets in the queue is province 10.\nthis is according to slide 31 the chance that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the province 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1689q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0-126.255,255,255",
        "answer_feedback": "please watch your notation: 1.0.0.0 - 126.255.255.255 does not mean, only addresses with .0.0.0 or .255.255.255, but every address in this range, for example 13.8.205.4, too",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "1.0.0.0-126.255.255.255",
        "original_sample_id": "smp1689q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1067q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property: as there is only a single and unique path between all the nodes in the tree and so there is no duplication while sending which makes them appealing for broad molding and multi molding. each node in cross tree knows to which group it belongs to but does not know (initially) which other is belong to the group as well.the dispersion depends on the underlying routing protocol.each is calculates a multicast tree from the locally available and complete state information and based on the information about the multicast tree,the is determines the outgoing lines on which packets have to be transmitted.",
        "answer_feedback": "the response correctly identifies the appealing property of a spanning tree for broadcast and multicast. the modification of the link state algorithm for constructing a spanning tree does not explain how each node shares its multicast information with others by adding it to the link state packet. this leads to each node having complete information to build a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "property: as there is only a single and unique path between all the nodes in the tree and so there is no duplication while sending which makes them appealing for broad casting and multi casting. each node in spanning tree knows to which group it belongs to but does not know (initially) which other is belong to the group as well.the distribution depends on the underlying routing protocol.each is calculates a multicast tree from the locally available and complete state information and based on the information about the multicast tree,the is determines the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1067q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0928q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table contains information for each known station/destination, on which the exit line towards the front packages in order to reach this station. in the learning phase back, it records information of all the images it receives on all the lans to which it is connected. if it receives a frame from a source q on the lan l, it updates or creates an entry in its table suggesting that q can be reached on the exit line at l. the bridge only needs to advance the frame if the source and the lans of destination differ or use the flood if the destination is unknown, otherwise the frame is abandoned. the advantage is, that the bridge learns from traffic, so for the stations the bridge is transparent, and it adapts to changes in topology",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the bridge table holds information for each known station/destination, on which output line to forward packets in order to reach that station. in the backwards learning phase, it saves information from all frames it receives on all lans it is connected to. if it receives a frame from a source q on lan l, it updates or creates an entry in its table suggesting that q can be reached over the output line to l. the bridge only needs to forward the frame if the source and destination lans differ or use flooding if the destination is unknown, otherwise the frame is dropped. the benefit is, that the bridge learns from traffic, so for stations the bridge is transparent, and it adapts to changes in the topology",
        "original_sample_id": "smp0928q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1629q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "from  0.0.0.0 to 0.255.255.255 : the current meshwork\n127.0.0.0 to 127.255.255.255 : loopback destination ( program )",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "from  0.0.0.0 to 0.255.255.255 : the current network\n127.0.0.0 to 127.255.255.255 : loopback addresses ( broadcast )",
        "original_sample_id": "smp1629q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0232q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "On average, there are 9 packages in the buffer per second. lambda = 9 t=1 p{less than 10 packages in the buffer) = p(0 packages) +...+ p(9 packages) = sum(k=0 to 9)[ 9^k * ex(-9) / k!] = 0.5874 0.5874 * 60s = 35s",
        "answer_feedback": "the obtained probability for less than 10 packets is incorrect, and so is the time. the idea behind the steps is correct, but the calculation is wrong.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "on average, there are 9 packets in the buffer per second.\nlambda = 9\nt=1\n\np(less than 10 packets in the buffer) = p(0 packets) +...+ p(9 packets) = sum(k=0 to 9)[ 9^k * exp(-9) / k!] = 0,5874\n\n0,5874 * 60s = 35s",
        "original_sample_id": "smp0232q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0232q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "On average, there are 9 packages in the buffer per second. lambda = 9 t=1 p{less than 10 packages in the buffer) = p(0 packages) +...+ p(9 packages) = sum(k=0 to 9)[ 9^k * ex(-9) / k!] = 0.5874 0.5874 * 60s = 35s",
        "answer_feedback": "the obtained probability for less than 10 packets is incorrect, and so is the time. the idea behind the steps is correct, but the calculation is wrong.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "on average, there are 9 packets in the buffer per second.\nlambda = 9\nt=1\n\np(less than 10 packets in the buffer) = p(0 packets) +...+ p(9 packets) = sum(k=0 to 9)[ 9^k * exp(-9) / k!] = 0,5874\n\n0,5874 * 60s = 35s",
        "original_sample_id": "smp0232q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1528q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "in order to use piggybacking extension, it's necessary that the used different frame formats:\n- the information frame with a field for the acknowledgement episode bit\n- a acknowlegment frame, that has the ack episode bit\nthis extension also demands more memory, because it's necessary to keep track of the exchanged episode bits (both data sent and ack episode bits).",
        "answer_feedback": "the response identifies a separate acknowledgment field in the frame correctly as one of the requirements.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in order to use piggybacking extension, it's necessary that the used different frame formats:\n- the information frame with a field for the acknowledgement sequence number\n- a acknowlegment frame, that has the ack sequence number\nthis extension also demands more memory, because it's necessary to keep track of the exchanged sequence numbers (both data sent and ack sequence numbers).",
        "original_sample_id": "smp1528q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0858q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, the hypothesis of independence (for each interval of the gap) does not apply to the real world. suppose video traffic in the form of viewing netflix: there will be much more video traffic in the evening than in the morning. therefore, it is dependent from the hour of the day and not independent as assumed in the fish process.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like more video traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, the assumption of independence (for each interval ∆t) does not apply to the real world. assume video traffic in the form of watching netflix: there will be significant more video traffic in the evening than in the morning. therefore, the it is dependent from the time of the day and not independent as assumed within the poisson process.",
        "original_sample_id": "smp0858q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0858q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, the hypothesis of independence (for each interval of the gap) does not apply to the real world. suppose video traffic in the form of viewing netflix: there will be much more video traffic in the evening than in the morning. therefore, it is dependent from the hour of the day and not independent as assumed in the fish process.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like more video traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, the assumption of independence (for each interval ∆t) does not apply to the real world. assume video traffic in the form of watching netflix: there will be significant more video traffic in the evening than in the morning. therefore, the it is dependent from the time of the day and not independent as assumed within the poisson process.",
        "original_sample_id": "smp0858q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0921q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the nosepiece receives every frame of each connected lan and the nosepiece table holds the mac adresses. in the backwards learning phase the nosepiece receives framing with the source adress q on lan l, so q can be reached over l and the according table entry gets created. the table is used in the forwarding appendage to examine the mac adresses to find the specific location of the devices.",
        "answer_feedback": "the bridge contains station to lan mappings for the previously received packets along with the timestamp, so stating it contains only the mac address is not completely correct. the explanation of backward learning and selective forwarding is correct. the benefit of using the bridge table in forwarding is not mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the bridge receives every frame of each connected lan and the bridge table holds the mac adresses. in the backwards learning phase the bridge receives frames with the source adress q on lan l, so q can be reached over l and the according table entry gets created. the table is used in the forwarding process to examine the mac adresses to find the specific location of the devices.",
        "original_sample_id": "smp0921q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0869q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis does not correspond perfectly to the real internet traffic, because in real traffic, there is often a continuous flow of data, when transmitting a file. If a file is for example divided into 3 packages and transmitted over a network, then these 3 packages will arrive relatively close to each other in relation to the packages of another transfer. Thus, in a transmission, delta t is usually much lower than between different transmissions, which means that delta t are not really independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption doesn't fit real internet traffic perfectly, because in real traffic, there often is a continuous flow of data, when transmitting a file. if a file is for example split into 3 packets and transmitted over a network, then these 3 packets will arrive relatively close to each other in comparison to the packets of another transfer. so within a transmission, delta t is usually a lot lower than between different transmissions, which means the delta t's are not really independent.",
        "original_sample_id": "smp0869q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1503q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "- the initial follow-up is 0 - the next follow-up and the next ack-seqno to be expected is given",
        "answer_feedback": "the response does not identify the underlying requirement for piggybacking. the\"initial seqno. is 0\" is incorrect and the next seqno. and the next ack-seqno alone cannot be considered as a requirement but more of an implementation detail.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "- the initial seqno. is 0\n- the next seqno. and the next ack-seqno to be expected is given",
        "original_sample_id": "smp1503q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0851q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the assumption. the arrivals are more or less bundled because the package are arriving after each other when you use the cyberspace. they are arriving more or less in a small timespan. therefore the arrival of two package is not sovereign.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption. the arrivals are more or less bundled because the packages are arriving after each other when you use the internet. they are arriving more or less in a small timespan. therefore the arrival of two packages is not independent.",
        "original_sample_id": "smp0851q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0851q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it doesn't have the guess. the arrivals are more or less packed because the packages arrive one after the other when the Internet is used. they arrive more or less in a small time frame. so the arrival of two packages is not independent.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption. the arrivals are more or less bundled because the packages are arriving after each other when you use the internet. they are arriving more or less in a small timespan. therefore the arrival of two packages is not independent.",
        "original_sample_id": "smp0851q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0849q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "in the poisson process, the number of incoming packages follows the poisson distribution, is easier to control than in the actual Internet traffic. observation by using the poisson process requires conservative operating point, which does not involve with the actual Internet traffic.",
        "answer_feedback": "the conclusion \"no\" is correct but the explanation does not explain why these conservative operating conditions do not hold true for the real internet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "in the poisson process, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet traffic. observation by using poisson process requires conservative operating point, that does not imply with real internet traffic.",
        "original_sample_id": "smp0849q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0849q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "in the poisson summons, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet dealings. observation by using poisson summons demand conservative operating point, that does not imply with real internet dealings.",
        "answer_feedback": "the conclusion \"no\" is correct but the explanation does not explain why these conservative operating conditions do not hold true for the real internet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "in the poisson process, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet traffic. observation by using poisson process requires conservative operating point, that does not imply with real internet traffic.",
        "original_sample_id": "smp0849q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0870q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption is not a good model in the real cyberspace traffic, since the packets come in bursts over a range of metre scales in the real network traffic, but not independently in a certain metre separation. so this process is just mathematically.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this assumption is not a good model in the real internet traffic, since the packets come in bursts over a range of time scales in the real network traffic, but not independently in a certain time interval. so this process is just mathematically.",
        "original_sample_id": "smp0870q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0870q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption is not a just simulation in the real internet traffic, since the packets come in bursts over a range of time scales in the real network traffic, but not independently in a certain time interval. so this outgrowth is just mathematically.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this assumption is not a good model in the real internet traffic, since the packets come in bursts over a range of time scales in the real network traffic, but not independently in a certain time interval. so this process is just mathematically.",
        "original_sample_id": "smp0870q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless service, the data link layer of the sending auto sends an independent frame to the data link layer on the receiving auto.\nacknowledged connectionless service, there is no ordered connection is set up between the host autos, however, each frame was sent is acknowledged by the destination auto.\nacknowledged connection-orientate service, a ordered connection is set up on the two autos and the data is transmitted along the ordered path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognized offline service, the data link layer of the sending machine sends an independent framework to the data link layer on the receiving machine. Recognized service without connection, no logical connection is established between the host machines, however, each frame was sent is recognized by the destination machine. Recognized connection-oriented service, a logical connection is established on the two machines and the data is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognized offline service, the data link layer of the sending machine sends an independent framework to the data link layer on the receiving machine. Recognized service without connection, no logical connection is established between the host machines, however, each frame was sent is recognized by the destination machine. Recognized connection-oriented service, a logical connection is established on the two machines and the data is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless overhaul, the datum link layer of the sending machine sends an independent frame to the datum link layer on the receiving machine.\nacknowledged connectionless overhaul, there is no logical connection is set up between the host machines, however, each frame was post is acknowledged by the destination machine.\nacknowledged connection-oriented overhaul, a logical connection is set up on the two machines and the datum is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectiveless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectiveless service, there is no ordered connective is set up between the host machines, however, each frame was mail is acknowledged by the destination machine.\nacknowledged connective-oriented service, a ordered connective is set up on the two machines and the data is transmitted along the ordered path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connexionless service, the data link layer of the sending machine charge an autonomous frame to the data link layer on the receiving machine.\nacknowledged connexionless service, there is no logical connexion is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connexion-oriented service, a logical connexion is set up on the two machines and the data is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1666q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0 - 126.0.0 1.255.255,255 - 126.255,255,255 (transmission) 127.0.0 - 127.255,255,255 (regress)",
        "answer_feedback": "please watch your notation: 1.0.0.0 - 126.0.0.0 does not mean, only addresses with .0.0.0, but every address in this range, for example 13.8.255.4, too",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "1.0.0.0 - 126.0.0.0\n1.255.255.255 - 126.255.255.255 (broadcast)\n127.0.0.0 - 127.255.255.255 (loopback)",
        "original_sample_id": "smp1666q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1666q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "1.0.0.0 - 126.0.0 1.255.255,255 - 126.255,255,255 (transmission) 127.0.0 - 127.255,255,255 (regress)",
        "answer_feedback": "please watch your notation: 1.0.0.0 - 126.0.0.0 does not mean, only addresses with .0.0.0, but every address in this range, for example 13.8.255.4, too",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "1.0.0.0 - 126.0.0.0\n1.255.255.255 - 126.255.255.255 (broadcast)\n127.0.0.0 - 127.255.255.255 (loopback)",
        "original_sample_id": "smp1666q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0345q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1\n(a, b, forward)(a, c, forward)(a, d, forward)\n\nhop 2\n(b,c, drop) not unforesightful itinerary, not minimal sweep tree, previously visited(d,c, drop) not unforesightful itinerary, not minimal sweep tree, previously visited(c,e, drop) not unforesightful itinerary, not minimal sweep tree(d,f, drop) not unforesightful itinerary, not minimal sweep tree(b,e, forward)(c,f, forward)hop 3\n(e,f, drop) not unforesightful itinerary, not minimal sweep tree, previously visited(f,e, drop) not unforesightful itinerary, not minimal sweep tree, previously visited(f,g, drop) not unforesightful itinerary, not minimal sweep tree(e,g, forward)\nhop 4\n(g, h, forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1\n(a, b, forward)(a, c, forward)(a, d, forward)\n\nhop 2\n(b,c, drop) not shortest route, not minimal spanning tree, previously visited(d,c, drop) not shortest route, not minimal spanning tree, previously visited(c,e, drop) not shortest route, not minimal spanning tree(d,f, drop) not shortest route, not minimal spanning tree(b,e, forward)(c,f, forward)hop 3\n(e,f, drop) not shortest route, not minimal spanning tree, previously visited(f,e, drop) not shortest route, not minimal spanning tree, previously visited(f,g, drop) not shortest route, not minimal spanning tree(e,g, forward)\nhop 4\n(g, h, forward)",
        "original_sample_id": "smp0345q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0889q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The table contains information on the associated stations and lans on which these stations could be reached through the bridge. in retrograde learning phase, the bridge operates in promiscuo mode, which means that it receives any frame in one of its lans, so that when the bridge receives frames with direction of origin q in lan l, it would mean that the station q can be reached on lan l. so now we create the entrance of the table according to this information learned. How is the table used in the turning process: by generation of trees that extend with lans as edges and bridges as knots. the bridge are actually identified by unique identifiers (such as serial number or mac direction) and then it is assumed that all bridges transmit their unique id, from which one chooses the lowest id as root for all other bridges. benefit is that loops can be avoided and this increases reliability since we are able to connect lans across several bridges in parallel.",
        "answer_feedback": "the response incorrectly mentions the forwarding and the benefit in multiple transparent bridges scenario but the question asked how the information learned in the backward learning is used for forwarding packets and the benefit derived from it. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "table holds information about stations and associated lans over which these stations could be reached through the bridge.\nin backwards learning phase, the bridge works in promiscuous mode, meaning that it receives any frame on any of its lans, so when bridge receives frames with source address q on lan l, this would mean that station q can be reached over lan l. therefore now we create table entry according to this learned information.\nhow is the table used in the forwarding process: by generation of spanning trees with lans as edges and bridges as nodes. the bridge are actually identified by unique identifiers (such as serial number or mac address) and then all the bridges are supposed to broadcast their unique id, from which lowest id is chosen as root for all other bridges. \nbenefit is that loops can be avoided and this increases reliability as we are able to connect lans via various bridges in parallel.",
        "original_sample_id": "smp0889q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen croak beiden cocroakrungstechniken manchester encoding und differential manchester encoding leider raus, da croakse eine doppelte bit pace bräuchten.\nich würde das binary encoding nutzen, da croakses künstig ist und croak bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen exit beiden coexitrungstechniken manchester encode und differential manchester encode leider raus, da exitse eine doppelte morsel rate bräuchten.\nich würde das binary encode nutzen, da exitses künstig ist und exit bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist shine croak beiden cocroakrungstechniken manchester encode und differential manchester encode leider raus, da croakse eine doppelte bit rate bräuchten.\nich würde das binary encode nutzen, da croakses künstig ist und croak bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen croak beiden cocroakrungstechniken manchester encode und differential manchester encode leider raus, da croakse eine doppelte bit rate bräuchten.\nich würde das binary encode nutzen, da croakses künstig ist und croak bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist lessen die beiden codierungstechniken manchester encryption und differential manchester encryption leider raus, da diese eine doppelte routine rate bräuchten.\nich würde das binary encryption nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen break beiden cobreakrungstechniken manchester encode und differential manchester encode leider raus, da breakse eine doppelte routine rate bräuchten.\nich würde das binary encode nutzen, da breakses künstig ist und break bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen expire beiden coexpirerungstechniken manchester encoding und differential manchester encoding leider raus, da expirese eine doppelte flake rate bräuchten.\nich würde das binary encoding nutzen, da expireses künstig ist und expire bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist fallen pass beiden copassrungstechniken manchester encode und differential manchester encode leider raus, da passse eine doppelte bit rate bräuchten.\nich würde das binary encode nutzen, da passses künstig ist und pass bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug08smp0178q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "dadurch das das netzwerk überlastet ist precipitate perish beiden coperishrungstechniken manchester encryption und differential manchester encryption leider raus, da perishse eine doppelte bit rate bräuchten.\nich würde das binary encryption nutzen, da perishses künstig ist und perish bandbreite komplett ausnutzt.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "dadurch das das netzwerk überlastet ist fallen die beiden codierungstechniken manchester encoding und differential manchester encoding leider raus, da diese eine doppelte bit rate bräuchten.\nich würde das binary encoding nutzen, da dieses künstig ist und die bandbreite komplett ausnutzt.",
        "original_sample_id": "smp0178q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1529q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for this to work, first you need a duplex mode of operation. in the normal concept of the sliding window, each incoming data unit is recognized as soon as the receiver receives it. for the recognition to be temporarily delayed, until the previous incoming data is processed and the network layer passes the next package to be sent back. the delayed recognition is now attached to the outgoing package.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in the piggybacking extension, outgoing acknowledgements are hooked onto the next outgoing packet. for this to work, you first need a duplex operation mode. in the normal sliding window concept, every incoming data unit is acknowledged as soon as the receiver gets it. for piggybacking, the acknowledgement needs to be temporarily delayed, until the previous incoming data is processed and the network layer passes the next packet to be sent back. the delayed acknowledgement is now attached to the outgoing packet.",
        "original_sample_id": "smp1529q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0239q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "For each second, there will be less than 10 packages, as more packages are served than packages that reach the queue.",
        "answer_feedback": "the response implies that the system is waiting for a whole minute which is incorrect as the system is less than full for 56.95 seconds instead.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "for every seconds, there will be less than 10 packets, since more packets are served than the packets arriving in the queue.",
        "original_sample_id": "smp0239q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0239q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "For each second, there will be less than 10 packages, as more packages are served than packages that reach the queue.",
        "answer_feedback": "the response implies that the system is waiting for a whole minute which is incorrect as the system is less than full for 56.95 seconds instead.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "for every seconds, there will be less than 10 packets, since more packets are served than the packets arriving in the queue.",
        "original_sample_id": "smp0239q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1524q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the initial sequence number is 0 and the next sequence number is given and the next sequence number is given.",
        "answer_feedback": "the response does not identify the underlying requirement of duplex operation. the stated points are not always true and depend on the implementation.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the initial sequence number is 0 and the next sequence number and the next ack-sequence number to be expected is given",
        "original_sample_id": "smp1524q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1693q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 255,255,255,255",
        "answer_feedback": "255.255.255.255 not in class a. -loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0\n255.255.255.255",
        "original_sample_id": "smp1693q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(h,g,forward) hop 2: (g,e,forward) (g,f,drop)$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(h,g,onwards)\nhop 2:\n(g,e,onwards)\n(g,f,drop)<=not the shortest course\nhop 3:\n(e,c,onwards)\n(e,b,drop)<=it is not settle on the unicast course from e to a\n(e,f,drop)<=it is not settle on the unicast course from e to a\nhop 4:\n(c,a,onwards)\n(c,b,drop)<=it is not settle on the unicast course from c to a\n(c,d,drop)<=it is not settle on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug02smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(h,g,forrad)\nhop 2:\n(g,e,forrad)\n(g,f,drop)<=not the shortest course\nhop 3:\n(e,c,forrad)\n(e,b,drop)<=it is not settle on the unicast course from e to a\n(e,f,drop)<=it is not settle on the unicast course from e to a\nhop 4:\n(c,a,forrad)\n(c,b,drop)<=it is not settle on the unicast course from c to a\n(c,d,drop)<=it is not settle on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug03smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(h,g,forward) hop 2: (g,e,forward) (g,f,drop)$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug04smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:(h,g,forward)\nskip 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest course\nskip 3:\n(e,c,forward)\n(e,b,drop)<=it is not place on the unicast course from e to a\n(e,f,drop)<=it is not place on the unicast course from e to a\nskip 4:\n(c,a,forward)\n(c,b,drop)<=it is not place on the unicast course from c to a\n(c,d,drop)<=it is not place on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug05smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:(h,g,forward)\nskip 2:\n(g,e,forward)\n(g,f,drop)<=not the unforesightful course\nskip 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast course from e to a\n(e,f,drop)<=it is not located on the unicast course from e to a\nskip 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast course from c to a\n(c,d,drop)<=it is not located on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug06smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1:(h,g,forward)\nskip 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest course\nskip 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast course from e to a\n(e,f,drop)<=it is not located on the unicast course from e to a\nskip 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast course from c to a\n(c,d,drop)<=it is not located on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug07smp0342q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the myopic course\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not settle on the unicast course from e to a\n(e,f,drop)<=it is not settle on the unicast course from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not settle on the unicast course from c to a\n(c,d,drop)<=it is not settle on the unicast course from c to a",
        "answer_feedback": "the routing starts from the a  as sender and this will result in change in the packets forwarded or dropped.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:(h,g,forward)\nhop 2:\n(g,e,forward)\n(g,f,drop)<=not the shortest path\nhop 3:\n(e,c,forward)\n(e,b,drop)<=it is not located on the unicast path from e to a\n(e,f,drop)<=it is not located on the unicast path from e to a\nhop 4:\n(c,a,forward)\n(c,b,drop)<=it is not located on the unicast path from c to a\n(c,d,drop)<=it is not located on the unicast path from c to a",
        "original_sample_id": "smp0342q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0455q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "For products not used in the manufacture of products of heading 8503, the value of the products of heading 8503 shall not exceed 50 % of the ex-works price of the product.",
        "answer_feedback": "only two methods given.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "eine seqno ausgeben, die für jede operation ausgeben wird, nachteil: empfänger muss nummern speichern, vorteil: nachfolgende pakete können ingoniert werden\neine neue tsap vergeben, nachteil: ist nicht immmer möglich, manche tsaps sind immer möglich, vorteil: ist nur einmal valide, danach keine verbindung möglich",
        "original_sample_id": "smp0455q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0455q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "For products not used in the manufacture of products of heading 8503, the value of the products of heading 8503 shall not exceed 50 % of the ex-works price of the product.",
        "answer_feedback": "only two methods given.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "eine seqno ausgeben, die für jede operation ausgeben wird, nachteil: empfänger muss nummern speichern, vorteil: nachfolgende pakete können ingoniert werden\neine neue tsap vergeben, nachteil: ist nicht immmer möglich, manche tsaps sind immer möglich, vorteil: ist nur einmal valide, danach keine verbindung möglich",
        "original_sample_id": "smp0455q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0455q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "For products not used in the manufacture of products of heading 8503, the value of the products of heading 8503 shall not exceed 50 % of the ex-works price of the product.",
        "answer_feedback": "only two methods given.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "eine seqno ausgeben, die für jede operation ausgeben wird, nachteil: empfänger muss nummern speichern, vorteil: nachfolgende pakete können ingoniert werden\neine neue tsap vergeben, nachteil: ist nicht immmer möglich, manche tsaps sind immer möglich, vorteil: ist nur einmal valide, danach keine verbindung möglich",
        "original_sample_id": "smp0455q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0455q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "For products not used in the manufacture of products of heading 8503, the value of the products of heading 8503 shall not exceed 50 % of the ex-works price of the product.",
        "answer_feedback": "only two methods given.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67,
        "original_answer": "eine seqno ausgeben, die für jede operation ausgeben wird, nachteil: empfänger muss nummern speichern, vorteil: nachfolgende pakete können ingoniert werden\neine neue tsap vergeben, nachteil: ist nicht immmer möglich, manche tsaps sind immer möglich, vorteil: ist nur einmal valide, danach keine verbindung möglich",
        "original_sample_id": "smp0455q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence number, recognition number, flag and alternative.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence numeral, acknowledgment numeral, flagstone and options.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence numeral, acknowledgment numeral, pin and options.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence number, recognition number, flag and pick.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1063q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an extension tree is a subset of subnets that includes all routers and does not contain loops. as soon as each router knows which lines belong to the extension tree, it can transmit / multicast all the packets on those lines except the one that came in. it is quite easy and makes efficient use of bandwidth as it generates only a minimum number of copies of packets. in the routing of the link state, all intermediate stations send liaison status packets periodically. they contain information about the distances to the neighbors. to build an extension tree, this information has to be expanded by information about the existing multicast groups. those packages will be transmitted and each of them will calculate, as is known, the best routes, but also the multicast tree and its outgoing lines.",
        "answer_feedback": "the response correctly states the attractive spanning-tree property and explains how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree is a subset of subnets which includes all routers and contains no loops. as soon as every router knows which lines belong to the spanning tree, it can broadcast/multicast all packages on those lines except the one it arrived on. it is quite easy and makes efficient use of bandwidth since the is generates only a minimum number of packet copies. in link state routing, all intermediate stations send link state packets periodically. they contain information about the distances to the neighbours. to construct a spanning tree, this information has to be expanded by the information on existing multicast groups. those packets will be broadcasted and every is will then calculate, as known, the best routes, but also the multicast tree and its outgoing lines.",
        "original_sample_id": "smp1063q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1063q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an extension tree is a subset of subnets that includes all routers and does not contain loops. as soon as each router knows which lines belong to the extension tree, it can transmit / multicast all the packets on those lines except the one that came in. it is quite easy and makes efficient use of bandwidth as it generates only a minimum number of copies of packets. in the routing of the link state, all intermediate stations send liaison status packets periodically. they contain information about the distances to the neighbors. to build an extension tree, this information has to be expanded by information about the existing multicast groups. those packages will be transmitted and each of them will calculate, as is known, the best routes, but also the multicast tree and its outgoing lines.",
        "answer_feedback": "the response correctly states the attractive spanning-tree property and explains how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree is a subset of subnets which includes all routers and contains no loops. as soon as every router knows which lines belong to the spanning tree, it can broadcast/multicast all packages on those lines except the one it arrived on. it is quite easy and makes efficient use of bandwidth since the is generates only a minimum number of packet copies. in link state routing, all intermediate stations send link state packets periodically. they contain information about the distances to the neighbours. to construct a spanning tree, this information has to be expanded by the information on existing multicast groups. those packets will be broadcasted and every is will then calculate, as known, the best routes, but also the multicast tree and its outgoing lines.",
        "original_sample_id": "smp1063q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1492q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "in this position can piggybacking be used:\n 1）the communication between sender and liquidator is duplex communication.\n 2)  the acknowledgements are contained in data frame. this means the acknowledgements don’t be sent alone.",
        "answer_feedback": "the response is correct. in absence of data on the receiver side, acknowledgments can be sent separately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in this situation can piggybacking be used:\n 1）the communication between sender and receiver is duplex communication.\n 2)  the acknowledgements are contained in data frames. this means the acknowledgements don’t be sent alone.",
        "original_sample_id": "smp1492q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0368q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a, c, forward) (a, b, forward) (a, d, fall) -> no shorter hops road 2: (b, e, forward) (c,f, fall) -> no shorter hops road 3: (e, g, forward) hops 4: (g, h, fall) —> no more nodes no shorter path implies that these nodes would never get packages aimed at a node",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,c, forward)\n(a, b, forward)\n(a, d, drop) -> not shortest path\nhop 2:\n(b, e, forward) \n(c,f, drop) -> not shortest path\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) —>no further nodes \nnot shortest path implicates that these nodes would never get packets addressed to node a",
        "original_sample_id": "smp0368q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1618q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 127.0.0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n127.0.0.0/8",
        "original_sample_id": "smp1618q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1665q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "from 0.0.0.0  to 127.0.0.0 are all speech in family a. except 0 and 127 are reserved for meshwork and broadcast",
        "answer_feedback": "network is x.0.0.0 and broadcast is x.255.255.255, with x between 0 and 127\nmissing: loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "from 0.0.0.0  to 127.0.0.0 are all addresses in class a. except 0 and 127 are reserved for network and broadcast",
        "original_sample_id": "smp1665q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data modesty is not look on the location, some have more frame than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "loveliness is the problem，the data reserve is not count on the placement, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is the problem，the data reservation is not calculate on the location, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data backlog is not count on the localization, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data backlog is not depending on the positioning, some have more frame than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug05smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the datum reserve is not reckon on the emplacement, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug06smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data reserve is not bet on the localisation, some have more figure than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug07smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "loveliness is the problem，the data reservation is not depending on the localization, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1117q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees prevent loops in a network and therefore avoid the creation of duplicating packages. that is the reason why spanning trees are used for broad- and multicasting, because these packages are adressed to many (all) network player, while a lot of connections may direct to loops which burden the network. to add spanning trees to the link state routing it would be necessary to alter the construction algorithm of the routing tables. the link state routing algorithm measures the distance to the adjacent knobs and contributes its information over the network. when every information is send out, then the knobs itself are able to locally compute a spanning tree. the network administrator would have to decide, which knob will act as the root knob, and then the knobs will have to use their best „shortest path“ for constructing a spanning tree.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is partially correct because it is not stated that multicast group information is shared in the link-state packet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees prevent loops in a network and therefore avoid the creation of duplicating packages. that is the reason why spanning trees are used for broad- and multicasting, because these packages are adressed to many (all) network participants, while a lot of connections may lead to loops which burden the network. to add spanning trees to the link state routing it would be necessary to alter the construction algorithm of the routing tables. the link state routing algorithm measures the distance to the adjacent nodes and contributes its information over the network. when every information is send out, then the nodes itself are able to locally compute a spanning tree. the network administrator would have to decide, which node will act as the root node, and then the nodes will have to use their best „shortest path“ for constructing a spanning tree.",
        "original_sample_id": "smp1117q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1627q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1627q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1627q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 - 10.255.255.255",
        "original_sample_id": "smp1627q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0351q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "Hops 1: (a,b, front) (a,c, front) (a,d, front) hops 2: (b,e, front) hops 3: (c,f, front) hops 4: (e,g, front) hops 5: (g,h, front)",
        "answer_feedback": "the reasoning behind which packets are dropped is not stated.  please go through the model solution. packets will be considered drop if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop). incorrect number of hops.(-0.25p)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a,b, forward)\n(a,c, forward)\n(a,d, forward)\nhop 2:\n(b,e, forward)\nhop 3:\n(c,f, forward)\nhop 4:\n(e,g, forward)\nhop 5:\n(g,h, forward)",
        "original_sample_id": "smp0351q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0136q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester proficiency. this is because the clocks and data signals combine to form a exclusive synchronise data stream of both 1 and 0 levels.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester technique. this is because the clocks and data signals combine to form a single synchronizing data stream of both 1 and 0 levels.",
        "original_sample_id": "smp0136q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0136q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester technique. this is because the filaria and data signals combine to forge a single contemporise data stream of both 1 and 0 levels.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester technique. this is because the clocks and data signals combine to form a single synchronizing data stream of both 1 and 0 levels.",
        "original_sample_id": "smp0136q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1101q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a property of a spanning tree, which make it appealing for broad-and multicasting is that it is a subset of subnets including all routers with no loop. contact province routing has to be modified such that the information on multicast groups is also included in the contact province packets.",
        "answer_feedback": "the response does not mention that only once all the network topology information along with multicast group information of all nodes is available locally, a node can calculate a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a property of a spanning tree, which make it appealing for broad-and multicasting is that it is a subset of subnets including all routers with no loops. link state routing has to be modified such that the information on multicast groups is also included in the link state packets.",
        "original_sample_id": "smp1101q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0935q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "at the beginning, when the deck table is an empty flood is used by the bridge for unknown destinations. the bridge operates in promiscuous mode and receives any frame on one of its lans. the bridge begins to learn about topology and can create a deck table by making a flood (if the destination is unknown), the fall of frame (if the source and destination are in the same lan) and the routing frame (if the source and frame are located in different lans).",
        "answer_feedback": "the response does not what entries are contained in the bridge table. how in backward learning, these entries are created and interpreted is also not mentioned. the stated benefit that forwarding is transparent is not the expected benefit, but the function of the bridge. the spanning-tree concept is introduced when multiple transparent bridges are used which is beyond the scope of the question.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "at the beginning when the bridge table is empty flooding is used by the bridge for unknown destinations. the bridge works in promiscuous mode and it receives any frame on any of its lans. the bridge starts to learn about the topology and can create a bridge table by doing flooding (if destination is unknown), frame dropping (if  source and destination are in the same lan) , and routing frame (if source and frame are located in different lans). therefore it creates a spanning tree. the benefit of this forwarding process is that it causes a transparency because different lans will be able to interconnect with each other like one lan.",
        "original_sample_id": "smp0935q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0159q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i will choose differential sleevescoding. It has a good auto-watch function and low noise sensitivity because only the polarity signal is recorded; absolute values are not relevant.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "i will choose differential manchester encoding.\nit has good \"self-clocking\" feature and low susceptibility to noise because only the signal’s polarity is recorded; absolute values are irrelevant.",
        "original_sample_id": "smp0159q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0159q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i will choose differential sleevescoding. It has a good auto-watch function and low noise sensitivity because only the polarity signal is recorded; absolute values are not relevant.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "i will choose differential manchester encoding.\nit has good \"self-clocking\" feature and low susceptibility to noise because only the signal’s polarity is recorded; absolute values are irrelevant.",
        "original_sample_id": "smp0159q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0936q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridgework table holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards learning phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the promotion process uses the table to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridgework table is that the bridgework doesn't have to repair to flooding a frame to all (except the source) lans if it knows what lan an address belongs to.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards learning phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the forwarding process uses the table to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridge table is that the bridge doesn't have to resort to flooding a frame to all (except the source) lans if it knows what lan an address belongs to.",
        "original_sample_id": "smp0936q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0936q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge mesa holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards con phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the forwarding process uses the mesa to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridge mesa is that the bridge doesn't have to resort to flooding a frame to all (except the source) lan if it knows what lan an address belongs to.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards learning phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the forwarding process uses the table to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridge table is that the bridge doesn't have to resort to flooding a frame to all (except the source) lans if it knows what lan an address belongs to.",
        "original_sample_id": "smp0936q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0936q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triple. during the learning phase back, whenever a frame is received from an address above a lan l at a time t, the entry for the address has been updated (or created if it did not exist) with the lan l and time t. the return process uses the table to look at which the lan a frame must be transmitted in order to reach the destination. one of the advantages of using a bridge table is that the bridge does not have to resort to flooding of a frame to all (except the source) lans if it knows which lan an address belongs.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards learning phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the forwarding process uses the table to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridge table is that the bridge doesn't have to resort to flooding a frame to all (except the source) lans if it knows what lan an address belongs to.",
        "original_sample_id": "smp0936q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0936q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triple. during the learning phase back, whenever a frame is received from an address above a lan l at a time t, the entry for the address has been updated (or created if it did not exist) with the lan l and time t. the return process uses the table to look at which the lan a frame must be transmitted in order to reach the destination. one of the advantages of using a bridge table is that the bridge does not have to resort to flooding of a frame to all (except the source) lans if it knows which lan an address belongs.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the bridge table holds (\"address\", \"lan\", \"timestamp\") triples. during the backwards learning phase, whenever a frame is received from an address a over a lan l at a time t, the entry for address a is updated (or created if it didn't exist) with the lan l and the timestamp t. the forwarding process uses the table to look up over which lan a frame has to be forwarded in order to reach the destination. one benefit of using a bridge table is that the bridge doesn't have to resort to flooding a frame to all (except the source) lans if it knows what lan an address belongs to.",
        "original_sample_id": "smp0936q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0788q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp is connected oriented, while udp is an offline Internet protocol. tcp is slower than udp because tcp performs many functions while udp has only limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total, while udp has only 8 bytes divided into 4 required fields.",
        "answer_feedback": "the response additionally states differences between udp and  tcp, which is not required for this question. only two differences between the udp and tcp headers are noted, out of which one is partially correct, i.e. tcp length varies from 20 to 60 bytes and is not fixed as stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.38,
        "original_answer": "tcp is connection-oriented, while udp is a connectionless internet protocol. tcp is slower than udp since tcp performs many functions while udp only has limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total while, udp only has 8 bytes divide into 4 required fields.",
        "original_sample_id": "smp0788q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0788q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp is connected oriented, while udp is an offline Internet protocol. tcp is slower than udp because tcp performs many functions while udp has only limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total, while udp has only 8 bytes divided into 4 required fields.",
        "answer_feedback": "the response additionally states differences between udp and  tcp, which is not required for this question. only two differences between the udp and tcp headers are noted, out of which one is partially correct, i.e. tcp length varies from 20 to 60 bytes and is not fixed as stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.38,
        "original_answer": "tcp is connection-oriented, while udp is a connectionless internet protocol. tcp is slower than udp since tcp performs many functions while udp only has limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total while, udp only has 8 bytes divide into 4 required fields.",
        "original_sample_id": "smp0788q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0788q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp is connected oriented, while udp is an offline Internet protocol. tcp is slower than udp because tcp performs many functions while udp has only limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total, while udp has only 8 bytes divided into 4 required fields.",
        "answer_feedback": "the response additionally states differences between udp and  tcp, which is not required for this question. only two differences between the udp and tcp headers are noted, out of which one is partially correct, i.e. tcp length varies from 20 to 60 bytes and is not fixed as stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.38,
        "original_answer": "tcp is connection-oriented, while udp is a connectionless internet protocol. tcp is slower than udp since tcp performs many functions while udp only has limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total while, udp only has 8 bytes divide into 4 required fields.",
        "original_sample_id": "smp0788q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0788q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp is connected oriented, while udp is an offline Internet protocol. tcp is slower than udp because tcp performs many functions while udp has only limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total, while udp has only 8 bytes divided into 4 required fields.",
        "answer_feedback": "the response additionally states differences between udp and  tcp, which is not required for this question. only two differences between the udp and tcp headers are noted, out of which one is partially correct, i.e. tcp length varies from 20 to 60 bytes and is not fixed as stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.38,
        "original_answer": "tcp is connection-oriented, while udp is a connectionless internet protocol. tcp is slower than udp since tcp performs many functions while udp only has limited functions. tcp header has 10 required fields with 20 bytes/160 bits in a total while, udp only has 8 bytes divide into 4 required fields.",
        "original_sample_id": "smp0788q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0418q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps\nreward：low usage of bandwidth and memorydisreward:process server addressing method not possible2. to identify connectedness individually\nreward：\n\ndisreward:endsystems must be capable of storing this information3.to identify pdus individuallyreward:highly applicabledisreward:sensible choice of the consecutive number range depends on the packet rate",
        "answer_feedback": "the response is correct",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. to use temporarily valid tsaps\nadvantage：low usage of bandwidth and memorydisadvantage:process server addressing method not possible2. to identify connections individually\nadvantage：\n\ndisadvantage:endsystems must be capable of storing this information3.to identify pdus individuallyadvantage:highly applicabledisadvantage:sensible choice of the sequential number range depends on the packet rate",
        "original_sample_id": "smp0418q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0418q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to apply temporarily valid tsaps\nreward：low usage of bandwidth and memorydisreward:process server addressing method not possible2. to identify joining individually\nreward：\n\ndisreward:endsystems must be capable of storing this information3.to identify pdus individuallyreward:highly applicabledisreward:sensible choice of the sequential number range depends on the packet rate",
        "answer_feedback": "the response is correct",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. to use temporarily valid tsaps\nadvantage：low usage of bandwidth and memorydisadvantage:process server addressing method not possible2. to identify connections individually\nadvantage：\n\ndisadvantage:endsystems must be capable of storing this information3.to identify pdus individuallyadvantage:highly applicabledisadvantage:sensible choice of the sequential number range depends on the packet rate",
        "original_sample_id": "smp0418q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0418q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps\nreward：low usage of bandwidth and memorydisreward:process server addressing method not possible2. to identify connections severally\nreward：\n\ndisreward:endsystems must be capable of storing this information3.to identify pdus severallyreward:highly applicabledisreward:sensible choice of the sequential number range depends on the packet pace",
        "answer_feedback": "the response is correct",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. to use temporarily valid tsaps\nadvantage：low usage of bandwidth and memorydisadvantage:process server addressing method not possible2. to identify connections individually\nadvantage：\n\ndisadvantage:endsystems must be capable of storing this information3.to identify pdus individuallyadvantage:highly applicabledisadvantage:sensible choice of the sequential number range depends on the packet rate",
        "original_sample_id": "smp0418q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0418q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps\nreward：low usage of bandwidth and memorydisreward:process server addressing method not possible2. to identify connections individually\nreward：\n\ndisreward:endsystems must be capable of store this information3.to identify pdus individuallyreward:highly applicabledisreward:sensible choice of the sequent number range depends on the packet rate",
        "answer_feedback": "the response is correct",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. to use temporarily valid tsaps\nadvantage：low usage of bandwidth and memorydisadvantage:process server addressing method not possible2. to identify connections individually\nadvantage：\n\ndisadvantage:endsystems must be capable of storing this information3.to identify pdus individuallyadvantage:highly applicabledisadvantage:sensible choice of the sequential number range depends on the packet rate",
        "original_sample_id": "smp0418q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0835q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. tcp has a champaign for the acknowledgement issue, but udp does not, as it is unreliable and does not check if the packet was received.\n2. tcp has a champaign for the advertised window, which is a way for the receiver to tell the sender how much he is still able to send without overflowing the receiver’s buffer. udp does not have this, because udp does not implement flow control.\n3. tcp has a champaign for the sequence issue, providing information about the correct order of packets, udp does not handle about the order the packets arrive.\n4. tcp has champaigns for flags like syn/fin for connection establishment and ack, which udp also does not have, because it is connectionless and does not use acknowledgements.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. tcp has a field for the acknowledgement number, but udp does not, as it is unreliable and does not check if the packet was received.\n2. tcp has a field for the advertised window, which is a way for the receiver to tell the sender how much he is still able to send without overflowing the receiver’s buffer. udp does not have this, because udp does not implement flow control.\n3. tcp has a field for the sequence number, providing information about the correct order of packets, udp does not care about the order the packets arrive.\n4. tcp has fields for flags like syn/fin for connection establishment and ack, which udp also does not have, because it is connectionless and does not use acknowledgements.",
        "original_sample_id": "smp0835q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1019q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The routing of retransmission with individual shipment to each destination is bad due to the loss of bandwidth and the sender has to know all destinations. also, the flood is not good because there will be too many duplicates. that's why the reverse route redirection and reverse path retransmission is used. the reverse route forwarding has the following algorithm implemented: has this package arrived at the input port on which the packets are sent for this station/source? - yes: did I resend over all borders (not including the incoming) - no: discard the package (probably duplicate) retransmission of reverse route has the following algorithm implemented: has this package arrived at the input port on which the packets are sent for this station/source are usually also sent? - yes: did the package use the best route so far? - yes: select the border where the packages arrived and from which they are rerouted to the source s (in reverse direction) - no: do not send over all borders (without the incoming), i.e., do not as the package (returned) invert)",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "broadcast routing with individual sending to every destination is bad because of waste of bandwidth and the sender has to know all destinations. also, flooding is not good because too many duplicates will exist. that's why reverse path forwarding and reverse path broadcast is used. reverse path forwarding has the following algorithm implemented: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? - yes: resend over all edges (not including the incoming one) - no: discard the packet (most likely duplicate) reverse path broadcast has the following algorithm implemented: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? - yes: packet used the best route until now?           - yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction) ﻿﻿          - no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf) - no: discard the packet (most likely duplicate)",
        "original_sample_id": "smp1019q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1019q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The routing of retransmission with individual shipment to each destination is bad due to the loss of bandwidth and the sender has to know all destinations. also, the flood is not good because there will be too many duplicates. that's why the reverse route redirection and reverse path retransmission is used. the reverse route forwarding has the following algorithm implemented: has this package arrived at the input port on which the packets are sent for this station/source? - yes: did I resend over all borders (not including the incoming) - no: discard the package (probably duplicate) retransmission of reverse route has the following algorithm implemented: has this package arrived at the input port on which the packets are sent for this station/source are usually also sent? - yes: did the package use the best route so far? - yes: select the border where the packages arrived and from which they are rerouted to the source s (in reverse direction) - no: do not send over all borders (without the incoming), i.e., do not as the package (returned) invert)",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "broadcast routing with individual sending to every destination is bad because of waste of bandwidth and the sender has to know all destinations. also, flooding is not good because too many duplicates will exist. that's why reverse path forwarding and reverse path broadcast is used. reverse path forwarding has the following algorithm implemented: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? - yes: resend over all edges (not including the incoming one) - no: discard the packet (most likely duplicate) reverse path broadcast has the following algorithm implemented: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? - yes: packet used the best route until now?           - yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction) ﻿﻿          - no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf) - no: discard the packet (most likely duplicate)",
        "original_sample_id": "smp1019q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0893q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "a transparent bridge mesa holds a mapping from stations/hosts to web and learns which station is where. the bridge inspects the traffic, learns where stations are on the network and updates their mesa by adding an entry for every new source that send a packet with the network it encounter it over. if a packet arrives at the transparent bridge and the receiver is listed in the forwarding mesa, the transparent bridge sends the packet to their respective network, if not it floods. this reduces traffic on all other web as the packet will be send into the right direction and not be flooded in all web.",
        "answer_feedback": "the response is correct except the bridge on inspecting packet saves the source as destination and the corresponding outgoing lan, so only the outgoing lan is known for a station, not where it is exactly located in the network. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "a transparent bridge table holds a mapping from stations/hosts to networks and learns which station is where. the bridge inspects the traffic, learns where stations are on the network and updates their table by adding an entry for every new source that send a packet with the network it received it over. if a packet arrives at the transparent bridge and the receiver is listed in the forwarding table, the transparent bridge sends the packet to their respective network, if not it floods. this reduces traffic on all other networks as the packet will be send into the right direction and not be flooded in all networks.",
        "original_sample_id": "smp0893q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0804q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "In the udp checksum header is optional while in the tcp header is mandatory for retransmission. The tcp header has a &lt; &gt; &gt; part announced, to avoid congestion while the udp header does not have a field for flow control. to ensure that the received byte sequences are correct and ordered, tcp; tcp; &lt; sequence number &gt; and &lt; &lt; recognition number &gt; , while the usp does not have a field for error control &lt; &lt; tcp &gt; &gt; has &lt; &gt; fields to help control the &gt; &gt; transmission, while the usp does not have a field for error control &lt; &lt; tcp &gt; &gt; .",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in udp header checksum is optional while in tcp header is obligatory for retransmission.\ntcp header has a part “ advertised window” for congestion avoidance while udp header has no field for flow control.\nto make sure that the received byte sequences are correct and ordered, tcp sets the fields “sequence number” and “acknowledgment number”, while udp has no field for error control\ntcp has fields “flags” to help control the transmission, while udp has no field for it.",
        "original_sample_id": "smp0804q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1660q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "127.x1.x2.x3 x1,x2,x3=[0,255]",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "127.x1.x2.x3       x1,x2,x3∈[0,255]",
        "original_sample_id": "smp1660q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0900q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "In transparent bridges, the deck table holds inputs that describe the output line of each station it knows, i.e. the station (host) -> lan (network). First, the deck table is essentially empty (as it does not know anything before on the networks connect to it), the flood is used to know one of the exit lines that reaches it. Then during the learning phase back, the bridge operates in promiscuous mode since it receives any frame on one of its connected lans and creates a table entry for each station accessible in relation to the corresponding connected lan. These inputs are used to transmit incoming frames to the specifically known and accessible destination without always having to blindly flood all the data at each possible station. Each input is inserted with a specific chronometer, which is the time of arrival of the frame. With these horodometers for each entry of the table, the table is dynamically updated by being periodically scanned for changes and removes the old and outdated entries. for a few minutes without a normal change.",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "in transparent bridges, the bridge table hold entries which describe the output line of each station it knows, i.e. station (host) -> lan (network). \n\ninitially, the bridge table is basically empty (as it knows nothing before about the networks connect to it), flooding is used to get to know any of the output line coming to it. then during the backward learning phase, bridge works in promiscuous mode as it receives any frame on any of its connected lans and creates one table entry for every reachable station over its corresponding connected lan. these entries used to forward incoming frames to the specifically known and reachable destination without having to always blindly flooding all the data to every possible station. \n\neach entry is inserted with a specific timestamp, which is the arrival time of the frame. with these timestamps for every entry of the table, the table is dynamically updated by being periodically scanned for changes and remove old and outdated entries. for a long enough period of time without any either updates or changes (normally a few minutes). flooding is started again as it is going to refresh the whole table. \n\nthe benefit of that is the adaptation to changes in network topology is made possible, since bridges are supposed to be transparent and not visible to other components of the networks. not much overhead has to be provided when there are any changes in the network topology or position.",
        "original_sample_id": "smp0900q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1535q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "with a windowpane sizing of 1, the sequence must always be correct.\nif the windowpane sizing is greater than 1, there are no requirements, but the sizing is determine by the windowpane sizing.",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. the above points are true for the sliding window protocol in general and are not specific to piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "with a window size of 1, the sequence must always be correct.\nif the window size is greater than 1, there are no requirements, but the size is limited by the window size.",
        "original_sample_id": "smp1535q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1069q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property : 1.use sunb tree (or other extension tree) for the router that initiates the 2.subset transmission of subnets including all routers without loops everything is to send link status packets periodically -containing information -distance to neighbors -expanded by information about multicast groups -by transmission to all others each is calculated a multicast tree -from the now available local and complete status information based on the information about the multicast tree -is determines the outgoing lines -in which packages have to be transmitted",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property : 1.use sink tree (or other spanning tree)  for router initiating broadcast  2.subset of subnets including all routers with no loops  all is send link state packets periodically  -containing information  -distance to neighbors  -expanded by information on  multicast groups  -by broadcast to all the others    each is calculates a multicast tree  -from the now locally available and  complete state information    based on the information about the  multicast tree  -is determines the outgoing lines  -on which packets have to be transmitted",
        "original_sample_id": "smp1069q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1069q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property : 1.use sink tree (or other spanning tree)  for router initiating broadcast  2.subset of subnets including all routers with no loops  all is send link state mailboat periodically  -containing entropy  -distance to neighbor  -expanded by entropy on  multicast groups  -by broadcast to all the others    each is calculates a multicast tree  -from the now locally available and  complete state entropy    based on the entropy about the  multicast tree  -is determines the outgoing lines  -on which mailboat have to be transmitted",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property : 1.use sink tree (or other spanning tree)  for router initiating broadcast  2.subset of subnets including all routers with no loops  all is send link state packets periodically  -containing information  -distance to neighbors  -expanded by information on  multicast groups  -by broadcast to all the others    each is calculates a multicast tree  -from the now locally available and  complete state information    based on the information about the  multicast tree  -is determines the outgoing lines  -on which packets have to be transmitted",
        "original_sample_id": "smp1069q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1093q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property which makes a traverse trees quite appealing for broadcast and multicast applications is that there exists a minimal amount of copies in the network. furthermore, a traverse tree does not contain any loops. traverse trees can be used with contact state routing in the following manner: all intermediate systems (is) broadcast contact state packets containing distances to neighbor nodes as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines on which packets will be transmitted.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is also correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the property which makes a spanning trees quite appealing for broadcast and multicast applications is that there exists a minimal amount of copies in the network. furthermore, a spanning tree does not contain any loops. spanning trees can be used with link state routing in the following manner: all intermediate systems (is) broadcast link state packets containing distances to neighbor nodes as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines on which packets will be transmitted.",
        "original_sample_id": "smp1093q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1093q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property that makes a tree that covers quite attractive for transmission and multicast applications is that there is a minimum number of copies on the network. plus, a tree that covers does not contain any loop. trees that span can be used with status link as follows: all intermediate systems (s) transmission link status packages containing distances to neighboring nodes, as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines in which packages will be transmitted.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is also correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the property which makes a spanning trees quite appealing for broadcast and multicast applications is that there exists a minimal amount of copies in the network. furthermore, a spanning tree does not contain any loops. spanning trees can be used with link state routing in the following manner: all intermediate systems (is) broadcast link state packets containing distances to neighbor nodes as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines on which packets will be transmitted.",
        "original_sample_id": "smp1093q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0338q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop 2 :\n(b,c,driblet) not on unicast course from a to c \n(b,e,forward)\n(c,b,driblet)  not on unicast course from a to b\n(c,d,driblet)  not on unicast course from a to d \n(c,e,driblet)  not on unicast course from a to e\n(c,f,forward)\n(d,c,driblet) not on unicast course from a to c \n(d,f,driblet) not on unicast course from a to f\nhop 3:\n(e,c,driblet)not on unicast course from a to c \n(e,f,driblet) not on unicast course from a to f\n(e,g,forward)\n(f,d,driblet) not on unicast course from a to d\n(f,e,driblet) not on unicast course from a to e \n(f,g,driblet) not on unicast course from a to g\nhop 4:\n(g,f,driblet)not on unicast course from a to f\n(g,h,forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop 2 :\n(b,c,drop) not on unicast path from a to c \n(b,e,forward)\n(c,b,drop)  not on unicast path from a to b\n(c,d,drop)  not on unicast path from a to d \n(c,e,drop)  not on unicast path from a to e\n(c,f,forward)\n(d,c,drop) not on unicast path from a to c \n(d,f,drop) not on unicast path from a to f\nhop 3:\n(e,c,drop)not on unicast path from a to c \n(e,f,drop) not on unicast path from a to f\n(e,g,forward)\n(f,d,drop) not on unicast path from a to d\n(f,e,drop) not on unicast path from a to e \n(f,g,drop) not on unicast path from a to g\nhop 4:\n(g,f,drop)not on unicast path from a to f\n(g,h,forward)",
        "original_sample_id": "smp0338q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0096q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the bit point protocol should be used, as the character point protocol requires additional time due to the introduction of dles into the physique and convert to the right encoding. in addition, the count point protocol leads to desynchronisation in the event of a transmission error and is therefore not reliable enough for everyday use.",
        "answer_feedback": "the provided response is not related to the theme of the question which is encoding type.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the bit oriented protocol should be used, as the character oriented protocol requires additional time due to the insertion of dles into the frame and convert to the right encoding. in addition, the count oriented protocol leads to desynchronisation in the event of a transmission error and is therefore not reliable enough for everyday use.",
        "original_sample_id": "smp0096q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0096q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "The bet-oriented protocol must be used, as the character-oriented protocol requires additional time due to insertion of data into the frame and convert to correct encoding. Furthermore, the oriented protocol accounts for desynchronization in case of transmission error and is therefore not reliable enough for daily use.",
        "answer_feedback": "the provided response is not related to the theme of the question which is encoding type.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the bit oriented protocol should be used, as the character oriented protocol requires additional time due to the insertion of dles into the frame and convert to the right encoding. in addition, the count oriented protocol leads to desynchronisation in the event of a transmission error and is therefore not reliable enough for everyday use.",
        "original_sample_id": "smp0096q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0363q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(g, h, drib) : \nf does not forward a broadcast parcel from g to h\nit is not located on the unicast route from g to h",
        "answer_feedback": "incomplete response.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.2,
        "original_answer": "(g, h, drop) : \nf does not forward a broadcast packet from g to h\nit is not located on the unicast path from g to h",
        "original_sample_id": "smp0363q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1113q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees are minimally connected (have no loops). therefore, if broad- and multicast packets are sent along a spanning tree only the minimal number of packets are sent. this reduces the overall meshing load.  with the knowledge gained via link state routing, each knob can reconstruct the meshing topology. then, it can calculate a spanning tree locally. knowing the topology and the receivers of the multicast, the knob can build a multicast table and optimize the spanning tree for each grouping.",
        "answer_feedback": "the description of link-state routing modification is partially correct because it is missing how the nodes receive multicast group information.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees are minimally connected (have no loops). therefore, if broad- and multicast packets are sent along a spanning tree only the minimal number of packets are sent. this reduces the overall network load.  with the knowledge gained via link state routing, each node can reconstruct the network topology. then, it can calculate a spanning tree locally. knowing the topology and the receivers of the multicast, the node can build a multicast table and optimize the spanning tree for each group.",
        "original_sample_id": "smp1113q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0767q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem of dqdb is equity due to the implementation of the so-called bandwidth balancing mechanism. This means that the network band is distributed fairly between stations and each station is able to send the same amount of data at the same time. This balancing mechanism results in available bad width portions that are not used.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb but in the wrong context. the stations have a fairness issue for reserving transmission rights that depends on the distance between a station and the frame generator or the slave frame generator. the bandwidth balancing mechanism is a way to overcome this problem.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem of dqdb is fairness due to implemented so called bandwidth balanding mechanism. it means, the network bandwith is fairly distributed among the stations and every stations is able to send the same amount data at the same time. this balancing mechanism results in portions of available badwidth which is unused.",
        "original_sample_id": "smp0767q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0767q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem of dqdb is equity due to the implementation of the so-called bandwidth balancing mechanism. This means that the network band is distributed fairly between stations and each station is able to send the same amount of data at the same time. This balancing mechanism results in available bad width portions that are not used.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb but in the wrong context. the stations have a fairness issue for reserving transmission rights that depends on the distance between a station and the frame generator or the slave frame generator. the bandwidth balancing mechanism is a way to overcome this problem.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem of dqdb is fairness due to implemented so called bandwidth balanding mechanism. it means, the network bandwith is fairly distributed among the stations and every stations is able to send the same amount data at the same time. this balancing mechanism results in portions of available badwidth which is unused.",
        "original_sample_id": "smp0767q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0767q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem of dqdb is equity due to the implementation of the so-called bandwidth balancing mechanism. This means that the network band is distributed fairly between stations and each station is able to send the same amount of data at the same time. This balancing mechanism results in available bad width portions that are not used.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb but in the wrong context. the stations have a fairness issue for reserving transmission rights that depends on the distance between a station and the frame generator or the slave frame generator. the bandwidth balancing mechanism is a way to overcome this problem.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem of dqdb is fairness due to implemented so called bandwidth balanding mechanism. it means, the network bandwith is fairly distributed among the stations and every stations is able to send the same amount data at the same time. this balancing mechanism results in portions of available badwidth which is unused.",
        "original_sample_id": "smp0767q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0767q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem of dqdb is equity due to the implementation of the so-called bandwidth balancing mechanism. This means that the network band is distributed fairly between stations and each station is able to send the same amount of data at the same time. This balancing mechanism results in available bad width portions that are not used.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb but in the wrong context. the stations have a fairness issue for reserving transmission rights that depends on the distance between a station and the frame generator or the slave frame generator. the bandwidth balancing mechanism is a way to overcome this problem.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem of dqdb is fairness due to implemented so called bandwidth balanding mechanism. it means, the network bandwith is fairly distributed among the stations and every stations is able to send the same amount data at the same time. this balancing mechanism results in portions of available badwidth which is unused.",
        "original_sample_id": "smp0767q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0767q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem of dqdb is equity due to the implementation of the so-called bandwidth balancing mechanism. This means that the network band is distributed fairly between stations and each station is able to send the same amount of data at the same time. This balancing mechanism results in available bad width portions that are not used.",
        "answer_feedback": "the response is partially correct as it states the fairness problem in dqdb but in the wrong context. the stations have a fairness issue for reserving transmission rights that depends on the distance between a station and the frame generator or the slave frame generator. the bandwidth balancing mechanism is a way to overcome this problem.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the problem of dqdb is fairness due to implemented so called bandwidth balanding mechanism. it means, the network bandwith is fairly distributed among the stations and every stations is able to send the same amount data at the same time. this balancing mechanism results in portions of available badwidth which is unused.",
        "original_sample_id": "smp0767q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1036q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in the transmission/ multicasting to route packets on the network. each node is supposed to have its own extension tree of the network, describing the optimal unicast path paths. if a package reaches an intermediate node, first check if the packet arrived through the path on which the nodes are normally sent to the sending source. only in this case, the package is processed later. in rpf the incoming package is simply distributed to all outgoing edges (excluding the incoming border). in rpb, the packet is only distributed across borders for which the router knows that they represent the optimal route between the source and the destination (i.e., packages are usually routed through this route). in other cases, the package is discarded.",
        "answer_feedback": "the response does not state the purpose behind using them which is to reduce duplicates during broadcasting. rpf's explanation is partially correct as in rpf, only the sender knows the spanning-tree instead of all nodes, which assume the best path based on unicast information. the explanation of rpb is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in broadcasting/ multicasting to route packages on the network. it is assumed that each node has it's own spanning tree of the network, describing the optimal unicast routing paths. if a packet arrives at one intermediate node, it first checks if the packat arrived via the path over which nodes to the sending source are usually sent. only of this is the case, the packet is further processed. in rpf the incoming packet is simply distributed to all outgoing edges (excluding the incoming edge). in rpb, the pacjet is only distributed via edges for which the router knows they represent the optimal path between the source and the destination (i.e. packets are usually routed via this path). in other cases, the packet is discarded.",
        "original_sample_id": "smp1036q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0229q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "to cipher the amount of seconds that the system would be in a state with less than 10 mailboat we first cipher the blocking probability of the system. this is the probability that the system is full, which we can then use to cipher the probability that the system is not full ( less than 10 mailboat waiting in queue) by simple substracting it from 1. we cipher the blocking probability p(b) using the formula pay on page 30 of the lecture slides. p(b)=0,05081373133 which means that the system is not full with a probability of 0,9491862687.\nwe now multiply this probability with the monitored time of 60 seconds and get the final result, that the system is in a state in which there are less than 10 mailboat waiting in queue for roughly 56,95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "to calculate the amount of seconds that the system would be in a state with less than 10 packets we first calculate the blocking probability of the system. this is the probability that the system is full, which we can then use to calculate the probability that the system is not full ( less than 10 packets waiting in queue) by simple substracting it from 1. we calculate the blocking probability p(b) using the formula given on page 30 of the lecture slides. p(b)=0,05081373133 which means that the system is not full with a probability of 0,9491862687.\nwe now multiply this probability with the monitored time of 60 seconds and get the final result, that the system is in a state in which there are less than 10 packets waiting in queue for roughly 56,95 seconds.",
        "original_sample_id": "smp0229q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0229q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "to calculate the amount of seconds that the organization would be in a state with less than 10 packets we first calculate the blocking probability of the organization. this is the probability that the organization is full, which we can then use to calculate the probability that the organization is not full ( less than 10 packets expect in queue) by simple substracting it from 1. we calculate the blocking probability p(b) using the formula given on page 30 of the lecture slides. p(b)=0,05081373133 which means that the organization is not full with a probability of 0,9491862687.\nwe now multiply this probability with the monitored time of 60 seconds and get the final result, that the organization is in a state in which there are less than 10 packets expect in queue for roughly 56,95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "to calculate the amount of seconds that the system would be in a state with less than 10 packets we first calculate the blocking probability of the system. this is the probability that the system is full, which we can then use to calculate the probability that the system is not full ( less than 10 packets waiting in queue) by simple substracting it from 1. we calculate the blocking probability p(b) using the formula given on page 30 of the lecture slides. p(b)=0,05081373133 which means that the system is not full with a probability of 0,9491862687.\nwe now multiply this probability with the monitored time of 60 seconds and get the final result, that the system is in a state in which there are less than 10 packets waiting in queue for roughly 56,95 seconds.",
        "original_sample_id": "smp0229q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1022q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of reverse way forwarding and reverse way broadcast is ensuring loop-free forwarding of multicast mailboats in multicast routing.  in reverse way forwarding, each is has its own spanning tree instead of a global unified spanning tree and does not need to know other spanning trees. each is has information which way it would use for (unicast)-mailboats. now if a mailboat arrives at the is entry port over which the mailboats for this station/source are usually also sent, this means: the mailboat used the best route until now and thus resend over all edges (not including the incoming one). if not, this means the mailboat did not use this route (it is not the best route) and thus dispose the mailboat as it is most likely a duplicate. the problem with reverse way forwarding is that the mailboat is sent through all edges except for the sender. this is solved by reverse way broadcast. here, each node learns from the unicast mailboats. only if the is is located on the unicast between the broadcast sender s and a neighbor node b, then it will forward the mailboat.",
        "answer_feedback": "the response is partially correct as in rpf, the sender alone needs to be aware of the spanning tree, and an intermediate system only needs to be aware of which path it would use for (unicast)-packets (known through the unicast routing algorithms). the explanation of rpb is correct. the purpose of reverse path forwarding and reverse path broadcast is not limited to multicasting but also broadcasting.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "the purpose of reverse path forwarding and reverse path broadcast is ensuring loop-free forwarding of multicast packets in multicast routing.  in reverse path forwarding, each is has its own spanning tree instead of a global unified spanning tree and does not need to know other spanning trees. each is has information which path it would use for (unicast)-packets. now if a packet arrives at the is entry port over which the packets for this station/source are usually also sent, this means: the packet used the best route until now and thus resend over all edges (not including the incoming one). if not, this means the packet did not use this route (it is not the best route) and thus discard the packet as it is most likely a duplicate. the problem with reverse path forwarding is that the packet is sent through all edges except for the sender. this is solved by reverse path broadcast. here, each node learns from the unicast packets. only if the is is located on the unicast between the broadcast sender s and a neighbor node b, then it will forward the packet.",
        "original_sample_id": "smp1022q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0152q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it look on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is expectant than the nexus's capacities.",
        "answer_feedback": "the correct encoding in this scenario is binary encoding as it provides better band utilization and in this case, there is no requirement for self-clocking.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it depends on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is greater than the link's capacities.",
        "original_sample_id": "smp0152q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0152q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the differential sleeveless encoding should be used, because - it is not sensitive to noise, it depends on the polarity of the signal, not absolute values - it has a good function of self-watching, so it is synchronous, which is useful for when the traffic is greater than the capacities of the link.",
        "answer_feedback": "the correct encoding in this scenario is binary encoding as it provides better band utilization and in this case, there is no requirement for self-clocking.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it depends on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is greater than the link's capacities.",
        "original_sample_id": "smp0152q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0918q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the array consists of multiple inputs. when a bridge receives a frame from the source q on the lan l (for the first time) then it adds an entry to the table of q, l and a time stamp. this entry indicates that q is accessible via l. the time stamping is used to purge the old inputs and adapt to changes in the topology. a time stamping of an entry is updated whenever a new frame is received from the same sourcenode. if the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is accessible via l and the advance to l. if the source and destination of the lans of a frame are the same, the bridge drops the package and if it does not have an entry for a destination it inundates it.",
        "answer_feedback": "the response correctly specifies the fields in the bridging table, how the table is modified during backward learning, and selective forwarding. however, the response does not mention the benefit of selective forwarding derived from using the bridging table.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table consists of multiple entries. when a bridge receives a frame from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same sourcenode. if the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is reachable via l and forwards it to l. if the source and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it floods it.",
        "original_sample_id": "smp0918q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0797q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp header does not have: - sequence number, which is used to check the correct duplicated order. - window displayed. the receiver uses this field to indicate to the sender how many bytes it can send (to limit the shipping rate). - recognition number: the receiver sends an ack number to the sender using this field. - urgent pointer: use for priority.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp header doesnt have: -  sequence number,  which is used for checking duplicate and correct order. -  advertised window. the receiver uses this field to signal the sender how many bytes it can send (to limit sending rate). - acknowledgment number: the receiver sends ack number to sender by using this field. - urgent pointer: use for priority.",
        "original_sample_id": "smp0797q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding technique should be used as it has honest utilization of the bandwidth. thus there will be less traffic in the meshwork.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption technique should be used as it has good utilisation of the bandwidth. thus there will be lesser dealings in the network.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has good employment of the bandwidth. thus there will be lesser traffic in the web.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption technique should be used as it has right utilization of the bandwidth. thus there will be less traffic in the network.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption proficiency should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the net.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding technique should be used as it has good utilisation of the bandwidth. thus there will be lesser dealings in the mesh.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has good usage of the bandwidth. thus there will be lesser traffic in the meshwork.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has good utilization of the bandwidth. thus there will be lesser dealings in the meshing.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug08smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has serious utilization of the bandwidth. thus there will be lesser dealings in the network.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0920q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The initial deck table is empty however learn through the learning process at the back how (on which path) the different stations arrive at the bridge. creates table entries associated with the original direction, the road (lan is reached by) and a time mark, so you can also update your entries as soon as you receive a new frame from a known station. the table is also checked periodically and the old entries are purged if there have been no updates for a certain time. if you know the direction of destination the frames are sent through the road of agreement, if the frames are not flooded. the advantages are an increase in reliability and more efficiency (-> formation of an extension tree).",
        "answer_feedback": "the response does not mention how a packet from source s received over lan l can be interpreted as \"destination s can be reached over l\" which forms the base for backward learning. the spanning-tree concept is introduced when multiple transparent bridges are used to increase reliability which is beyond the scope of the question, so the benefit is incorrect. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the initial bridge table is empty however it learns via the the backward learning process how (on which path) the different stations reach the bridge. it creates table entries associated with the source address, the path (lan it is reached by) and a timestamp, so it can also update its entries as soon as it receives a new frame from a known station. the table is also checked periodically and old entries are purged if there were no updates for some time. \nif the destination address is known the frames are sent via the according path, if not the frames are flooded.\nthe benefits are an increase in reliability and greater efficiency (-> formation of a spanning tree).",
        "original_sample_id": "smp0920q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, intromission, changing of bits possible\n\nl2 overhaul \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and period control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug06smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug07smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0236q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the finite polisher case (m/m/1/n):\n\n9 package arrive per second \n=> lamda = 9\n10 package served per second \n=> µ = 10\n=> roh = lamda / µ = 0.9\npolisher size 10\n=> n  = 10 \nprobability for \np_n = ((1-roh)*roh^n) / (1-roh^n+1)\n=> p_10 =  (0.1*0.9^10) / (1-0.9^11) = 0.05081\nthe whole probabilities combined are 1, the probability for 10 package is now known, so the probability for less than 10 package is also known.\np_0to9 = 1 - p_10 = 0.9491\nthe expected metre is the whole metre metres the probability.\np_0to9 * 60 s = 0.9491 * 60s = 56.95s\n\nthe expected metre with less than 10 package in 1 minute is 56.95s.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the finite buffer case (m/m/1/n):\n\n9 packets arrive per second \n=> lamda = 9\n10 packets served per second \n=> µ = 10\n=> roh = lamda / µ = 0.9\nbuffer size 10\n=> n  = 10 \nprobability for \np_n = ((1-roh)*roh^n) / (1-roh^n+1)\n=> p_10 =  (0.1*0.9^10) / (1-0.9^11) = 0.05081\nthe whole probabilities combined are 1, the probability for 10 packets is now known, so the probability for less than 10 packets is also known.\np_0to9 = 1 - p_10 = 0.9491\nthe expected time is the whole time times the probability.\np_0to9 * 60 s = 0.9491 * 60s = 56.95s\n\nthe expected time with less than 10 packets in 1 minute is 56.95s.",
        "original_sample_id": "smp0236q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0236q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the finite cowcatcher case (m/m/1/n):\n\n9 parcel arrive per second \n=> lamda = 9\n10 parcel served per second \n=> µ = 10\n=> roh = lamda / µ = 0.9\ncowcatcher size 10\n=> n  = 10 \nprobability for \np_n = ((1-roh)*roh^n) / (1-roh^n+1)\n=> p_10 =  (0.1*0.9^10) / (1-0.9^11) = 0.05081\nthe whole probabilities combined are 1, the probability for 10 parcel is now known, so the probability for less than 10 parcel is also known.\np_0to9 = 1 - p_10 = 0.9491\nthe expected meter is the whole meter meters the probability.\np_0to9 * 60 s = 0.9491 * 60s = 56.95s\n\nthe expected meter with less than 10 parcel in 1 minute is 56.95s.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the finite buffer case (m/m/1/n):\n\n9 packets arrive per second \n=> lamda = 9\n10 packets served per second \n=> µ = 10\n=> roh = lamda / µ = 0.9\nbuffer size 10\n=> n  = 10 \nprobability for \np_n = ((1-roh)*roh^n) / (1-roh^n+1)\n=> p_10 =  (0.1*0.9^10) / (1-0.9^11) = 0.05081\nthe whole probabilities combined are 1, the probability for 10 packets is now known, so the probability for less than 10 packets is also known.\np_0to9 = 1 - p_10 = 0.9491\nthe expected time is the whole time times the probability.\np_0to9 * 60 s = 0.9491 * 60s = 56.95s\n\nthe expected time with less than 10 packets in 1 minute is 56.95s.",
        "original_sample_id": "smp0236q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0808q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp head is much more complex than udp head.\n\nthe following battleground belong to tcp head but not to udp head:\n- sequence number\n- ack number\n- advertisement windowpane\n- options\n\nboth heads have the battleground source and receiver port and head checksum.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp header is much more complex than udp header.\n\nthe following fields belong to tcp header but not to udp header:\n- sequence number\n- ack number\n- advertisement window\n- options\n\nboth headers have the fields source and receiver port and header checksum.",
        "original_sample_id": "smp0808q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1098q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "traverse trees, which form a subset of all subnets including all routers have the main posivite property that they do not include any loops. so transmission along a traverse tree is also loop-free and therefore more efficient than a “wild” transmission in all direction for all nodes (flooding).  to implement a traverse tree in connexion state routing, all nodes have to know the common traverse tree. to achieve this, all nodes send connexion state bundle periodically, which include information about the distance to its neighbours as well as multicast-group information. those bundle are broadcasted to all nodes. then, all nodes can calculate (and later improve) the multicast tree with the completed state information, which then determines the outgoing lines for further transmission.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees, which form a subset of all subnets including all routers have the main posivite property that they do not include any loops. so transmission along a spanning tree is also loop-free and therefore more efficient than a “wild” transmission in all direction for all nodes (flooding).  to implement a spanning tree in link state routing, all nodes have to know the common spanning tree. to achieve this, all nodes send link state packets periodically, which include information about the distance to its neighbours as well as multicast-group information. those packets are broadcasted to all nodes. then, all nodes can calculate (and later improve) the multicast tree with the completed state information, which then determines the outgoing lines for further transmission.",
        "original_sample_id": "smp1098q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1098q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The transmission along a cover tree is also free of loop and therefore more efficient than the transmission of the link state in all directions for all nodes (flood). To implement a cover tree in the routing of the link state, all nodes must know the common cover tree. To achieve this, all nodes periodically send connecting state packets, which contain information about distance to its neighbours as well as information about multicast groups. These packets are broadcast to all nodes. So, all nodes can calculate (and improve later) the multicast tree with the completed state information, which then determines the outgoing lines for subsequent transmission.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees, which form a subset of all subnets including all routers have the main posivite property that they do not include any loops. so transmission along a spanning tree is also loop-free and therefore more efficient than a “wild” transmission in all direction for all nodes (flooding).  to implement a spanning tree in link state routing, all nodes have to know the common spanning tree. to achieve this, all nodes send link state packets periodically, which include information about the distance to its neighbours as well as multicast-group information. those packets are broadcasted to all nodes. then, all nodes can calculate (and later improve) the multicast tree with the completed state information, which then determines the outgoing lines for further transmission.",
        "original_sample_id": "smp1098q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1668q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "network ip adress broadcast ads",
        "answer_feedback": "what are the addresses?\nmissing: loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "network ip adress\nbroadcast adress",
        "original_sample_id": "smp1668q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1654q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/8 10.00.0/8 127,00,0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n10.0.0.0/8\n127.0.0.0/8",
        "original_sample_id": "smp1654q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1058q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the most important property of the spanning tree is that they do not contain loops, this is appealing to the broad- and multicasting , because the amount of outgoing lines will be reduced , making also the number of mailboats smaller and the number of repeated mailboats will decrease. in the case of the multicast, all is belonging to the group have to know the multicast tree, that is why connexion state routing is appropriate. it is important to know that the basis of this kind of routing is that all neighbors send each other their own connexion state mailboat in which they have information about the costs that their own adjacent connexions have.",
        "answer_feedback": "the response is missing how link-state routing can be modified to construct a spanning tree. to calculate the spanning trees, you have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the most important property of the spanning trees is that they do not contain loops, this is appealing to the broad- and multicasting , because the amount of outgoing lines will be reduced , making also the number of packets smaller and the number of repeated packets will decrease. in the case of the multicast, all is belonging to the group have to know the multicast tree, that is why link state routing is appropriate. it is important to know that the basis of this kind of routing is that all neighbors send each other their own link state packet in which they have information about the costs that their own adjacent links have.",
        "original_sample_id": "smp1058q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0204q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first of all we can derive all necessary values from the text: the buffer sizing is n=10, the arrival rate is ƛ = 9 and the service rate is μ = 10. as a next step, we can then calculate the change rate of the queue to ρ = ƛ/μ = 0.9. what we have to do next is to calculate the land probability for all lands with less than 10 packets in the queue and sum those values up. we use the formula p_n = ((1-ρ)ρ^n)/(1-ρ^(n+1)) for each single land. the land probability for all lands with less than 10 waitress packets can be calculated as the following term: p(waitress packets less than 10) = p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 + p_7 + p_8 + p_9 = 0.9492. in the last step, we have to combine this finding with the time of observation. multiplying those values delivers us the expected length of a land with less than 10 packets in the queue: e(t | waitress packets less than 10) = 0.9492 * 60s = 56.952s. so we expect the system to be for about 57s in a land with less than 10 waitress packets.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first of all we can derive all necessary values from the text: the buffer size is n=10, the arrival rate is ƛ = 9 and the service rate is μ = 10. as a next step, we can then calculate the change rate of the queue to ρ = ƛ/μ = 0.9. what we have to do next is to calculate the state probability for all states with less than 10 packets in the queue and sum those values up. we use the formula p_n = ((1-ρ)ρ^n)/(1-ρ^(n+1)) for each single state. the state probability for all states with less than 10 waiting packets can be calculated as the following term: p(waiting packets less than 10) = p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 + p_7 + p_8 + p_9 = 0.9492. in the last step, we have to combine this finding with the time of observation. multiplying those values delivers us the expected length of a state with less than 10 packets in the queue: e(t | waiting packets less than 10) = 0.9492 * 60s = 56.952s. so we expect the system to be for about 57s in a state with less than 10 waiting packets.",
        "original_sample_id": "smp0204q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0204q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first of all we can derive all necessary values from the text: the buffer size is n=10, the arrival rate is ƛ = 9 and the service rate is μ = 10. as a next footfall, we can then calculate the change rate of the queue to ρ = ƛ/μ = 0.9. what we have to do next is to calculate the dos probability for all doss with less than 10 parcel in the queue and sum those values up. we use the formula p_n = ((1-ρ)ρ^n)/(1-ρ^(n+1)) for each single dos. the dos probability for all doss with less than 10 waiting parcel can be calculated as the following term: p(waiting parcel less than 10) = p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 + p_7 + p_8 + p_9 = 0.9492. in the last footfall, we have to combine this finding with the time of observation. multiplying those values delivers us the expected length of a dos with less than 10 parcel in the queue: e(t | waiting parcel less than 10) = 0.9492 * 60s = 56.952s. so we expect the system to be for about 57s in a dos with less than 10 waiting parcel.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first of all we can derive all necessary values from the text: the buffer size is n=10, the arrival rate is ƛ = 9 and the service rate is μ = 10. as a next step, we can then calculate the change rate of the queue to ρ = ƛ/μ = 0.9. what we have to do next is to calculate the state probability for all states with less than 10 packets in the queue and sum those values up. we use the formula p_n = ((1-ρ)ρ^n)/(1-ρ^(n+1)) for each single state. the state probability for all states with less than 10 waiting packets can be calculated as the following term: p(waiting packets less than 10) = p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 + p_7 + p_8 + p_9 = 0.9492. in the last step, we have to combine this finding with the time of observation. multiplying those values delivers us the expected length of a state with less than 10 packets in the queue: e(t | waiting packets less than 10) = 0.9492 * 60s = 56.952s. so we expect the system to be for about 57s in a state with less than 10 waiting packets.",
        "original_sample_id": "smp0204q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1009q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The purpose of reverse route forwarding and reverse route retransmission is to avoid the duplicate sending of messages that results in a congested network and save the effort that arises when messages already received have to be stored in memory. in reverse path forwarding a node remembers in which route it has previously sent something to another node (assuming that this is the best path based on routing tables) and only accepts and forwards packets from that other node that are returning from that same route. an accepted package is forwarded in each outgoing link except the one that came from. if the packages come from other routes that are discarded based on the assumption that they are copies. the reverse route broadcast makes use of the principle of reverse route forwarding except that the packages are not forwarded at each departure line but only in those that are part of a better route between two nodes. each node is inspecting the flow of a network and, therefore, can discover, whether they are on the best route between two nodes or not. if they are not on the best route they will not forward the packages to those nodes.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding and reverse path broadcast is to avoid duplicate sending of messages which results in a congested network and to save the effort that emerges when already received messages have to be stored in memory. in reverse path forwarding a node remembers on which path it has previously sent something to another node (assumption that this is the best path based on routing tables) and only accepts and forwards packets from that other node that are returning from that same path. an accepted packet is forwarded on every outgoing link except the one it came from. if packets are coming from other paths they are discarded based on the assumption that they are copies. reverse path broadcasting makes use of the reverse path forwarding principle except that the packets are not forwarded on every outgoing line but only on the ones which are part of a best path between two nodes. every node is inspecting the flow of a network and can thus find out, whether they are on the best path between two nodes or not. if they are not on that best path they will not forward the packets to those nodes. by doing this the traffic in a network is restricted to less and less packets (fewer copies).",
        "original_sample_id": "smp1009q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1009q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The purpose of reverse route forwarding and reverse route retransmission is to avoid the duplicate sending of messages that results in a congested network and save the effort that arises when messages already received have to be stored in memory. in reverse path forwarding a node remembers in which route it has previously sent something to another node (assuming that this is the best path based on routing tables) and only accepts and forwards packets from that other node that are returning from that same route. an accepted package is forwarded in each outgoing link except the one that came from. if the packages come from other routes that are discarded based on the assumption that they are copies. the reverse route broadcast makes use of the principle of reverse route forwarding except that the packages are not forwarded at each departure line but only in those that are part of a better route between two nodes. each node is inspecting the flow of a network and, therefore, can discover, whether they are on the best route between two nodes or not. if they are not on the best route they will not forward the packages to those nodes.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding and reverse path broadcast is to avoid duplicate sending of messages which results in a congested network and to save the effort that emerges when already received messages have to be stored in memory. in reverse path forwarding a node remembers on which path it has previously sent something to another node (assumption that this is the best path based on routing tables) and only accepts and forwards packets from that other node that are returning from that same path. an accepted packet is forwarded on every outgoing link except the one it came from. if packets are coming from other paths they are discarded based on the assumption that they are copies. reverse path broadcasting makes use of the reverse path forwarding principle except that the packets are not forwarded on every outgoing line but only on the ones which are part of a best path between two nodes. every node is inspecting the flow of a network and can thus find out, whether they are on the best path between two nodes or not. if they are not on that best path they will not forward the packets to those nodes. by doing this the traffic in a network is restricted to less and less packets (fewer copies).",
        "original_sample_id": "smp1009q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0369q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(a,b,forward), (a,c,forward), (a,d,forward) (a,d,forward) (b: (b,c,drop) <=car b knows that c does not receive unicast packages via c (b,e,drop) (c,b,drop) <=car c knows that b does not receive unicast packages via c (c,d,drop), <=car c knows that d does not receive unicast packages via c (c,e,drop), <=car c knows that d does not receive unicast packages via c (c,f,drop) (d,c,drop),<=car d knows that c does not receive unicast packages via d (d,f,drop) <=car d knows that f does not receive unicast packets via d hop 3: message (e,c,drop), <=because c does not receive unicast packages via e (f,drop), <=d knows that f does not receive unicast packets via d hop 3: message (e,c,drop), <=c does not receive unicast packets via d over (f), <=",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: from a: (a,b,forward),(a,c,forward ),(a,d,forward)\n\nhop 2:from b:\n(b, c, drop) <=because b knows that c does not receive unicast packets via c\n(b, e, forward)from c: \n(c, b, drop) <=because c knows that b does not receive unicast packets via c\n(c, d, drop),  <=because c knows that d does not receive unicast packets via c\n(c, e, drop),  <=because c knows that d does not receive unicast packets via c\n(c, f, forward) \nfrom d: \n(d, c, drop),<=because d knows that c does not receive unicast packets via d\n (d, f, drop)  <=because d knows that f does not receive unicast packets via d\nhop 3:from e: \n(e, c, drop), <=because e knows that c does not receive unicast packets via e\n(e, f, drop),  <=because e knows that f does not receive unicast packets via e\n(e, g, forward) \nfrom f: \n(f, d, drop), <=because f knows that d does not receive unicast packets via f\n (f, e, drop),  <=because f knows that e does not receive unicast packets via f\n(f, g, drop) <=because f knows that g does not receive unicast packets via f\nhop 4:from g: \n(g, f, drop),  <=because g knows that f does not receive unicast packets via g\n(g, h, drop)<=because h has only one neighbor from which it got the message, h does not forward the message.",
        "original_sample_id": "smp0369q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1510q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "as the piggyback means that instead of a simple ack there are also data returned from the receiver to the sender (so now both are receivers as well as the sender) the channel between the two must be able to cope with duplex/transfer operations.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "as piggyback means that instead of a simple ack there is also data being send back from the receiver to the sender ( so now both are receiver as well as sender) the channel in between has to be able to cope with duplex operations/transfers.",
        "original_sample_id": "smp1510q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0943q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "At first, the bridge knows nothing about the network, so it uses floods for all unknown destinations. But over time the bridge learns, from traffic, that the sources are in the directions and where you have to send packages to check them. At regular intervals the reference table is updated to adapt to changes in topology. compares the frames of a source to the registered address and updates it if it changes. (time of this frame is more new than my information --> update the location).",
        "answer_feedback": "the response correctly states the information contained in the bridge table. in backward learning, what is learned and interpreted on receiving a packet from source s over link l is not mentioned. the response does not mention how this is used for selective forwarding and what is the benefit of using the bridge table.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "at first the bridge knows nothing about the network, so it uses flooding for all the unknown destinations.\nbut with time the bridge learns, from traffic, wich sources are in wich directions and where it needs to send packets to rech them.\nin regular intervals the forwarding table gets refreshed to adapt to topology changes. compares the frames from a source to the saved direction and updates it if it changes. (timestamp of this frame is newer than my information ---> update the location).\nbridge scans for machines with flooding if they were quiet some minutes.",
        "original_sample_id": "smp0943q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1011q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the forwarding path (rpf) is a technique used in modern routers in order to ensure the unlooped forwarding of multicast packets in multicast routing and to help prevent the IP Spoofing address in unicast routing. Network administrators can use the unicast or forwarding path (unicast rpf) to help limit malicious traffic in a business network. This security feature works by allowing a router to verify the accessibility of the source address in packages that are forwarded. the return package of the forwarding interface is each sender has its own data tree but it is not necessary to know the trees that extend. each router has the information that it would use in (unicast)-packages. the rpf algorithm is as indicated below. the forwarding package of the forwarding interface is not the only one in the forwarding route: the packets for this station/source are generally also: the return package uses the best route until now the return action (more likely).",
        "answer_feedback": "the stated purposes are correct but they are not limited to unicast and multicast instead used widely in broadcast too. the response correctly explains both rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) is a technique used in modern routers for the purposes of ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent ip address spoofing in unicast routing. network administrators can use unicast reverse path forwarding (unicast rpf) to help limit the malicious traffic on an enterprise network. this security feature works by enabling a router to verify the reachability of the source address in packets being forwarded. the principle of rpf is each sender has its own spanning tree but is does not need to know the spanning trees. each router has information which path it would use for (unicast)-packets. algorithm of rpf is as below: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: assumption: packet used the best route until now action: resend over all edges (not including the incoming one) no: assumption: packet did not use this route (it is not the best route) action: discard packet (most likely duplicate reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path in relation to the interface on which the multicast packets are received, but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to make the decision about forwarding, the routers must be informed about the shortest paths. trpb routing is an extension of rpb routing. it ensures that the multicast packets do not get into subnets in which there are no current group members. the principle of rpb is every router forwards a broadcast packet to every adjacent router, except the one where it received the packet. a router u accepts a broadcast packet p originating at router s only if p arrives on the link that is on the direct (unicast) path from u to s. the algorithm of rpb is as below: has this packet arrived at the is entry over which the packets for this station/source s are usually also sent?  yes: packet used the best route until now?   yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction)  no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf)  no: discard packet (is most likely a duplicate)",
        "original_sample_id": "smp1011q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1011q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the forwarding path (rpf) is a technique used in modern routers in order to ensure the unlooped forwarding of multicast packets in multicast routing and to help prevent the IP Spoofing address in unicast routing. Network administrators can use the unicast or forwarding path (unicast rpf) to help limit malicious traffic in a business network. This security feature works by allowing a router to verify the accessibility of the source address in packages that are forwarded. the return package of the forwarding interface is each sender has its own data tree but it is not necessary to know the trees that extend. each router has the information that it would use in (unicast)-packages. the rpf algorithm is as indicated below. the forwarding package of the forwarding interface is not the only one in the forwarding route: the packets for this station/source are generally also: the return package uses the best route until now the return action (more likely).",
        "answer_feedback": "the stated purposes are correct but they are not limited to unicast and multicast instead used widely in broadcast too. the response correctly explains both rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) is a technique used in modern routers for the purposes of ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent ip address spoofing in unicast routing. network administrators can use unicast reverse path forwarding (unicast rpf) to help limit the malicious traffic on an enterprise network. this security feature works by enabling a router to verify the reachability of the source address in packets being forwarded. the principle of rpf is each sender has its own spanning tree but is does not need to know the spanning trees. each router has information which path it would use for (unicast)-packets. algorithm of rpf is as below: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: assumption: packet used the best route until now action: resend over all edges (not including the incoming one) no: assumption: packet did not use this route (it is not the best route) action: discard packet (most likely duplicate reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path in relation to the interface on which the multicast packets are received, but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to make the decision about forwarding, the routers must be informed about the shortest paths. trpb routing is an extension of rpb routing. it ensures that the multicast packets do not get into subnets in which there are no current group members. the principle of rpb is every router forwards a broadcast packet to every adjacent router, except the one where it received the packet. a router u accepts a broadcast packet p originating at router s only if p arrives on the link that is on the direct (unicast) path from u to s. the algorithm of rpb is as below: has this packet arrived at the is entry over which the packets for this station/source s are usually also sent?  yes: packet used the best route until now?   yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction)  no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf)  no: discard packet (is most likely a duplicate)",
        "original_sample_id": "smp1011q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1540q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "we require an extra field for the acknowledgement in the datum form.",
        "answer_feedback": "the response identifies an additional field in the data frame for acknowledgment which is correct. another requirement is a duplex connection.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we require an additional field for the acknowledgement in the data frame.",
        "original_sample_id": "smp1540q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1064q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees are interesting for broad- and multicasting because they represent a subset of a graph that contains all nodes but no loops. if every router in the network knows about the structure of the sweep tree, it can simply forward a received broadcast to the remaining sweep tree lines without creating duplicates or not using the bandwidth optimally. in the link state algorithm all stations have information about the subsist other stations and can create a model of the topology by themselves. this model can then be used to create a sweep tree that fulfills the reward mentioned above.",
        "answer_feedback": "to calculate the spanning trees, you have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees are interesting for broad- and multicasting because they represent a subset of a graph that contains all nodes but no loops. if every router in the network knows about the structure of the spanning tree, it can simply forward a received broadcast to the remaining spanning tree lines without creating duplicates or not using the bandwidth optimally. in the link state algorithm all stations have information about the existing other stations and can create a model of the topology by themselves. this model can then be used to create a spanning tree that fulfills the advantages mentioned above.",
        "original_sample_id": "smp1064q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0910q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information of which station is connected to which departure line. the table is initially empty and uses floods for unknown destinations to collect data and learn by inspecting all traffics and building tables. for the advance process a extension tree is used, because in this way each bridge has the ability to communicate between other bridges. with which you are able to connect lans through different bridges in parallel.",
        "answer_feedback": "the response correctly states the information contained in the bridge table. in backward learning, what is learned and interpreted on receiving a packet from source s over link l is not mentioned. the spanning-tree concept is introduced when multiple transparent bridges are used to increase reliability which is beyond the scope of the question, so the benefit and forwarding process is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the table holds the information of which station is connected to which output line.\nthe table is initially empty and uses flooding for unknown destinations to collect data and learn by inspecting all the traffics and build the tables. \nfor the forward process a spanning tree is used, because this way each bridge has the capability to communicate among other bridges. \nwith that you are able to connect lans via different bridges in parallel.",
        "original_sample_id": "smp0910q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0203q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first at second 0, 9 mailboat arrive, the waiting time for the first packet w1 is not given therefore adopt with 1second. there are now 9 mailboat in the buffer. at second 1, 9 more mailboat arrive. the buffer is completely filled with 10 mailboat, 8 more are discharge.  the mailboat are starting to be served with an average service rate of 10. at second 2, there are no mailboat left in the buffer. 9 new ones arrive and are directly served. from now on the buffer won’t fill up again. this means there are 58 seconds with less than 10 mailboat waiting in the queue.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "first at second 0, 9 packets arrive, the waiting time for the first packet w1 is not given therefore assumed with 1second. there are now 9 packets in the buffer. at second 1, 9 more packets arrive. the buffer is completely filled with 10 packets, 8 more are dropped.  the packets are starting to be served with an average service rate of 10. at second 2, there are no packets left in the buffer. 9 new ones arrive and are directly served. from now on the buffer won’t fill up again. this means there are 58 seconds with less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0203q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0203q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first at second 0, 9 package arrive, the waiting time for the first packet w1 is not given therefore assumed with 1second. there are now 9 package in the polisher. at second 1, 9 more package arrive. the polisher is completely fulfil with 10 package, 8 more are dropped.  the package are starting to be served with an average service rate of 10. at second 2, there are no package left in the polisher. 9 new ones arrive and are directly served. from now on the polisher won’t fill up again. this means there are 58 seconds with less than 10 package waiting in the queue.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "first at second 0, 9 packets arrive, the waiting time for the first packet w1 is not given therefore assumed with 1second. there are now 9 packets in the buffer. at second 1, 9 more packets arrive. the buffer is completely filled with 10 packets, 8 more are dropped.  the packets are starting to be served with an average service rate of 10. at second 2, there are no packets left in the buffer. 9 new ones arrive and are directly served. from now on the buffer won’t fill up again. this means there are 58 seconds with less than 10 packets waiting in the queue.",
        "original_sample_id": "smp0203q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1626q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "127,0.0.0 to 127,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "127.0.0.0 to 127.255.255.255",
        "original_sample_id": "smp1626q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0878q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "could not be on the real Internet. on the real Internet if a package is lost or has error, it needs to be retransmitted. obviously it could affect the next arrivals. means that time intervals cannot be independent.",
        "answer_feedback": "“no” is the correct answer. while the example is correct, it limits the dependency of packet arrival to only retransmission.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it couldn’t be in the real internet. in the real internet if a packet is lost or has error, it needs to be retransmitted. obviously it could affect the following arrivals. it means the time intervals could not be independent.",
        "original_sample_id": "smp0878q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0878q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "could not be on the real Internet. on the real Internet if a package is lost or has error, it needs to be retransmitted. obviously it could affect the next arrivals. means that time intervals cannot be independent.",
        "answer_feedback": "“no” is the correct answer. while the example is correct, it limits the dependency of packet arrival to only retransmission.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it couldn’t be in the real internet. in the real internet if a packet is lost or has error, it needs to be retransmitted. obviously it could affect the following arrivals. it means the time intervals could not be independent.",
        "original_sample_id": "smp0878q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it works with high-power in order to work very performant with a high amount of datum.\nproblem is that it is not that expert, when there is less datum.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it works with eminent-force in order to work very performant with a eminent amount of data.\nproblem is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it shape with high-power in ordering to work very performant with a high amount of data.\njob is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it gos with high-power in rescript to go very performant with a high amount of data.\njob is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "works with great power in order to work very efficient with a large amount of data. problem is that it is not so good, when there are less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug05smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it gos with high-might in society to go very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug06smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it act with high-power in club to forge very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug07smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it plays with high-power in order to play very performant with a high amount of data.\njob is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp0890q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table on cobwebby bridge is empty at first. it is then filled with the information on which interface a certain meshwork can be reached and when this information has been found (timestamp).\nwith an empty table, an incoming packet is flooded to all other meshworks at first. for every incoming packet it creates an entry in the bridge table and can route the packets belonging to this meshwork accordingly in the future. this is called backward learning.\nin the forwarding phase the table is used to route packets via those meshworks where packets, which had the same source meshwork as the currents packets destination meshwork, have been received before. whenever such a packet is forwarded, the timestamp in the table is updated. old entries are purged after some time, usually several minutes.",
        "answer_feedback": "the response incorrectly uses network instead of station(even for outgoing lan which is not precise). the timestamp is updated on receiving a packet, not while forwarding. the benefit derived from using the table is also no stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the table on transparent bridges is empty at first. it is then filled with the information on which interface a certain network can be reached and when this information has been found (timestamp).\nwith an empty table, an incoming packet is flooded to all other networks at first. for every incoming packet it creates an entry in the bridge table and can route the packets belonging to this network accordingly in the future. this is called backward learning.\nin the forwarding phase the table is used to route packets via those networks where packets, which had the same source network as the currents packets destination network, have been received before. whenever such a packet is forwarded, the timestamp in the table is updated. old entries are purged after some time, usually several minutes.",
        "original_sample_id": "smp0890q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1657q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 ~ 0.255,255,255 10.0.0 ~ 10,255,255,255 127,0.0 ~ 127,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 ~ 0.255.255.255\n10.0.0.0 ~ 10.255.255.255\n127.0.0.0 ~ 127.255.255.255",
        "original_sample_id": "smp1657q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0938q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa starts empty. a frame with source address x arriving on port k of a given bridge, will cause that bridge to create or update an entry in its mesa, suggesting that any frame addressed to destination x should be sent on through port k. a bridge will flood frames whose destination addresses are unknown to all embrasure other than the one on which the frame arrived. \nframe furtherance processes are effective and lead to correct operation of the transparent bridging architecture as long as the overall network does not contain any loops.",
        "answer_feedback": "apart from the benefit which does not specify how frame forwarding is effective or leads to correct operation, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the table starts empty. a frame with source address x arriving on port k of a given bridge, will cause that bridge to create or update an entry in its table, suggesting that any frame addressed to destination x should be sent on through port k. a bridge will flood frames whose destination addresses are unknown to all ports other than the one on which the frame arrived. \nframe forwarding processes are effective and lead to correct operation of the transparent bridging architecture as long as the overall network does not contain any loops.",
        "original_sample_id": "smp0938q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1534q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it is a duplex process so communication has to be potential in both directions. also the initial succession number is 0 and the next succession number and the next acknowledge succession number to be expected is given.",
        "answer_feedback": "the response answers the underlying requirement. however, the initial sequence need not be 0. apart from the duplex connection and initial sequence number, the other points are valid but refer to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial sequence number is 0 and the next sequence number and the next acknowledge sequence number to be expected is given.",
        "original_sample_id": "smp1534q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1534q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it is a duplex operation so communication has to be potential in both directions. also the initial episode number is 0 and the next episode number and the next acknowledge episode number to be expected is given.",
        "answer_feedback": "the response answers the underlying requirement. however, the initial sequence need not be 0. apart from the duplex connection and initial sequence number, the other points are valid but refer to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial sequence number is 0 and the next sequence number and the next acknowledge sequence number to be expected is given.",
        "original_sample_id": "smp1534q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1534q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it is a duplex operation so communicating has to be possible in both directions. also the initial sequence figure is 0 and the next sequence figure and the next acknowledge sequence figure to be gestate is given.",
        "answer_feedback": "the response answers the underlying requirement. however, the initial sequence need not be 0. apart from the duplex connection and initial sequence number, the other points are valid but refer to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial sequence number is 0 and the next sequence number and the next acknowledge sequence number to be expected is given.",
        "original_sample_id": "smp1534q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1534q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it is a duplex operation so communicating has to be possible in both directions. also the initial sequence figure is 0 and the next sequence figure and the next acknowledge sequence figure to be expected is break.",
        "answer_feedback": "the response answers the underlying requirement. however, the initial sequence need not be 0. apart from the duplex connection and initial sequence number, the other points are valid but refer to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial sequence number is 0 and the next sequence number and the next acknowledge sequence number to be expected is given.",
        "original_sample_id": "smp1534q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1534q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial succession number is 0 and the next succession number and the next acknowledge succession number to be anticipate is given.",
        "answer_feedback": "the response answers the underlying requirement. however, the initial sequence need not be 0. apart from the duplex connection and initial sequence number, the other points are valid but refer to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it is a duplex operation so communication has to be possible in both directions. also the initial sequence number is 0 and the next sequence number and the next acknowledge sequence number to be expected is given.",
        "original_sample_id": "smp1534q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0830q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "compare to udp, the tcp header is overleap the \"packet length\" field.\ncompare to tcp, \"sequence number\", \"acknowledgment number\" and \"advertised windowpane size\" are some of the fields that are overleap in the udp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "compared to udp, the tcp header is missing the \"packet length\" field.\ncompared to tcp, \"sequence number\", \"acknowledgment number\" and \"advertised window size\" are some of the fields that are missing in the udp header.",
        "original_sample_id": "smp0830q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0894q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "a transparant span receives every underframe from each connected lan including the source address \"s\" of the underframe on a lan \"l\". the span creates a table entry with the information that \"s\" can be reached via \"l\". this is done for every underframe. the advantage of this approach is that the span is invisible for other components of the network leading to reduction.",
        "answer_feedback": "the response correctly describes how transparent bridges build their bridge table and what information they contain. how this information is later used in forwarding packets selectively is not mentioned. the stated benefit is also incorrect as the question asked for the benefit derived from using the bridge table based forwarding, not simply about using bridges.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a transparant bridge receives every frame from each connected lan including the source address \"s\" of the frame on a lan \"l\". the bridge creates a table entry with the information that \"s\" can be reached via \"l\". this is done for every frame. the advantage of this approach is that the bridge is invisible for other components of the network leading to simplification.",
        "original_sample_id": "smp0894q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0381q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forrad)(a,c,forrad)\n(a,d,forrad)\nhop 2:\n(b,e,forrad)\n(b,c,forrad)\n(c,e,forrad)\n(c,d,forrad)\n(d,f,forrad)\n(d,c,drib) was sent from c\n(c,b,drib) was sent from b\nhop 3:\n\n(e,g,forrad)\n\n\n(f,g,forrad)\n(e,f,forrad)(f,e,drib) was sent from e\n\nhop 4:\n(g,h, forrad)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,b,forward)(a,c,forward)\n(a,d,forward)\nhop 2:\n(b,e,forward)\n(b,c,forward)\n(c,e,forward)\n(c,d,forward)\n(d,f,forward)\n(d,c,drop) was sent from c\n(c,b,drop) was sent from b\nhop 3:\n\n(e,g,forward)\n\n\n(f,g,forward)\n(e,f,forward)(f,e,drop) was sent from e\n\nhop 4:\n(g,h, forward)",
        "original_sample_id": "smp0381q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1015q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Reverse route forwarding and reverse route retransmission are routing algorithms that are used for multicast routing scenarios. to adjust to changing topologies use floods to find suitable routes. the principle of reverse route forwarding is that each station has a tree that represents routing to other stations. the packages are flooded from the first shipping station and propagated through the network. when a package is received, each station checks if a package arrives at the port it normally arrives at. if it is assumed that it has used the best route until now and the package is sent to the other adjacent stations, otherwise it is discarded. the reverse route retransmission follows a similar approach. it differs in how it handles the packets that are received in the port packets of entry to this destination are normally assumed. there is an additional check, if the package uses the best route until now. if so selects the edge on which unicat packages arrive and from which they are forwarded to the source. otherwise it is not sent over all the edges.",
        "answer_feedback": "the response incorrectly states the purpose. the purpose of rpf and rpb is to reduce redundant packets/duplicates when broadcasting instead of just adapting to changing topology. the explanation of rpf is partially correct as each station(say x) checks if the packets arrived at a port that is used in unicast for sending a packet from x to s. therefore, stating \"each station checks whether a packet arrived at the port it usually arrives at.\" is not correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "reverse path forwarding and reverse path broadcast are routing algorithms that are used for multicast routing scenarios. to adjust to changing topologies they utilize flooding to find suitable routes. the principle of the reverse path forwarding is that each station has a spanning tree that represents the routing to other stations. the packets are flooded from the first sending station and propagated through the network. when a packet is received, each station checks whether a packet arrived at the port it usually arrives at. if so it is assumed that it used the best path until now and the packet is sent to the other adjacent stations, otherwise it is discarded.  the reverse path broadcast follows a similar approach. it differs in how it handles packets that are received on the entry port packets to this destination are usually assumed at. there is an additional check, if the packet used the best route until now. if so the edge is selected at which unicast packets arrive and from which they are then rerouted to the source. otherwise it is not sent over all edges.",
        "original_sample_id": "smp1015q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1085q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the central node of the spanning tree can generate a copy of a packet for each required outgoing line, therefore minimzing the overhead/network load. every node measures the distance to its adjacent is and distributes this local link province entropy thrive by entropy on multicast groups in a packet to all is. therefore, each node can calculates a multicast tree and complete province entropy. based on the entropy about the multicast tree the is determines the outgouing lines on which packets have to be transmitted.",
        "answer_feedback": "there is a unique path to reach all nodes from another node, so only a central node generating a copy of the packet and that leading to reduced load is not correct. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the central node of the spanning tree can generate a copy of a packet for each required outgoing line, therefore minimzing the overhead/network load. every node measures the distance to its adjacent is and distributes this local link state information expanded by information on multicast groups in a packet to all is. therefore, each node can calculates a multicast tree and complete state information. based on the information about the multicast tree the is determines the outgouing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1085q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1087q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees are interesting for broadcasting and multicasting, because they include every node of the graph (that is, the network in this case) without including all edges of the graph (or even only the minimal amount of edges necessary to connect all nodes). nexus state routing can be modified for multicasting via a spanning tree by adding information about the group membership of the immediate arrangement to the periodically mail nexus state packets. each is then knows about the group membership of all other is and can determine a spanning tree for efficiently mailing messages to these groups.",
        "answer_feedback": "the explanation behind using a spanning tree for multicast and broadcast is partially correct because though they have minimal edges that remove loops and hence reduces unnecessary duplicates. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees are interesting for broadcasting and multicasting, because they include every node of the graph (that is, the network in this case) without including all edges of the graph (or even only the minimal amount of edges necessary to connect all nodes). link state routing can be modified for multicasting via a spanning tree by adding information about the group membership of the immediate system to the periodically send link state packets. each is then knows about the group membership of all other is and can determine a spanning tree for efficiently sending messages to these groups.",
        "original_sample_id": "smp1087q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1631q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "diffusion: x.255,255,255 network identifier: x.0.0.0",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast: x.255.255.255\nnetwork identifier: x.0.0.0",
        "original_sample_id": "smp1631q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1631q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "diffusion: x.255,255,255 network identifier: x.0.0.0",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast: x.255.255.255\nnetwork identifier: x.0.0.0",
        "original_sample_id": "smp1631q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0842q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for real internet traffic, because usually data transfer on any layer happens in multiple, often many packet.\nif a machine initiates a data transfer, it is very likely that it wants to send more data than fitting in one packet, so it will send many\nof them in succession. in this case the time interval between the packet arrivals is not sovereign since they belong to one connection\nor data transfer. for example if a machine wants to receive a video stream of netflix, it will have a lot of packet continuously \n(although buffered) receiving from the netflix servers, so the arrivals of the packet of the video stream are not sovereign, therefore\nthe time intervals δt between them are also not sovereign.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, this assumption does not hold for real internet traffic, because usually data transfer on any layer happens in multiple, often many packets.\nif a machine initiates a data transfer, it is very likely that it wants to send more data than fitting in one packet, so it will send many\nof them in succession. in this case the time interval between the packet arrivals is not independent since they belong to one connection\nor data transfer. for example if a machine wants to receive a video stream of netflix, it will have a lot of packets continuously \n(although buffered) receiving from the netflix servers, so the arrivals of the packets of the video stream are not independent, therefore\nthe time intervals δt between them are also not independent.",
        "original_sample_id": "smp0842q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1006q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Both share the objective of inundating a network with a message while they cause as few duplicates as possible. Inverse diffusion: a sender sends a message to another node through the shortest path. the recipient sends a message back to the sender through all its adjacent nodes. If the original sender now receives the package back from several routes and releases each package received from a path different from the shorter one to the original receiver because these packages are considered duplicated. Inverse diffusion: all nodes inspect the sender and receiver of incoming packets and check whether these messages have been returned in the past. based on the historical information that they can now decide to be part of the shortest route between the sender and the recipient of the inspected package. The inspected package is not sent beyond the nodes for which the inspection node is part of the shortest route.",
        "answer_feedback": "the response correctly answers the purpose and explanation of rpf and rpb broadcastings.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both share the goal of flooding a network with some message while causing as few duplicates as possible. reverse path forwarding: a sender sends a message to another node via the shortest route. the receiver sends a message back to the sender via all of its adjacent nodes. if the original sender now receives the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. reverse path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such messages in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "original_sample_id": "smp1006q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1006q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "both share the goal of flooding a network with some substance while causing as few duplicates as possible. vacate path forwarding: a sender sends a substance to another node via the shortest route. the receiver sends a substance back to the sender via all of its adjacent nodes. if the original sender now incur the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. vacate path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such substances in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "answer_feedback": "the response correctly answers the purpose and explanation of rpf and rpb broadcastings.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both share the goal of flooding a network with some message while causing as few duplicates as possible. reverse path forwarding: a sender sends a message to another node via the shortest route. the receiver sends a message back to the sender via all of its adjacent nodes. if the original sender now receives the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. reverse path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such messages in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "original_sample_id": "smp1006q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0387q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (a, b, before) (a, c, before) (a, d, fall) <= no known unicast road from f or c to hops 2: (b, e, before) (c, f, fall) <= no known unicast road from f to hops 3: (e, g, before) hops 4: (g, h, fall) <= no neighbour except g from which package was received",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward) (a, c, forward) (a, d, drop) <= no known unicast route from f or c to a\nhop 2:\n(b, e, forward) (c, f, drop) <= no known unicast route via f to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= no neighbors except g from which packet was received",
        "original_sample_id": "smp0387q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1060q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a traverse tree is a tree that connects all edges in a graph with the minimum number of possible edges. in this way, traverse trees help in avoiding loops while unite all the edges in a graph that makes them good for building networks for broad and multicasting.  the already existing lsr can be used to construct a traverse tree for multicasting, first, each node must find the shortest path to all other nodes(linked state path/lsp), and every clip the network changes, this must be repeated and new lsps must be calculated. these lsps wil be the only paths used to communicate between the nodes.",
        "answer_feedback": "the response correctly answers why using a spanning tree is a good idea in multicast and broadcast. the provided explanation just states the original link-state algorithm with no information about how it should include the new multicast group information and how each node will form part of the multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a spanning tree is a tree that connects all edges in a graph with the minimum number of possible edges. in this way, spanning trees help in avoiding loops while connecting all the edges in a graph that makes them good for building networks for broad and multicasting.  the already existing lsr can be used to construct a spanning tree for multicasting, first, each node must find the shortest path to all other nodes(linked state path/lsp), and every time the network changes, this must be repeated and new lsps must be calculated. these lsps wil be the only paths used to communicate between the nodes.",
        "original_sample_id": "smp1060q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1026q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of these two algorithms is to broadcast the mailboats to all the nodes present while reducing the matchings. reverse path forwarding: when a mailboat is received at an is from a sender,  then it is checked whether this is the correct and shortest path followed or not ie if the is had to send the mailboats back will it utilize the same route or not. if the route is correct, in that case the mailboat is accepted and then forwarded to all other edges. if not then then mailboat is discarded as it might be a matching mailboat. reverse path broadcast: when a mailboat is unicasted to a particular station the other other station listen to check if that is the best route to the mailboat forwarding for the receiver station or not. if that is the best route then when a mailboat arrives at a station then it is also send to this edge. if that is not the best route then the mailboat is rejected and not sent on that path. in this case it learns from the mailboats whether a node lies in the path of sending or receiving to a particular node or not if it does then it also forwards the mailboat to that path else it does not forward to that path.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.in both algorithms, the packet is also not forwarded to the edge from which it was received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.9,
        "original_answer": "the purpose of these two algorithms is to broadcast the packets to all the nodes present while reducing the duplicates. reverse path forwarding: when a packet is received at an is from a sender,  then it is checked whether this is the correct and shortest path followed or not ie if the is had to send the packets back will it use the same route or not. if the route is correct, in that case the packet is accepted and then forwarded to all other edges. if not then then packet is discarded as it might be a duplicate packet. reverse path broadcast: when a packet is unicasted to a particular station the other other station listen to check if that is the best route to the packet forwarding for the receiver station or not. if that is the best route then when a packet arrives at a station then it is also send to this edge. if that is not the best route then the packet is rejected and not sent on that path. in this case it learns from the packets whether a node lies in the path of sending or receiving to a particular node or not if it does then it also forwards the packet to that path else it does not forward to that path.",
        "original_sample_id": "smp1026q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1625q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.0—10.255.255.255 (individual habit)\n127.x.x.x (loopback tryout)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "10.0.0.0—10.255.255.255 (private use)\n127.x.x.x (loopback test)",
        "original_sample_id": "smp1625q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1652q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0 , 127 255 255 255 255",
        "answer_feedback": "the addresses have ranges: from x.0.0.0 and x.255.255.255 with x between 0 and 127\nmissing: loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0 , 127.255.255.255",
        "original_sample_id": "smp1652q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0208q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "of the question we know that this is a model m/m/1/n. of “buffer of size is 10 ” we know that n=10. the average rate of arrival of packages is",
        "answer_feedback": "the calculation steps are given correctly in the response but the final number of seconds where the system has less than 10 packets is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "from the question we know that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we know that n=10.\nthe average rate of packets arrival is  λ = 9/s.\nthe average rate of service is  μ = 10/s.\ntherefore, the average probability of the service being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe know that blocking probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above known quantity into blocking probability formula for calculation, we can get the pb.\nthe expected time of the system to be in a state in which there are less than 10 packets waiting in the queue in one minute after the system reaches equilibrium = 60 seconds*(1-pb).",
        "original_sample_id": "smp0208q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0208q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "from the question we know that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we know that n=10.\nthe average rate of mailboat arrival is  λ = 9/s.\nthe average rate of service is  μ = 10/s.\ntherefore, the average probability of the service being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe know that jam probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above known quantity into jam probability formula for calculation, we can get the pb.\nthe expected time of the organization to be in a state in which there are less than 10 mailboat waiting in the queue in one minute after the organization reaches equilibrium = 60 seconds*(1-pb).",
        "answer_feedback": "the calculation steps are given correctly in the response but the final number of seconds where the system has less than 10 packets is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "from the question we know that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we know that n=10.\nthe average rate of packets arrival is  λ = 9/s.\nthe average rate of service is  μ = 10/s.\ntherefore, the average probability of the service being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe know that blocking probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above known quantity into blocking probability formula for calculation, we can get the pb.\nthe expected time of the system to be in a state in which there are less than 10 packets waiting in the queue in one minute after the system reaches equilibrium = 60 seconds*(1-pb).",
        "original_sample_id": "smp0208q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0208q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "from the question we eff that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we eff that n=10.\nthe average rate of packets arrival is  λ = 9/s.\nthe average rate of overhaul is  μ = 10/s.\ntherefore, the average probability of the overhaul being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe eff that blocking probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above effn quantity into blocking probability formula for calculation, we can get the pb.\nthe expected time of the arrangement to be in a state in which there are less than 10 packets waiting in the queue in one minute after the arrangement reaches equilibrium = 60 seconds*(1-pb).",
        "answer_feedback": "the calculation steps are given correctly in the response but the final number of seconds where the system has less than 10 packets is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "from the question we know that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we know that n=10.\nthe average rate of packets arrival is  λ = 9/s.\nthe average rate of service is  μ = 10/s.\ntherefore, the average probability of the service being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe know that blocking probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above known quantity into blocking probability formula for calculation, we can get the pb.\nthe expected time of the system to be in a state in which there are less than 10 packets waiting in the queue in one minute after the system reaches equilibrium = 60 seconds*(1-pb).",
        "original_sample_id": "smp0208q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0820q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: header size is more (20 bytes minimum) may contain optional data a at least 10 fields is larger as tcp provides more features. udp: header size is only 8 bytes does not contain optional data with 4 fields of 2 bytes each is smaller as udp has fewer features and is used for applications requiring higher speeds",
        "answer_feedback": "the response is partially correct as it only identifies three differences, the difference in size, the options field and the varying number of fields.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "tcp: header size is more (20 bytes minimum) can contain optional data has atleast 10 fields is bigger in size since tcp provides more features. udp: header size is 8 bytes only does not contain optional data has 4 fields of 2 bytes each is smaller in size since udp has less features and used for applications requiring higher speeds",
        "original_sample_id": "smp0820q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0820q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: lintel size is more (20 bytes minimum) can comprise optional data has atleast 10 fields is vainglorious in size since tcp provides more features. udp: lintel size is 8 bytes only does not comprise optional data has 4 fields of 2 bytes each is smaller in size since udp has less features and used for applications requiring higher speeds",
        "answer_feedback": "the response is partially correct as it only identifies three differences, the difference in size, the options field and the varying number of fields.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "tcp: header size is more (20 bytes minimum) can contain optional data has atleast 10 fields is bigger in size since tcp provides more features. udp: header size is 8 bytes only does not contain optional data has 4 fields of 2 bytes each is smaller in size since udp has less features and used for applications requiring higher speeds",
        "original_sample_id": "smp0820q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0820q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: lintel sizing is more (20 bytes minimum) can contain optional data has atleast 10 fields is bigger in sizing since tcp provides more features. udp: lintel sizing is 8 bytes only does not contain optional data has 4 fields of 2 bytes each is smaller in sizing since udp has less features and used for applications requiring higher speeds",
        "answer_feedback": "the response is partially correct as it only identifies three differences, the difference in size, the options field and the varying number of fields.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "tcp: header size is more (20 bytes minimum) can contain optional data has atleast 10 fields is bigger in size since tcp provides more features. udp: header size is 8 bytes only does not contain optional data has 4 fields of 2 bytes each is smaller in size since udp has less features and used for applications requiring higher speeds",
        "original_sample_id": "smp0820q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0820q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: header size is more (20 bytes minimum) may contain optional data a at least 10 fields is larger as tcp provides more features. udp: header size is only 8 bytes does not contain optional data with 4 fields of 2 bytes each is smaller as udp has fewer features and is used for applications requiring higher speeds",
        "answer_feedback": "the response is partially correct as it only identifies three differences, the difference in size, the options field and the varying number of fields.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "tcp: header size is more (20 bytes minimum) can contain optional data has atleast 10 fields is bigger in size since tcp provides more features. udp: header size is 8 bytes only does not contain optional data has 4 fields of 2 bytes each is smaller in size since udp has less features and used for applications requiring higher speeds",
        "original_sample_id": "smp0820q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1662q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127)0.0 chain (0-127) 255.255,255 transmission",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0 network\n(0-127).255.255.255 broadcast",
        "original_sample_id": "smp1662q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1662q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127)0.0 chain (0-127) 255.255,255 transmission",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0 network\n(0-127).255.255.255 broadcast",
        "original_sample_id": "smp1662q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1051q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf can work using uni-cast and multi-cast. when a transmitted message reaches a node, the node keeps a record of where the message came from from from the beginning, and ignores the messages that arrive later. next, the node transmits the package in all directions except the path from which it came. in this way, the abbreviated track between the source and the node is tracked. rpb works by forwarding packages only on the best path of unicast. the best route is known by maintaining a record of the route used to relay packets between nodes.",
        "answer_feedback": "the rpf explanation is partially correct as it incorrectly states that the receiving node ignores the later messages. rpb's explanation is also partially correct as the best path is identified by keeping track of unicast and not broadcast messages. also, the purpose of reducing duplicate packets in the network is missing in response.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.4,
        "original_answer": "reverse path forwarding and reverse path broadcast are variations of broadcast routing algorithms.  rpf can work using uni-cast and multi-cast. when a broadcasted message arrives at a node, the node keeps track of where the message arrived from first, and ignores the messages that arrive later. next, the node broadcasts the packet in all directions except the path it came from. this way, the shorted track between the source and node are tracked.  rpb works by forwarding packets only on the best unicast path. the best path is known by keeping track of the path used to broadcast packets between nodes.",
        "original_sample_id": "smp1051q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0996q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "we learned about reverse route forwarding and reverse route program regarding program routing. 1. reverse route forwarding / reverse route flooding: the purpose of this algorithm is to efficiently distribute program messages. therefore, each sender maintains its own spanning tree. the spanning tree gives us information about how much does it cost to reach a node in a tree to deliver a unicast message. there can be different routes to reach this node from sender to recipient - the cheapest route is considered to be the best one. when a program sender s sends a program message to all nodes in the network (see slideway 9) every node  in the network checks: is the program message received via the best route the node itself would use to send a unicast message to s? - if it is true: then the node resends the program messages via all edges in the network except the edge over which the program message was received - otherwise the node will ignore the program message (duplicate) 2. reverse route program the purpose of this algorithm is to efficiently distribute program messages. it basically works as reverse route forwarding with one difference: when a program sender s sends a program message to all nodes in the network, every node selects specific edges which are used to resent the message. a node will resent the message via a specific edge if this node is typcially on the route to this node regarding the sending of unicast messages and if it is the best route until now.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we learned about reverse path forwarding and reverse path broadcast regarding broadcast routing. 1. reverse path forwarding / reverse path flooding: the purpose of this algorithm is to efficiently distribute broadcast messages. therefore, each sender maintains its own spanning tree. the spanning tree gives us information about how much does it cost to reach a node in a tree to deliver a unicast message. there can be different paths to reach this node from sender to recipient - the cheapest path is considered to be the best one. when a broadcast sender s sends a broadcast message to all nodes in the network (see slide 9) every node  in the network checks: is the broadcast message received via the best route the node itself would use to send a unicast message to s? - if it is true: then the node resends the broadcast messages via all edges in the network except the edge over which the broadcast message was received - otherwise the node will ignore the broadcast message (duplicate) 2. reverse path broadcast the purpose of this algorithm is to efficiently distribute broadcast messages. it basically works as reverse path forwarding with one difference: when a broadcast sender s sends a broadcast message to all nodes in the network, every node selects specific edges which are used to resent the message. a node will resent the message via a specific edge if this node is typcially on the path to this node regarding the sending of unicast messages and if it is the best route until now.",
        "original_sample_id": "smp0996q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp0996q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "we learned about reverse path forwarding and reverse path programme regarding programme routing. 1. reverse path forwarding / reverse path flooding: the purpose of this algorithm is to efficiently distribute programme messages. therefore, each transmitter maintains its own spanning tree. the spanning tree gives us information about how much does it cost to reach a node in a tree to deliver a unicast message. there can be different paths to reach this node from transmitter to recipient - the cheapest path is considered to be the best one. when a programme transmitter s sends a programme message to all nodes in the network (see slide 9) every node  in the network checks: is the programme message received via the best route the node itself would use to send a unicast message to s? - if it is true: then the node resends the programme messages via all borders in the network except the border over which the programme message was received - otherwise the node will ignore the programme message (duplicate) 2. reverse path programme the purpose of this algorithm is to efficiently distribute programme messages. it basically works as reverse path forwarding with one difference: when a programme transmitter s sends a programme message to all nodes in the network, every node selects specific borders which are used to resent the message. a node will resent the message via a specific border if this node is typcially on the path to this node regarding the sending of unicast messages and if it is the best route until now.",
        "answer_feedback": "the response correctly explains the rpf and rpb algorithms and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we learned about reverse path forwarding and reverse path broadcast regarding broadcast routing. 1. reverse path forwarding / reverse path flooding: the purpose of this algorithm is to efficiently distribute broadcast messages. therefore, each sender maintains its own spanning tree. the spanning tree gives us information about how much does it cost to reach a node in a tree to deliver a unicast message. there can be different paths to reach this node from sender to recipient - the cheapest path is considered to be the best one. when a broadcast sender s sends a broadcast message to all nodes in the network (see slide 9) every node  in the network checks: is the broadcast message received via the best route the node itself would use to send a unicast message to s? - if it is true: then the node resends the broadcast messages via all edges in the network except the edge over which the broadcast message was received - otherwise the node will ignore the broadcast message (duplicate) 2. reverse path broadcast the purpose of this algorithm is to efficiently distribute broadcast messages. it basically works as reverse path forwarding with one difference: when a broadcast sender s sends a broadcast message to all nodes in the network, every node selects specific edges which are used to resent the message. a node will resent the message via a specific edge if this node is typcially on the path to this node regarding the sending of unicast messages and if it is the best route until now.",
        "original_sample_id": "smp0996q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "The initial sequence no. must be 0. 4. The next sequence no. what is estimated is given. 5. the next sequence ack no. which is also expected to be given.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex surgery\n3.the initial succession no.should be 0.\n4.the next succession no. what is estimated is pay.\n5.the next ack-succession no. that is expected is also pay.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "The initial sequence no. must be 0. 4. The next sequence no. what is estimated is given. 5. the next sequence ack no. which is also expected to be given.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial episode no.should be 0.\n4.the next episode no. what is gauge is dedicate.\n5.the next ack-episode no. that is expected is also dedicate.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "essential for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is gauge is render.\n5.the next ack-sequence no. that is expected is also render.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1066q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "1. The extension tree is a subset of subnets that include all routers without loops. Therefore, duplicates cannot be generated while the width and multicasting. 2. You can expand the link status packets by information in multicast groups. then all the link status packets have to be transmitted to all others. then, each one is calculated a multicast tree and based on the information about the multicast tree it is determined the outgoing lines and transmits the package.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. spanning tree is a subset of subnets including all routers with no loops. therefore no duplicates can be generated while broad- and multicasting. 2. you can expand the link state packets by information on multicast groups. then all link state packets have to be broadcasted to all the other. afterwards, each is calculates a multicast tree and based on the information about the multicast tree the is determines the outgoing lines and transmit the package.",
        "original_sample_id": "smp1066q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1066q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "1. sweep tree is a subset of subnets including all routers with no loops. therefore no duplicates can be generated while broad- and multicasting. 2. you can expand the link state packets by information on multicast groups. then all link state packets have to be disseminate to all the other. afterwards, each is calculates a multicast tree and based on the information about the multicast tree the is determines the outgoing lines and impart the package.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. spanning tree is a subset of subnets including all routers with no loops. therefore no duplicates can be generated while broad- and multicasting. 2. you can expand the link state packets by information on multicast groups. then all link state packets have to be broadcasted to all the other. afterwards, each is calculates a multicast tree and based on the information about the multicast tree the is determines the outgoing lines and transmit the package.",
        "original_sample_id": "smp1066q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0850q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this is a very strong assumption and not realistic since in reality you often have a period of sentence where you need a constant packet transmission, like for example in video streaming. this then depends on the usage of the application. therefore it is often even more likely that in the next sentence separation the same event will occur as in the previous one, which would make it questionable whether it is a random appendage at all.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this is a very strong assumption and not realistic since in reality you often have a period of time where you need a constant packet transmission, like for example in video streaming. this then depends on the usage of the application. therefore it is often even more likely that in the next time interval the same event will occur as in the previous one, which would make it questionable whether it is a random process at all.",
        "original_sample_id": "smp0850q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1079q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the purpose of both is to forward broadcast packets without forward iterations. - traverse trees are iteration free, so recieving twinned packages is impossible - in case of having a single traverse tree for the whole network, one node has to be chosen by some alogirthm or manually to be the root node. after this the root node can announce itself through the link state packages as the root of the tree. all other nodes send then their multicast packets to this node, which then get forwarded iteration free to their destinations",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. however, the description of how link state routing is used for the construction of multicast spanning trees is incorrect, because it is not necessary to define a root node that distributes all of the multicast packages. all nodes can calculate the spanning tree themselves, with the complete state information they have distributed with the link state algorithm.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the purpose of both is to forward broadcast packets without forward loops. - spanning trees are loop free, so recieving duplicate packages is impossible - in case of having a single spanning tree for the whole network, one node has to be chosen by some alogirthm or manually to be the root node. after this the root node can announce itself through the link state packages as the root of the tree. all other nodes send then their multicast packets to this node, which then get forwarded loop free to their destinations",
        "original_sample_id": "smp1079q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0206q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "By dividing the rate of arrival of the maintenance rate and with n=10, we can continue to calculate the probability of blocking p_b. by subtracting that of 1 we get the probability in which the buffer is not fully full.Once we calibrate this probability up to a full minute, we can calculate the amount of seconds in which the buffer contains less than 10 packets.In this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "by dividing the arrival rate from the servicing rate and with n=10, we can go on to calculate the blocking probability p_b. by subtracting that from 1 we get the probability in which the buffer is not entirely full. once we scale that probability up to a full minute, we can calculate the amount of seconds in which the buffer holds less than 10 packets. in this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "original_sample_id": "smp0206q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0206q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "By dividing the rate of arrival of the maintenance rate and with n=10, we can continue to calculate the probability of blocking p_b. by subtracting that of 1 we get the probability in which the buffer is not fully full.Once we calibrate this probability up to a full minute, we can calculate the amount of seconds in which the buffer contains less than 10 packets.In this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "by dividing the arrival rate from the servicing rate and with n=10, we can go on to calculate the blocking probability p_b. by subtracting that from 1 we get the probability in which the buffer is not entirely full. once we scale that probability up to a full minute, we can calculate the amount of seconds in which the buffer holds less than 10 packets. in this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "original_sample_id": "smp0206q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0333q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "schnellster weg von jeder node zur quelle:\n\nb -> a\nc -> a\nd -> a\ne -> b -> a\nf -> c -> a\ng -> e -> b -> a\nh -> g -> e -> b -> a\nhops,abuse 1:\n\n(a,b,f )\n(a,c,f )\n(a,d,d) ,weil d es nicht weiterleiten kann. (endstation)\nhops,abuse 2:\n\n(b,e,f)\n(c,f,d) ,weil f es nicht weiterleiten kann. (endstation)\nhops,abuse 3: \n\n(e,g,f)hops,abuse 4:\n\n(g,h,d)  ,weil h es nicht weiterleiten kann. (endstation)\n 7 packete wurden gesendet, davon sind 3 gedropped worden.",
        "answer_feedback": "the reason need to explain why the packet is dropped or not forwarded further. example: (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a. similarly for (c,f,d).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "schnellster weg von jeder node zur quelle:\n\nb -> a\nc -> a\nd -> a\ne -> b -> a\nf -> c -> a\ng -> e -> b -> a\nh -> g -> e -> b -> a\nhop,step 1:\n\n(a,b,f )\n(a,c,f )\n(a,d,d) ,weil d es nicht weiterleiten kann. (endstation)\nhop,step 2:\n\n(b,e,f)\n(c,f,d) ,weil f es nicht weiterleiten kann. (endstation)\nhop,step 3: \n\n(e,g,f)hop,step 4:\n\n(g,h,d)  ,weil h es nicht weiterleiten kann. (endstation)\n 7 packete wurden gesendet, davon sind 3 gedropped worden.",
        "original_sample_id": "smp0333q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0815q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header includes several different fields that are not included in the upp headers, such as: -sequence number: the following from the first data byte of this tcp package, which is used to reorganize the tcp segments, as they can arrive in a different order from the receiver. -recognition number: the following of the following expected tcp-segment segments: the flag field indicates which other parts of the header should be considered. examples are: recognition flag, urgent flag or syn flag (connection establishment) -window: how many bytes can receive the package sender. -option field: the option field can be used to enlarge the header with data that is not included in the tcp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header includes multiple different fields that are not included in the udp headers, such as: -sequence number: the seqno of the first data-byte of this tcp-packet, which is used to reorganize the tcp segments, as they may arrive in a different order at the receiver. -acknowledgment number: the seqno of the next expected tcp-segment -flags: the flag field states which other parts of the header have to be considered. examples are: acknowledgement flag, urgent flag or syn flag (connection establishment) -window: how many bytes the sender of the packet is able to receive. -options field: the options field can be used to extend the header with data that is not included in the tcp header.",
        "original_sample_id": "smp0815q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0911q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "an unveiling in the bridge board check three informations: timestamp (frame arrival time), from which lan the frame came and node, from which the frame came from. an unveiling is created for the first time, when the first frame from specific node comes. after some time the board is scanned periodically to keep the board up2date. if there is no answer from the node (usually after several minutes) using the path from the unveiling, the router uses flooding to locate the node. if there is still no answer, the unveiling is removed from the board.\nwith the information gathered in the board, the router can now decide which operation to apply on the packet. this could, for example, be the decision between forwarding a packet to another segment or to filter it and thus not forwarding it.",
        "answer_feedback": "the response does not mention what is learned from capturing the incoming packet source and lan information in backward learning and what is the benefit of using the bridge table information in packet forwarding.  apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "an entry in the bridge table contains three informations: timestamp (frame arrival time), from which lan the frame came and node, from which the frame came from. an entry is created for the first time, when the first frame from specific node comes. after some time the table is scanned periodically to keep the table up2date. if there is no answer from the node (usually after several minutes) using the path from the entry, the router uses flooding to locate the node. if there is still no answer, the entry is removed from the table.\nwith the information gathered in the table, the router can now decide which operation to apply on the packet. this could, for example, be the decision between forwarding a packet to another segment or to filter it and thus not forwarding it.",
        "original_sample_id": "smp0911q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0937q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "for each station (source address q) the table stores the output line (lan  l), that indicates that q can be reached over l. the table modification works as follows:\nthe nosepiece works in promiscuous fashion, thus it receives the frames from all connected lans and updates its table accordingly. as the entries are timestamped, old ace are removed and destinations which are not in the table are reached by flooding.\nthe nosepiece table is used for an address lookup to forward frames accordingly or to drop a frame if source and destination are both within the same lan (filtering), which provides the benefit of reduced traffic.",
        "answer_feedback": "during backward learning, what is learned and interpreted on receiving a packet from source s over link l is not mentioned. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "for each station (source address q) the table stores the output line (lan  l), that indicates that q can be reached over l. the table modification works as follows:\nthe bridge works in promiscuous mode, thus it receives the frames from all connected lans and updates its table accordingly. as the entries are timestamped, old ones are removed and destinations which are not in the table are reached by flooding.\nthe bridge table is used for an address lookup to forward frames accordingly or to drop a frame if source and destination are both within the same lan (filtering), which provides the benefit of reduced traffic.",
        "original_sample_id": "smp0937q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0235q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "you add up all the prolabiertes of the buffer nation from 0 to 9 (94,91%) . you reproduce this percentage with the time (60 sec). you get the expected time in which there are less than 10 mailboat in the buffer -->57 sec.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you add up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the time (60 sec). you get the expected time in which there are less than 10 packets in the buffer -->57 sec.",
        "original_sample_id": "smp0235q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0235q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "you sum up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the meter (60 sec). you get the await meter in which there are less than 10 packets in the buffer -->57 sec.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you add up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the time (60 sec). you get the expected time in which there are less than 10 packets in the buffer -->57 sec.",
        "original_sample_id": "smp0235q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0213q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p = 9/10 p_10 = ((1-p)p^10)/(1-p^11) ~ 0.05 the probability of having 10 packets in which is 5% which means that for 95 percent of the time the system has less than 10 packages on hold. 60*0.95 = 57 the system must be in a non-complete state for 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "p = 9/10  p_10 = ((1-p)p^10)/(1-p^11) ~ 0.05\nthe probability of having 10 packets in the que is 5% meaning that for 95 percent of the time the system has less thatn 10 packets waiting.\n60*0.95 = 57\nthe system should be in a non full state for 57 seconds.",
        "original_sample_id": "smp0213q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0213q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p = 9/10  p_10 = ((1-p)p^10)/(1-p^11) ~ 0.05\nthe chance of having 10 packets in the que is 5% meaning that for 95 percent of the clip the scheme has less thatn 10 packets waiting.\n60*0.95 = 57\nthe scheme should be in a non full state for 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "p = 9/10  p_10 = ((1-p)p^10)/(1-p^11) ~ 0.05\nthe probability of having 10 packets in the que is 5% meaning that for 95 percent of the time the system has less thatn 10 packets waiting.\n60*0.95 = 57\nthe system should be in a non full state for 57 seconds.",
        "original_sample_id": "smp0213q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0340q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1:\n(a, b, frontwards)\n\n(a, c, frontwards)\n\n(a, d, frontwards)\n\nhop2:\n\n\n(b, e, frontwards)\n\n(c, f, frontwards)\n\nhop3:\n\n(e, g, frontwards)\n\nhop4:\n(g, h, drop) -> packet drib because it only has one neighbour and node h does not frontwards the content",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.5 for reasoning (a,d, drop), (c, f, drop)  ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop1:\n(a, b, forward)\n\n(a, c, forward)\n\n(a, d, forward)\n\nhop2:\n\n\n(b, e, forward)\n\n(c, f, forward)\n\nhop3:\n\n(e, g, forward)\n\nhop4:\n(g, h, drop) -> packet drops because it only has one neighbour and node h does not forward the message",
        "original_sample_id": "smp0340q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0848q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption does not concord in the real world, because, in the real world, networks must deal with bursty dealings, as well as times when there is no or very less dealings, and this change in dealings is dependent on a number of factors. \nfor eg. when using a streaming service, the probability of seeing packets arrive continuously is very high as opposed to downloading a pdf file, and the reaching of the packets is very much dependent on the activity or dealings at previous and future time intervals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of an arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold in the real world, because, in the real world, networks must deal with bursty traffic, as well as times when there is no or very less traffic, and this change in traffic is dependent on a number of factors. \nfor eg. when using a streaming service, the probability of seeing packets arrive continuously is very high as opposed to downloading a pdf file, and the arrival of the packets is very much dependent on the activity or traffic at previous and future time intervals.",
        "original_sample_id": "smp0848q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0156q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "sliding window, because they demand a good throughput and good channel employment. and also they have perfect clocks for polisher.",
        "answer_feedback": "non-related response, the question asks for the encoding types.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "sliding window, because they need a good throughput and good channel utilization. and also they have perfect clocks for buffer.",
        "original_sample_id": "smp0156q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0156q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "sliding windowpane, because they need a good throughput and good channel exercise. and also they have perfect alfilaria for buffer.",
        "answer_feedback": "non-related response, the question asks for the encoding types.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "sliding window, because they need a good throughput and good channel utilization. and also they have perfect clocks for buffer.",
        "original_sample_id": "smp0156q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0223q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the process still changes nations when it is in equilibrium. however, the steady-nation probability pk to find the process in nation k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability catamenia, also called flux, into nation k equals the probability catamenia out of nation k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "answer_feedback": "the response is incorrect because it states a description of the system's equilibrium state. however, the question requirement is to calculate the number of expected seconds where the system has less than 10 packets waiting in the queue.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the process still changes states when it is in equilibrium. however, the steady-state probability pk to find the process in state k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability flow, also called flux, into state k equals the probability flow out of state k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "original_sample_id": "smp0223q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0223q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the process still changes provinces when it is in counterbalance. however, the steady-province chance pk to find the process in province k does not change anymore, thus dpk (t )/dt = 0. \n\nin counterbalance, it follows from dpk (t )/dt = 0 that the chance flow, also called flux, into province k equals the chance flow out of province k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "answer_feedback": "the response is incorrect because it states a description of the system's equilibrium state. however, the question requirement is to calculate the number of expected seconds where the system has less than 10 packets waiting in the queue.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the process still changes states when it is in equilibrium. however, the steady-state probability pk to find the process in state k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability flow, also called flux, into state k equals the probability flow out of state k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "original_sample_id": "smp0223q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0243q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first step: bet the forget chance, i.e. that the system is full. n=10 and rho = 0.9, giving us a forget chance of 0.05. \n\nthen we can bet the chance that the system is not full. for this we bet 1 - forget chance = 0.95. if we multiply this chance by 60 seconds, the system will be in a state with less than 10 packets waiting for 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first step: calculate the blocking probability, i.e. that the system is full. n=10 and rho = 0.9, giving us a blocking probability of 0.05. \n\nthen we can calculate the probability that the system is not full. for this we calculate 1 - blocking probability = 0.95. if we multiply this probability by 60 seconds, the system will be in a state with less than 10 packets waiting for 57 seconds.",
        "original_sample_id": "smp0243q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0243q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first step: calculate the bar chance, i.e. that the system is full. n=10 and rho = 0.9, giving us a bar chance of 0.05. \n\nthen we can calculate the chance that the system is not full. for this we calculate 1 - bar chance = 0.95. if we breed this chance by 60 seconds, the system will be in a state with less than 10 packets waiting for 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first step: calculate the blocking probability, i.e. that the system is full. n=10 and rho = 0.9, giving us a blocking probability of 0.05. \n\nthen we can calculate the probability that the system is not full. for this we calculate 1 - blocking probability = 0.95. if we multiply this probability by 60 seconds, the system will be in a state with less than 10 packets waiting for 57 seconds.",
        "original_sample_id": "smp0243q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0927q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table consists of multiple entries. when a nosepiece receives a skeleton from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new skeleton is received from the same sourcenode.\nif the nosepiece then receives a skeleton from a different lan with the address q, it looks up in the table and finds that q is reachable via l and forwards it to l.\nif the source and address lans of a skeleton are the same, the nosepiece drops the packet and if it has no entry for a address it floods it.\nthis reduces the amount of floodings which are very resource-consuming.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table consists of multiple entries. when a bridge receives a frame from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same sourcenode.\nif the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is reachable via l and forwards it to l.\nif the source and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it floods it.\nthis reduces the amount of floodings which are very resource-consuming.",
        "original_sample_id": "smp0927q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0927q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table consists of multiple inputs. when a bridge receives a frame from the source q in lan l (for the first time) then adds an entry to its table which consists of q, l and a mark of time. this entry indicates that q is accessible via l. the time mark is used to purge old entries and adapt to changes in topology. a mark of time of an entry is updated whenever a new frame of the same sourcenode is received. If the bridge receives a frame from another lan with the destination q, look up on the table and find that q is accessible through l and sends it to l. if the source and the destination lans of a frame are the same, the bridge leaves the package and if it does not have an entry to a destination the inwave. this reduces the number of floods that are very resource consuming.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table consists of multiple entries. when a bridge receives a frame from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same sourcenode.\nif the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is reachable via l and forwards it to l.\nif the source and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it floods it.\nthis reduces the amount of floodings which are very resource-consuming.",
        "original_sample_id": "smp0927q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0927q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table consists of multiple inputs. when a bridge receives a frame from the source q in lan l (for the first time) then adds an entry to its table which consists of q, l and a mark of time. this entry indicates that q is accessible via l. the time mark is used to purge old entries and adapt to changes in topology. a mark of time of an entry is updated whenever a new frame of the same sourcenode is received. If the bridge receives a frame from another lan with the destination q, look up on the table and find that q is accessible through l and sends it to l. if the source and the destination lans of a frame are the same, the bridge leaves the package and if it does not have an entry to a destination the inwave. this reduces the number of floods that are very resource consuming.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table consists of multiple entries. when a bridge receives a frame from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same sourcenode.\nif the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is reachable via l and forwards it to l.\nif the source and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it floods it.\nthis reduces the amount of floodings which are very resource-consuming.",
        "original_sample_id": "smp0927q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0927q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the mesa consists of multiple entries. when a bridge receives a frame from rootage q on lan l (for the first time) then it adds an entry to it’s mesa consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same rootagenode.\nif the bridge then receives a frame from a different lan with the destination q, it looks up in the mesa and finds that q is reachable via l and forwards it to l.\nif the rootage and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it glut it.\nthis reduces the amount of floodings which are very rerootage-consuming.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table consists of multiple entries. when a bridge receives a frame from source q on lan l (for the first time) then it adds an entry to it’s table consisting of q, l and a timestamp. this entry indicates that q is reachable via l. the timestamp is used to purge old entries and adapt to changes in the topology. a timestamp of an entry is updated whenever a new frame is received from the same sourcenode.\nif the bridge then receives a frame from a different lan with the destination q, it looks up in the table and finds that q is reachable via l and forwards it to l.\nif the source and destination lans of a frame are the same, the bridge drops the packet and if it has no entry for a destination it floods it.\nthis reduces the amount of floodings which are very resource-consuming.",
        "original_sample_id": "smp0927q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1484q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the acknowledgment added to the next form has to refer to the received form so that it can be specify to the related datum. otherwise you cannot identify which form is confirmed by your acknowledgment.",
        "answer_feedback": "the response does not identify the duplex connection as the requirement. acknowledgments, whether sent independently or piggybacked, specify which frame is acknowledged, so it is not a  specific requirement for piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the acknowledgment added to the next frame has to refer to the received frame so that it can be assigned to the related data. otherwise you cannot identify which frame is confirmed by your acknowledgment.",
        "original_sample_id": "smp1484q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0852q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not this hypothesis is not supported for the real Internet traffic. real Internet traffic has built in congestion and flow control mechanisms, therefore, if the packages fall due to the overflow of queue buffer at high rate of arrival, the ack messages would not be detected on the sender side. therefore, the transmission speed of the sender will be reduced or reduced to compensate the slow receiver. in this sense, the arrivals in each time interval are not really independent.",
        "answer_feedback": "while the congestion does affect the arrival dependency at a node,  the main cause is how data is sent normally, which is in bursts.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow control mechanisms, therefore if the packets get dropped due to queue buffer overflow from high arrival rate, there would be missing ack messages detected at the sender side. therefore the rate of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "original_sample_id": "smp0852q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0852q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow ascendency mechanisms, therefore if the mailboat get dropped due to queue buffer overflow from high arrival pace, there would be missing ack messages detected at the sender side. therefore the pace of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "answer_feedback": "while the congestion does affect the arrival dependency at a node,  the main cause is how data is sent normally, which is in bursts.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow control mechanisms, therefore if the packets get dropped due to queue buffer overflow from high arrival rate, there would be missing ack messages detected at the sender side. therefore the rate of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "original_sample_id": "smp0852q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1694q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "class to: 0.0.0.0. - 127.255.255.255",
        "answer_feedback": "not all addresses are reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "class a:\n0.0.0.0. - 127.255.255.255",
        "original_sample_id": "smp1694q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0431q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps - advantage: solves the problem in double - disadvantage: you cannot direct the process servers 2. identify the connections individually - advantage: solves the problem in double - disadvantage: endsystems must be able to store this information 3. identify pdus ididially - advantage: high repetition time - disadvantage: increased use of bandwoth and memory",
        "answer_feedback": "no duplicate is not an advantage, it is the usage of the method. apart from this the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0431q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0431q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps\n- reward: solves duplicate job\n- disreward: can't adress process servers\n\n2. identify connections individually\n\n- reward: solves duplicate job\n- disreward: endsystems must be able of storing this information\n\n3. identify pdus idividually\n\n- reward: high reiteration time \n- disreward: higher usage of bandwoth and memory",
        "answer_feedback": "no duplicate is not an advantage, it is the usage of the method. apart from this the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0431q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0431q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps\n- vantage: solves matching problem\n- disvantage: can't adress process servers\n\n2. identify connections individually\n\n- vantage: solves matching problem\n- disvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- vantage: high reiteration time \n- disvantage: higher usage of bandwoth and memory",
        "answer_feedback": "no duplicate is not an advantage, it is the usage of the method. apart from this the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0431q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0431q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary tsaps - advantage: solves the problem in double - disadvantage: you cannot direct the process servers 2. identify the connections individually - advantage: solves the problem in double - disadvantage: endsystems must be able to store this information 3. identify pdus ididially - advantage: high repetition time - disadvantage: increased use of bandwoth and memory",
        "answer_feedback": "no duplicate is not an advantage, it is the usage of the method. apart from this the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83,
        "original_answer": "1. temporary tsaps\n- advantage: solves duplicate problem\n- disadvantage: can't adress process servers\n\n2. identify connections individually\n\n- advantage: solves duplicate problem\n- disadvantage: endsystems must be capable of storing this information\n\n3. identify pdus idividually\n\n- advantage: high reiteration time \n- disadvantage: higher usage of bandwoth and memory",
        "original_sample_id": "smp0431q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp0241q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the answer is 56.952s\n\nρ = 9/10 = 0.9\nthe blocking chance, is also the chance of that the buffer is full, is:\n     p(b) = 0.0508,\nwhich means that in one minute, the chance of that there're exact 10 mailboat is 0.0508\nso the chance of that there're less than 10 mailboat waiting in the queue is 1-0.0508 = 0.9492.\nso, the time that there're less than 10 mailboat irrigate in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the answer is 56.952s\n\nρ = 9/10 = 0.9\nthe blocking probability, is also the probability of that the buffer is full, is:\n     p(b) = 0.0508,\nwhich means that in one minute, the probability of that there're exact 10 packets is 0.0508\nso the probability of that there're less than 10 packets waiting in the queue is 1-0.0508 = 0.9492.\nso, the time that there're less than 10 packets watering in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "original_sample_id": "smp0241q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0241q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "The answer is 56.952s: 9/10 = 0.9 the probability of blocking is also the probability that the buffer is filled, i.e.: p(b) = 0.0508, which means that within one minute, the probability that there are exactly 10 packages is 0.0508, so that the probability that there are less than 10 packages in the queue is 1.0.0508 = 0.9492. So the time that there are less than 10 packages watering in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the answer is 56.952s\n\nρ = 9/10 = 0.9\nthe blocking probability, is also the probability of that the buffer is full, is:\n     p(b) = 0.0508,\nwhich means that in one minute, the probability of that there're exact 10 packets is 0.0508\nso the probability of that there're less than 10 packets waiting in the queue is 1-0.0508 = 0.9492.\nso, the time that there're less than 10 packets watering in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "original_sample_id": "smp0241q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0233q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "We know: 1 tail buffer is 10 9 pkts/s arrive on average → lambda = 9 10 pkts/s served on average → mu = 10 clock for 1 minute after the equilibrium ro = lamb101010101010,1010,1010,1010,101010,1010,101010,1010,101010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,10,1010,10,10,10,10,0,0,1010,10,10,1010,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we know:\n1 queue\nbuffer is 10\n9 pkts/s arrive on average → lambda = 9\n10 pkts/s serviced on average → mu = 10\nwatch for 1 minute after equilibrium\n\nro = lamba / mu = 9/10 = 0,9\nwith the help of the formula on slide 30, we can calculate the probabilities of each buffer size:\np0 = (1-ro)/ (1-ro^(n+1)) = 0,146\npn = ((1-ro)*ro^n)/(1-ro^(n+1))\np1 = 0,131\np2 = 0,118\np3 = 0,106\np4 = 0,096\np5 = 0,086\np6 = 0,077\np7 = 0,070\np8 = 0,063\np9 = 0,056\np10 = 0,051\nsum(p0 - p10) = 1.\n\nlooking for n being smaller than 10. p(x less than 10) = 1- p(x=10) = 1 - 0,051 = 0,949 so 94,9% of the time the time the buffer is smaller than 10. → 60 seconds * 0,949 around 56,94 so around 57 seconds the buffer is smaller than 10 on average.",
        "original_sample_id": "smp0233q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0233q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "we know:\n1 queue\npolisher is 10\n9 pkts/s arrive on average → lambda = 9\n10 pkts/s serviced on average → mu = 10\nwatch for 1 minute after equilibrium\n\nro = lamba / mu = 9/10 = 0,9\nwith the help of the formula on slide 30, we can calculate the probabilities of each polisher size:\np0 = (1-ro)/ (1-ro^(n+1)) = 0,146\npn = ((1-ro)*ro^n)/(1-ro^(n+1))\np1 = 0,131\np2 = 0,118\np3 = 0,106\np4 = 0,096\np5 = 0,086\np6 = 0,077\np7 = 0,070\np8 = 0,063\np9 = 0,056\np10 = 0,051\nsum(p0 - p10) = 1.\n\nlooking for n being smaller than 10. p(x less than 10) = 1- p(x=10) = 1 - 0,051 = 0,949 so 94,9% of the clip the clip the polisher is smaller than 10. → 60 seconds * 0,949 around 56,94 so around 57 seconds the polisher is smaller than 10 on average.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we know:\n1 queue\nbuffer is 10\n9 pkts/s arrive on average → lambda = 9\n10 pkts/s serviced on average → mu = 10\nwatch for 1 minute after equilibrium\n\nro = lamba / mu = 9/10 = 0,9\nwith the help of the formula on slide 30, we can calculate the probabilities of each buffer size:\np0 = (1-ro)/ (1-ro^(n+1)) = 0,146\npn = ((1-ro)*ro^n)/(1-ro^(n+1))\np1 = 0,131\np2 = 0,118\np3 = 0,106\np4 = 0,096\np5 = 0,086\np6 = 0,077\np7 = 0,070\np8 = 0,063\np9 = 0,056\np10 = 0,051\nsum(p0 - p10) = 1.\n\nlooking for n being smaller than 10. p(x less than 10) = 1- p(x=10) = 1 - 0,051 = 0,949 so 94,9% of the time the time the buffer is smaller than 10. → 60 seconds * 0,949 around 56,94 so around 57 seconds the buffer is smaller than 10 on average.",
        "original_sample_id": "smp0233q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1487q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Duplex transmission.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "duplex transmission.",
        "original_sample_id": "smp1487q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0794q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "some spheres the tcp head is offering and the udp head not: 1. acknowledgment number sphere 2. hl/resv/flags sphere 3. advertised window size sphere 4. urgent pointer sphere",
        "answer_feedback": "the response identifies four differences correctly. however, abbreviations, such as hl and resv, should be introduced.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "some fields the tcp header is offering and the udp header not: 1. acknowledgment number field 2. hl/resv/flags field 3. advertised window size field 4. urgent pointer field",
        "original_sample_id": "smp0794q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1516q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "1.first, it must be duplex performance.\n2.the data underframe and the confirmation underframe use the same formatting.",
        "answer_feedback": "both points are correct as the acknowledgment field is contained within the outgoing data frame.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1.first, it must be duplex operation.\n2.the data frame and the confirmation frame use the same format.",
        "original_sample_id": "smp1516q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. purpose of temporarily valid tsaps:\n2. indentify association singly\n3. identify pdus singly:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use of temporarily valid tsaps:\n2. indentify association severally\n3. identify pdus severally:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug02smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. usance of temporarily valid tsaps:\n2. indentify joining singly\n3. identify pdus singly:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. habit of temporarily valid tsaps:\n2. indentify joining separately\n3. identify pdus separately:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1644q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 127.0.0/8 (reimbursement)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8\n127.0.0.0/8 (loopback)",
        "original_sample_id": "smp1644q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1670q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "form a means the following referencees:\n0.0.0.0 - 127.255.255.255\n\nreserved referencees:\nreserved for host:\n0.0.0.0 - 0.255.255.255\n\nreserved for loopback:\n127.0.0.0 - 127.255.255.255\n\nthe first and last reference of every network can't be used, because they are for host and program.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "class a means the following addresses:\n0.0.0.0 - 127.255.255.255\n\nreserved addresses:\nreserved for host:\n0.0.0.0 - 0.255.255.255\n\nreserved for loopback:\n127.0.0.0 - 127.255.255.255\n\nthe first and last address of every network can't be used, because they are for host and broadcast.",
        "original_sample_id": "smp1670q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0364q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops1: (a,b, before)(a,c, before)(a,d, fall) - point dead. neither c nor f use as a unicast path to a. hops 2: (b,e, before)(c,f, fall) - same as for. f is not pursued by e,g or d. hops 3: (e,g, before) hops 4: (g,h, drop) - no outgoing link except for the incoming edge.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop1:\n(a,b, forward)(a,c, forward)(a,d, drop) - dead end. neither c nor f use d as the unicast path to a.\nhop 2:\n(b,e, forward)(c,f, drop) - same as befor. f is not sued by e,g or d.\nhop 3:\n(e, g, forward)\nhop 4:\n(g,h,drop) - no outgoing links except incoming edge.",
        "original_sample_id": "smp0364q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption is the estimable way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion ascendence you can ascendence the congestion and avoid it",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding is the best way, because it has the highest baud rate and so it can keep congestion as small as possible and with congestion control you can control congestion and avoid congestion",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption is the unspoilt way, because it has the highest baud pace and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding is the best way, because it has the highest baud rate and so it can keep congestion as small as possible and with congestion control you can control congestion and avoid congestion",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding is the best way, because it has the highest baud rate and so it can keep congestion as small as possible and with congestion control you can control congestion and avoid congestion",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption is the best mode, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and quash it",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption is the unspoiled way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion ascendence you can ascendence the congestion and avoid it",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption is the best agency, because it has the highest baud pace and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug08smp0187q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding is the best way, because it has the highest baud rate and so it can keep congestion as small as possible and with congestion control you can control congestion and avoid congestion",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding is the best way, because it has the highest baud rate and so you can keep the congestion as small as possible and with congestion control you can control the congestion and avoid it",
        "original_sample_id": "smp0187q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp1003q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "both are transmission routing methods that allow you to extend trees without needing to know the trees that cross it: rpf: a node receives a package. if you reached the usual input link, assume that the package has used the best route so far and forwards it over all the other links. if the package has reached an unusual link, assume that it is a duplicate (because it did not use the optimal route (of the extension tree)) a discard. rpf: works as rpf but does not forward the package over all the outgoing links, but only to those who would send a package to this is to send a package to the source of the original package rpb.",
        "answer_feedback": "the stated purpose is incorrect. it should be to reduce the number of duplicates and unnecessary packets in flooding/broadcasting by inspecting the optimal unicast paths. in rpf, what constitutes the usual link needs to be explained. the explanation of rpb is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6,
        "original_answer": "both are broadcast routing methods that enables spanning trees without the is required to know the spanning trees: rpf: a node receives a packet. if it arrived at the usual entry link, it assumes the packet used the best route until now and forwards it over all other links. if the packet arrived at a unusual link, it assumes it is a duplicate (because it didn't use the optimal path (of the spanning tree)) an discards it. rpf: works like rpf but doesn't forward the packet over all it's outgoing links but only to those which would send a packet to this is to send a packet to the source of the original rpb-packet.",
        "original_sample_id": "smp1003q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1517q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Both parties have to agree to the protocol before and therefore consider the additional access field in a data transmission framework. Both parties have to have a buffer and should be able to reflect on their status. in the data frames are the buffer size, ack and subsequent sent fields - in both directions.",
        "answer_feedback": "the response is correct as a separate field for acknowledgment in the data frame is a must.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both parties have to agree on the protocol before and therefore consider the additional ack-field in a data transmission frame.both parties have to have a buffer and must be able to reflect on its status. \nin the data frames are the fields buffer size, ack and seq sent - in both directions.",
        "original_sample_id": "smp1517q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0388q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n\n(a, b, forth)\n\n(a, c, forth)\n\n(a, d, drop) => d does not forth the package because it is not the next hop on the shortest unicast path to a of any neighbor (mailboat came from a, c transport directly to a, f transport over c)\n\n \n\nhop 2:\n\n(b, e, forth)\n\n(c, f, drop) => f does not forth the package because it is not part of the shortest unicast path to a of any neighbor (mailboat came from c, d transport directly to a, e transport over b, g transport over e)\n\n \n\nhop 3:\n\n(e, g, forth)\n\n \n\nhop 4:\n\n(g, h, drop) => h's only neighbor is g from which it got the mailboat",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n\n(a, b, forward)\n\n(a, c, forward)\n\n(a, d, drop) => d does not forward the package because it is not the next hop on the shortest unicast path to a of any neighbor (packet came from a, c sends directly to a, f sends over c)\n\n \n\nhop 2:\n\n(b, e, forward)\n\n(c, f, drop) => f does not forward the package because it is not part of the shortest unicast path to a of any neighbor (packet came from c, d sends directly to a, e sends over b, g sends over e)\n\n \n\nhop 3:\n\n(e, g, forward)\n\n \n\nhop 4:\n\n(g, h, drop) => h's only neighbor is g from which it got the packet",
        "original_sample_id": "smp0388q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0925q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "initially, the bridgework mesa is empty, therefore, flooding is used to reach all destinations. during the backward learning process, the bridgework remembers the incoming links, from which frames of a source a received. using this information, it incrementally builds up the bridgework mesa. the mesa contains information on which destination can be hand via which connected lan. thus, it can be used in the forward pass to make more intelligent choice on where to forward incoming frames.",
        "answer_feedback": "the response does not mention the benefit of using the bridge table in selective forwarding. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "initially, the bridge table is empty, therefore, flooding is used to reach all destinations. during the backward learning process, the bridge remembers the incoming links, from which frames of a source a received. using this information, it incrementally builds up the bridge table. the table contains information on which destination can be reached via which connected lan. thus, it can be used in the forward pass to make more intelligent choice on where to forward incoming frames.",
        "original_sample_id": "smp0925q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1000q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of rpf and rpb is to reduce redundancy, when broadcasting mailboats, on connection lines, which are not useful to the broadcasting process and try to create a spanning tree (without loops). in inverse path forwarding the sender broadcasts its mailboats to its neighbours with their source node noted. they will rebroadcast the mailboats to their neighbours, only not back to the sender, until the mailboats reached every node. every receiving node has to \"ask itself the question\": has this mailboat arrived at the is entry port over which the mailboats for this station/source are usually also sent? if the answer is yes, it will assume that the received mailboats used the best route until now and they are rebroadcasted on all edges. otherwise the node will assume that the mailboats did not take the best route until now and they will be discarded. inverse path broadcast is a more complex version of rpf. in this scheme the mailboats will also carry information about the taken route. every time a node receives mailboats it will have to \"ask itself\" two doubt. first \"has this mailboat arrived at the is entry over which the mailboats for this source station are usually also sent? if the answer is no, the mailboats will be discarded. otherwise it will \"ask itself\" the next question. \"have the mailboats used the best route until now?\" if the answer is yes the node will send the mailboats onto an edge. this edge lies on the best route from the destination node to the source node. otherwise the mailboats will be discarded.",
        "answer_feedback": "the purpose of rpf and rpb is to reduce redundant packets/duplicates and make use of the spanning tree to realize it. the response is otherwise complete and correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of rpf and rpb is to reduce redundancy, when broadcasting packets, on connection lines, which are not useful to the broadcasting process and try to create a spanning tree (without loops). in reverse path forwarding the sender broadcasts its packets to its neighbours with their source node noted. they will rebroadcast the packets to their neighbours, only not back to the sender, until the packets reached every node. every receiving node has to \"ask itself the question\": has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? if the answer is yes, it will assume that the received packets used the best route until now and they are rebroadcasted on all edges. otherwise the node will assume that the packets did not take the best route until now and they will be discarded. reverse path broadcast is a more complex version of rpf. in this scheme the packets will also carry information about the taken route. every time a node receives packets it will have to \"ask itself\" two questions. first \"has this packet arrived at the is entry over which the packets for this source station are usually also sent? if the answer is no, the packets will be discarded. otherwise it will \"ask itself\" the next question. \"have the packets used the best route until now?\" if the answer is yes the node will send the packets onto an edge. this edge lies on the best route from the destination node to the source node. otherwise the packets will be discarded.",
        "original_sample_id": "smp1000q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1000q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The aim of rpf and rpb is to reduce redundancy, when packets are emitted, on the connecting lines, which are not useful for the emission process and try to create an extension tree (without loops).In reverse path forwarding the sender transmits its packets to its neighbors with its observed source node.They will relay the packets to their neighbors, only not return to the sender, until the packets arrive at each node.Each recipient node has to \"ask itself the question\": has this package arrived at the input port on which the packets for this station/source are usually also sent?If the answer is yes, it will assume that the packets received used the best route so far and that they are relayed at all edges. Otherwise, the node will assume that the packages did not take the best route until now and will be discarded. retransmitted is a more complex version of rpf. in this scheme the packets of the network that otherwise is the source response if a node receives packages will have to \"will\" two questions.",
        "answer_feedback": "the purpose of rpf and rpb is to reduce redundant packets/duplicates and make use of the spanning tree to realize it. the response is otherwise complete and correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of rpf and rpb is to reduce redundancy, when broadcasting packets, on connection lines, which are not useful to the broadcasting process and try to create a spanning tree (without loops). in reverse path forwarding the sender broadcasts its packets to its neighbours with their source node noted. they will rebroadcast the packets to their neighbours, only not back to the sender, until the packets reached every node. every receiving node has to \"ask itself the question\": has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? if the answer is yes, it will assume that the received packets used the best route until now and they are rebroadcasted on all edges. otherwise the node will assume that the packets did not take the best route until now and they will be discarded. reverse path broadcast is a more complex version of rpf. in this scheme the packets will also carry information about the taken route. every time a node receives packets it will have to \"ask itself\" two questions. first \"has this packet arrived at the is entry over which the packets for this source station are usually also sent? if the answer is no, the packets will be discarded. otherwise it will \"ask itself\" the next question. \"have the packets used the best route until now?\" if the answer is yes the node will send the packets onto an edge. this edge lies on the best route from the destination node to the source node. otherwise the packets will be discarded.",
        "original_sample_id": "smp1000q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1680q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0.810.0.0.0/8 100.64.0.0/10127.0.0.0.0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/810.0.0.0/8 100.64.0.0/10127.0.0.0/8",
        "original_sample_id": "smp1680q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0791q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp and tcp have both the port of origin, the destination port and a check sum for the header. udp also has a package length tcp has more information to make the connection completely orderly and totally reliable: sequence number recognize number hl/resv/fags announced again.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp and tcp have both source port, destination port and a checksum for the header.\nudp also has a package length\ntcp has more information to make the connection fully ordered and fully reliable:\nsequence number \nacknowledge number\nhl/resv/fags\nadvertised winred again.",
        "original_sample_id": "smp0791q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0810q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- episode number: tcp needs a connection setup to jibe on a starting episode number, which is then incremented. - reference number: tcp messages contain the episode number of the last acknowledged message. - advertised win: widow size dermines how much unacknowledged data the sender can send - urgent pointer: tcp thus signals that there is important data at a certain position in the data stream which should be read immediately. the field is only read if the urgent flag is also set. - sender port is optional in udp - udp header contains a packet length field",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- sequence number: tcp needs a connection setup to agree on a starting sequence number, which is then incremented. - acknowledgment number: tcp messages contain the sequence number of the last acknowledged message. - advertised win: widow size dermines how much unacknowledged data the sender can send - urgent pointer: tcp thus signals that there is important data at a certain position in the data stream which should be read immediately. the field is only read if the urgent flag is also set. - sender port is optional in udp - udp header contains a packet length field",
        "original_sample_id": "smp0810q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0348q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forrard)\n(a,c,forrard)\n(a,d,forrard)\nhop 2:\n(b,e,forrard)\n(b,c,drop)<=not at the estimable path\n(c,b,drop)<=not at the estimable path\n(c,d,drop)<=not at the estimable path\n(c,e,drop)<=not at the estimable path\n(c,f,forrard)\n(d,c,drop)<=not at the estimable path\n(d,f,drop)<=not at the estimable path\nhop3:\n(e,g,forrard)\n(e,f,drop)<=not at the estimable path\n(f,g,drop)<=not at the estimable path\nhop 4:\n(g,h,forrard)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,forward)\nhop 2:\n(b,e,forward)\n(b,c,drop)<=not at the best route\n(c,b,drop)<=not at the best route\n(c,d,drop)<=not at the best route\n(c,e,drop)<=not at the best route\n(c,f,forward)\n(d,c,drop)<=not at the best route\n(d,f,drop)<=not at the best route\nhop3:\n(e,g,forward)\n(e,f,drop)<=not at the best route\n(f,g,drop)<=not at the best route\nhop 4:\n(g,h,forward)",
        "original_sample_id": "smp0348q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0218q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "One of the most important aspects of these rates that are given is that they are not constant. This means that not because the rate of arrival is lower than the rate of service will not be formed any queue, what we are considering are average and these can vary over time. It is also important to keep in mind that the time we consider is 60 seconds and we want to know how long the state has not been 10. This means that we will contemplate the probability that the state has been 0 to 9 during this period of time and multiply the sum of them by 60. result: 56,940 seconds (approximately 57 seconds)",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "one of the most important aspects of these rates that are given is that they are not constant. this means that not because the arrival rate is smaller than the serving rate no queue will be formed, what we are contemplating are averages and these can vary through the time. \nalso it is important to take into account that the time we are contemplating is 60 seconds and we want to know for how long the state was not 10. this means that we will contemplate the probability that the state was from 0 to 9 during this period of time and will multiply the sum of them by 60.\nresult: 56.940 seconds (approximately 57 seconds)",
        "original_sample_id": "smp0218q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0218q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "one of the most important aspects of these paces that are throw is that they are not constant. this means that not because the arrival pace is smaller than the serving pace no queue will be spring, what we are contemplating are averages and these can vary through the time. \nalso it is important to take into account that the time we are contemplating is 60 seconds and we want to know for how long the state was not 10. this means that we will contemplate the probability that the state was from 0 to 9 during this period of time and will multiply the sum of them by 60.\nresult: 56.940 seconds (approximately 57 seconds)",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "one of the most important aspects of these rates that are given is that they are not constant. this means that not because the arrival rate is smaller than the serving rate no queue will be formed, what we are contemplating are averages and these can vary through the time. \nalso it is important to take into account that the time we are contemplating is 60 seconds and we want to know for how long the state was not 10. this means that we will contemplate the probability that the state was from 0 to 9 during this period of time and will multiply the sum of them by 60.\nresult: 56.940 seconds (approximately 57 seconds)",
        "original_sample_id": "smp0218q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(h,g, forrard)\nhop 2:\n(g,f, forrard), (g,e, forrard)\nhop 3:\n(e,b, forrard), (e,c, forrard), (e,f, drop)<=  because of extra\n(f,c, drop)<= because of extra, (f,d, forrard)\nhop 4:\n(b,c, drop)<= becuase of extra, (b,a, forrard), (c,a drop)<= becuase of extra, (d,a, drop)<= becuase of extra",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug02smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(h,g, forrard)\nhop 2:\n(g,f, forrard), (g,e, forrard)\nhop 3:\n(e,b, forrard), (e,c, forrard), (e,f, drop)<=  because of extra\n(f,c, drop)<= because of extra, (f,d, forrard)\nhop 4:\n(b,c, drop)<= becuase of extra, (b,a, forrard), (c,a drop)<= becuase of extra, (d,a, drop)<= becuase of extra",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug03smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(h,g, forrader)\nhop 2:\n(g,f, forrader), (g,e, forrader)\nhop 3:\n(e,b, forrader), (e,c, forrader), (e,f, drop)<=  because of extra\n(f,c, drop)<= because of extra, (f,d, forrader)\nhop 4:\n(b,c, drop)<= becuase of extra, (b,a, forrader), (c,a drop)<= becuase of extra, (d,a, drop)<= becuase of extra",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug04smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(h,g, forwards)\nhop 2:\n(g,f, forwards), (g,e, forwards)\nhop 3:\n(e,b, forwards), (e,c, forwards), (e,f, drop)<=  because of matching\n(f,c, drop)<= because of matching, (f,d, forwards)\nhop 4:\n(b,c, drop)<= becuase of matching, (b,a, forwards), (c,a drop)<= becuase of matching, (d,a, drop)<= becuase of matching",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug05smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug06smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug07smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(h,g, forrard)\nhop 2:\n(g,f, forrard), (g,e, forrard)\nhop 3:\n(e,b, forrard), (e,c, forrard), (e,f, drop)<=  because of extra\n(f,c, drop)<= because of extra, (f,d, forrard)\nhop 4:\n(b,c, drop)<= becuase of extra, (b,a, forrard), (c,a drop)<= becuase of extra, (d,a, drop)<= becuase of extra",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1647q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0 (network number) 127,255,255,255 (dissemination)",
        "answer_feedback": "missing loopback. and 126.255.255.255 or 98.255.255.255 is broadcast, too, not only 127.255.255.255",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "0.0.0.0 (network number)\n127.255.255.255 (broadcast)",
        "original_sample_id": "smp1647q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0871q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No. In the real world, packet arrivals are rarely independent. It is very likely that the data are divided into several packages that are then sent and received in rapid succession. Moreover, the packages caused by human beings will always share the dependencies of human beings. For example, if the packages are sent because of human action, it is likely that most human beings in an area operate for about the same periods of time. Most get up early, start their work, have a lunch break, finish the work and come home. In this scenario, packet arrivals are not 100% independent, because they are related to the productive hours of a population.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no. in the real world, packet arrivals are rarely independent. it is very likely that data is split into multiple packets that are then sent and received in rapid succession. \n\nfurthermore, packets caused by humans will always share the dependencies of humans. for example if packets are sent because of human action, chances are that most humans in an area operate during roughly the same time frames. the majority will get up early, start their work, have a lunch break, finish work and go home. in this scenario, packet arrivals are not 100% independent, because they correlate with the productive hours of a population.",
        "original_sample_id": "smp0871q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0367q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1: (a, b, before) (a, c, before) (a, d, before) hub 2: (b, c, fall) <= b knows that he is not on the best path of c to a (b, e, before) (c, b, fall) <= c is not on the best path of b (c, e, fall) <= c is not on the best path of e (c, f, before) (c, d, fall) <= c is not on the best path of d (d, c, fall) <= d is not on the best path of c (d, f, fall) <= d is not on the best path of f hub 3: (e, f, fall) <= e is not on the best path of f (e, c, fall) <= e is not on the best path of c (e, g, before) (f, e, fall) <= f is not on the best path of e (f, d, fall) <= g is not on the best path of f (f, d, fall) <= g is not on the best path of c (e, f is not on the best path of f is before",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, drop) <= b knows it is not on c's best path to a\n(b, e, forward)\n(c, b, drop) <= c is not on best path of b\n(c, e, drop) <= c is not on best path of e\n(c, f, forward)\n(c, d, drop) <= c is not on best path of d\n(d, c, drop) <= d is not on best path of c\n(d, f, drop) <= d is not on best path of f\nhop 3:\n(e, f, drop) <= e is not on best path of f\n(e, c, drop) <= e is not on best path of c\n(e, g, forward)\n(f, e, drop) <= f is not on best path of e\n(f, d, drop) <= f is not on best path of d\n(f, g, drop) <= f is not on best path of g\nhop 4:\n(g, h, forward)\n(g, f, drop) <= g is not on best path of f",
        "original_sample_id": "smp0367q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1675q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0  - 10.255.255.255",
        "original_sample_id": "smp1675q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1675q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 - 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0  - 10.255.255.255",
        "original_sample_id": "smp1675q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0884q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because dealings can be dependent on the time or previous arriver. for video streaming, arriver are more probable to occur during the evening than during the morning, and are also dependent on previous arriver (it’s probable for streaming that an arrival follows another arriver, meaning the user continues to stream).",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because traffic can be dependent on the time or previous arrivals. for video streaming, arrivals are more likely to occur during the evening than during the morning, and are also dependent on previous arrivals (it’s likely for streaming that an arrival follows another arrivals, meaning the user continues to stream).",
        "original_sample_id": "smp0884q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0884q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because traffic can be dependent on the time or previous reaching. for picture streaming, reaching are more likely to occur during the evening than during the morning, and are also dependent on previous reaching (it’s likely for streaming that an arrival follows another reaching, meaning the exploiter continues to stream).",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because traffic can be dependent on the time or previous arrivals. for video streaming, arrivals are more likely to occur during the evening than during the morning, and are also dependent on previous arrivals (it’s likely for streaming that an arrival follows another arrivals, meaning the user continues to stream).",
        "original_sample_id": "smp0884q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0886q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption of independent arrivals for each time interval is not maintained for real Internet traffic. if we use streaming as an example for Internet traffic, we will see that arrivals for each time interval are not independent. the video buffer may be on or off for some time, so if your ignition we receive the next video segment and then stops for some time and starts again. so it is not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption of independent arrivals for each time interval δt doesn’t hold for real internet traffic. if we use streaming as an example for internet traffic, we will see that the arrivals for each time interval aren’t independent. the video buffer can be on or off for some time, so if its on we receive the next video segment and then it stops for some time and starts over again. so its not independent.",
        "original_sample_id": "smp0886q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0715q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem with the dqdb is that it miss blondness because every station does not receive the same entropy. this means that the blondness was the biggest issue.",
        "answer_feedback": "the response is partially correct because there is lack of fairness based on location rather than lack of information as stated above.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the main problem with the dqdb is that it lacks fairness because every station does not receive the same information. this means that the fairness was the biggest issue.",
        "original_sample_id": "smp0715q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug01smp0715q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem with the dqdb is that it lacks fairness because every post does not receive the same information. this mean that the fairness was the biggest progeny.",
        "answer_feedback": "the response is partially correct because there is lack of fairness based on location rather than lack of information as stated above.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the main problem with the dqdb is that it lacks fairness because every station does not receive the same information. this means that the fairness was the biggest issue.",
        "original_sample_id": "smp0715q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug02smp0715q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the principal problem with the dqdb is that it lacks paleness because every station does not incur the same information. this means that the paleness was the biggest issue.",
        "answer_feedback": "the response is partially correct because there is lack of fairness based on location rather than lack of information as stated above.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the main problem with the dqdb is that it lacks fairness because every station does not receive the same information. this means that the fairness was the biggest issue.",
        "original_sample_id": "smp0715q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug03smp0715q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem with the dqdb is that it lacks fairness because every post does not receive the same information. this intend that the fairness was the giving issue.",
        "answer_feedback": "the response is partially correct because there is lack of fairness based on location rather than lack of information as stated above.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the main problem with the dqdb is that it lacks fairness because every station does not receive the same information. this means that the fairness was the biggest issue.",
        "original_sample_id": "smp0715q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug04smp0715q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The main problem with dqdb is that it lacks justice because each station does not receive the same information. This means that equity was the biggest problem.",
        "answer_feedback": "the response is partially correct because there is lack of fairness based on location rather than lack of information as stated above.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the main problem with the dqdb is that it lacks fairness because every station does not receive the same information. this means that the fairness was the biggest issue.",
        "original_sample_id": "smp0715q011",
        "is_augmented": "true",
        "question_id": "q011"
    },
    {
        "id": "aug00smp1083q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees avoid loops in the subnets which make them pretty useful for multicast, as the sweep tree already mitigates any loops in the multicast forwarding. to work with link state routing, the link state packets have to be broadcasted to all other knob to be able to cipher a sweep tree on each node separately. the distance information are updated periodically with the distances to the neighbors by the other is.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast, but the same reasoning also holds for broadcast. the response only describes the classic link-state algorithm without mentioning any details on how the packet is expanded with multicast group information and how it is used to construct a  multicast spanning tree by each node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees avoid loops in the subnets which make them pretty useful for multicast, as the spanning tree already mitigates any loops in the multicast forwarding. to work with link state routing, the link state packets have to be broadcasted to all other nodes to be able to calculate a spanning tree on each node separately. the distance information are updated periodically with the distances to the neighbors by the other is.",
        "original_sample_id": "smp1083q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0801q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "source larboard in udp optional, in tcp necessary no acknowledgement bit in udp header no packet length field in tcp header no sequence bit in udp header",
        "answer_feedback": "the response states four differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "source port in udp optional, in tcp necessary no acknowledgement number in udp header no packet length field in tcp header no sequence number in udp header",
        "original_sample_id": "smp0801q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1495q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "1.an interlocal concord between agencies must be signalise and filed with the county auditor or posted online.\n2.the original contracting agency has complied with all requirements and posts the collection online.\n3.the vendor agrees to the arrangement through the initial collection.",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking as it is out of topic and context.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1.an interlocal agreement between agencies must be signed and filed with the county auditor or posted online.\n2.the original contracting agency has complied with all requirements and posts the solicitation online.\n3.the vendor agrees to the arrangement through the initial solicitation.",
        "original_sample_id": "smp1495q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0783q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "different from udp, tcp also includes the following headers: recognition issue sequence issue urgent cursor advertised window",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "different from udp, tcp also includes the following headers: acknowledgement number sequence number urgent pointer advertised window",
        "original_sample_id": "smp0783q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0126q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the use of differential sleeveter encoding (dme) would be applicable in this situation. it has a good auto-clock function that allows a good way to identify bits. Moreover, it has a low sensitivity to noise because dme only records the polarity of signals. it is great when there is a lot of traffic on a link.",
        "answer_feedback": "incorrect response as we already have perfect clock manchester is not required. secondly, binary encoding provides better bandwidth utilization.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to identify bits. furthermore it has a low susceptibility to noise because dme only records the polarity of signals. this is great when there is a lot of traffic on a link.",
        "original_sample_id": "smp0126q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0126q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to key bits. furthermore it has a low susceptibility to noise because dme only memorialise the polarity of signals. this is great when there is a lot of traffic on a connexion.",
        "answer_feedback": "incorrect response as we already have perfect clock manchester is not required. secondly, binary encoding provides better bandwidth utilization.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to identify bits. furthermore it has a low susceptibility to noise because dme only records the polarity of signals. this is great when there is a lot of traffic on a link.",
        "original_sample_id": "smp0126q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0906q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent bridge contains for a known destination the next jump indicating which network we have to go to then to reach our destination. initially this information is obtained using floods. in the next learning process the bridge table remembers, which destinations can be reached on which lans by analyzing the directions of origin of incoming packages. this has the advantage that the network is not flooded and congested by sending a frame in all directions, as it is sent only through a path.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge contains for a known destination the next hop telling which network we need to go to next in order to reach our destination. initially this information is gained using flooding. in the following learning process the bridge table remembers, which destinations can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the network is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "original_sample_id": "smp0906q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug01smp0906q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a gossamer bridge contains for a recognize destination the next hop telling which network we take to go to next in order to reach our destination. initially this information is gained using flooding. in the following learning process the bridge table remembers, which destinations can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the network is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge contains for a known destination the next hop telling which network we need to go to next in order to reach our destination. initially this information is gained using flooding. in the following learning process the bridge table remembers, which destinations can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the network is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "original_sample_id": "smp0906q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug02smp0906q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent bridge contains for a known terminus the next hop telling which meshwork we need to go to next in order to reach our terminus. initially this information is gained using flooding. in the following eruditeness process the bridge table remembers, which terminuss can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the meshwork is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge contains for a known destination the next hop telling which network we need to go to next in order to reach our destination. initially this information is gained using flooding. in the following learning process the bridge table remembers, which destinations can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the network is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "original_sample_id": "smp0906q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug03smp0906q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table of a transparent bridge contains for a known destination the next jump indicating which network we have to go to then to reach our destination. initially this information is obtained using floods. in the next learning process the bridge table remembers, which destinations can be reached on which lans by analyzing the directions of origin of incoming packages. this has the advantage that the network is not flooded and congested by sending a frame in all directions, as it is sent only through a path.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the table of a transparent bridge contains for a known destination the next hop telling which network we need to go to next in order to reach our destination. initially this information is gained using flooding. in the following learning process the bridge table remembers, which destinations can be reached over which lans by analyzing the source addresses of incoming packets. this has the advantage that the network is not flooded and congested when sending a frame in all directions as it is sent only over one path.",
        "original_sample_id": "smp0906q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1678q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "100.0 10255.255 100.64.0.0 100.127.255.255.255 127.0.0.0 127.255.255 127.0.0.0 127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 - 0.255.255.255\n10.0.0.0 - 10.255.255.255\n100.64.0.0 - 100.127.255.255\n127.0.0.0 - 127.255.255.255",
        "original_sample_id": "smp1678q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0393q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\nfrom a: (a, b, forrard) (a, c, forrard) (a, d, forrard)\n\nhop 2:\nfrom b: (b, c, dip)  (b, e, forrard) (b, a, dip) \nfrom c:   (c, d, dip) (c, f, forrard) (c, b, dip) (c, e, dip) \nfrom d:   (d, a, dip) (d, c, dip)  (d, f, dip)\n\nhop 3:\nfrom e:  e, g, forrard) (e, c, dip) (e, b, dip)   (e, f, dip)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\nfrom a: (a, b, forward) (a, c, forward) (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop)  (b, e, forward) (b, a, drop) \nfrom c:   (c, d, drop) (c, f, forward) (c, b, drop) (c, e, drop) \nfrom d:   (d, a, drop) (d, c, drop)  (d, f, drop)\n\nhop 3:\nfrom e:  e, g, forward) (e, c, drop) (e, b, drop)   (e, f, drop)",
        "original_sample_id": "smp0393q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0874q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "In real Internet traffic, package arrivals occur in bursts (or batches), batch times are independent and distributed exponentially, and batch sizes are random. package arrivals are not independent and there is a high probability of receiving the following packages after receiving one. for example, in torrent applications for sharing files or web conferences, the packets received must be related to the previous one once.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, it does not hold. in real internet traffic, packet arrivals happen in bursts (or batches), the inter batch times are independent and exponentially distributed, and the batch sizes are random. the arriving packets are not independent and there is a high chance of receiving the following packets after receiving one. for instance, in torrent applications for file-sharing or web conferencing, the received packets should be related to the previous once.",
        "original_sample_id": "smp0874q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0354q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1: (a,b,forward) (a,c,forward) (a,d,forward) hop2: (b,c,drop) heating not located on the unicast path of c a (b,e,forward) (c,b,drop) not located on the unicast path of b a (c,e,drop) not located on the unicast path of c a (d,f,drop) not located on the unicast path of f to a hop3: (e,c,drop) < = not located on the unicast path of c to a (d,f,drop) < = not located on the unicast path of f to a hop3: (e,c,drop) < = not located on the unicast path of c to a (e,f,drop) to a (e,f,no located on the unicast path of f to a hop3: (e,c,drop)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop1:\n(a,b,forward)\n(a,c,forward)\n(a,d,forward)\nhop2:\n(b,c,drop) <= not located on the unicast path from c to a\n(b,e,forward)\n(c,b,drop) <= not located on the unicast path from b to a\n(c,e,drop) <= not located on the unicast path from e to a\n(c,f,forward)\n(c,d,drop) <= not located on the unicast path from d to a\n(d,c,drop) <= not located on the unicast path from c to a\n(d,f,drop) <= not located on the unicast path from f to a\nhop3:\n(e,c,drop) <= not located on the unicast path from c to a\n(e,f,drop) <= not located on the unicast path from f to a\n(e,g,forward)\n(f,d,drop) <= not located on the unicast path from d to a\n(f,e,drop) <= not located on the unicast path from e to a\n(f,g,drop) <= not located on the unicast path from g to a\nhop4:\n(g,f,drop) <= not located on the unicast path from f to a\n(g,h,forward)",
        "original_sample_id": "smp0354q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0335q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forrard)\n(a, c, forrard)\n(a, d, forrard)\nhop 2:\n(b, e, forrard)\n(c, f, forrard)\nhop 3:\n(e, g, forrard)\n(g, h, forrard)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, f, forward)\nhop 3:\n(e, g, forward)\n(g, h, forward)",
        "original_sample_id": "smp0335q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0329q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1:\n(a, b, forrard)\n(a, c, forrard)\n(a,d, pearl) <= d is not located at unicast itinerary of f or a\nhop 2:\n(b, e, forrard)\n(c, f, pearl) <= f not located at unicast itinerary of g to a\nhop 3:\n(e, g, forrard)\nhop 4:\n(g, h, pearl) <= no outgoing edges except the incoming one",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop1:\n(a, b, forward)\n(a, c, forward)\n(a,d, drop) <= d is not located at unicast path of f or a\nhop 2:\n(b, e, forward)\n(c, f, drop) <= f not located at unicast path of g to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= no outgoing edges except the incoming one",
        "original_sample_id": "smp0329q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "succession number \nacknowledgment number (ack. no.)   \nhl/resv/flag \npressing pointer",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number recognition number (pack no) hl/resv/emergency pointer flags",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug02smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence routine \nacknowledgement routine (ack. no.)   \nhl/resv/pin \nurgent pointer",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug03smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number recognition number (pack no) hl/resv/emergency pointer flags",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1041q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "with reverse path forwarding, grommet are avoided. each sender has its own spanning tree, but the is doesnt need to know all. while sending, ,stations pass the package to the particular subnets. in  rpf, package see a reachable list of stations when arriving at a station, and are eventually transmitted to all substation. with reverse path broadcast, packet paths are sent over the usually used path if they arrived via the most used path, else the are sent via a selected edge.",
        "answer_feedback": "the purpose is partially correct as it is only referring to rpf and does not explain how loops avoid duplicates forwarding during broadcasting. in rpf, there is no mention or description of the optimal path and how unicast information is used to derive that. the explanation of rpb is self-conflicting as it states that if it is not sent over the best path, it will be sent over the selected edge which is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.1,
        "original_answer": "with reverse path forwarding, loops are avoided. each sender has its own spanning tree, but the is doesnt need to know all. while sending, ,stations pass the packets to the particular subnets. in  rpf, packets see a reachable list of stations when arriving at a station, and are eventually transmitted to all substations. with reverse path broadcast, packet paths are sent over the usually used path if they arrived via the most used path, else the are sent via a selected edge.",
        "original_sample_id": "smp1041q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1095q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a sweep tree has only one connection to every node of the network. if it is used for broadcasting, no unnecessary extra are needed since every duplicate reaches a destination node. this means unlike flooding under any portion only on packet arrives at each node. if you have a sweep tree containing all nodes of a multicast, the same works for multicasting.   link state routing usually uses flooding to find the shortest path to a certain node in this case you use flooding to find a sweep tree by only returning paths to nodes which have not been found yet.",
        "answer_feedback": "the modification description of the link-state algorithm to construct a  multicast spanning tree is not correct as the is nodes are not aware of all multicast group members. this information needs to be shared along with other link-state information. so the spanning tree constructed out of only the classic link-state algorithm is only useful for unicasting, not multi-/broadcast.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a spanning tree has only one connection to every node of the network. if it is used for broadcasting, no unnecessary duplicates are needed since every duplicate reaches a destination node. this means unlike flooding under any circumstances only on packet arrives at each node. if you have a spanning tree containing all nodes of a multicast, the same works for multicasting.   link state routing usually uses flooding to find the shortest path to a certain node in this case you use flooding to find a spanning tree by only returning paths to nodes which have not been found yet.",
        "original_sample_id": "smp1095q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1028q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "According to wikipedia: \"reverse-path redirecting (rpf) is a technique used in modern routers in order to ensure the loopless routing of multicast packets in multicast routing and to help prevent the ippoofing address in unicast routing\" → meaning the routing of packets on all paths except that from which it came. reverse path broadcast improves on this method with the observation and recording of unicast routes between the different nodes while determining which routes will not work from the routes that have worked.",
        "answer_feedback": "the response answers the purpose of rpf only which should ideally also include broadcast. the explanation of rpf is and lacks a description of when packets are forwarded and when discarded. the rpb explanation is partially correct but does not start which outgoing link is selected and how.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.3,
        "original_answer": "according to wikipedia: \"reverse-path forwarding (rpf) is a technique used in modern routers for the purposes of ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent ip address spoofing in unicast routing\" → meaning forwarding packets along all the paths except the one from which it came. reverse path broadcast improves upon this method with observation and recording the unicast routes between different nodes while determining which routes will not work from the routes which have worked.",
        "original_sample_id": "smp1028q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0245q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the following information are given (written in kandall notation):\na - m ( with lambda = 9)\nb - m ( with my = 10 )\nc - 1\nd - 10\nthis means we have a finite pilot case - m/m/1/n with \nn = 10, rho = 0,9\nthe blocking probability p_b is: 0.0508 \n(cipher using the formula on coast 31.)\nthis means that at any given moment the chance that the pilot is full is equal to 5,08%. therefore the chance that the pilot is not full is equal to: 1-0.0508 = 0.9492 or 94.92%. therefore, one can expect that in a time period of 60s the system will be  in a state with less than 10 packets in the waiting queue for 56.952 seconds (see calculation below).\n60s*0.9492=56.952s",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the following information are given (written in kandall notation):\na - m ( with lambda = 9)\nb - m ( with my = 10 )\nc - 1\nd - 10\nthis means we have a finite buffer case - m/m/1/n with \nn = 10, rho = 0,9\nthe blocking probability p_b is: 0.0508 \n(calculated using the formula on slide 31.)\nthis means that at any given moment the chance that the buffer is full is equal to 5,08%. therefore the chance that the buffer is not full is equal to: 1-0.0508 = 0.9492 or 94.92%. therefore, one can expect that in a time period of 60s the system will be  in a state with less than 10 packets in the waiting queue for 56.952 seconds (see calculation below).\n60s*0.9492=56.952s",
        "original_sample_id": "smp0245q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0245q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the following entropy are given (written in kandall notation):\na - m ( with lambda = 9)\nb - m ( with my = 10 )\nc - 1\nd - 10\nthis means we have a finite pilot case - m/m/1/n with \nn = 10, rho = 0,9\nthe blocking probability p_b is: 0.0508 \n(calculated using the formula on slide 31.)\nthis means that at any given moment the chance that the pilot is full is equal to 5,08%. therefore the chance that the pilot is not full is equal to: 1-0.0508 = 0.9492 or 94.92%. therefore, one can expect that in a time period of 60s the system will be  in a state with less than 10 package in the waiting queue for 56.952 seconds (see calculation below).\n60s*0.9492=56.952s",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the following information are given (written in kandall notation):\na - m ( with lambda = 9)\nb - m ( with my = 10 )\nc - 1\nd - 10\nthis means we have a finite buffer case - m/m/1/n with \nn = 10, rho = 0,9\nthe blocking probability p_b is: 0.0508 \n(calculated using the formula on slide 31.)\nthis means that at any given moment the chance that the buffer is full is equal to 5,08%. therefore the chance that the buffer is not full is equal to: 1-0.0508 = 0.9492 or 94.92%. therefore, one can expect that in a time period of 60s the system will be  in a state with less than 10 packets in the waiting queue for 56.952 seconds (see calculation below).\n60s*0.9492=56.952s",
        "original_sample_id": "smp0245q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1110q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "it does not contain cycles and is the minimal tree that connects all nodes. so it is the most efficient way to potentially reach all systems in the network. in the sweep tree modification of contact state routing, each intermediate system uses the information from its neighbour to locally construct a multicast tree. this tree is eventually the same sweep tree for each node.",
        "answer_feedback": "the response correctly explains the desirable property of a spanning tree. the description of modifying the link-state algorithm is not complete as there is no mention of how this information is shared by expanding the link-state packet with multicast information of the sender. also, the multicast tree is the same for all the same multicast group nodes.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it does not contain cycles and is the minimal tree that connects all nodes. so it is the most efficient way to potentially reach all systems in the network. in the spanning tree modification of link state routing, each intermediate system uses the information from its neighbors to locally construct a multicast tree. this tree is eventually the same spanning tree for each node.",
        "original_sample_id": "smp1110q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there are certain requirements that needs to be met as:\n\nack is beam by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored shape at receiver are the unacknowledged shape not beam to sender and max turn is the receivers window size.\nand the stored shape at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nshape might contain implicit acks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There are certain requirements that must be met as: ack is sent by the receiver if the frame is identified as correct and is correctly transmitted to the network layer. also frames stored in the receiver are unrecognized frames not sent to the sender and the maximum number is the size of the receiver window. and frames stored in the sender are not yet recognized by the receiver. expected order if the window size is 1 then the sequence must always be correct, or if the window size is n then the size is limited by the size of the window. frames may contain implicit jacks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there are certain prerequisite that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored inning at receiver are the unacknowledged inning not sent to sender and max number is the receivers window sizing.\nand the stored inning at the sender are not yet acknowledged by receiver.\n\nexpected order if the window sizing is 1 then the sequence should always be correct, or if window sizing is n then sizing is limited by window sizing.\n\ninning might contain implicit acks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There are certain requirements that must be met as: ack is sent by the receiver if the frame is identified as correct and is correctly transmitted to the network layer. also frames stored in the receiver are unrecognized frames not sent to the sender and the maximum number is the size of the receiver window. and frames stored in the sender are not yet recognized by the receiver. expected order if the window size is 1 then the sequence must always be correct, or if the window size is n then the size is limited by the size of the window. frames may contain implicit jacks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the web layer.\nalso the stored chassis at receiver are the unacknowledged chassis not sent to sender and max number is the receivers window size.\nand the stored chassis at the sender are not yet acknowledged by receiver.\n\nexpected decree if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nchassis might contain implicit acks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1081q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link province routing can be modified by expanding the contained entropy of the periodically send link province packets with entropy on multicast groups. because these link province packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete province entropy. based on the entropy about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link state routing can be modified by expanding the contained information of the periodically send link state packets with information on multicast groups. because these link state packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete state information. based on the information about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "original_sample_id": "smp1081q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1081q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the extension tree is a subset of subredes including all routers without loops. this leads to a generation of a minimum number of copies of packets. the routing of the link state can be modified by extending the information contained in the link status packets to be sent periodically with information about multicast groups. because these link status packages are transmitted to all others is, each can be calculated a multicast tree from the state information now available locally and complete. based on the information about the multicast tree, the outgoing lines in which the packages have to be relayed are determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link state routing can be modified by expanding the contained information of the periodically send link state packets with information on multicast groups. because these link state packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete state information. based on the information about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "original_sample_id": "smp1081q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1669q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "2.147.483.648",
        "answer_feedback": "what do you mean?",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0,
        "original_answer": "2,147,483,648",
        "original_sample_id": "smp1669q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1537q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "-packs or naks and data are not sent separately. ack or nak is attached to the next data frame and then sent with data together on the other side. -the data link layer of a station must get a new package of the top layer before the end of the wait time interval. then theack or nak is copied into the data frame and sent together. otherwise, the data link layer only sends ack or nak frame.",
        "answer_feedback": "the response answers no parts of the question correctly. the response contains only the description of what happens in piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "-acks or naks and data are not sent separately. ack or nak is attached to the next data frame and then sent with data together to the other side.\n\n-the data link layer of one station must get a new packet from the upper layer by the end of the timeout interval. then the ack or nak is piggybacked on the data frame and sent together. otherwise, the data link layer sends only ack or nak frame.",
        "original_sample_id": "smp1537q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0919q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains entries with a direction, a lan and a time mark. the bridge receives a frame in any of its lans and creates a corresponding entry. the table is scanned periodically to see changes in topology and the old entries are purged if no update has occurred for some time (usually several minutes).",
        "answer_feedback": "the response only states the information contained in the bridge table correctly. the response does not mention how this entry is used in backward learning and for forwarding packets selectively. no benefit is stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the table contains entries with an address, a lan and a timestamp. the bridge receives a frame on any of its lans and creates an entry correspondingly. the table is scanned periodically to see changes in topology and old entries are purged if no update happened for some time (usually several minutes).",
        "original_sample_id": "smp0919q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1080q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The properties of the tree extension is subset of subset including any router without loop and to provide link redundancy while at the same time avoiding undesirable loops avoiding transmission storms keeping the global load at a low level to modify the link status routing to build an extension tree for multicasting, all is to send link status packets periodically per transmission to all others containing information such as the distance to neighbors, expanded by information about multicast groups. then each one is calculated a multicast tree from the now locally available and complete status information. based on the information about the multicast tree, is to determine the outgoing lines and on which the packages have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast except that it does not provide link redundancy. on the contrary, the spanning-tree algorithm blocks forwarding on redundant links by setting up one preferred link between nodes. the description of modification related to the link state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the properties of spanning tree is subset of subset including all router with no loop and to provide link redundancy while simultaneously preventing undesirable loops prevent broadcast storms maintain the overall load at a low level   to modify link state routing to construct a spanning tree for multicasting, all is send link state packets periodically by broadcast to all the others containing information like distance to neighbors, expanded by information on multicast groups. then each is calculates a multicast tree from the now locally available and complete state information. based on the information about the multicast tree, is determines the outgoing lines and on which packets have to be transmitted.",
        "original_sample_id": "smp1080q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0909q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges receive all the frames of all the connected lan, and keeps the table for the packet flowing from the station to lan. receive any frame in your lan so you know how you can get to a source with the source direction of lan frames. check if the source and the destination lans are identical, then the packages fall or redirect to the lan and if it is unknown then flood. also use the flood when the system is silent for several time. offer control over the flow of data.",
        "answer_feedback": "the response does not mention the benefit of selective forwarding derived from using the bridging table. also note that if lans of the source and the destination are identical, the packet is dropped \"else\" it is rerouted. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the transparent bridges receive all the frames of all connected lan, and keeps the table for packet flowing from station to lan.\nit receives any frames on its lan so it knows how a source can be reached with the source address from lan frames.\nit checks if the source and the destination lans are identical then the packets are dropped or rerouted to the lan and if unknown then flooded.\nalso flooding is used when system is quiet for several time.\noffers the control over the data flow.",
        "original_sample_id": "smp0909q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0355q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, cliff) not the inadequate path from a-c (not the best route)\n(b, e, forward)\n(c, b, cliff) not the inadequate path from a-b (not the best route)\n(c, e, cliff) not the inadequate path from a-e (not the best route)\n(c, f, forward)\n(c, d, cliff) not the inadequate path from a-d (not the best route)\n(d, c, cliff) not the inadequate path from a-c (not the best route)\n(d, f, cliff) not the inadequate path from a-f (not the best route)\nhop 3:\n(e, c, cliff) not the inadequate path from a-c (not the best route)\n(e, f, cliff) not the inadequate path from a-f (not the best route)\n(e, g, forward)\n(f, d, cliff) not the inadequate path from a-d (not the best route)\n(f, e, cliff) not the inadequate path from a-e (not the best route)\n(f, g, cliff) not the inadequate path from a-g (not the best route)\nhop 4:\n(g, h, forward)",
        "answer_feedback": "the flow appears more akin to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, drop) not the shortest path from a-c (not the best route)\n(b, e, forward)\n(c, b, drop) not the shortest path from a-b (not the best route)\n(c, e, drop) not the shortest path from a-e (not the best route)\n(c, f, forward)\n(c, d, drop) not the shortest path from a-d (not the best route)\n(d, c, drop) not the shortest path from a-c (not the best route)\n(d, f, drop) not the shortest path from a-f (not the best route)\nhop 3:\n(e, c, drop) not the shortest path from a-c (not the best route)\n(e, f, drop) not the shortest path from a-f (not the best route)\n(e, g, forward)\n(f, d, drop) not the shortest path from a-d (not the best route)\n(f, e, drop) not the shortest path from a-e (not the best route)\n(f, g, drop) not the shortest path from a-g (not the best route)\nhop 4:\n(g, h, forward)",
        "original_sample_id": "smp0355q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1033q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward path forwarding and rearward path broadcast prevent loops in networks. every router knows all road to the other nodes but blocks all of them besides the shortest. if a packet now arrives at an intermediate system, it will be checked if the packet has used the shortest path so far by comparing the incoming direction with the usual direction packets with the same sender come from. in case it is the same direction it will be forwarded over every other edge besides the one where it has arrived. if it has arrived from another direction the packet will be discarded since it is most likely a duplicate. rearward path broadcast uses rearward path forwarding in an algorithm to send a packet to everyone with less duplicates than deluge.",
        "answer_feedback": "the purpose of both is to avoid forwarding of broadcast packets in loops/ duplicates like stated in the rpb explanation, not prevent loops in networks as stated in the first sentence. the description of the rpb algorithm is incorrect. rpb works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree. in rpf, if it followed the same route as the outgoing packet from the is is the correct explanation instead of stating the same direction.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.4,
        "original_answer": "reverse path forwarding and reverse path broadcast prevent loops in networks. every router knows all routes to the other nodes but blocks all of them besides the shortest. if a packet now arrives at an intermediate system, it will be checked if the packet has used the shortest path so far by comparing the incoming direction with the usual direction packets with the same sender come from. in case it is the same direction it will be forwarded over every other edge besides the one where it has arrived. if it has arrived from another direction the packet will be discarded since it is most likely a duplicate. reverse path broadcast uses reverse path forwarding in an algorithm to send a packet to everyone with less duplicates than flooding.",
        "original_sample_id": "smp1033q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0385q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forrard)\n(a, c, forrard)\n(a, d, forrard)\n\nhop 2:\nfrom b: \n(b, e, forrard)\n\nfrom c: \n(c, e, drop) <= e jazz that isnt receiving unicast mailboat via c , \n(c, f, forrard)\n\nfrom d: \n(d, f, drop) <= f jazz that isnt receiving unicast mailboat via d \n\nhop 3:\nfrom e: \n(e, g, forrard)  \n\nfrom f: \n(f, g, drop) <= g jazz that isnt receiving unicast mailboat via f\n\nhop 4:\nfrom g: \n(g, h, drop) <=  h jazz that isnt receiving unicast mailboat via g\n\n\nhint: mailboat which aren't considered to be forrarded rpb are left out explicitly.",
        "answer_feedback": "(a,d, drop) and subsequent flow will change accordingly. also (c, f, drop).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\nfrom b: \n(b, e, forward)\n\nfrom c: \n(c, e, drop) <= e knows that isnt receiving unicast packets via c , \n(c, f, forward)\n\nfrom d: \n(d, f, drop) <= f knows that isnt receiving unicast packets via d \n\nhop 3:\nfrom e: \n(e, g, forward)  \n\nfrom f: \n(f, g, drop) <= g knows that isnt receiving unicast packets via f\n\nhop 4:\nfrom g: \n(g, h, drop) <=  h knows that isnt receiving unicast packets via g\n\n\nhint: packets which aren't considered to be forwarded rpb are left out explicitly.",
        "original_sample_id": "smp0385q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0839q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no since arrivals are not always independent. there are a lot of services, which send packages depending on when the last one arrived and was hacked.",
        "answer_feedback": "the response is partially correct because it is true that the assumption doesn’t hold for real internet traffic. however, the stated explanation is incorrect because the arrival at a node is independent of whether a packet is acknowledged or not.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "no since the arrivals are not always independent. there are lots of services, that send the packets dependent on when the last one arrived and was acked.",
        "original_sample_id": "smp0839q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0839q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no since arrivals are not always independent. there are a lot of services, which send packages depending on when the last one arrived and was hacked.",
        "answer_feedback": "the response is partially correct because it is true that the assumption doesn’t hold for real internet traffic. however, the stated explanation is incorrect because the arrival at a node is independent of whether a packet is acknowledged or not.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "no since the arrivals are not always independent. there are lots of services, that send the packets dependent on when the last one arrived and was acked.",
        "original_sample_id": "smp0839q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0939q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information: lan outputs/out-line. and receives each frame of each connected lan. it receives all images or all connected lan's. the bridge contains the images with a source address and the lan from where they come from. this information is stored as table entries, with a time stamping (arrical time of the image). once an image is received, the time stamping of an entry receives an update. this way, the system and the network adapt to changes in topology. after a period, the table gets a scan and the old entries are deleted. the table is used for the decision procedure. if the source and the destination are identical, it is not necessary to send a frame, it is abandoned. if the source and the destination are different, the frame is resented and rerouted to the Lan destination (given by the table). if the destination is unknown in the table, the flood will be applied to the network.",
        "answer_feedback": "the response does not mention how a packet q received over lan l is interpreted as “q can be reached over l”. also, the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "table holds the information: lan outputs/out-line. and receives every frame of each connected lan.\n\nit receives all frames o all lan's connected. the bridge contains frames with a source address and the lan where it comes from.\nthese informations are stored as table entries, with a timestamp (frame arrical time).\nonce a frame is received the timestamp of an entry gets an update.in that way the system and network adapts to changes in topology.\nafter a period the table get a scan and old entries are deleted. \n\nthe table is used for decision procedure. if source and destination lan's are indentical, there is no need to send a frame, it is dropped.\nif the source and destination lan's differ, the frame is resent and rerouted to the destination lan (given by the table).\nif the destination is unknown in the table, flooding will be applied to the network. (flooding means that every packet is sent through all the outgoing links except\nthe one the packet arrived on.\n\nbridges have the advantage transparency. so, it simplifies other components because a bridge is not visible for other components of the network.",
        "original_sample_id": "smp0939q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1071q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "globally knowledge of multicast group's spanning tree is what cause it appealing for broad/multicasting. nexus land routing is modified to construct spanning tree for multicasting by: 1. all is send nexus land periodically, and it contains the distance to neighbours, expanded by information of multicast groups 2. each is calculates a multicast tree, from the now locally available and complete land information 3. is determines the outgoing lines and on which packets have to be transmitted based on the information of the multicast tree",
        "answer_feedback": "the stated property of a spanning tree is incorrect. there is a single unique path between every pair of nodes in the spanning tree which makes it appealing for the broad and multicast.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "globally knowledge of multicast group's spanning tree is what makes it appealing for broad/multicasting. link state routing is modified to construct spanning tree for multicasting by: 1. all is send link state periodically, and it contains the distance to neighbours, expanded by information of multicast groups 2. each is calculates a multicast tree, from the now locally available and complete state information 3. is determines the outgoing lines and on which packets have to be transmitted based on the information of the multicast tree",
        "original_sample_id": "smp1071q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1037q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "overthrow track forwarding : it is for broadcasting, it is for fowarding and transmission packages in multicast routing without getting false ip addresses. it is a variation of the spanning tree, where every sender node has its own spanning tree and track. the intermediate systems in between don't need to know those. if the packages arrive at an is, the package used the best route available at that time. this is done by a resend over all edges, but not for the incoming one. if no package arrived at the is, the package didn't use that route being not the best route. this is done by dismissing packages. overthrow track broadcast : it is for broadcasting. it is an improvement of overthrow track forwarding. it works like overthrow track forwarding but with a specific selection of the outgoing links. the \"rpf\" has the disadvantage of resending over all edges. it would be better to forward packages over suitable edges. so if a package arrived at the is over which the packages for this station are usually sent before and the package has used the best route until now, the suitable edges are selected at which the packages arrived. from those packages they are rerouted and resent to the source c. otherwise the packages are not send over all edges. if no package arrived, discard the packages.",
        "answer_feedback": "the main purpose of rpf and rpb is to reduce redundant packets/duplicates in broadcast or multicast, ip address spoofing is also correct but that is not the primary purpose.the response correctly explains both rpf and rpb.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "reverse path forwarding : it is for broadcasting, it is for fowarding and transmission packets in multicast routing without getting false ip addresses. it is a variation of the spanning tree, where every sender node has its own spanning tree and path. the intermediate systems in between don't need to know those. if the packets arrive at an is, the packet used the best route available at that time. this is done by a resend over all edges, but not for the incoming one. if no packet arrived at the is, the packet didn't use that route being not the best route. this is done by dismissing packets. reverse path broadcast : it is for broadcasting. it is an improvement of reverse path forwarding. it works like reverse path forwarding but with a specific selection of the outgoing links. the \"rpf\" has the disadvantage of resending over all edges. it would be better to forward packets over suitable edges. so if a packet arrived at the is over which the packets for this station are usually sent before and the packet has used the best route until now, the suitable edges are selected at which the packets arrived. from those packets they are rerouted and resent to the source c. otherwise the packets are not send over all edges. if no packet arrived, discard the packets.",
        "original_sample_id": "smp1037q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0380q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward), (a, c, forward), (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) inflict in hop 1, (b, e, forward)\nfrom c: (c, b, drop) inflict in hop 1, (c, d, drop) inflict in hop 1, (c, e, drop) inflict in hop 2, (c, f, forward)\nfrom d: (d, c, drop) inflict in hop 1, (d, f, drop) inflict in hop 2\n\nhop 3:\nfrom e: (e, c, drop) inflict in hop 1, (e, f, drop) inflict in hop 2, (e, g, forward)\nfrom f: (f, d, drop) inflict in hop 1, (f, e, drop) inflict in hop 2, (f, g, drop) inflict in hop 3\n\nhop 4:\nfrom g: (g, f, drop) inflict in hop 2, (g, h, drop) no new neighbors",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward), (a, c, forward), (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) visited in hop 1, (b, e, forward)\nfrom c: (c, b, drop) visited in hop 1, (c, d, drop) visited in hop 1, (c, e, drop) visited in hop 2, (c, f, forward)\nfrom d: (d, c, drop) visited in hop 1, (d, f, drop) visited in hop 2\n\nhop 3:\nfrom e: (e, c, drop) visited in hop 1, (e, f, drop) visited in hop 2, (e, g, forward)\nfrom f: (f, d, drop) visited in hop 1, (f, e, drop) visited in hop 2, (f, g, drop) visited in hop 3\n\nhop 4:\nfrom g: (g, f, drop) visited in hop 2, (g, h, drop) no new neighbors",
        "original_sample_id": "smp0380q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0217q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this is always the eccentric, because the arrival pace (9) is lower than the serving pace (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. the correct answer is 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "this is always the case, because the arrival rate (9) is lower than the service rate (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "original_sample_id": "smp0217q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0217q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this is always the suit, because the arrival rate (9) is lower than the serving rate (10). \nso on average the buffer is always below its maximal capacity of 10.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. the correct answer is 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "this is always the case, because the arrival rate (9) is lower than the service rate (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "original_sample_id": "smp0217q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1016q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Reverse path forwarding and reverse path transmission help reduce unwanted duplication of transmission packages. Reverse path forwarding works by checking the incoming edge of a transmission package: if it is not the border used to send a package to the emission source, the package is discarded (because packages using any non-optimal route are considered duplicates). Otherwise it is sent over all borders except the incoming one. Reverse path transmission works similar to rpf, but a package is not sent to an adjacent node if the current is not part of the optimal unicast route from the node adjacent to the emission source.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast help to reduce unwanted duplication of broadcast packets. reverse path forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because packets using any non-optimal path are considered duplicate). otherwise it is sent over all edges except the incoming one. reverse path broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast path from the adjacent node to the broadcast source.",
        "original_sample_id": "smp1016q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1016q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse course forwarding and reverse course broadcast help to reduce unwanted duplication of broadcast package. reverse course forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because package using any non-optimal course are considered twin). otherwise it is sent over all edges except the incoming one. reverse course broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast course from the adjacent node to the broadcast source.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast help to reduce unwanted duplication of broadcast packets. reverse path forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because packets using any non-optimal path are considered duplicate). otherwise it is sent over all edges except the incoming one. reverse path broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast path from the adjacent node to the broadcast source.",
        "original_sample_id": "smp1016q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0328q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(a, c, forward) (a, d, forward) (b, c, forward) (a, d, forward) (b: (b, c, fall) = > (already covered with a) (c, e, fall) = > (already covered with b and shorter track) (c, f, forward) (c, d, fall) = > (already covered with a) (c, a, fall) = > (already covered with a) (c, e, e, fall) = > (already covered with b and shorter track) (c, f, fall) (d, a, drop) = > (already covered with a) (d, c, c, drop) = ) (d, c, f, already covered with )",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\nfrom a: (a, b, forward) (a, c, forward) (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) => (c was already covered) (b, e, forward) (b, a, drop) => (a was already covered)\nfrom c: (c, b, drop) => (already covered from a) (c, e, drop) => ( e was already covered from b and shorter way) (c, f, forward) (c, d, drop) => ( already covered from a) (c, a, drop) => ( a was already covered)\nfrom d: (d, c, drop) => (already covered from a) (d, f, drop) => ( f was covered from c and shorter way) (d, a, drop) => ( a was covered already)\n\nhop 3:\nfrom e: (e, c, drop) => (already covered from a) (e, f, drop) => (already covered from c) (e, g, forward) (e, b, drop) => ( b was already covered)\nfrom f: (f, g, drop) => (g was already covered)  (f, e, drop) => (e was already covered) (f, c, drop) => (c was already covered) (f, d, drop) => (d was already covered)\n\nhop 4:\nfrom g: (g,f, drop) => ( f was already covered) (g,e, drop) => (e was already covered) (g,h,forward)\n\nhop 5:\nfrom h: (h, g, drop) (g was already covered)",
        "original_sample_id": "smp0328q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0882q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This is not true for the real internet, because we often have a rampant traffic. First of all, there could be long-line traffic, which for example is caused by the user's behavior as people watching video streams more likely at night. then we also have long-range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high brightness until it is full.",
        "answer_feedback": "the first example in the response is partially correct because the arrival process' parameters can be time-dependent. that can model such intra-day variations like more video traffic during the evening. knowing previous arrivals no longer has to capture this information for us, thus making the inter-arrival times independent in this regard. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this doesn't hold true for the real internet, because we often have bursty traffic. first of all there could be long-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have long range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high burst until it's full.",
        "original_sample_id": "smp0882q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0882q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this doesn't hold true for the real internet, because we often have outbursty traffic. first of all there could be farsighted-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have farsighted compass dependencies. video streaming for example is implemented with buffers where the buffer is filled with high outburst until it's full.",
        "answer_feedback": "the first example in the response is partially correct because the arrival process' parameters can be time-dependent. that can model such intra-day variations like more video traffic during the evening. knowing previous arrivals no longer has to capture this information for us, thus making the inter-arrival times independent in this regard. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this doesn't hold true for the real internet, because we often have bursty traffic. first of all there could be long-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have long range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high burst until it's full.",
        "original_sample_id": "smp0882q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on receiver side, the receiver will attach ack with bundle and send them both at the same sentence to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down sentencekeeper. if sentencekeeper reaches 0, even it has no data to send, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "On the side of the receiver, the receiver will attach ack with packet and send them at the same time to save bandwidth. But if it has nothing to send, if it cannot be handed over to the sender. So the requirement here is that the receiver must have something to return. If it has nothing to send, it must have an account chronometer. if timer reaches 0, even it does not have data to send, theack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on receiver side, the receiver will attach ack with packet and station them both at the same metre to save bandwidth. but if it has nothing to station, so ack also can not be rescue back to stationer.\n\nso the requirement here is that the receiver must have something to station back. if it has nothing to station, it must have a count down metrer. if metrer reaches 0, even it has no data to station, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "On the side of the receiver, the receiver will attach ack with packet and send them at the same time to save bandwidth. But if it has nothing to send, if it cannot be handed over to the sender. So the requirement here is that the receiver must have something to return. If it has nothing to send, it must have an account chronometer. if timer reaches 0, even it does not have data to send, theack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on recipient side, the recipient will confiscate ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the recipient must have something to send back. if it has nothing to send, it must have a count down timekeeper. if timekeeper reaches 0, even it has no data to send, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1623q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "broadcast (255.255.255.255), local host speech (0.0.0.0) and web host speech (0.x.x.x) and loopback",
        "answer_feedback": "what is the loopback address?",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast (255.255.255.255), local host address (0.0.0.0) and network host address (0.x.x.x) and loopback",
        "original_sample_id": "smp1623q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1623q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "broadcast (255.255.255.255), local host speech (0.0.0.0) and net host speech (0.x.x.x) and loopback",
        "answer_feedback": "what is the loopback address?",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast (255.255.255.255), local host address (0.0.0.0) and network host address (0.x.x.x) and loopback",
        "original_sample_id": "smp1623q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1478q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "duplex datum transfer (both face should be able to send and get datum)",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "duplex data transfer (both sides should be able to send and receive data)",
        "original_sample_id": "smp1478q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0330q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forrad)\n(a, c, forrad)\n(a, d, pearl) because c is already reached and f will be reached faster via c.\n\nhop 2:\n(b, e, forrad)\n(c, f, pearl) because d is already reached and e,g will be reached faster via b.\n\nhop 3:\n(e, g, forrad)\n\nhop 4:\n(g, h, pearl) because no further thickening could be reached.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) because c is already reached and f will be reached faster via c.\n\nhop 2:\n(b, e, forward)\n(c, f, drop) because d is already reached and e,g will be reached faster via b.\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop) because no further node could be reached.",
        "original_sample_id": "smp0330q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would happen. so the liquidator may not wait too long. if no frame appears powerful in time, piggybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there has to be a duplex communication because the meter period by which the response is to be delayed (to await for a inning to piggyback the acknowledgement onto) must not exceed the meterout period of the sender whose inning is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not await too long. if no inning appears right in meter, piggybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0940q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The tables contain information where the frame of a node in a lan must send to the node of another lan and the table is modified by doing and learning, so at the start if a bridge gets a frame and does not know the destination that are flooding, if the origin and the destination lans are identical then the frame where they fell and if the origin and the destination lans where the frame differs have been redirected to the lan destination, so the bridge learns from traffic and constructs its table of diversion from this learning process. e.g., the bridge receives frames with direction of origin qon lan l, which can be reached on the, create the entrance of the table accordingly. the profit is, more learning traffic, so that the efficiency depends on the intensity of the traffic.",
        "answer_feedback": "the stated benefit presents the scenario when the bridge works best but the question asked for the benefit derived once the bridge table is available, i.e. fewer duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the tables hold information where the frame from node in one lan should send to the node of other lan and the table is modified by doing and learning, so at the beginning if a bridge get a frame and they don’t know the destination they do flooding, if the source and destination lans are identical then the frame where dropped and if the source and destination lans where differ the frame were rerouted to destination lan, so the bridge learns from traffic and builds up their for-warding table from this learning process. \nfor example, bridge receives frames with source address q on lan l, q can be reached over l, it will create table entry accordingly.\nthe benefit is, more traffic more learning, so the efficiency depends on the intensity of traffic.",
        "original_sample_id": "smp0940q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1488q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "datum frames contain an additional ack discipline which contains the sequence bit.",
        "answer_feedback": "the response is correct as an additional field is required in the frame for acknowledgment. moreover, a duplex channel is required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "data frames contain an additional ack field which contains the sequence number.",
        "original_sample_id": "smp1488q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0102q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding is the estimable option because of its good self-clocking lineament which is important in a congested network. it also provides fault detection.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding is the best option because of its good self-clocking feature which is important in a congested network. it also provides error detection.",
        "original_sample_id": "smp0102q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0102q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encryption is the best option because of its good self-clocking feature which is crucial in a congested network. it also provides error sensing.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding is the best option because of its good self-clocking feature which is important in a congested network. it also provides error detection.",
        "original_sample_id": "smp0102q002",
        "is_augmented": "true",
        "question_id": "q002"
    }
]
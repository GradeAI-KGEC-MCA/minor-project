[
    {
        "id": "aug00smp1099q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees prevent cringle in your topology. you only have to modify the link nation packets by adding entropy on multicast groups. with that entropy each is can calculate a multicast tree",
        "answer_feedback": "the response correctly identifies the spanning-tree property and explains how the link state routing can be modified to construct a spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees prevent loops in your topology. you only have to modify the link state packets by adding information on multicast groups. with that information each is can calculate a multicast tree",
        "original_sample_id": "smp1099q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0856q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not this is not maintained for internet traffic, because if you look at data that exceeds the standard package size (e.g. streaming videos), receiving another package that depends on the previous one and potentially took the same route is a likely occurrence. the Poisson process also does not count for packet falls where a forwarding might be necessary, so it also depends on the rate of packet loss.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no this does not hold for internet traffic, because if you look at data that exceeds the standard packet size (e.g. streaming of videos), receiving another packet that depends on the previous one and potentially took the same path is a likely occurrence. the poisson process also doesn’t account for packet drops where a resend might be necessary, making it also dependent on packet loss rate.",
        "original_sample_id": "smp0856q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0357q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:\n(a,b, frontward), (a,c, frontward)(a,d, drop) <= from node d there is no promotion to node f, because d is not on the unicast path from a to d\nhops 2:\n(b,e,frontward)\n(c,f,drop) <= from node f there is no promotion to node d e and g, because node d is not on the unicast path from a to d, e or g\nhops 3:\n(e,g,frontward)\nhops 4:\n(g,h,drop) <= there is no more promotion, because there h is the last node on this path",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b, forward), (a,c, forward)(a,d, drop) <= from node d there is no forwarding to node f, because d is not on the unicast path from a to d\nhop 2:\n(b,e,forward)\n(c,f,drop) <= from node f there is no forwarding to node d e and g, because node d is not on the unicast path from a to d, e or g\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop) <= there is no more forwarding, because there h is the last node on this path",
        "original_sample_id": "smp0357q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectorless  data is transferred without regards for parcel loss, as opposed to the confirmed connectorless option.\nconfirmed connectorless data is transferred and acknowledged, contrary to the unconfirmed connectorless option.\nconnector-oriented 3-stage communication with connector data transfer and disconnect, opposed to the connectorless option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless  datum is channelize without regards for packet loss, as fight to the confirmed connectionless option.\nconfirmed connectionless datum is channelize and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection datum transfer and disconnect, fight to the connectionless option.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0698q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "uncorroborate connectionless  data is transferred without regards for packet loss, as opposed to the corroborate connectionless alternative.\ncorroborate connectionless data is transferred and acknowledged, wayward to the uncorroborate connectionless alternative.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless alternative.",
        "answer_feedback": "the response answers the services' names and differences correctly. but there is no common theme of the difference between them. the last point should also discuss the presence or absence of acknowledgments.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unconfirmed connectionless  data is transferred without regards for packet loss, as opposed to the confirmed connectionless option.\nconfirmed connectionless data is transferred and acknowledged, contrary to the unconfirmed connectionless option.\nconnection-oriented 3-phase communication with connection data transfer and disconnect, opposed to the connectionless option.",
        "original_sample_id": "smp0698q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only need to send out the data as one mailboat and dont have to send a exclusive mailboat for each receiver, you also dont need to know all the receivers as the tree will plow the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp1104q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the fact that you only need to post out the data as one packet and dont have to post a single packet for each receiver, you also dont need to fuck all the liquidator as the tree will handle the transmission.",
        "answer_feedback": "the response's reasoning will not hold when we have a sender with 5 nodes directly connected to it. in such a case, 5 copies will be made at the sender and individually sent to each node. the explanation for the link-state modification is missing.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the fact that you only need to send out the data as one packet and dont have to send a single packet for each receiver, you also dont need to know all the receivers as the tree will handle the transmission.",
        "original_sample_id": "smp1104q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0793q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is an offline transport service and tcp is oriented to the connection. Therefore, sending data on the loss of udp data is possible because it is unreliable and has no error control or diffusion. it can be transmitted from the application, but not from udp itself. udp is much faster than tcp and uses less resources (buffering, state information, timer, ...). These differences explain the different headers of udp and tcp. The udp header consists only in the port of the sender, receiving port, package length and a checksum (8 byte long). The ttcp header also includes a (1) sequence number, (2) recognition number, (3) options field and (4) tcp flags.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the response states some additional points that are more the general differences between udp and tcp.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is a connectionless transport service and tcp is connection oriented. therefore, sending data over udp data loss is possible because it is unreliable and has no error control or retransmission. it may be retransmit from application, but not from udp itself.\nudp is way more faster than tcp and uses less resources (buffering, status information, timer, …).\n\nthese differences explain the different headers of udp and tcp. the udp header consists of only of sender port, receiver port, packet length and a checksum (8 byte long). the tcp header additionally consist of a \n(1) sequence number,\n(2) acknowledgement number,\n(3) options field and\n(4) the tcp flags",
        "original_sample_id": "smp0793q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0238q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1) cypher the probability for the state p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 packets p( less than 10) = 1 - p10 = 0.949\n3) expected turn of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the balance state during the entire minute.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1) calculate the probability for the state p10 (using the formula derived on the slides) => 0.051\n2) probability for less than 10 packets p( less than 10) = 1 - p10 = 0.949\n3) expected number of seconds in p0, ..., or p9: 60 x p(less than 10) = 56,94 seconds\n\nthe last step is possible because we assume that we are in the equilibrium state during the entire minute.",
        "original_sample_id": "smp0238q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0347q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (a, b, front) (a, c, front) (a, d, front) hop 2: (b, c, drop) < = because b never got a package for c in the past (because ac is the best way) (b, e, front) (c, b, drop) < = because c never got a package for b in the past (because ab is the best way) (c, d, drop) < = because c never got a package for d in the past (because the ad is the best way) (c, f, drop) (d, c, drop) < = because d never got a package for c in the past (because ac, drop) < get a package for c in the past (e, c, drop) < get a package for c in the past (e, get a < < < < < < < < < < < < < < < < < < < < package for the past (e, drop) p, c, drop) < get a package for f, drop) < get a package for f in the past (e, get a package for the past (e, get a package for the < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:(a, b, forward)\n(a, c, forward)\n(a, d, forward) \nhop 2:\n(b, c, drop) <= because b never got a packet for c in the past (because ac is the best path)\n(b, e, forward)\n(c, b, drop) <= because c never got a packet for b in the past (because ab is the best path)\n(c, d, drop) <= because c never got a packet for d in the past (because ad is the best path)\n(c, f, forward)\n(d, c, drop) <= because d never got a packet for c in the past (because ac is the best path)\n(d, f, drop) <= because d never got a packet for f  in the past (because acf is the best path)\nhop 3:\n(e, c, drop) <= because e never got a packet for c in the past (because ac is the best path)\n(e, f, drop) <= because e never got a packet for f in the past (because acf ist the best path)\n(e, g, forward)\n(f, d, drop) <= because f never got a packet for d in the past (because ad is the best path)\n(f, e, drop) <= because f never got a packet for e in the past (because abe is the best path)\n(f, g, drop) <= because f never got a packet for g in the past (because abeg is the best path)\nhop 4: \n(g, f, drop) <= because g never got a packet for f in the past (because acf is the best path)\n(g, h, drop) <= because h has no further links to forward to",
        "original_sample_id": "smp0347q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0811q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is mainly ip with a short transport header (8 bytes) with only the source and destination port and the length of the package and checksum. while the tcp header can be more complex and is at least 20 bytes large. the tcp header contains the source port, the port dest., the sequence number, the recognition number, hl/resv/flags, the announced victory., the urgent checksum pointer and other optional options. the header length only represents the size of the header, while the length of the udp package also contains the size of the payload.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv, should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is mostly ip with a short transport header (8 byte) with only source and destination port and packet length and checksum. while the tcp header can be more complex and is at least 20 byte big. the tcp header contains source port, dest. port, sequence number,\nacknowledgment number, hl/resv/flags, advertised win., checksum urgent pointer and optional further options. the header length represents only the header size, while udp packet length contains also the size of the payload.",
        "original_sample_id": "smp0811q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0359q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: from a: (a,b,forward), (a,c,forward), (a,d,forward) hop 2: from b: (b,c,drop), because he sent directly to c, (b,e,forward) from c: (c,b,d,drop) because he sent a, (c,d,drop), because he sent to d (c,e,drop), because b sent to e (c,f,forward) from d: (d,c,d,d,drop), because he sent to c (d,f,drop) because c sent to e hop 3: from: (e,c,drop), because he sent to c (e,f,d,drop), because c sent to f (e,g,g,award) from f: (f,d,drop), because he sent to (f,d,d), because he sent to e (f,g,d,d,d), because c sent to f (e,f,d,d,d) because h (f,d,d,d,d,d, because h (f,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,d,",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: from a: (a,b,forward), (a,c, forward), (a,d, forward)\n\nhop 2:\nfrom b: (b, c, drop), because a sends directly to c, (b, e, forward)\nfrom c: (c, b, drop) because a sends to a, (c, d, drop), because a sends to d (c, e, drop), because b sends to e (c, f, forward)\nfrom d: (d, c, drop), because a sends to c (d, f, drop) because c sends to e \n\nhop 3:\nfrom e: (e, c, drop), because a sends to c (e, f, drop), because c sends to f (e, g, forward)\nfrom f: (f, d, drop), because a sends to a (f, e, drop), because b sends to e (f, g, drop) because e sends to g\n\nhop 4:\nfrom g: (g, f, drop), because c sends to e (g, h, drop) because h doesn´t have any other destination to forward the message",
        "original_sample_id": "smp0359q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0846q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being watercourseed via netflix, the package will always arrive with time interval 1. especially, for the swarm service, the package will arrive via a watercourse buffer with more package in a row, meaning the arrivals are not independent.",
        "answer_feedback": "the correct answer is \"no\" but the explanation of requiring constant time intervals for packet arrival is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with time interval 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "original_sample_id": "smp0846q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0846q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "for real cyberspace traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the cyberspace, the metre separation will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with metre separation 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "answer_feedback": "the correct answer is \"no\" but the explanation of requiring constant time intervals for packet arrival is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "for real internet traffic, the assumption is not always hold. for example, for a specific moment where nobody is using the internet, the time interval will always be 0. on the other hand, when a movie is being streamed via netflix, the packets will always arrive with time interval 1. especially, for the streaming service, the packets will arrive via a stream buffer with more packets in a row, meaning the arrivals are not independent.",
        "original_sample_id": "smp0846q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1032q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "1. purpose:  help preclude ip address spoofing. 2. rpf a chargeer broadcasts to all the stations. when a packet reaches a is ,the is will agree the path. if it is the usually path. it will charge to others",
        "answer_feedback": "the stated purpose is correct but not the main purpose which is to reduce duplicates when broadcasting. the explanation of rpf is incomplete, as it is not clear what is meant by the usual path or how the packet is forwarded.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. purpose:  help prevent ip address spoofing. 2. rpf a sender broadcasts to all the stations. when a packet reaches a is ,the is will check the path. if it is the usually path. it will send to others",
        "original_sample_id": "smp1032q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "use temporarily valid tsaps\n\nplace association separately\n- disadvantage: only for connection-oriented services\n\nplace pdus separately\n- disadvantage: higher bandwidth usage",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0464q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "use temporarily valid tsaps\n\nkey connectors individually\n- disadvantage: only for connector-oriented services\n\nkey pdus individually\n- disadvantage: eminent bandwidth usage",
        "answer_feedback": "description and advantages are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "use temporarily valid tsaps\n\nidentify connections individually\n- disadvantage: only for connection-oriented services\n\nidentify pdus individually\n- disadvantage: higher bandwidth usage",
        "original_sample_id": "smp0464q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1659q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "\"this host\": 0.0.0.0\nhosts/broadcast at this network: 0.0.0.1 - 0.255.255.254 / 0.255.255.255\nnetwork speech: 1-126.0.0.0\nbroadcast speech: 1-126.255.255.255\nloopback: 127.0.0.0 - 127.255.255.255\nalthough definitions vary whether or not 0.x.x.x and 127.x.x.x speech go to category a networks, i listed these for completeness; in my opinion, the definition of category a networks includes these ranges as well and hence, they go to the reserved speech.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "\"this host\": 0.0.0.0\nhosts/broadcast at this network: 0.0.0.1 - 0.255.255.254 / 0.255.255.255\nnetwork addresses: 1-126.0.0.0\nbroadcast addresses: 1-126.255.255.255\nloopback: 127.0.0.0 - 127.255.255.255\nalthough definitions vary whether or not 0.x.x.x and 127.x.x.x addresses belong to class a networks, i listed these for completeness; in my opinion, the definition of class a networks includes these ranges as well and hence, they belong to the reserved addresses.",
        "original_sample_id": "smp1659q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not charge faster than a receiver can receive\n2. framing: datum are packed in a inning, this inning contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to charge the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. period control: ensures that a sender does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, finish address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a chargeer does not charge faster than a receiver can receive\n2. framing: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to charge the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive 2. framming: the data is packed in a frame, this framework contains, for example, the data, the destination address and the source 3. error detection: important to ensure that all the data have been correctly received. if an error is detected, the receiver can be reported to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. menses control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to send the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive 2. framming: the data is packed in a frame, this framework contains, for example, the data, the destination address and the source 3. error detection: important to ensure that all the data have been correctly received. if an error is detected, the receiver can be reported to send the data again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0675q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. flow control: check that a transmitter does not send faster than a receiver can receive\n2. frame: datum are packed in a frame, this frame contains e.g. the datum, destination address and source \n3. error detection: important to ensure that all datum has been received correctly. if an error is detected, the receiver may be signalled to send the datum again",
        "answer_feedback": "the response answers no parts of the question correctly and is not related to the question.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. flow control: ensures that a transmitter does not send faster than a receiver can receive\n2. framing: data are packed in a frame, this frame contains e.g. the data, destination address and source \n3. error detection: important to ensure that all data has been received correctly. if an error is detected, the receiver may be signalled to send the data again",
        "original_sample_id": "smp0675q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1068q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Extending trees identify in multiple ways, from node to node, and transfer them to a tree topology with shorter paths ensuring loopless communication (package) * overall knowledge of the multicast tree that extends by sharing them with each other, e.g. via the routing of the link state * routing of the link state and the range tree: * in the routing of the link state, each one collects information on distances to adjacent stations, and now knows to which multicast group it belongs * distributes this information (distances + multicast group) in the link state packages * with this complete state information each can calculate a multicast tree and based on those that determine outgoing lines",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees identify multiple ways from node to node and transfer them into a tree topology with shortest paths ensuring loop free (packet) communication * global knowledge of the multicast group’s spanning tree by sharing them with each other e.g. via link state routing  * link state routing and spanning tree: * in link state routing each is gathers information about distances to the adjacent stations, and now also knows which multicast group it belongs to * is distribute these information (distances + multicast group) in periodically send link state packets  * with these complete state information each is can calculate a multicast tree and based on those determine outgoing lines",
        "original_sample_id": "smp1068q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1068q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Extending trees identify in multiple ways, from node to node, and transfer them to a tree topology with shorter paths ensuring loopless communication (package) * overall knowledge of the multicast tree that extends by sharing them with each other, e.g. via the routing of the link state * routing of the link state and the range tree: * in the routing of the link state, each one collects information on distances to adjacent stations, and now knows to which multicast group it belongs * distributes this information (distances + multicast group) in the link state packages * with this complete state information each can calculate a multicast tree and based on those that determine outgoing lines",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees identify multiple ways from node to node and transfer them into a tree topology with shortest paths ensuring loop free (packet) communication * global knowledge of the multicast group’s spanning tree by sharing them with each other e.g. via link state routing  * link state routing and spanning tree: * in link state routing each is gathers information about distances to the adjacent stations, and now also knows which multicast group it belongs to * is distribute these information (distances + multicast group) in periodically send link state packets  * with these complete state information each is can calculate a multicast tree and based on those determine outgoing lines",
        "original_sample_id": "smp1068q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0864q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, this hypothesis is not supported for real Internet traffic because problems that can block the arrival of packages can usually persist more than a step of time. If for example the arrival is blocked by congestion is more likely to still have congestion in the next step of time. On the other hand, if the arrival is not blocked it is likely that the following packages will also arrive. the arrival of packages is not a completely random process, blocking is caused by observable problems.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the persistence of problems may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, this assumption does not hold for real internet traffic since problems that may block the arrival of packets may usually persist longer than one time step δt. if for example the arrival is blocked by congestion it is more likely to still have congestion in the next time step. on the other hand, if the arrival is not blocked it is likely that the following packets will also arrive. the arrival of packets is not a wholly random process, blocking is caused by observable problems.",
        "original_sample_id": "smp0864q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0864q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for real internet traffic since problems that may stymy the arrival of packets may usually persist longer than one clip step δt. if for example the arrival is stymyed by congestion it is more likely to still have congestion in the next clip step. on the other hand, if the arrival is not stymyed it is likely that the survey packets will also arrive. the arrival of packets is not a wholly random process, stymying is caused by observable problems.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the persistence of problems may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, this assumption does not hold for real internet traffic since problems that may block the arrival of packets may usually persist longer than one time step δt. if for example the arrival is blocked by congestion it is more likely to still have congestion in the next time step. on the other hand, if the arrival is not blocked it is likely that the following packets will also arrive. the arrival of packets is not a wholly random process, blocking is caused by observable problems.",
        "original_sample_id": "smp0864q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1054q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "goal: avoid flood duplicates and guarantee loopless rotation. how they work: when a multicast package enters a router's interface, look for the source of the multicast package in your unicat routing table to see if the output interface associated with this ip source address is the interface in which this package arrived. if it matches, the router doubles the package and returns it, if it fails, the package will be deleted.",
        "answer_feedback": "the response is partially correct because it's unclear whether the stated description is referring to the rpf or rpb algorithm.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.2,
        "original_answer": "purpose: avoid flood duplicates and ensure loop-free forwarding. how they work: when a multicast packeting enters a router's interface,  it looks up the source of the multicast packet in its unicast routing table to see if the outgoing interface associated with that source ip address is the interface on which that packet arrived. if matched, the router duplicate the packet and forward it, if fails, the packet will be discarded.",
        "original_sample_id": "smp1054q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1111q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "with multicasting relative to broadcasting, you have a unique expedition instead of multiple shipping. so it is important for everyone to have a global knowledge of the multicast tree. this property applies to trees that extend and can therefore be used for multicasting. to use the link state routing to build a multicasting extension tree, the link state packets need to be expanded to contain information about the multicast groups. these are regularly transmitted to all the other is and now each can calculate a multicast tree.",
        "answer_feedback": "the response is incorrect regarding why multicast and broadcast use spanning tree. a spanning tree is used to reduce unnecessary duplicates by removing loops. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "with multicasting compared to broadcasting, you have one-time sending instead of multiple sending. therefore it is important for all the is to have global knowledge of the multicast tree. this property applies to spanning trees and thus they can be used for multicasting. to use link state routing to construct a spanning tree for multicasting, the link state packets have to be expanded to contain information on the multicast groups. these periodically get broadcasted to all the other is and now each is can calculate a multicast tree.",
        "original_sample_id": "smp1111q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1109q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Therefore, they allow routers to make copies on the last intermediate systems. in this way, traffic and duplicate packages are reduced on the network. for link status routing, the information that contains link status packets in addition to the distance and neighbors has to be expanded by information on multicast groups. with this information, each router can calculate a multicast tree using local and complete status information. based on the multicast tree, the intermediate systems determine the outgoing lines on which the packets must be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for link state routing, the containing information of link state packets besides distance and neighbors has to be expanded by information on multicast groups. with this information, every router can calculate a multicast tree using the now locally available and complete state information. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "original_sample_id": "smp1109q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1109q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for nexus state routing, the moderate entropy of nexus state packets besides distance and neighbors has to be expanded by entropy on multicast groups. with this entropy, every router can calculate a multicast tree using the now locally available and complete state entropy. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree covers all routers without loops. therefore, they allow routers to make copies at the latest intermediate systems. that way, traffic and duplicate packets are reduced in the network.   for link state routing, the containing information of link state packets besides distance and neighbors has to be expanded by information on multicast groups. with this information, every router can calculate a multicast tree using the now locally available and complete state information. based on the multicast tree, intermediate systems determine the outgoing lines on which packets should be transmitted.",
        "original_sample_id": "smp1109q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0386q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: \n(a,b,forrad)\n(a,c, forrad)\n(a,d, forrad)\nhop 2:\n(b, e, forrad)\n(b, c, bead) c would not send package to a via b, it would send directly\n(c, b, bead) same reason as above\n(c, d, bead) d would not send package to a via b, it would send directly\n(c, f, forrad)\n(d, c, bead) c would not send package to a via d\n(d, f, bead) f would send package to a via c\nhop 3:\n(e, c, bead) c would sent package to a directly\n(e, f, bead) f would sent package to a via c\n(e,g, forrad)\n(f, e, bead) e would sent package to a via b\n(f, d, bead) d would sent package to a directly\n(f, g, bead) g would sent package to a via e\nhop 4:\n(g, f, bead) f would sent package to a via c\n(g, h, bead) h only has 1 link which is the incoming link",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: \n(a,b,forward)\n(a,c, forward)\n(a,d, forward)\nhop 2:\n(b, e, forward)\n(b, c, drop) c would not send packet to a via b, it would send directly\n(c, b, drop) same reason as above\n(c, d, drop) d would not send packet to a via b, it would send directly\n(c, f, forward)\n(d, c, drop) c would not send packet to a via d\n(d, f, drop) f would send packet to a via c\nhop 3:\n(e, c, drop) c would sent packet to a directly\n(e, f, drop) f would sent packet to a via c\n(e,g, forward)\n(f, e, drop) e would sent packet to a via b\n(f, d, drop) d would sent packet to a directly\n(f, g, drop) g would sent packet to a via e\nhop 4:\n(g, f, drop) f would sent packet to a via c\n(g, h, drop) h only has 1 link which is the incoming link",
        "original_sample_id": "smp0386q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1684q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "first destination of the subnetwork: network destination\nlast destination of the subnetwork: broadcast destination",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "first address of the subnetwork: network address\nlast address of the subnetwork: broadcast address",
        "original_sample_id": "smp1684q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1684q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "first sub-network address: network address last sub-network address: distribution address",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "first address of the subnetwork: network address\nlast address of the subnetwork: broadcast address",
        "original_sample_id": "smp1684q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0394q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: from a: (a, b, forwards) (a, c, forwards) (a, d, downwards) - the forwards node d is not the ideal unicast path to nodes c and f. hop 2: from b: (b, e, forwards) from c: (c, f, downwards) - the forwards node f is not the ideal unicast path to nodes d, e and g. hop 3: from e: (e, g, forwards) hop 4: from g: (g, h, downwards) - since the h node has no more links than g where it receives its package package can be released",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\nfrom a:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) - the forward over node d is not the ideal unicast path towards nodes c and f.\n\nhop 2:\nfrom b:\n(b, e, forward)\nfrom c:\n(c, f, drop) - the forward over node f is not the ideal unicast path towards nodes d, e and g.\n\nhop 3:\nfrom e:\n(e, g, forward)\n\nhop 4:\nfrom g:\n(g, h, drop) - since node h has no links other than to g where it receives its packet from the packet can be dropped",
        "original_sample_id": "smp0394q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0865q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it doesn't hold. on the real Internet, there are all kinds of traffic. on a tcp connection, for example, packages highly depend on each other in several ways. the sequence in which packages should arrive is critical. there are recognitions, which are only sent if a package arrives at its destination. and if some packages fail, they will be transmitted.",
        "answer_feedback": "as mentioned in the response, the correct answer is \"no\". real internet traffic is bursty, which is the main reason for the assumption being false. the above example attributes the burstiness to the sequencing, retransmission, and acknowledgement, which may contribute but are not the main cause of the assumption's violation.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it doesn’t hold. on the real internet, there’s all kind of traffic. in a tcp-connection for example, the packets strongly depend on one another in various ways. the sequence in which the packets need to arrive is critical. there are acknowledgements, which are only sent if a packet arrives at the destination. and if some packets don’t arrive, they will be retransmit.",
        "original_sample_id": "smp0865q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0865q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it doesn't hold. on the real Internet, there are all kinds of traffic. on a tcp connection, for example, packages highly depend on each other in several ways. the sequence in which packages should arrive is critical. there are recognitions, which are only sent if a package arrives at its destination. and if some packages fail, they will be transmitted.",
        "answer_feedback": "as mentioned in the response, the correct answer is \"no\". real internet traffic is bursty, which is the main reason for the assumption being false. the above example attributes the burstiness to the sequencing, retransmission, and acknowledgement, which may contribute but are not the main cause of the assumption's violation.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it doesn’t hold. on the real internet, there’s all kind of traffic. in a tcp-connection for example, the packets strongly depend on one another in various ways. the sequence in which the packets need to arrive is critical. there are acknowledgements, which are only sent if a packet arrives at the destination. and if some packets don’t arrive, they will be retransmit.",
        "original_sample_id": "smp0865q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0377q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,onwards)\n(a,c,onwards)\n(a,d,drop)<=d doesn't foward a substance from a to f, because f doesn't receive unicast parcel via d.\nhop 2:\n(b,e,onwards)\n(c,f,drop)<=f doesn't foward a substance from a to g, because g doesn't receive unicast parcel via f.\nhop 3:\n(e,g,onwards)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the substance, vertex h does not onwards the substance.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=d doesn't foward a message from a to f, because f doesn't receive unicast packets via d.\nhop 2:\n(b,e,forward)\n(c,f,drop)<=f doesn't foward a message from a to g, because g doesn't receive unicast packets via f.\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the message, vertex h does not forward the message.",
        "original_sample_id": "smp0377q005",
        "is_augmented": "true",
        "question_id": "q005",
        "audit": "incorrect",
        "confidence": 0.2
    },
    {
        "id": "aug00smp0378q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: (c, a, forward) (d, a, forward) (b, a, forward) hop 2: (b, c, drop) duplicate package, (b, e, forward) (c, b, drop) duplicate package, (c, drop) duplicate package, (c, f, drop) duplicate package, (c, f, drop) duplicate package, (d, f, drop) duplicate package hop 3: (e, c, drop) duplicate package hop 4: (e, g, f, drop) duplicate package, (e, g, drop), (f, drop) duplicate package h does not send the message.",
        "answer_feedback": "(a,d, drop) and subsequent flow will change accordingly. also (c, f, drop).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(c, a, forward)\n(d, a, forward)\n(b, a, forward)\n\nhop 2: \n(b, c, drop) duplicate packet  , (b, e, forward) \n(c, b, drop) duplicate packet, (c, d, drop) duplicate packet, (c, e, drop) duplicate packet, (c, f, forward) \n(d, c, drop) duplicate packet, (d, f, drop) duplicate packet\n\nhop 3: \n (e, c, drop) duplicate packet,\n (e, f, drop) duplicate packet,\n (e, g, forward),  \n(f, d, drop) duplicate packet, \n(f, e, drop) duplicate packet,\n (f, g, drop) duplicate packet\n\nhop 4:\n(g, f, drop) duplicate packet, \n(g, h, drop)  vertex h does not forward the message.",
        "original_sample_id": "smp0378q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward path forwarding (rpf) and rearward path programme (rpb) are used in networks with programmeing ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and programme them to every knob attached to them, except to the knob where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination knob always take this exact is port. in this way, the programme is done by using unicast paths. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward route forwarding (rpf) and rearward route broadcast (rpb) are used in networks with broadcasting ability to find the best routes between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every knob attached to them, except to the knob where it came from. to accomplish the best route, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination knob always take this exact is port. in this way, the broadcast is done by using unicast routes. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding (rpf) and reverse path circularize (rpb) are used in networks with circularizeing ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and circularize them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has exact the best route. this is the case, when packets with a sealed destination node always take this exact is port. in this way, the circularize is done by using unicast paths. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse itinerary forwarding (rpf) and reverse itinerary program (rpb) are used in networks with programing ability to find the best itinerarys between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and program them to every node attached to them, except to the node where it came from. to accomplish the best itinerary, the is keeps track of where incoming packets were itineraryd and if the packet has taken the best itinerary. this is the case, when packets with a certain destination node always take this exact is port. in this way, the program is done by using unicast itinerarys. all other packets are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp1044q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The reverse path forwarding (rpf) and the reverse path forwarding (rpb) are used in networks with retransmission capability to find the best paths between senders/receivers. they work by flooding the network with packages. the intermediate stations will receive the packets and transmit them to each node connected to them, except to the node from where it came. to achieve the best path, it is monitored where the incoming packets were headed and if the package has taken the best route. this is the case, when the packets with a given destination node always take this exact node is port. thus, the retransmission is made using unicast routes. all other packages are not transmitted.",
        "answer_feedback": "both algorithms are indeed used to broadcast packets in the network but the main purpose is to minimize the number of duplicate packets during broadcasting. also, it's unclear which algorithm the stated description is explaining.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are used in networks with broadcasting ability to find the best paths between senders/receivers. they work by flooding the network with packets. the intermediate stations will receive the packets and broadcast them to every node attached to them, except to the node where it came from. to accomplish the best path, the is keeps track of where incoming packets were routed and if the packet has taken the best route. this is the case, when packets with a certain destination node always take this exact is port. in this way, the broadcast is done by using unicast paths. all other packets are not transmitted.",
        "original_sample_id": "smp1044q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1097q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "holding: the span tree does not have any loop.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is not provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "property: the spanning tree does not have any loops.",
        "original_sample_id": "smp1097q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0827q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. the tcp header has an announced win. field, but the dose is not udp. so tcp supports flow control. 2. tcp has a recognition number field, but the dose is not udp. so tcp supports a reliable two-way byte stream in order. 3. tcp has a sequence number field, but the dose is not udp. so tcp supports error control. 4.tcp has a range of options, but udp does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. tcp header has a advertised win. field, but udp dose not. so tcp supports flow control. \n2. tcp has a acknowledgement number field, but udp dose not. so tcp supports reliable bidirectional in-order byte stream. \n3. tcp has a sequence number field, but udp dose not. so tcp supports error control. \n4.tcp has a options field, but udp does not. so tcp's header length can change.",
        "original_sample_id": "smp0827q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0787q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header is fixed and 64 bit long, while tcp is minimum 160 bit (more optional header) long. the udp header is very short, it consists only in the information of the sender and receiver, the length of the package and a sum of verification. the tcp header has much more information, because it offers complementary services such as two-way communication, the interaction based on connection and avoidance of congestion.Therefore there is a need to have more information recorded in the tcp header. uses the sequence and the recognition number to ensure that each package is received and in the correct order.",
        "answer_feedback": "all the stated differences between a tcp header and a udp header are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header is fixed and 64 bit long, while tcp is minimum 160 bit ( plus optional header) long. \nthe udp header is very short, it only consists of the sender and receiver information, the packet length and a checksum. \nthe tcp header has a lot more information, because it offers supplementary services like i.e. two-way communication, connection-based interaction and congestion avoidance. therefore there is a need to have more information saved inside of the tcp header. it uses the sequence and acknowledgement number to make sure that every packet is received and is in the correct order.",
        "original_sample_id": "smp0787q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1074q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "with the cover trees you are able to acquire an overall knowledge of the multicast groups from an initial local knowledge, which makes the cover trees attractive. in order to modify the routing of the link state to build a cover tree for the multicasting you can use the normal procedure of routing the link state but also add information about the multicast groups. with each being calculated its own multicast trees with the information available locally. then based on the information about the multicast tree that it determines the paths to be used to transmit packages.",
        "answer_feedback": "yes, global knowledge can be obtained from local knowledge, but that is the description of constructing spanning trees with link-state, not a desirable property of spanning trees. it is desirable for use in multicast and broadcast because of the absence of loops which reduces unnecessary duplicates.  the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "with spanning trees you are able to gain global knowledge of the multicast groups from an initial local knowledge, which makes the spanning trees appealing. in order to modify the link state routing to construct a spanning tree for multicasting you can use the normal procedure of the link state routing but also add the information on the multicast groups. with that each is calculates its own multicast trees with the locally available information. then based on the information about the multicast tree it determines which paths to use for transmitting packets.",
        "original_sample_id": "smp1074q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1108q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "- good property: not all roads between roads should be used. Therefore, the topology of the network will be simplified and the formation of the loop can be avoided. In other words, the accessibility of the network remains the same even though some links between routers are freed. - extended tree construction mechanism with routing of the state of the link: nodes will send its distance (or delay) to its neighbours periodically. then they can calculate the tree based on this information.",
        "answer_feedback": "the response correctly answers why using a spanning tree is desirable in multicast and broadcast. the provided explanation just partially states the original link-state algorithm,  which can only be used to create a unicast spanning-tree, not a multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "- good property: not all paths between the routes must be used. therefore, the network topology will be simplified and loop formation can be prevented. in other word, the reachability of network remains the same even though some links between routers are released. - mechanism to build spanning tree with link state routing: nodes will send its distance (or delay) to its neighbors periodically. then they can calculate the tree based on these information.",
        "original_sample_id": "smp1108q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1077q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The goal of multicasting is to achieve multiple - all in the case of broadcasting - other nodes in a network. an extension tree contains the minimum amount of hops to reach all destinations that makes it a perfect candidate for this purpose. in the link status routing, this tree is shared across all nodes. link status packages now also contain information about multicast groups. nodes now calculate separate trees that span depending on the new information from other nodes. now, we have an extension tree for each multicast group that can be used to send data on the shortest route.",
        "answer_feedback": "spanning trees are used for broadcasting because they are loop-free and hence, reduce duplicates, and do not necessarily contain paths with minimal hops. the explanation for the modification of the link-state algorithm to form a multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the goal of multicasting is to reach multiple - all in the case of broadcasting -other nodes in a network. a spanning tree contains the minimal amount of hops to reach all destinations which makes it a perfect candidate for this purpose.    \n\t\n\tin link state routing, this tree is shared across all nodes. link state packets now also contain information about the multicast groups. the nodes now calculate separate spanning trees depending on the new information from other nodes. now, we have a spanning tree for each multicast group which can be used to send the data on the shortest path.",
        "original_sample_id": "smp1077q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is degraded and simple, but is not always applicable.\nprivate conn designation\nprivate pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is riotous and simple, but is not always applicable.\nprivate conn recognition\nprivate pdu recognition",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug02smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is degenerate and childlike, but is not always applicable.\nindividual conn designation\nindividual pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0452q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "tsap is dissipated and elementary, but is not always applicable.\nindividual conn designation\nindividual pdu designation",
        "answer_feedback": "description missing for remaining two.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.5,
        "original_answer": "tsap is fast and simple, but is not always applicable.\nindividual conn identification\nindividual pdu identification",
        "original_sample_id": "smp0452q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1479q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggyback does only make sense if the liquidator has also data at hand, beyond protocol overhead, to be sent back to the liquidator in time with the potential ack message. otherwise piggyback makes no sense. in this instance a simple ack can be sent, without piggyback. this scenario is only useful in bidirectional channel with data traffic in both directions.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking does only make sense if the receiver has also data at hand, beyond protocol overhead, to be sent back to the receiver in time with the potential ack message. otherwise piggybacking makes no sense. in this case a simple ack can be sent, without piggybacking. this scenario is only useful in bidirectional channel with data traffic in both directions.",
        "original_sample_id": "smp1479q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0352q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1:(a, c, before)(a, b, before)(a, d, before) hub 2:(b, a, drop) already received(b, c, drop) already received(b, e, before)(c, b, drop) already received(c, a, drop) already received(d, a, drop) already received(d, c, drop) already received(d, f, before) hub 3:(e, b, drop) already received(e, c, drop) already received(e, f, drop) already received(e, g, drop) already received(f, d, drop) already received(f, c, drop) already received(f, e, drop) already received(f, g, drop) already received(g, e, drop) already received(g, e, drop) already received(g, f, drop) already received(g, f, drop) already received(g, h, before)",
        "answer_feedback": "n  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur and reasoning needs to be provided. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:(a, c, forward)(a, b, forward)(a, d, forward)hop 2:(b, a, drop) already received(b, c, drop) already received(b, e, forward)(c, b, drop) already received(c, a, drop) already received(c, d, drop) already received(d, a, drop) already received(d, c, drop) already received(d, f, forward)hop 3:(e, b, drop) already received(e, c, drop) already received(e, f, drop) already received(e, g, drop) already received(f, d, drop) already received(f, c, drop) already received(f, e, drop) already received(f, g, drop) already receivedhop 4:(g, e, drop) already received(g, f, drop) already received(g, h, forward)",
        "original_sample_id": "smp0352q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0803q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "seq issue, ack issue, hl/resv/flagstone, selection are only in the tcp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the terms hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "seq number, ack number, hl/resv/flags, options are only in the tcp header.",
        "original_sample_id": "smp0803q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0231q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. step: queue: service of 10 packages: service of 10 packages 2. step: service of 9 packages: service of 10 packages 3. step: service of 9 packages: service of 9 packages 4. step: service of 9 packages: service of 9 packages and so on. if always arrives 9 packages per second and the server can serve a maximum of 10 packages per second, there will never be 10 packages in the queue except in the first step.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. step:\nqueue: 10 packets\nservice: 10 packets\n\n2. step:\nqueue: 9 packets\nservice: 10 packets\n\n3.step:\nqueue: 9 packets\nservice: 9 packets\n\n4. step:\nqueue: 9 packets\nservice: 9 packets\n\nand so on. if there will always arrive 9 packets per second and the server can serve maximum 10 packets per second, there will never be 10 packets in the queue except in the first step.",
        "original_sample_id": "smp0231q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0231q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. step: queue: service of 10 packages: service of 10 packages 2. step: service of 9 packages: service of 10 packages 3. step: service of 9 packages: service of 9 packages 4. step: service of 9 packages: service of 9 packages and so on. if always arrives 9 packages per second and the server can serve a maximum of 10 packages per second, there will never be 10 packages in the queue except in the first step.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "1. step:\nqueue: 10 packets\nservice: 10 packets\n\n2. step:\nqueue: 9 packets\nservice: 10 packets\n\n3.step:\nqueue: 9 packets\nservice: 9 packets\n\n4. step:\nqueue: 9 packets\nservice: 9 packets\n\nand so on. if there will always arrive 9 packets per second and the server can serve maximum 10 packets per second, there will never be 10 packets in the queue except in the first step.",
        "original_sample_id": "smp0231q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0246q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "9 * 60 = 540 bundle arrive in 1 minute\n10 * 60 = 600 bundle can be processed in 1 minute\n\nbased on the effrontery that the bundle arrive uniformly distributed in the minute (i.e. 9 bundle per second) and we can process 10 bundle per second, this means that the scheme is busy in 90 % of the time with processing the bundle. in 10 % of the time the scheme has no bundle to process. \nsince the scheme can process more bundle in a second than we expect to arrive in a second, the scheme will be in a state with less than 10 bundle waiting in the queue for the whole time.",
        "answer_feedback": "the description to justify the system waiting time is missing in the response. additionally, the system does not stay in a less than 10 packets state for a whole minute, only 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "9 * 60 = 540 packets arrive in 1 minute\n10 * 60 = 600 packets can be processed in 1 minute\n\nbased on the assumption that the packets arrive uniformly distributed in the minute (i.e. 9 packets per second) and we can process 10 packets per second, this means that the system is busy in 90 % of the time with processing the packets. in 10 % of the time the system has no packets to process. \nsince the system can process more packets in a second than we expect to arrive in a second, the system will be in a state with less than 10 packets waiting in the queue for the whole time.",
        "original_sample_id": "smp0246q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0246q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "9 * 60 = 540 bundle arrive in 1 minute\n10 * 60 = 600 bundle can be processed in 1 minute\n\nbased on the supposal that the bundle arrive uniformly distributed in the minute (i.e. 9 bundle per second) and we can process 10 bundle per second, this means that the organisation is busy in 90 % of the time with processing the bundle. in 10 % of the time the organisation has no bundle to process. \nsince the organisation can process more bundle in a second than we expect to arrive in a second, the organisation will be in a state with less than 10 bundle waiting in the queue for the whole time.",
        "answer_feedback": "the description to justify the system waiting time is missing in the response. additionally, the system does not stay in a less than 10 packets state for a whole minute, only 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "9 * 60 = 540 packets arrive in 1 minute\n10 * 60 = 600 packets can be processed in 1 minute\n\nbased on the assumption that the packets arrive uniformly distributed in the minute (i.e. 9 packets per second) and we can process 10 packets per second, this means that the system is busy in 90 % of the time with processing the packets. in 10 % of the time the system has no packets to process. \nsince the system can process more packets in a second than we expect to arrive in a second, the system will be in a state with less than 10 packets waiting in the queue for the whole time.",
        "original_sample_id": "smp0246q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "An important feature of the fish distribution is that the probability of x taking a discrete value is independent of the previous values, i.e. the probability is independent of the past. Fish distribution is often used to model the arrival of packages over an interval. The arrival times of the package modelled by the fish distribution have an exponential distribution and constitute an independent process distributed identically. However, in practice, it has been shown that the arrival times of the package do not have exponential distribution, hence the error introduced by the modeling as a fish distribution is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in recitation it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug02smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in practice it has been express that the packet inter-arrival times do not have an exponential dispersion, hence the error infix by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug03smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "An important feature of the fish distribution is that the probability of x taking a discrete value is independent of the previous values, i.e. the probability is independent of the past. Fish distribution is often used to model the arrival of packages over an interval. The arrival times of the package modelled by the fish distribution have an exponential distribution and constitute an independent process distributed identically. However, in practice, it has been shown that the arrival times of the package do not have exponential distribution, hence the error introduced by the modeling as a fish distribution is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug04smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a discrete value is sovereign upon the previous values i.e. the probability is sovereign of the past. poisson dispersion is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson dispersion have an exponential dispersion and nominate an sovereign identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by modeling them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug05smp0885q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "an important characteristic of the poisson dispersion is that the probability of x taking a distinct value is independent upon the previous values i.e. the probability is independent of the past. poisson dispersion is often used to mold arrival of packets during an interval. the packet arrival times molded by the poisson dispersion have an exponential dispersion and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential dispersion, hence the error introduced by molding them as poisson dispersion is significantly large.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals at the same node for real internet traffic. however, the response states an explanation of the error introduced while modelling the packet arrival using poisson distribution due to non-exponential distributions.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "an important characteristic of the poisson distribution is that the probability of x taking a discrete value is independent upon the previous values i.e. the probability is independent of the past. poisson distribution is often used to model arrival of packets during an interval. the packet arrival times modeled by the poisson distribution have an exponential distribution and constitute an independent identically distributed process. however, in practice it has been shown that the packet inter-arrival times do not have an exponential distribution, hence the error introduced by modeling them as poisson distribution is significantly large.",
        "original_sample_id": "smp0885q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1088q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "This is favorable for transmission and multicasting because it limits the number of packages-copies and avoids loops. each is transmissions is local link status information periodically to all others is. the information is distributed in packets and contains the distance to neighbors as well as the information about multicast groups (each one knows which group it belongs to)! then each one is has all the link status information and calculates the multicast tree.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees allows to reach all other nodes of a network with a small subset of links. this is favorable for broadcasting and multicasting because it limits the number of packet-copies and prevents loops. each is broadcasts it’s local link state info periodically to all other is. the info is distributed in packets and contains the distance to the neighbors as well as the info on multicast groups (each is knows to which group it belongs to)! then each is has all the link state info and calculates the multicast tree.",
        "original_sample_id": "smp1088q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug02smp1521q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a demand is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the windowpane size should be smaller than a half of seq. figure.",
        "answer_feedback": "it is correct that a duplex connection is a must. however, when the two sides' data is imbalanced, a dedicated timer timeout is used to send acknowledgments independently. the other points are related to the sliding window protocol in general.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a requirement is that we have an duplex connection and a cos or ccs.\nthe data from two side is roughly equal. the window size should be smaller than a half of seq. number.",
        "original_sample_id": "smp1521q024",
        "is_augmented": "true",
        "question_id": "q024",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1661q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "for software: 0.0.0.0 - 0.255.255,255 used for local communications within a private network: 10.0.0 - 10.255,255,255 used for loopback addresses to the local host: 127.0.0 - 127.255,255,255 for the international shared public address space system for communications between a service provider: 100.64.0.0–100.127,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "for software: 0.0.0.0 - 0.255.255.255\nused for local communications within a private network: 10.0.0.0 - 10.255.255.255 \n\nused for loopback addresses to the local host: 127.0.0.0 - 127.255.255.255\n\nfor international system of public \n\nshared address space for communications between a service provider： 100.64.0.0–100.127.255.255",
        "original_sample_id": "smp1661q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can estimate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 mailboat is 1-pb. based on the 1 minute monitoring time we can get the consequence 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. accord to the limited fender size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. establish on the 1 minute monitoring time we can get the result 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0214q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s the average rate of arrival is 9 and the average rate of service is 10. depending on the limited size of buffer 10 we can calculate pb, which means the probability that the system is full. so the probability that there are less than 10 packages is 1-bp. based on the 1 minute monitoring time we can get the result 57s.",
        "answer_feedback": "the response correctly states the steps required to calculate the non-blocking time and the obtained time. however, it is not clear how the end result was obtained; that is what mathematical operation was performed between 1-pb and 1 minute.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s.",
        "original_sample_id": "smp0214q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own cross tree but is do not demand to know the cross trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own cross tree but is do not need to fuck the cross trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp1043q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "each transmitter has its own spanning tree but is do not need to bonk the spanning trees each router has information which way it would use for (unicast)-packets because of the unicast routing algorithms",
        "answer_feedback": "the response is incomplete as it does not mention where the provided incomplete information is used in, rpf or rpb. the purpose of using them is also not mentioned.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "each sender has its own spanning tree but is do not need to know the spanning trees each router has information which path it would use for (unicast)-packets because of the unicast routing algorithms",
        "original_sample_id": "smp1043q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1656q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 - 0.255.255.255 earmark for current host or meshwork\n\n10.0.0.0 - 10.255.255.255 earmark for individual (sub)net\n\n127.0.0.0 - 127.255.255.255 earmark for localhost (loopback)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0 - 0.255.255.255 reserved for current host or network\n\n10.0.0.0 - 10.255.255.255 reserved for private (sub)net\n\n127.0.0.0 - 127.255.255.255 reserved for localhost (loopback)",
        "original_sample_id": "smp1656q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1017q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective is to ensure a free rotation of the multicast packages. Inverse return: when the package arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have sent the package on all the edges except the incoming edge. If this is not the case, we have excluded the package, because it is probably a double. Inverse forwarding: when the packet arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have checked whether the package used the best route so far. If this is the best route we have chosen the edge on which the packets arrived and from which they are redirected to the station. if this is not the best route contrary to rpf we have not sent the package on all the edges. when the packet did not arrive at the entrance we have excluded the package because it is probably a double.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types except that the purpose is not limited to only mutlicast but also used in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to ensure a loop-free forwarding of multicast packets. reverse path forwarding: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we resend the packet over all edges except the incoming edge. if thats not the case we discard the packe, because its probably a duplicate. reverse path broadcast: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we check if the packet used the best route until now. if its the best route we select the edge at which the packets arrived and from which they are then rerouted to the station. if its not the best route on the contrary to rpf we don't send the packet over all edges. when the packet didn't arrive at the is entry we discard the packet, because its probably a duplicate.",
        "original_sample_id": "smp1017q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1017q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective is to ensure a free rotation of the multicast packages. Inverse return: when the package arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have sent the package on all the edges except the incoming edge. If this is not the case, we have excluded the package, because it is probably a double. Inverse forwarding: when the packet arrived at the port of entry, on which the packets for this station are also sent in the usual way, we have checked whether the package used the best route so far. If this is the best route we have chosen the edge on which the packets arrived and from which they are redirected to the station. if this is not the best route contrary to rpf we have not sent the package on all the edges. when the packet did not arrive at the entrance we have excluded the package because it is probably a double.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types except that the purpose is not limited to only mutlicast but also used in broadcast.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose is to ensure a loop-free forwarding of multicast packets. reverse path forwarding: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we resend the packet over all edges except the incoming edge. if thats not the case we discard the packe, because its probably a duplicate. reverse path broadcast: when the packet arrived at the is entry port, over which the packets for this station are usally also sent, we check if the packet used the best route until now. if its the best route we select the edge at which the packets arrived and from which they are then rerouted to the station. if its not the best route on the contrary to rpf we don't send the packet over all edges. when the packet didn't arrive at the is entry we discard the packet, because its probably a duplicate.",
        "original_sample_id": "smp1017q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0838q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the network load varies. for exemplar look on time and day there may be more or less traffic (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of traffic: for exemplar some video streaming applications produce a bursty traffic, if they buffer the video to some extend (which means continous traffic load), pause after the buffer is full (no load), and then continue after a certain buffer threshold.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the network load varies. for example depending on time and day there may be more or less traffic (i.e. evening vs. morning, days before work days vs work-free days, etc.). another factor can be the type of traffic: for example some video streaming applications produce a bursty traffic, if they buffer the video to some extend (which means continous traffic load), pause after the buffer is full (no load), and then continue after a certain buffer threshold.",
        "original_sample_id": "smp0838q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0828q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header is shorter than the tcp header. the udp header has the sender port, the receiving port, the package length and the check sum. the tcp header also has a sender port, the destination port, and the check sum, but it does not have a package length. it also has a sequence number, recognition number, data compensation, a \"reserved\" field, control windows, the urgent pointer and a choice field. in other words, both protocols make use of different types of headers to transmit their data. the udp headers contain information only about the required functions and therefore are 8 bytes in length. the tcp headers contain mandatory and optional features resulting in 20 bytes and 60 bytes (heading allows up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tap. tcp headers cannot guarantee the delivery of data and 60 bytes (heading allows up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tap. the tcp headers cannot guarantee the delivery of data and 60 bytes (heading up to 40 bytes for options).",
        "answer_feedback": "the response is correct, but apart from the differences between the tcp and udp headers, it also contains general differences between the two transport layer protocols, which were not required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp header is shorter than the tcp header. the udp header has the sender port, receiver port, packet length, and checksum. the tcp header also has a sender port, destination port, and the checksum but doesnt have a packet length. it also has a sequence number, acknowledgment number, the data offset, a \"reserved\" field, control fields, receive windows, the urgent pointer, and a field for options. in other words, both protocols make use of different types of headers to transmit their data. udp headers contain information only about the necessary functions and are therefore 8 bytes in length. tcp headers contain both mandatory and optional features resulting in 20 bytes and 60 bytes (header allows for up to 40 bytes for options) in length without and with options, respectively. udp is less robust than tcp. it cannot guarantee the delivery of the data, and the packets can get lost or corrupt. tcp, on the other hand, tracks and error-checks its streams of data and is therefore reliable. because udp has only limited functions and doesnt perform many features such as error correction, it is faster than tcp. further, tcp can handle flow control, whereas udp doesnt have the required option.",
        "original_sample_id": "smp0828q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0831q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp has has sequence issue, udp does not\n\nthere are acknowledgment issue in tcp \n\ntcp has a advertisemed win header\n\ntcp has a urgent arrow",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp has has sequence numbers, udp does not\n\nthere are acknowledgement numbers in tcp \n\ntcp has a advertisemed win header\n\ntcp has a urgent pointer",
        "original_sample_id": "smp0831q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0854q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the arriver are dependent from each other in terms of network state. for example, if a link go, the likelihood that the next bundle will not arrive is high if the last sent bundle also did not. reason for that is that in this case the link failure prevented the last bundle from arriving and it is likely that the next bundle will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the given example may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the arrivals are dependent from each other in terms of network state. for example, if a link fails, the likelihood that the next packet will not arrive is high if the last sent packet also did not. reason for that is that in this case the link failure prevented the last packet from arriving and it is likely that the next packet will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "original_sample_id": "smp0854q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0854q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because the arrivals are dependent on each other in terms of network status. e.g., if a link fails, the probability that the next package will not arrive is high if the last package sent does not have it either. reason why in this case the link failure prevented the last package from arriving and it is likely that the next package will take the same route. therefore, it would probably also be abandoned at this failed link. even applies to the complete nodes buffers located on a road.",
        "answer_feedback": "the response is correct about the packets being dependent on each other. while the given example may be true, it is more of a pathological case and doesn’t reflect an inherent shortcoming of the model that makes the assumption false.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because the arrivals are dependent from each other in terms of network state. for example, if a link fails, the likelihood that the next packet will not arrive is high if the last sent packet also did not. reason for that is that in this case the link failure prevented the last packet from arriving and it is likely that the next packet will take the same route. hence, it probably would also be dropped at that failed link. same applies to full buffers of nodes lying on a route.",
        "original_sample_id": "smp0854q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diam is the aloofness between two locations/nodes. when increasing the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision field diam is the distance between two locations/knob. when increasing the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug05smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localisation/nodes. when increase the speed the maximum distance between two localisation has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug06smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision sphere diameter is the distance between two locations/node. when increasing the speed the maximal distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug09smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the aloofness between two locations/nodes. when increasing the speed the maximal aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug10smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two locations/thickening. when increasing the hurrying the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug11smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the space between two locations/nodes. when increasing the speed the maximum space between two locations has to cringe.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug12smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug13smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug15smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the length between two locations/thickening. when increasing the speed the maximum length between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug16smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the space between two locations/nodes. when increase the speed the maximum space between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug17smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the space between two locations/nodes. when increasing the amphetamine the maximum space between two locations has to reduce.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug18smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two location/nodes. when increasing the swiftness the maximum distance between two location has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug21smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increasing the speed the maximum aloofness between two locations has to wither.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug22smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the aloofness between two locations/knob. when increasing the speed the maximal aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug23smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two locations/knob. when increase the swiftness the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug24smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision area diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug25smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug27smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug29smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter of the collision area is the distance between two locations/nodes. By increasing the speed, the maximum distance between two locations must be reduced.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug30smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is the distance between two location/nodes. when increasing the swiftness the maximum distance between two location has to squinch.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug31smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localization/nodes. when increasing the speed the maximum distance between two localization has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug32smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug33smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the distance between two localization/nodes. when increasing the speed the maximum distance between two localization has to wither.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug34smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug35smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision sphere diameter is the space between two locations/thickening. when increasing the speed the maximum space between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug36smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug37smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two fix/nodes. when increasing the speed the maximum aloofness between two fix has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug38smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diameter is the distance between two locations/thickening. when increasing the speed the maximal distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug39smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diam is the aloofness between two locations/nodes. when increase the speed the maximum aloofness between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug40smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision orbit diameter is the distance between two localisation/nodes. when increasing the speed the maximum distance between two localisation has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug42smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision area diameter is the distance between two positioning/nodes. when increasing the speed the maximum distance between two positioning has to quail.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug43smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increasing the speeding the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug44smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision demesne diameter is the distance between two locations/nodes. when increase the velocity the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug45smp1268q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the hit domain diam is the distance between two locations/nodes. when increase the speed the maximum distance between two locations has to shrink.",
        "answer_feedback": "the response explains what a collision domain diameter is and that it shrinks with increasing speed. that only partially answers the question as the magnitude of reduction is missing. the correct answer is that the diameter decreases by a factor of 10, for example, from 300m to 30m.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the collision domain diameter is the distance between two locations/nodes. when increasing the speed the maximum distance between two locations has to shrink.",
        "original_sample_id": "smp1268q020",
        "is_augmented": "true",
        "question_id": "q020",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0382q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:\n(a, b, frontwards)\n(a, c, frontwards)\n(a, d, drop) <= node d doesn't receive parcels to a\nhops 2:\n(b, e, frontwards)\n(c, f, drop) <= node f doesn't receive parcels to a\nhops 3:\n(e, g, frontwards)\nhops 4:\n(g, h, drop) <= no other nodes to send the parcel to",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= node d doesn't receive packets to a\nhop 2:\n(b, e, forward)\n(c, f, drop) <= node f doesn't receive packets to a\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= no other nodes to send the packet to",
        "original_sample_id": "smp0382q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0863q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "it is not realistic because the amount of traffic is different at different times of the day. another example are the buffers for example video streaming where several packages are sent followed by a pause until the next package train.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it is not realistic because the amount of traffic is different at different times of the day. another example are buffers e.g. video streaming where several packets are send followed by a break until the next train of packets.",
        "original_sample_id": "smp0863q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1679q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00.0/810.0.0.0/8100.64.0.0/10127.0.0.0.0/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/810.0.0.0/8100.64.0.0/10127.0.0.0/8",
        "original_sample_id": "smp1679q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1056q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property: a cross tree has a route to each router without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. based on that information each is can locally calculate a cross tree for themselves.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property: a spanning tree has a route to each routers without any loops defined. explanation: the link state packets are expanded by information on multicast groups. that way each is knows it's distance to all other is and which is is part of which multicast group. based on that information each is can locally calculate a spanning tree for themselves.",
        "original_sample_id": "smp1056q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0840q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this effrontery does not halt for real internet traffic, since when we are watching a video, for example, we need to receive the packets, so we need the probability a packet to be delivered to be 1 and not 0. if we are not watching we need the probability to be 0. and a part from this when we are watching a video, we get a bunch of packets, then there is a higher probability that we receive also the next packets.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold for real internet traffic, since when we are watching a video, for example, we want to receive the packets, so we want the probability a packet to be delivered to be 1 and not 0. if we are not watching we want the probability to be 0. and a part from this when we are watching a video, we get a bunch of packets, then there is a higher probability that we receive also the next packets.",
        "original_sample_id": "smp0840q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1671q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0,0,0,0,0,2552,255 10,0,0,055 10,255,255 100,64,0,0,05,100,127,255,255 127,0,0,0,07,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "original_sample_id": "smp1671q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp0237q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "in this case the system will be for the whole time in a state, in which there are less than 10 mailboat waiting in the queue, due to the fact that there are always more mailboat processed pro second than arriving.\nutilisation = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of mailboat in the system\nn =  utilisation / 1 - utilisation which gives = 9 mailboat\nwe can also calculate the probability, that the system is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a outcome. because the utilisation ist the same at every time, the probability that the system is full remains equally.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time as was done for p_10. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "in this case the system will be for the whole time in a state, in which there are less than 10 packets waiting in the queue, due to the fact that there are always more packets processed pro second than arriving.\nutilisation = arrival rate / service rate = 9 pkts/s / 10 pkts/s = 0.9\nn - average number of packets in the system\nn =  utilisation / 1 - utilisation which gives = 9 packets\nwe can also calculate the probability, that the system is full: p_10 = (1-p)*p^10 / (1-p^11) we get 0.05 as a result. because the utilisation ist the same at every time, the probability that the system is full remains equally.",
        "original_sample_id": "smp0237q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1010q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective of restarting the reverse route (rpf) and retransfering the reverse route (rpb) is to guarantee the most efficient way to re-send the information of any sender to any receiving terminal, thus providing the best possible loopless extension tree for each transmitting terminal. using the most efficient means rpf and rpb to reduce the number of packages required for broadcasting. in rpf each router must have information about the route he would use for unicast-packages. when a package arrives at the entrance, one will wonder whether the packages are also sent by that station for that source. Yes, then the package will use the best route so far and will be felt on all edges (except for revenue). Otherwise, the package does not use the best route and will throw itself. Therefore, the most efficient form is established, but rpf still requires re-allocation on all edges, which costs a great bandwidth capacity. in rpb is not re-placed on all edges.",
        "answer_feedback": "the response correctly answers all three parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) and reverse path broadcast (rpb) is to guarantee the most efficient way to forward information from any sender to any receiver terminal, thus providing the best possible loop-free spanning tree for each sender terminal. by using the most efficient way rpf and rpb reduce the number of packets needed for broadcasting. in rpf each router must have information which path it would use for unicast-packets. when a packet arrives at the is entry, it will be asked whether packets are normally also sent over this station for this source. if yes, then the packet will use the best route so far and will be resent over all edges (except the income one). if not, the packet does not use the best route and is discarded. therefore, the most efficient way is then established, but rpf always requires a resend over all edges, which costs a lot of bandwidth capacity.     in rpb is no resend over all edges. when the packet arrives at the is entry, it will be asked whether the packets are normally also sent over this station for this specific source. if yes the edge will be selected at which the packets arrived and from which they are then rerouted to the specific source (in reversed direction). if not, the packet gets discarded.",
        "original_sample_id": "smp1010q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1010q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the objective of restarting the reverse route (rpf) and retransfering the reverse route (rpb) is to guarantee the most efficient way to re-send the information of any sender to any receiving terminal, thus providing the best possible loopless extension tree for each transmitting terminal. using the most efficient means rpf and rpb to reduce the number of packages required for broadcasting. in rpf each router must have information about the route he would use for unicast-packages. when a package arrives at the entrance, one will wonder whether the packages are also sent by that station for that source. Yes, then the package will use the best route so far and will be felt on all edges (except for revenue). Otherwise, the package does not use the best route and will throw itself. Therefore, the most efficient form is established, but rpf still requires re-allocation on all edges, which costs a great bandwidth capacity. in rpb is not re-placed on all edges.",
        "answer_feedback": "the response correctly answers all three parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the purpose of reverse path forwarding (rpf) and reverse path broadcast (rpb) is to guarantee the most efficient way to forward information from any sender to any receiver terminal, thus providing the best possible loop-free spanning tree for each sender terminal. by using the most efficient way rpf and rpb reduce the number of packets needed for broadcasting. in rpf each router must have information which path it would use for unicast-packets. when a packet arrives at the is entry, it will be asked whether packets are normally also sent over this station for this source. if yes, then the packet will use the best route so far and will be resent over all edges (except the income one). if not, the packet does not use the best route and is discarded. therefore, the most efficient way is then established, but rpf always requires a resend over all edges, which costs a lot of bandwidth capacity.     in rpb is no resend over all edges. when the packet arrives at the is entry, it will be asked whether the packets are normally also sent over this station for this specific source. if yes the edge will be selected at which the packets arrived and from which they are then rerouted to the specific source (in reversed direction). if not, the packet gets discarded.",
        "original_sample_id": "smp1010q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this mesh to encode bitstreams. this is because manchester and differential manchester encoding scheme occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the mesh being choke.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encode needs to be used in this web to encode bitstreams. this is because manchester and differential manchester encode schemes occupy twice as much as bandwidth as the binary encode scheme. so this in turn result to the web being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug05smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding dodging occupy twice as much as bandwidth as the binary encoding scheme. so this in go extend to the network being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug07smp0133q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encode needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encode schemes occupy twice as much as bandwidth as the binary encode scheme. so this in bend lead to the network being congested.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the better bandwidth efficiency provided",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding needs to be used in this network to encode bitstreams. this is because manchester and differential manchester encoding schemes occupy twice as much as bandwidth as the binary encoding scheme. so this in turn leads to the network being congested.",
        "original_sample_id": "smp0133q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the guileless bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the web. that means the guileless bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the guileless bridge floods the web with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the web.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the filmy bridge receives every frame of each connected side. the bridge board holds the information about which components are attached to the network. that entail the filmy bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the filmy bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the crystalline bridge receives every figure of each connected side. the bridge table holds the information about which components are attached to the network. that means the crystalline bridge receives from the component a a figure which has the information \"a can be reached over lan l.\" in the forwarding process, the crystalline bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent bridge receives each frame on each connected side. the bridge table contains information about the components that are connected to the network. which means that the transparent bridge receives from the component a frame that has the information \"can be reached on the lan l.\" in the turning process, the transparent bridge floods the network with this information, so that other bridges also have information about the component a. a benefit of flooding is that it uses the shortest path of the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the guileless bridge receives every frame of each connected side. the bridge table holds the information about which parts are bind to the network. that means the guileless bridge receives from the part a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the guileless bridge floods the network with this information, so that other bridges also have the information about part a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the limpid bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the limpid bridge receives from the component a a frame which has the information \"a can be strain over lan l.\" in the forwarding process, the limpid bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent nosepiece receives every frame of each connected side. the nosepiece table agree the information about which components are attached to the network. that means the transparent nosepiece receives from the component a a frame which has the information \"a can be strain over lan l.\" in the forwarding process, the transparent nosepiece floods the network with this information, so that other nosepieces also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every frame of each connected side. the span table holds the entropy about which components are attached to the network. that means the transparent span receives from the component a a frame which has the entropy \"a can be pass over lan l.\" in the forwarding process, the transparent span floods the network with this entropy, so that other spans also have the entropy about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug08smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent bridge receives each frame on each connected side. the bridge table contains information about the components that are connected to the network. which means that the transparent bridge receives from the component a frame that has the information \"can be reached on the lan l.\" in the turning process, the transparent bridge floods the network with this information, so that other bridges also have information about the component a. a benefit of flooding is that it uses the shortest path of the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug09smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the gauzy bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the gauzy bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the gauzy bridge floods the network with this information, so that other bridges also have the information about component a. a welfare of flooding is that it uses the brusk path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug10smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every frame of each connected side. the span table holds the information about which components are attached to the meshing. that means the transparent span receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent span floods the meshing with this information, so that other spans also have the information about component a. a benefit of flooding is that it uses the shortest path in the meshing.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug11smp0901q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the transparent span receives every physique of each connected side. the span table holds the information about which factors are attached to the network. that means the transparent span receives from the factor a a physique which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent span floods the network with this information, so that other spans also have the information about factor a. a benefit of flooding is that it uses the shortest path in the network.",
        "answer_feedback": "the bridge table does not contain component information. the response does not mention how the information \"a can be reached over lan l\" is used in backward learning and selective forwarding. the stated benefit is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the transparent bridge receives every frame of each connected side. the bridge table holds the information about which components are attached to the network. that means the transparent bridge receives from the component a a frame which has the information \"a can be reached over lan l.\" in the forwarding process, the transparent bridge floods the network with this information, so that other bridges also have the information about component a. a benefit of flooding is that it uses the shortest path in the network.",
        "original_sample_id": "smp0901q014",
        "is_augmented": "true",
        "question_id": "q014",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0373q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1:de a:(a, b, before)(a, c, before)(a, d, fall) // d is not on the unicast path from c to a and f to a. hops 2:de b:(b, e, before)de c:(c, f, fall) // f is not on the unicast path from d, e or g to a hops 3:de e:(e, g, before) hops 4:de g:(g, h, fall) // h is not connected to other nodes (except the receiver node)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:from a:(a, b, forward)(a, c, forward)(a, d, drop) // d is not on unicast path from c to a and f to a.\nhop 2:from b:(b, e, forward)from c:(c, f, drop) // f is not on unicast path from d, e or g to a\nhop 3:from e:(e, g, forward)\nhop 4:from g:(g, h, drop) // h is not connected to further nodes (except the receiving node)",
        "original_sample_id": "smp0373q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow mastery on transport level\n\nrecognition mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-room handshake protocol\n+ ds\n- \n\nflow command on transport layer\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncurrent mastery on rapture layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on shipping level\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-manner handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncatamenia control on transferral bed\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on exaltation level\n\nreference mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on shipping stratum\n\nmention mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug08smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncatamenia control on exaltation bed\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug09smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-agency handshake protocol\n+ ds\n- \n\nmenses control on raptus layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug10smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflowing control on rapture layer\n\ncredit mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug11smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-fashion handshake protocol\n+ ds\n- \n\ncatamenia control on transport stratum\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug12smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow ascendence on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug13smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on transport stratum\n\nquotation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug14smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on shipping bed\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug15smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-room handshake protocol\n+ ds\n- \n\nflow control on transport stratum\n\nquotation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug16smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow controller on transport bed\n\ncitation mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug17smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-fashion handshake protocol\n+ ds\n- \n\nmenstruum control on transportation layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug18smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nperiod control on transport layer\n\nrecognition mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug19smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nflow ascendency on raptus layer\n\ncredit mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug20smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-mode handshake protocol\n+ ds\n- \n\nmenstruum controller on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug21smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\ncurrent control on transportation layer\n\nrecognition mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug22smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nperiod control on transport layer\n\ncitation mechanics\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug23smp0438q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "three-way handshake protocol\n+ ds\n- \n\nmenstruum control on transport level\n\ncite mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "answer_feedback": "the response is incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.5,
        "normalized_score": 0.0,
        "original_answer": "three-way handshake protocol\n+ ds\n- \n\nflow control on transport layer\n\ncredit mechanism\n+ \n-\nmultiplexing / demultiplexing\n+\n-",
        "original_sample_id": "smp0438q006",
        "is_augmented": "true",
        "question_id": "q006",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1014q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The inverted road shuttle ensures a free loop rotation for multicast multicast packets in multicast routing, in addition to avoiding the replacement of IP addresses on a unicat routing. It works by returning the packet away from the sources to move along the distribution tree and preventing routing loops. Retransmission of inverted routes works at the reception of a multicast package, then a router records the original address of the package and the port in which the package arrives.",
        "answer_feedback": "the response is partially correct. the purpose for only rpf is stated and is also not in the context of the broadcast. the explanation for rpf  and rpb is not complete as the response does not explain how packets are forwarded and based on what information.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.1,
        "original_answer": "reverse path forwarding ensures a loop-free forwarding for multicast packets in multicast routing moreover, it prevents ip address spoofing in a unicast routing. it works by forwarding the packet away from the sources to make progress along the distribution tree and prevents routing loops.  reverse path broadcast works by receiving a multicast packet, then a router records the source address of the packet and the port the packet arrives on.",
        "original_sample_id": "smp1014q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug02smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 byte, the maximum collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 time.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug05smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 bytes, the maximal collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increase 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug07smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the minuscule package is at least 64 byte, the maximum collision domain diameter is calculated by the time it takes for the minuscule package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 byte/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug14smp1240q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "since the smallest parcel is at least 64 bytes, the maximum collision domain diameter is calculated by the time it deal for the smallest parcel to locomote at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "answer_feedback": "the answer is incorrect as it states that the collision domain diameter increases 100 times, but for collisions to be detected, the diameter decreases by a factor of 10. for example, from 1000m to 100m.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "since the smallest package is at least 64 bytes, the maximum collision domain diameter is calculated by the time it takes for the smallest package to travel at a certain speed. thus, at 10 mb/s = 1x10^7 bytes/s, 64/1x10^7 = 6.4x10^-6 s while on 100mb/s, 64/100x10^7 = 6.4 x 10^-8 s. thus the collision domain diameter is increased 100 times.",
        "original_sample_id": "smp1240q020",
        "is_augmented": "true",
        "question_id": "q020"
    },
    {
        "id": "aug00smp1683q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127).0.0 (0-127).255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0\n(0-127).255.255.255",
        "original_sample_id": "smp1683q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1683q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "(0-127).0.0 (0-127).255,255,255",
        "answer_feedback": "missing loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "(0-127).0.0.0\n(0-127).255.255.255",
        "original_sample_id": "smp1683q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1084q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "These paths are unicast. This property can be used to define a range tree, which contains everything that participates in a multicast group. If a wide/multicast is then sent to one of the nodes, it will distribute the data to all the other nodes in the range tree. These range trees can be calculated with the routing of the link state use the best path (the shortest, the smallest delay, the highest bandwidth, etc.) specific for data transfer. For multicast, the participating nodes all have the same tree of reach (perhaps also other trees) so that it does not matter to which the multicast node is sent, it will always reach each node in the group. for scattering, this range tree simply includes each node in the network.",
        "answer_feedback": "the response is partially correct because it lacks how the link-state routing can be modified to construct the multicast tree. to calculate the spanning trees, you also have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees are individual for every is and are initially not known to other is.  they represent a subnetwork, with one fixed path from this is to every other node in this subnet. these paths are unicast paths. this property can be used to define a spanning tree, which contains all is that participate in a multicast group. if a broad/multicast is then sent to one of the nodes, it will distribute the data to every other node in the spanning tree. these spanning trees can be calculated with link state routing use the best path (shortest, smallest delay, highest bandwidth etc.) specific for data transfer. for multicast, the participating nodes all have the same spanning tree (maybe also other trees) so it does not matter to which node the multicast is sent, it will always reach every node in the group. for broadcasting, this spanning tree simply includes every node in the network.",
        "original_sample_id": "smp1084q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0461q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "throw-away tsaps:\nrestrict packet life time:\na meshwork monitoring shift:\nadvantage: meshwork monitoring shiftes facilitate centralizing meshwork traffic monitoring in the noc.\ndisadvantage: meshwork monitoring shiftes take a simple concept, the passive meshwork tap, and make it an expensive, complex device that involve configuration and management.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service need to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17,
        "original_answer": "throw-away tsaps:\nrestrict packet life time:\na network monitoring switch:\nadvantage: network monitoring switches facilitate centralizing network traffic monitoring in the noc.\ndisadvantage: network monitoring switches take a simple concept, the passive network tap, and make it an expensive, complex device that requires configuration and management.",
        "original_sample_id": "smp0461q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1112q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The minimum calibration trees represent the minimum (shortest/lowest cost) connection of all nodes in the network. This is particularly useful for broadcasting/multicasting because we want to transmit packages to several destinations with minimal effort. Assuming that each node has information about the multicast groups to which it belongs, the lsr routing can be extended by including information from the mutlicast group in the periodic broadcasts of link-state packets.",
        "answer_feedback": "spanning trees do not necessarily contain the shortest path between all nodes, only the minimal number of edges. the unique paths between each node minimize the number of duplicates needed. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "minimal spanning trees represent the minimal (shortest/ lowest cost) connection of all nodes in the network. this is especially useful for broadcast/ multicast as we want to transmit packets to multiple destination with minimal effort. assuming that each node has information on the multicast groups it belongs to, lsr routing can be extended by including the mutlicast group information in the periodical link state packet broadcasts. based on this information received from every other node on the network, each node can calculate its own mutlicast tree to determine the routes, via which packets should be distributed.",
        "original_sample_id": "smp1112q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0209q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first, we have to calculate the probability where there are exactly 10 mailboat in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the meter (one minute, or 60 seconds) the system being in a state which there are exactly 10 mailboat waiting in the queue. the amount of this meter should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never outgo 10, then other than 10 mailboat waiting in the buffer, the system will have less than 10 mailboat waiting, and the amount of meter for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first, we have to calculate the probability where there are exactly 10 packets in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the time (one minute, or 60 seconds) the system being in a state which there are exactly 10 packets waiting in the queue. the amount of this time should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 packets waiting in the buffer, the system will have less than 10 packets waiting, and the amount of time for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "original_sample_id": "smp0209q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0209q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first, we have to calculate the probability where there are exactly 10 mailboat in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the land of the system for exactly one minute, then 5.0813731% of the clip (one minute, or 60 seconds) the system being in a land which there are exactly 10 mailboat waiting in the queue. the amount of this clip should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 mailboat waiting in the buffer, the system will have less than 10 mailboat waiting, and the amount of clip for this land would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "first, we have to calculate the probability where there are exactly 10 packets in the system, which is p_10 with the size of the buffer is limited at n=10. with that, we have this probability value equals to 0.050813731. \n\nsince we observe the state of the system for exactly one minute, then 5.0813731% of the time (one minute, or 60 seconds) the system being in a state which there are exactly 10 packets waiting in the queue. the amount of this time should be 3.04882388 seconds. \n\nsince the utilisation of this system is 0.9, the buffer never exceeds 10, then other than 10 packets waiting in the buffer, the system will have less than 10 packets waiting, and the amount of time for this state would be 60 - 3.04882388 = 56.95117612 seconds, or about 57 seconds.",
        "original_sample_id": "smp0209q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp1039q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "The main objective of reverse route forwarding and reverse route retransmission is to initiate router retransmission and reduce packet copies on the network. for reverse route forwarding each sender has its own forwarding tree, but it is not necessary to know the forwarding tree, so each router has information about the route it would use for packets (unicast). each one checks if a packet arrived at the input port is the input port on which the packets are usually sent for this station. if we can assume that the best route is used up to now and we can continue to send through all borders except the incoming one. if not, discard the packet. the reverse route retransmission is like re-shipment of inverse routes with a specific selection of outgoing links (instead of forwarding over all borders). the reverse route retransmission can learn by packets that do not appear on the unicat route and also learn by means of the unicat packets inspection that is found in the unicast route from the destination to the sender more copies that help to get rid.",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the main purpose of both reverse path forwarding and reverse path broadcast is router initiating broadcast and to reduce copies of packets in the network. for reverse path forwarding each sender has its own spanning tree but the is do not need to know the spanning tree hence each router has information which path it would use for (unicast)-packets. each is checks whether a packet arrived at the is entry port over which the packets for this station are usually sent. if so we can assume that the best route is used so far and we can continue sending over all edges except the incoming one. if not, discard the package. reverse path broadcast is like reverse path forwarding with specific selection of the outgoing links (instead of resending over all edges). reverse path broadcast can learn by packets failing to appear that it is not located on the unicast path and also learn by inspecting the unicast packets that it is located on the unicast path from destination to sender which helps to get rid of even more copies in the network compared to reverse path forwarding.",
        "original_sample_id": "smp1039q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0837q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no. typically users dont use internet overhaul continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in realism bundle may depend on other bundle e.g. with tcp traffic.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like non-continuous internet use over the day. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no. typically users dont use internet services continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "original_sample_id": "smp0837q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0837q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no. typically applyrs dont apply internet services continuesly throughout the whole day (and nighttime), but in relatively short bursts. so this framework would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like non-continuous internet use over the day. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no. typically users dont use internet services continuesly throughout the whole day (and night), but in relatively short bursts. so this model would not hold over this timescales. another reason is that in reality packages may depend on other packages e.g. with tcp traffic.",
        "original_sample_id": "smp0837q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1518q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the next successiveness-number and the next ack-successiveness-number to be expected must be given or computable. furthermore, the data physique have to consist of an ack discipline.",
        "answer_feedback": "the response answers the requirement correctly as a separate acknowledgment field is a must for piggybacking. the other points are more related to window sliding in general.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the next sequence-number and the next ack-sequence-number to be expected must be given or computable. furthermore, the data frames have to consist of an ack field.",
        "original_sample_id": "smp1518q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1018q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "If this is the case, there is no transfer to avoid loops. Inverse path routing (also referred to as reverse path flooding) (rpf) is a variation of the method tree. Each sender has its range tree. Other nodes do not have to know the range tree. the hypothesis is that each router knows which path he would use for packages. The rpf algorithm checks if a packet has arrived at the port of entry on which the packets of this station are usually also sent. If yes, then the algorithm assumes that the packet has gone the best path until a node reaches it first by the shortest route, everything that does not need to use the best route.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and broadcast are methods for broadcast routing. they enable improved flooding: it is checked whether a copy of a data unit has been received. if this is the case, no forwarding takes place to avoid loops. reverse path forwarding (also called reverse path flooding) (rpf) is a variation of the method spanning tree. each sender has its spanning tree. the other nodes don't have to know the spanning tree. the assumption is that each router knows which path it would use for packets.  the rpf algorithm checks whether a packet arrived at the is entry port over which the packets for this station are usually also sent. if yes, then the algorithm assumes the packet went the best path until now and resends the packet to all edges but the incoming one. if not, it assumes that the packet is a duplicate and didn't use the best route. this duplicate is then not forwarded but discarded. the significant advantage of this algorithm is its simple implementation. if a node assumes that a packet will reach it first by the shortest route, all that needs to be done is to ensure that a receiver can detect duplicates. as soon as a duplicate is received, it is assumed that the shortest route did not receive the packet, and it is not forwarded. the disadvantage of this method is that some nodes receive the packet unnecessarily several times. the reverse path broadcast (rpb) is like rpf but with a specific selection of outgoing links. after the first check, the algorithm checks if the packet used the best route until then. if yes, it selects the edge at which the packets arrived and from which they are then rerouted to source s. if not, it won't send over all edges. reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path concerning the interface on which the multicast packets are received but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to decide about forwarding, the routers must be informed about the shortest paths.",
        "original_sample_id": "smp1018q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1018q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "If this is the case, there is no transfer to avoid loops. Inverse path routing (also referred to as reverse path flooding) (rpf) is a variation of the method tree. Each sender has its range tree. Other nodes do not have to know the range tree. the hypothesis is that each router knows which path he would use for packages. The rpf algorithm checks if a packet has arrived at the port of entry on which the packets of this station are usually also sent. If yes, then the algorithm assumes that the packet has gone the best path until a node reaches it first by the shortest route, everything that does not need to use the best route.",
        "answer_feedback": "the response correctly explains the purpose and concepts of rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and broadcast are methods for broadcast routing. they enable improved flooding: it is checked whether a copy of a data unit has been received. if this is the case, no forwarding takes place to avoid loops. reverse path forwarding (also called reverse path flooding) (rpf) is a variation of the method spanning tree. each sender has its spanning tree. the other nodes don't have to know the spanning tree. the assumption is that each router knows which path it would use for packets.  the rpf algorithm checks whether a packet arrived at the is entry port over which the packets for this station are usually also sent. if yes, then the algorithm assumes the packet went the best path until now and resends the packet to all edges but the incoming one. if not, it assumes that the packet is a duplicate and didn't use the best route. this duplicate is then not forwarded but discarded. the significant advantage of this algorithm is its simple implementation. if a node assumes that a packet will reach it first by the shortest route, all that needs to be done is to ensure that a receiver can detect duplicates. as soon as a duplicate is received, it is assumed that the shortest route did not receive the packet, and it is not forwarded. the disadvantage of this method is that some nodes receive the packet unnecessarily several times. the reverse path broadcast (rpb) is like rpf but with a specific selection of outgoing links. after the first check, the algorithm checks if the packet used the best route until then. if yes, it selects the edge at which the packets arrived and from which they are then rerouted to source s. if not, it won't send over all edges. reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path concerning the interface on which the multicast packets are received but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to decide about forwarding, the routers must be informed about the shortest paths.",
        "original_sample_id": "smp1018q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are unite at least one other, all client can be reached. constructing a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are relate at least one other, all client can be reached. constructing a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are connected at least one other, all client can be reached. constructing a span tree: first measuring the distance to the neighbors, organize your package(send the distance), all client do the calculation which aloofness are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all guest are connected at least one other, all guest can be reached. constructing a cross tree: first measuring the space to the neighbors, organize your package(send the space), all guest do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all client are connected at least one other, all client can be reached. retrace a spanning tree: first measuring the space to the neighbors, organize your package(send the space), all client do the calculation which spaces are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp1102q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all nodes are join at least one other, all nodes can be reached. constructing a spanning tree: first measuring the aloofness to the neighbors, orchestrate your package(send the aloofness), all nodes do the calculation which aloofnesss are the shortest.",
        "answer_feedback": "although all nodes are connected with at least one link, that is also the case in the original network. more importantly, they need to have only one unique path so that the number of duplicate messages can be minimized. the description of modification related to the link state algorithm to construct a  multicast spanning tree is not correct because it just partially describes the classic link-state algorithm without any modification to include multicast group information.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "all nodes are connected at least one other, all nodes can be reached. constructing a spanning tree: first measuring the distance to the neighbors, organize your package(send the distance), all nodes do the calculation which distances are the shortest.",
        "original_sample_id": "smp1102q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1677q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 refer to the current meshwork\n10.0.0.0/8 is a individual meshwork range\n127.0.0.0/8 is used for localhost as loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8 refers to the current network\n10.0.0.0/8 is a private network range\n127.0.0.0/8 is used for localhost as loopback",
        "original_sample_id": "smp1677q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1096q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "If there are no loops, duplicates cannot be produced. Link status packages need to be extended by information about multicast groups. in lsr each has complete information about network status. with this information each node can calculate its own multicast tree.",
        "answer_feedback": "the response correctly identifies the appealing property of a spanning tree for broadcast and multicast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees have no loops, that makes them interesting for broad- and multicasts. if there are no loops, no duplicates can occur.  the link state packets need to be extended by the information on multicast groups. in lsr each is has complete information about the network state. with this information each node can calculate its own multicast spanning tree.",
        "original_sample_id": "smp1096q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1504q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Therefore, the media has to provide a duplex operation. If the sender expects a response containing data, the response itself can be seen as an implicit recognition.",
        "answer_feedback": "the response answers the underlying requirement correctly. however, by implicit acknowledgment, one implies a data frame received as a response from the receiver contains an acknowledgment of previously sent packet/packets.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking only makes sense in a two-way communication with both participants sending data packets to each other. therefore, the communication medium has to provide duplex operation.\nif the sender expects an answer which contains data the answer itself can be seen as an implicit acknowledgement.",
        "original_sample_id": "smp1504q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp0860q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the poisson outgrowth is found on probabilities found on randomly arriving packets, found on t indepedent.\nevery separation is independent to the previous separations, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson outgrowth.",
        "answer_feedback": "the correct answer is \"no\". the packets in streaming are not random but depend on the previous arrivals at a node.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the poisson process is based on probabilities based on randomly arriving packets, based on t indepedent.\nevery interval is independent to the previous intervals, so arrivals are memoryless.\nthe same situation is for the internet. here we have server/client application, webserver, streaming clients which have different and randomly packet arrivals which can be modelled as poisson process.",
        "original_sample_id": "smp0860q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1114q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend allow to model nodes, store and update information about nearby intermediate stations (s) and to determine and calculate wide and multicast routes on the march. link routing of the state to build a multicasting extension tree - allowing all intermediate stations (s) to send regularly connecting state packets to neighbours and multicast groups. using transmission to and from others, each one is calculated its multicast tree, which can be used to determine outgoing lines or new routes on which packets can be transmitted.",
        "answer_feedback": "though the stated information about a spanning tree may be true in certain cases, it is not the main reason why a spanning tree is used in the multicast and broadcast algorithm. the correct property is the absence of loops, thereby reducing unnecessary duplicates. the description of modification related to the link state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees make it convenient to model nodes, store and update information about neighboring intermediate stations (is) and determine and compute broad and multicast routes on the go. link state routing to construct a spanning tree for multicasting - by allowing all intermediate stations (is) to send link state packets about neighbors and multicast groups periodically. using broadcast to and from others, each is calculates its multicast tree, which can be used to determine outgoing lines or new routes on which packets can be transmitted.",
        "original_sample_id": "smp1114q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0391q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1: (a,c,forward) (a,b,forward) (a,d,forward) hop2: (b,e,forward) (c,f,forward) (c,d,drop)-> a package cannot be redirected (d,f,drop)-> a package cannot be redirected hop3: (e,g,forward) (e,f,forward) (f,g,drop) -> a package cannot be redirected hop4: (g,h,drop) -> a package cannot be redirected 7 packages",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. one need to provide the reason why the packet is not forwarded or dropped.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.5,
        "original_answer": "hop1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop2:\n(b,e,forward)\n(c,f,forward)\n(c,d,drop )-> a packet can't be forwarded \n(d,f,drop)-> a packet can't be forwarded \nhop3:\n(e,g,forward)\n(e,f,forward)\n(f,g,drop) -> a packet can't be forwarded \nhop4:\n(g,h,drop) -> a packet can't be forwarded \n\n7packets",
        "original_sample_id": "smp0391q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the added probabilities of 0,1,..,9 mailboat waiting in the queue, we can just calculate the probability that 10 mailboat are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate equilibrium equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this lead in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the lend probabilities of 0,1,..,9 packets look in the queue, we can just calculate the probability that 10 packets are look in the queue (=fender is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite fender of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0207q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "since we are looking for the added probabilities of 0,1,..,9 package waiting in the queue, we can just calculate the probability that 10 package are waiting in the queue (=pilot is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate counterpoise equation. since we have a finite pilot of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "answer_feedback": "the response correctly states the first step to calculate the blocking probability and the non-blocking probability. it is not clear how the final non-blocking time was calculated from the probability and the stated time is also not rounded correctly.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "since we are looking for the added probabilities of 0,1,..,9 packets waiting in the queue, we can just calculate the probability that 10 packets are waiting in the queue (=buffer is full), substracted from 1, s.t. p_0 + p_1 + ... + p_9 = 1 - p_10 .\nthis can be done with the appropriate balance equation. since we have a finite buffer of 10 we have to take n=10 into account. furthermore, the utilization rho is 9/10. this results in the probability of p_10 = 0.05081\nthis turn means the solution is 0.949 = 56",
        "original_sample_id": "smp0207q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0859q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption is not 100% applicable due to the fact that there are packages that depend on each other as tcp packages.In this case, to establish a tcp connection, the specific packages have to be sent, which are strictly dependent on each other.If we have a tcp connection, which starts at t time and ends at t+n time, there are some packages in this time period, which are dependent on each other.",
        "answer_feedback": "indeed, the assumption doesn’t hold for real internet traffic. however, the explanation is incorrect because many packets may arrive at a queue so that a specific tcp connection will likely not significantly influence the arrival probabilities.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "this assumption is not 100% applicable due to the fact, that there are packets which are dependent on each other like tcp packets. in this case, in order to estabilish a tcp connection, pecific packets have to be sent, which are strict dependent on each other. if we have a tcp connection, which starts at time t and ends at time t+n, there are some packets in this time period, which are dependent on each other.",
        "original_sample_id": "smp0859q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0859q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption is not 100% applicable due to the fact that there are packages that depend on each other as tcp packages.In this case, to establish a tcp connection, the specific packages have to be sent, which are strictly dependent on each other.If we have a tcp connection, which starts at t time and ends at t+n time, there are some packages in this time period, which are dependent on each other.",
        "answer_feedback": "indeed, the assumption doesn’t hold for real internet traffic. however, the explanation is incorrect because many packets may arrive at a queue so that a specific tcp connection will likely not significantly influence the arrival probabilities.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "this assumption is not 100% applicable due to the fact, that there are packets which are dependent on each other like tcp packets. in this case, in order to estabilish a tcp connection, pecific packets have to be sent, which are strict dependent on each other. if we have a tcp connection, which starts at time t and ends at time t+n, there are some packets in this time period, which are dependent on each other.",
        "original_sample_id": "smp0859q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0358q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(b, a, onwards)\n(c, a, onwards)\n\nhop 2:\n(e, c, drop) <= going over c to a is not on the ripe course from e to a\n\n(f, d, drop) <= going over d to a is not on the ripe course from f to a\n(e, b, onwards)\n(f, c, onwards)\n\nhop 3:\n\n(g, e, onwards)\n(g, f, drop) <= going over f to a is not on the ripe course from g to a\n\n\n\n\nhop 4:\n(h, g, onwards)",
        "answer_feedback": "the notation is (sender, receiver, forward/drop), not (receiver, sender, forward/drop). (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.3,
        "original_answer": "hop 1:\n(b, a, forward)\n(c, a, forward)\n\nhop 2:\n(e, c, drop) <= going over c to a is not on the best path from e to a\n\n(f, d, drop) <= going over d to a is not on the best path from f to a\n(e, b, forward)\n(f, c, forward)\n\nhop 3:\n\n(g, e, forward)\n(g, f, drop) <= going over f to a is not on the best path from g to a\n\n\n\n\nhop 4:\n(h, g, forward)",
        "original_sample_id": "smp0358q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0883q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, it does not. in the real Internet traffic, there are gusts / peaks with a large quantity of packages delivered simultaneously. These peak phases are likely to last more than a time interval (for example, if an application requires a large amount of data), so that arrivals in a time interval and arrivals in the previous / next interval are interdependent and therefore not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, it does not. in real internet traffic, there are bursts / peaks with a high amount of packages delivered simultaneously. these peak phases are likely to last more than only one time interval (e.g. if an application requests a lot of data), so the arrivals in one time interval and the arrivals in the previous / next interval are correlated and therefore not independent.",
        "original_sample_id": "smp0883q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1622q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 bis 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 bis 10.255.255.255",
        "original_sample_id": "smp1622q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1622q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0 bis 10.255,255,255",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "10.0.0.0 bis 10.255.255.255",
        "original_sample_id": "smp1622q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1073q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the tree that extends is especially interesting for the width and multicasting because it has all the network without any loop, which reduces traffic, which is very important especially for the width and multicasting due to the high load of the network. link state routing can be used to produce the trees that extend in that way, which measure the distances of all the neighbors, which are then distributed to all the other nodes. once each node has all the information about all the delays between them, all can calculate the trees that spread optimally for themselves.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast. the explanation for modifying the link-state algorithm is incomplete because, firstly, there is no mention of how the packets are expanded to contain additional multicast information. and secondly, each node has information about the network topology and multicast-group in the end, not about delays as stated in the response.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the spanning tree is espescially interesting for broad and multicasting because it has the whole network without any loop, that reduces traffic, which is very important espescially for broad and multicasting because of the high network load. link state routing can be used to produce the spanning trees in that way, that you measure the distances of all the neighbours, which you then distribute to all other nodes. once every node has all the information about all the delays between them, they can all calculate the optimale spanning trees for themselfs.",
        "original_sample_id": "smp1073q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1498q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking requires a two way datum communication between two parties (a and b). this essential exists, because instead of both parties immediately sending acknowledgement-frames to each other when\nthey recieve a datum-mailboat, they include the acknowledgement in the next datum-mailboats header. this means that, when a sends a datum-mailboat to b, b has to answer at some time with datum to fulfill the\nessential for an acknowledgement.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "piggybacking requires a two way data communication between two parties (a and b). this requirement exists, because instead of both parties immediately sending acknowledgement-frames to each other when\nthey recieve a data-packet, they include the acknowledgement in the next data-packets header. this means that, when a sends a data-packet to b, b has to answer at some time with data to fulfill the\nrequirement for an acknowledgement.",
        "original_sample_id": "smp1498q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1699q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1699q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1699q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1699q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0249q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "adopt a fifo queue, and adopt that the parcels arrive and are processed continuously with equal time distribution for each parcel within the second:\nservice time: u = 10 parcels/second => x1 = 1/10s\narrival rate = 9 parcels/second => arrival time = every 1/9s\nbuffer = 10 parcels\n\nsince the service time is smaller than the parcel arrival time for each parcel, and the number of parcels arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more parcels in it, hence, the queue always has less than 10 parcels in it.",
        "answer_feedback": "the response is incorrect because it is purely based on assumptions. additionally, the arrival and service rates are not constant and vary with time, so the stated argument of the queue never containing 10 packets for an entire minute is invalid.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "assuming a fifo queue, and assuming that the packets arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 packets/second => x1 = 1/10s\narrival rate = 9 packets/second => arrival time = every 1/9s\nbuffer = 10 packets\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of packets arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more packets in it, hence, the queue always has less than 10 packets in it.",
        "original_sample_id": "smp0249q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0249q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "assuming a fifo queue, and assuming that the bundle arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 bundle/second => x1 = 1/10s\narrival rate = 9 bundle/second => arrival time = every 1/9s\nbuffer = 10 bundle\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of bundle arriving per second is smaller than the queue's buffer size, we can simulate that in the entire minute, the queue never contains 10 or more bundle in it, hence, the queue always has less than 10 bundle in it.",
        "answer_feedback": "the response is incorrect because it is purely based on assumptions. additionally, the arrival and service rates are not constant and vary with time, so the stated argument of the queue never containing 10 packets for an entire minute is invalid.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "assuming a fifo queue, and assuming that the packets arrive and are processed continuously with equal time distribution for each packet within the second:\nservice time: u = 10 packets/second => x1 = 1/10s\narrival rate = 9 packets/second => arrival time = every 1/9s\nbuffer = 10 packets\n\nsince the service time is smaller than the packet arrival time for each packet, and the number of packets arriving per second is smaller than the queue's buffer size, we can assume that in the entire minute, the queue never contains 10 or more packets in it, hence, the queue always has less than 10 packets in it.",
        "original_sample_id": "smp0249q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0812q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header is longer than the udp header and has a variable length which is set in the hl champaign. it also has sequence and acknowledgement number champaigns as well as flags used to ensure reliability in terms of avoiding packet losses, keeping packet order and detecting duplicates. the flags are also used to manage connections. furthermore, the tcp header’s advertised window champaign holds the initial size of the congestion window used for congestion control. the urgent pointer champaign of the tcp header is only used when the urg flag is set in order to assure the receiver that data located at a specific offset is to be read firstly. the options champaign may be used to provide functions that are not defined within the normal tcp protocol head. eventually there are 6 unused reserved bits in the resv champaign.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header is longer than the udp header and has a variable length which is set in the hl field. it also has sequence and acknowledgement number fields as well as flags used to ensure reliability in terms of avoiding packet losses, keeping packet order and detecting duplicates. the flags are also used to manage connections. furthermore, the tcp header’s advertised window field holds the initial size of the congestion window used for congestion control. the urgent pointer field of the tcp header is only used when the urg flag is set in order to tell the receiver that data located at a specific offset is to be read firstly. the options field may be used to provide functions that are not defined within the normal tcp protocol head. finally there are 6 unused reserved bits in the resv field.",
        "original_sample_id": "smp0812q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, pearl) c is not located on the unicast path from b to a\n           (c, d, pearl) c is not located on the unicast path from d to a\n           (c, e, pearl) c is not located on the unicast path from e to a\n           (d, f, pearl) d is not located on the unicast path from f to a\n           (f, g, pearl) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug01smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, cliff) c is not located on the unicast path from b to a\n           (c, d, cliff) c is not located on the unicast path from d to a\n           (c, e, cliff) c is not located on the unicast path from e to a\n           (d, f, cliff) d is not located on the unicast path from f to a\n           (f, g, cliff) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug02smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1c, a, forwards)  (d, a, forwards)  (b, a, forwards)  (e, b, forwards)  (g, e, forwards)\n           (h,g,forwards)   (f,c,forwards)\n           (c, b, drib) c is not located on the unicast path from b to a\n           (c, d, drib) c is not located on the unicast path from d to a\n           (c, e, drib) c is not located on the unicast path from e to a\n           (d, f, drib) d is not located on the unicast path from f to a\n           (f, g, drib) f is not located on the unicast path from g to a\nskip 2e, a, forwards) (f, a, forwards)\nskip 3g, a, forwards)     \nskip 4h, a, forwards)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug03smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, drop) c is not located on the unicast course from b to a\n           (c, d, drop) c is not located on the unicast course from d to a\n           (c, e, drop) c is not located on the unicast course from e to a\n           (d, f, drop) d is not located on the unicast course from f to a\n           (f, g, drop) f is not located on the unicast course from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug04smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, drop) c is not situate on the unicast course from b to a\n           (c, d, drop) c is not situate on the unicast course from d to a\n           (c, e, drop) c is not situate on the unicast course from e to a\n           (d, f, drop) d is not situate on the unicast course from f to a\n           (f, g, drop) f is not situate on the unicast course from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug05smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrard)  (d, a, forrard)  (b, a, forrard)  (e, b, forrard)  (g, e, forrard)\n           (h,g,forrard)   (f,c,forrard)\n           (c, b, pearl) c is not located on the unicast path from b to a\n           (c, d, pearl) c is not located on the unicast path from d to a\n           (c, e, pearl) c is not located on the unicast path from e to a\n           (d, f, pearl) d is not located on the unicast path from f to a\n           (f, g, pearl) f is not located on the unicast path from g to a\nhop 2e, a, forrard) (f, a, forrard)\nhop 3g, a, forrard)     \nhop 4h, a, forrard)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug06smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "skip 1c, a, fore)  (d, a, fore)  (b, a, fore)  (e, b, fore)  (g, e, fore)\n           (h,g,fore)   (f,c,fore)\n           (c, b, drop) c is not located on the unicast way from b to a\n           (c, d, drop) c is not located on the unicast way from d to a\n           (c, e, drop) c is not located on the unicast way from e to a\n           (d, f, drop) d is not located on the unicast way from f to a\n           (f, g, drop) f is not located on the unicast way from g to a\nskip 2e, a, fore) (f, a, fore)\nskip 3g, a, fore)     \nskip 4h, a, fore)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug07smp0325q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1c, a, forrad)  (d, a, forrad)  (b, a, forrad)  (e, b, forrad)  (g, e, forrad)\n           (h,g,forrad)   (f,c,forrad)\n           (c, b, cliff) c is not located on the unicast itinerary from b to a\n           (c, d, cliff) c is not located on the unicast itinerary from d to a\n           (c, e, cliff) c is not located on the unicast itinerary from e to a\n           (d, f, cliff) d is not located on the unicast itinerary from f to a\n           (f, g, cliff) f is not located on the unicast itinerary from g to a\nhop 2e, a, forrad) (f, a, forrad)\nhop 3g, a, forrad)     \nhop 4h, a, forrad)",
        "answer_feedback": "the response is incorrect. please check the model solution.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1c, a, forward)  (d, a, forward)  (b, a, forward)  (e, b, forward)  (g, e, forward)\n           (h,g,forward)   (f,c,forward)\n           (c, b, drop) c is not located on the unicast path from b to a\n           (c, d, drop) c is not located on the unicast path from d to a\n           (c, e, drop) c is not located on the unicast path from e to a\n           (d, f, drop) d is not located on the unicast path from f to a\n           (f, g, drop) f is not located on the unicast path from g to a\nhop 2e, a, forward) (f, a, forward)\nhop 3g, a, forward)     \nhop 4h, a, forward)",
        "original_sample_id": "smp0325q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0887q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the reaching are not independt for real internet traffic, because they can influence one another.\ne.g if a request is transport, the probabillity of a next message (the response) is more probable.",
        "answer_feedback": "the response is partially correct because the question requirement is to identify whether the arrivals at a node depend on previous arrivals at the same node. therefore, the explanation that the arrival at a node depends on the outgoing packets is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the arrivals are not independt for real internet traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more likely.",
        "original_sample_id": "smp0887q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0887q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the arrivals are not independt for genuine cyberspace traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more probable.",
        "answer_feedback": "the response is partially correct because the question requirement is to identify whether the arrivals at a node depend on previous arrivals at the same node. therefore, the explanation that the arrival at a node depends on the outgoing packets is incorrect.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the arrivals are not independt for real internet traffic, because they can influence one another.\ne.g if a request is sent, the probabillity of a next message (the response) is more likely.",
        "original_sample_id": "smp0887q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1692q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0,0,0,0,0,2552,255 10,0,0,055 10,255,255 100,64,0,0,05,100,127,255,255 127,0,0,0,07,255,255,255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "original_sample_id": "smp1692q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0799q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp header arrest only the sender embrasure, receiver embrasure, packet length, checksum.tcp and udp same headers have sender embrasure, receiver embrasure and checksum, more information than udp, e.g. sequence bit, acknowledgment bit, hl/resv/flags, advertised window.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp header contains only the sender port, receiver port, packet length, checksum.tcp and udp same headers have sender port, receiver port and checksum, more information than udp, e.g. sequence number, acknowledgment number, hl/resv/flags, advertised window.",
        "original_sample_id": "smp0799q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1002q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding purpose: broadcasting methods with reduction of duplicates reverse path forwarding working: each sender has an own spanning tree but is does not know them. packet arrives at is → check the port (is it the usual one for sending the packages for this station)  yes → (seems like best route) → resend over all edges no → (appears not to be the best route → duplicate) → drop package reverse path broadcast purpose: like rpf but not use all edges instead only suitable ones  reverse path broadcast working: check entry port the same way as in rpf  yes → check if best route until now? - yes → select arriving and rerouting (for packages) edge and send in opposite direction via this way  - no  → do not send over all edges (as it would be in rpf) no → discard (similar to rpf)",
        "original_sample_id": "smp1002q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1002q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding purpose: broadcasting methods with reduction of duplicates reverse path forwarding working: each sender has an own spanning tree but is does not know them. packet arrives at is → check the port (is it the usual one for sending the packages for this station)  yes → (seems like best route) → resend over all edges no → (appears not to be the best route → duplicate) → drop package reverse path broadcast purpose: like rpf but not use all edges instead only suitable ones  reverse path broadcast working: check entry port the same way as in rpf  yes → check if best route until now? - yes → select arriving and rerouting (for packages) edge and send in opposite direction via this way  - no  → do not send over all edges (as it would be in rpf) no → discard (similar to rpf)",
        "original_sample_id": "smp1002q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp cope contain a checksum, while udp cope have no error control. tcp cope have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp cope contain an advertised window to avoid the sender overmaster the receiver while udp has no means of stream control in their cope.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp cope incorporate a checksum, while udp cope have no error control. tcp cope have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp cope incorporate an advertised window to avoid the sender overwhelming the receiver while udp has no mean of flow control in their cope.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug02smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "The tcp headers contain a control sum, while the udp headers do not have an error control. The tcp headers have recognition numbers to ensure reliable communications while udp does not have an ack process. The tcp headers contain an announced window to prevent the sender from overwriting the receiver while udp has no means of flow control in their headers.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0826q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp head arrest a checksum, while udp head have no error control. tcp head have acknowledgement numbers to ensure reliable communications while udp has no ack appendage.\ntcp head arrest an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their head.",
        "answer_feedback": "the response states only three differences. the first difference does not bring out the difference as both tcp and udp header contain a checksum, though the usage is optional in udp. the other two differences are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "tcp headers contain a checksum, while udp headers have no error control. tcp headers have acknowledgement numbers to ensure reliable communications while udp has no ack process.\ntcp headers contain an advertised window to avoid the sender overwhelming the receiver while udp has no means of flow control in their headers.",
        "original_sample_id": "smp0826q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0334q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: \n(a, b, fore)(a, c, fore)\n(a, d, fore)\nhop 2:\n(b, e, fore)\n(b, c, cliff) <= (a, c) is myopic\n(c, b, cliff) <= (a, b) is myopic\n(c, e, cliff) <= (a, b, e) is myopic\n(c, f, fore)\n(c, d, cliff) <= (a, d) is myopic\n(d, c, cliff) <= (a, c) is myopic\n(d, f, cliff) <= (a, c, f) is myopic\nhop 3:\n(e, c, cliff) <= (a, c) is myopic\n(e, f, cliff) <= (a, c, f) is myopic\n(e, g, fore)\n(f, d, cliff) <= (a, d) is myopic\n(f, e, cliff) <= (a, b , e) is myopic\n(f, g, cliff) <= (a, b, e, g) is myopic\n(g, f, cliff) <= (a, c, f) is myopic\n(g, h, fore)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1: \n(a, b, forward)(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(b, c, drop) <= (a, c) is shorter\n(c, b, drop) <= (a, b) is shorter\n(c, e, drop) <= (a, b, e) is shorter\n(c, f, forward)\n(c, d, drop) <= (a, d) is shorter\n(d, c, drop) <= (a, c) is shorter\n(d, f, drop) <= (a, c, f) is shorter\nhop 3:\n(e, c, drop) <= (a, c) is shorter\n(e, f, drop) <= (a, c, f) is shorter\n(e, g, forward)\n(f, d, drop) <= (a, d) is shorter\n(f, e, drop) <= (a, b , e) is shorter\n(f, g, drop) <= (a, b, e, g) is shorter\n(g, f, drop) <= (a, c, f) is shorter\n(g, h, forward)",
        "original_sample_id": "smp0334q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1059q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend are attractive for wide diffusion and multicasting due to their efficient form of route search algorithm. it adds a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link status routing (lsr) to use with extension tree: all is to have to know the multicast tree. the is sends the liaison status packets periodically with its distance to the neighbors and information about its multicast group and transmits it to all others. then, each one is calculated a multicast tree from the available information. based on the multicast tree built the output line is determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing to broad- and multicasting because of its efficient way of path-finding algorithm. it aggregates a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link state routing (lsr) to use with spanning tree: all is have to know the multicast tree. the is sends the link-state packets periodically with its distance to neighbors and information about its multicast group and broadcasts it to all others. afterward, each is calculates a multicast tree from the available information received. based on the built multicast tree the is determines the outgoing line.",
        "original_sample_id": "smp1059q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1059q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The trees that extend are attractive for wide diffusion and multicasting due to their efficient form of route search algorithm. it adds a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link status routing (lsr) to use with extension tree: all is to have to know the multicast tree. the is sends the liaison status packets periodically with its distance to the neighbors and information about its multicast group and transmits it to all others. then, each one is calculated a multicast tree from the available information. based on the multicast tree built the output line is determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees are appealing to broad- and multicasting because of its efficient way of path-finding algorithm. it aggregates a network so that, for example in broadcasting (or multicasting), a sender can send information to any possible receiver (or to a limited group) in the most efficient way without loops modification of link state routing (lsr) to use with spanning tree: all is have to know the multicast tree. the is sends the link-state packets periodically with its distance to neighbors and information about its multicast group and broadcasts it to all others. afterward, each is calculates a multicast tree from the available information received. based on the built multicast tree the is determines the outgoing line.",
        "original_sample_id": "smp1059q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0834q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp headers have a episode routine, an acknowledgement routine, an advertised window and an extra options section.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "tcp headers have a sequence number, an acknowledgement number, an advertised window and an additional options section.",
        "original_sample_id": "smp0834q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0853q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption is not maintained in real Internet traffic. in real Internet traffic packages arrive in bursts and for longer periods of time there are phases with more or less traffic. so the probability of arrival of a package is higher if the packages arrived at the previous intervals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no, this assumption does not hold in the real internet traffic. in the real internet traffic packets arrive in bursts and over longer time periods there are phases with more or with less traffic. so the probability for the arrival of a packet is higher in δt if packets arrived in the previous intervals.",
        "original_sample_id": "smp0853q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0877q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not because Internet traffic is usually ruined which means that there is more than one package by data transmission. e.g., if you open a video on the Internet, the website sends a part of the video to fill a buffer for several seconds, so wait for the user to see a few seconds of the video and then fill it with the next part of the video. while it sends these parts, each time interval is not really independent of the previous one because the packages are too small to send the buffer data into a single package.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "no because internet traffic is normally bursty which means that there are more than one packet per data transmission. for example if you open a video in the internet the webpage sends some part of the video to fill a buffer for several seconds, then waits until the user has watch some seconds of the video and then fills the buffer with the next part of the video. while sending these parts, each time interval is not really independent of the one before because the packets are too small to send the buffer data in one single packet.",
        "original_sample_id": "smp0877q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0201q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the arrangement is not full, so there are less than 10 packets wait in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the arrangement being in a state with less than 10 packets wait in the queue if the arrangement is monitored for one minute after equipoise has been reached",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the system is not full, so there are less than 10 packets waiting in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 packets waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "original_sample_id": "smp0201q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0201q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "1. calculate the blocking chance for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this chance from one in club to get the chance that the system is not full, so there are less than 10 mailboat waiting in the queue\n\n3. multiply the last chance with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 mailboat waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. calculate the blocking probability for an m/m/1/10 model using the formula ((1-p)*p^n)/(1-p^(n+1)) with p=λ/µ=9/10 and n=10\n\n2. subtract this probability from one in order to get the probability that the system is not full, so there are less than 10 packets waiting in the queue\n\n3. multiply the last probability with 60 seconds\n\n4. the result is 0.949 * 60s = 56.94s, which is the expected number of seconds for the system being in a state with less than 10 packets waiting in the queue if the system is monitored for one minute after equilibrium has been reached",
        "original_sample_id": "smp0201q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1076q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees have no cycles. * we add the additional dimension group to every link country mailboat indicating which group the sending is belongs to.",
        "answer_feedback": "while the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops. additionally, how the multicast information is used by every node to construct a multicast spanning tree is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees have no cycles. * we add the additional attribute group to every link state packet indicating which group the sending is belongs to.",
        "original_sample_id": "smp1076q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1643q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "these addresses have a range: so not only 127.0.0.0, but 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1643q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1643q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.00,0 127.0,0",
        "answer_feedback": "these addresses have a range: so not only 127.0.0.0, but 127.0.0.0 - 127.255.255.255",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "0.0.0.0\n127.0.0.0",
        "original_sample_id": "smp1643q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp0240q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "It is to be expected, that almost every second the queue, there are less than 10 packages. because first, the server has only a buffer size of 10, so there are no more than 10 packages in the possible queue, they would be rejected instead. Then, the service rate is higher than the rate of arrival, leading to a trend, that the system should not be full for too long. we can calculate the probability explicitly, adding all the p_i for i = 1, ..., 9 and get a result of 98%, which for one minute is about 59 seconds of that.",
        "answer_feedback": "the response is partially correct because the probability calculation step is explained correctly, but the probability of the system not being full is 94.92% instead of 98%, and the time is 56.9512 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "it is to be expected, that close to every second the queue, there are less than 10 packets. because first, the server only has a buffer size of 10, so there is not more than 10 packets in the queue possible, they would get discarded instead. second, the serving rate is higher than the arrival rate, leading to a tendency, that the system should not be full for too long. we can calculate the probability explicitly, by summing over all p_i for i = 1, …, 9 and get a result of 98%, which for a minute is about 59 seconds of that.",
        "original_sample_id": "smp0240q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0817q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-the sender identification in udp is optional -in tcp there is an options field where you can add extra information in the lintel, this means that the tcp lintel does not have a fixed length compared to the udp lintel -the use of the checksum in udp is also optional -since tcp is connection-oriented, the tcp lintel has a lot of control flags that udp doesnt postulate. for example the syn and fin flag for establishing and releasing a connection. -the tcp lintel uses sequence numbers in order to sort packages in lawsuit they do not arrive in the correct order.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "-the sender identification in udp is optional -in tcp there is an options field where you can add extra information in the header, this means that the tcp header does not have a fixed length compared to the udp header -the use of the checksum in udp is also optional -since tcp is connection-oriented, the tcp header has a lot of control flags that udp doesnt need. for example the syn and fin flag for establishing and releasing a connection. -the tcp header uses sequence numbers in order to sort packages in case they do not arrive in the correct order.",
        "original_sample_id": "smp0817q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1021q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rpf and rpb are used to reduce traffic when sending broadcast messages. rpf: they only send incoming transmission packages if they arrive by the best link (usually used link for licast) to the source. rpb: the nodes look at the packets to see if they are on the unicast path from one node to another. If they receive a transmission package, they only return them to nodes that use them on the path for a unicast package.",
        "answer_feedback": "the response is partially correct as in rpf, the node forwards the packet instead of \"resending\" it. in both algorithms, the packet is also not forwarded to the edge from which it was received. the other parts are correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "rpf and rpb are used to reduce traffic when sending broadcast messages. rpf: only resend incoming broadcast packets if they came over the best link (link usually used for unicast) to the source. rpb: nodes look at packets to find out, if they are on the unicast path from one node to another. if they receive a broadcast packet, they only forward them to nodes that use them on the path for a unicast packet.",
        "original_sample_id": "smp1021q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1055q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "traverse tree is a subset of subnets including all routers which does not comprise loops, and thus there are no duplicates in broad- and multicasting using a traverse tree. to modify link state routing to construct a traverse tree, all is have to send link state packets peridodically, which is expanded by entropy on multicast groups. then, each is calculates a multicast tree, and based on the entropy about this tree, is determines the outgoing lines on which packets have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is a subset of subnets including all routers which does not contain loops, and thus there are no duplicates in broad- and multicasting using a spanning tree. to modify link state routing to construct a spanning tree, all is have to send link state packets peridodically, which is expanded by information on multicast groups. then, each is calculates a multicast tree, and based on the information about this tree, is determines the outgoing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1055q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug03smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the datum and ackknowledgements are marry together and post to poster and receiver and vice versa.\ntherefore you need to address which part of datum and acknowledgement you post by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the datum number and the acknowledgement number.\notherwise there wouldn't be an assigment which datum and ackknowledgement is post or post back between poster and receiver,\nwhen datum and ack are marry together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1530q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for piggybacking the data and ackknowledgements are tied together and broadcast to broadcaster and receiver and vice versa.\ntherefore you need to address which part of data and recognition you broadcast by expressing anatomy(x,y), f.e. anatomy (1,0) or anatomy (1,2) .\nin brackets there is the data number and the recognition number.\notherwise there wouldn't be an assigment which data and ackknowledgement is broadcast or broadcast back between broadcaster and receiver,\nwhen data and ack are tied together.",
        "answer_feedback": "the response is partially correct as it states data and acknowledgment are sent in both directions and, therefore, implies a duplex channel. however, a new acknowledgment field is included in the frame to differentiate between data and acknowledgment. frame(x,y) is just a way to express it to students for better understanding.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "for piggybacking the data and ackknowledgements are tied together and send to sender and receiver and vice versa.\ntherefore you need to address which part of data and acknowledgement you send by expressing frame(x,y), f.e. frame (1,0) or frame (1,2) .\nin brackets there is the data number and the acknowledgement number.\notherwise there wouldn't be an assigment which data and ackknowledgement is send or send back between sender and receiver,\nwhen data and ack are tied together.",
        "original_sample_id": "smp1530q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0872q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "may not always contain for actual Internet traffic, because the receiver accepts a package or does not depend on the data packet transmission protocol. For example, the protocol requires that packages need to be received in a certain order, at this time, the time interval is not independent.",
        "answer_feedback": "though the assumption does not hold for the real internet, the reason behind this is the bursty nature of internet traffic. the arrival of a packet at a node is not dependent on whether it is accepted, buffered or dropped at a node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it can’t always hold for real internet traffic, because receiver accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time interval is not independent.",
        "original_sample_id": "smp0872q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0872q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "it can’t always hold for real internet dealings, because recipient accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time separation is not independent.",
        "answer_feedback": "though the assumption does not hold for the real internet, the reason behind this is the bursty nature of internet traffic. the arrival of a packet at a node is not dependent on whether it is accepted, buffered or dropped at a node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "it can’t always hold for real internet traffic, because receiver accepts a packet or not  depends on the data packet transmission protocol. for example, the protocol requires that packets need to be received in a certain order, at this time, the time interval is not independent.",
        "original_sample_id": "smp0872q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1508q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "- you ask a full-duplex connection\n- both sides have to be capable to act as sender and liquidator\n- the liquidator asks some data to send back along with the acknowledgement",
        "answer_feedback": "the response answers the underlying requirement correctly. apart from duplex communication other points also hold true but in absence of data, separate or explicit acknowledgment can also be sent by using a timeout timer.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- you need a full-duplex connection\n- both sides have to be able to act as sender and receiver\n- the receiver needs some data to send back along with the acknowledgement",
        "original_sample_id": "smp1508q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1062q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "extension tree is attractive for transmission and multicasting because it allows all nodes to be reached, without loops and with a minimum number of copies of packets. in order to use link state routing to build the extension tree, all intermediate systems would periodically issue link state packages, which contain the distance to their neighbors, expanded with information about multicast groups. then, each node would recalculate the best route to the other nodes and determine the outgoing lines, in which packages have to be transmitted.",
        "answer_feedback": "the response correctly states the spanning-tree property and explanation regarding the link state routing modification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is appealing for broadcast and multicasting because it allows for all nodes to be reached, without loops and with a minimum number of packet copies. in order to use link state routing to build the spanning tree, all intermediate systems would broadcast periodically link state packets, containing the distance to their neighbours, expanded with the informations on multicast groups. then, each node would recalculate the best route to the other nodes and determining the outgoing lines, on which packets have to be transmitted.",
        "original_sample_id": "smp1062q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1062q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "extension tree is attractive for transmission and multicasting because it allows all nodes to be reached, without loops and with a minimum number of copies of packets. in order to use link state routing to build the extension tree, all intermediate systems would periodically issue link state packages, which contain the distance to their neighbors, expanded with information about multicast groups. then, each node would recalculate the best route to the other nodes and determine the outgoing lines, in which packages have to be transmitted.",
        "answer_feedback": "the response correctly states the spanning-tree property and explanation regarding the link state routing modification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning tree is appealing for broadcast and multicasting because it allows for all nodes to be reached, without loops and with a minimum number of packet copies. in order to use link state routing to build the spanning tree, all intermediate systems would broadcast periodically link state packets, containing the distance to their neighbours, expanded with the informations on multicast groups. then, each node would recalculate the best route to the other nodes and determining the outgoing lines, on which packets have to be transmitted.",
        "original_sample_id": "smp1062q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1072q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "Trees that extend have no loops, which could be a problem for routing algorithms, also only a minimum number of copies are required. First, neighbors' addresses are determined and the distance is calculated. for multicast, receiver groups are considered when c calculation paths",
        "answer_feedback": "the response is partially correct because it lacks the link-state routing modification. to calculate the spanning trees for multicasting, you also have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees don't have loops, which might be a problem for routing algorithms, also only a minimal amount of copies are required. first, adresses of neighbours are determined and the distance is calculated. for multicast, receiving groups are considered whenc calculating routes",
        "original_sample_id": "smp1072q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1667q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - addresses in this occlusion refer to source hosts on \"this\" network.  (for software)\n10.0.0.0/8 - this occlusion is set aside for use in private meshwork.\n4.0.0.0/8 - this occlusion is set aside for assignments to the outside system of public data meshwork.\n24.0.0.0/8 - this occlusion was allocated in early 1996 for use in provisioning ip service over cable television systems. \n39.0.0.0/8 - this occlusion was used in the \"class a subnet experiment\" that commenced in may 1995.\n127.0.0.0/8 - this occlusion is assigned for use as the internet host loopback address.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.0.0.0/8 - addresses in this block refer to source hosts on \"this\" network.  (for software)\n10.0.0.0/8 - this block is set aside for use in private networks.\n4.0.0.0/8 - this block is set aside for assignments to the international system of public data networks.\n24.0.0.0/8 - this block was allocated in early 1996 for use in provisioning ip service over cable television systems. \n39.0.0.0/8 - this block was used in the \"class a subnet experiment\" that commenced in may 1995.\n127.0.0.0/8 - this block is assigned for use as the internet host loopback address.",
        "original_sample_id": "smp1667q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0822q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp lintel includes - a sequence number, - an acknowledgement number and - an advertised window field not present in the udp-lintel. the udp lintel includes - a packet duration field not present in the tcp-lintel.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header includes - a sequence number, - an acknowledgement number and - an advertised window field not present in the udp-header. the udp header includes - a packet length field not present in the tcp-header.",
        "original_sample_id": "smp0822q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1105q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a tree that extends contains only one path (most likely the shortest) each to all nodes of a given node. generate a tree that extends for multicasting, by using link status routing. 1. It is all to send link status packets periodically to all others through transmissions, containing information about the distance to their neighbors and information about multicast groups. 2. each is to calculate a multicast tree from the now available locally and complete status information. 3. It is to determine the outgoing lines in which packages have to be transmitted, based on information about the multicast tree. also, all outgoing links are removed, which do not connect group members to the node.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree contains only one (most likely the shortest) route each to all nodes from a certain node. generating a spanning tree for multicasting, by the use of link-state routing. 1. all is send link-state packets periodically to all the others by broadcasts, containing information about the distance to its neighbours and information on multicast groups. 2. each is calculates a multicast tree from the now locally available and complete state information. 3. the is determines the outgoing lines on which packets have to be transmitted, based on the information about the multicast tree. also, all outgoing links are removed, that do not connect group members to the node.",
        "original_sample_id": "smp1105q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1105q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a tree that extends contains only one path (most likely the shortest) each to all nodes of a given node. generate a tree that extends for multicasting, by using link status routing. 1. It is all to send link status packets periodically to all others through transmissions, containing information about the distance to their neighbors and information about multicast groups. 2. each is to calculate a multicast tree from the now available locally and complete status information. 3. It is to determine the outgoing lines in which packages have to be transmitted, based on information about the multicast tree. also, all outgoing links are removed, which do not connect group members to the node.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree contains only one (most likely the shortest) route each to all nodes from a certain node. generating a spanning tree for multicasting, by the use of link-state routing. 1. all is send link-state packets periodically to all the others by broadcasts, containing information about the distance to its neighbours and information on multicast groups. 2. each is calculates a multicast tree from the now locally available and complete state information. 3. the is determines the outgoing lines on which packets have to be transmitted, based on the information about the multicast tree. also, all outgoing links are removed, that do not connect group members to the node.",
        "original_sample_id": "smp1105q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0873q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a bundle was encounter or not. but for exemplar, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where bundles are arriving.",
        "answer_feedback": "the response points out that packets are received continuously while streaming, but in reality, they are received in bursts. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a packet was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packets are arriving.",
        "original_sample_id": "smp0873q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0873q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the premiss realistically. the poisson process implies that for every interval delta t there is a propability wich say if a package was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packages are arriving.",
        "answer_feedback": "the response points out that packets are received continuously while streaming, but in reality, they are received in bursts. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption realistically. the poisson process implies that for every interval delta t there is a propability wich states if a packet was received or not. but for example, if we are watching a video stream, then we are watching it consecutively and hence, we have multiple delta t´s where packets are arriving.",
        "original_sample_id": "smp0873q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10\narrival pace = 9 mailboat/sec\nprocessing pace = 10 mailboat/sec\nu = arrival pace/processing pace = 9/10 = 0.9\n\nthe chance of being less 10 mailboat (p(less 10)) in the buffer is the chance of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 mailboat in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 mailboat in the queue.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10\narrival rate = 9 parcel/sec\nprocessing rate = 10 parcel/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 parcel (p(less 10)) in the fender is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 parcel in the fender.\nsince n=10 we believe a queue model with a finite fender, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 parcel in the queue.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0242q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "n = 10 arrival rate = 9 packets/seg processing rate = 10 packets/seg u = arrival/processing rate = 9/10 = 0.9 the probability of being less than 10 packets (p{min 10) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer because n = 10 we consider a tail model with a finished buffer, so that in this case pn = ((1-u)(u^n))/(1-(u^n+1)) so, p{min 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94, because t=1min = 60seg 60seg * 0.94 = 56.4 sec, the system is expected to have less than 10 packets in the queue for 56.4 sec.",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the non-blocking probability is rounded incorrectly, resulting in an incorrect time. the correct value is 56.952 instead of 56.4 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "n = 10\narrival rate = 9 packets/sec\nprocessing rate = 10 packets/sec\nu = arrival rate/processing rate = 9/10 = 0.9\n\nthe probability of being less 10 packets (p(less 10)) in the buffer is the probability of being 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 packets in the buffer.\nsince n=10 we consider a queue model with a finite buffer, so for this case pn = ((1-u)(u^n))/(1-(u^(n+1)))\nso, p(less 10) = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 = 0.94\nso, since t=1min = 60sec\n60sec * 0.94 = 56.4 sec\n\nthen, is expect that for 56.4 sec the system has less than 10 packets in the queue.",
        "original_sample_id": "smp0242q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledge connectionless servicing: sender sends independet data soma without waiting for an acknowledgement from the receiver.\nacknowledge connectionless servicing: sender sends independet data soma which are individually acknowledge by the receiver.\nacknowledge connection-oriented servicing: before any soma will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming soma.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unrecognize connectionless service: sender sends independet data form without waiting for an acknowledgement from the receiver.\nrecognize connectionless service: sender sends independet data form which are individually recognize by the receiver.\nrecognize connection-oriented service: before any form will be sent, sender and receiver establish a connection between each other. the receiver recognize then incoming form.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognised offline service: the sender sends independent data frames without waiting for an acknowledgement of receipt.Recognised offline service: the sender sends independent data frames that are individually recognized by the receiver.Recognised connection-oriented service: before frames are sent, the sender and the receiver establish a connection with each other.The receiver recognizes the incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unnotice associationless avail: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nnotice associationless avail: sender sends independet data frames which are individually notice by the receiver.\nnotice association-oriented avail: before any frames will be sent, sender and receiver establish a association between each other. the receiver acknowledges then incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0654q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unrecognised offline service: the sender sends independent data frames without waiting for an acknowledgement of receipt.Recognised offline service: the sender sends independent data frames that are individually recognized by the receiver.Recognised connection-oriented service: before frames are sent, the sender and the receiver establish a connection with each other.The receiver recognizes the incoming frames.",
        "answer_feedback": "the response answers the services' names and differences correctly, except instead of \"acknowledged\", \"confirmed\" should have been used.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service: sender sends independet data frames without waiting for an acknowledgement from the receiver.\nacknowledged connectionless service: sender sends independet data frames which are individually acknowledged by the receiver.\nacknowledged connection-oriented service: before any frames will be sent, sender and receiver establish a connection between each other. the receiver acknowledges then incoming frames.",
        "original_sample_id": "smp0654q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendence -cease to cease flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and pullulate",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -fault control -end to end catamenia control udp: -connectionless -no catamenia control -no fault control or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error command -end to end course command udp: -connectionless -no course command -no error command or retransmission -maybe used with broadcast/multicast and stream",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascstopance -stop to stop flow ascstopance udp: -connectionless -no flow ascstopance -no error ascstopance or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error restraint -end to end menstruum restraint udp: -connectionless -no menstruum restraint -no error restraint or retransmission -maybe used with broadcast/multicast and swarm",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no wrongdoing ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendancy -end to end period ascendancy udp: -connectionless -no period ascendancy -no error ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug08smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end course ascendency udp: -connectionless -no course ascendency -no error ascendency or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug09smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascterminateence -terminate to terminate feed ascterminateence udp: -connectionless -no feed ascterminateence -no error ascterminateence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug10smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end menses ascendency udp: -connectionless -no menses ascendency -no error ascendency or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug11smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendency -end to end current ascendency udp: -connectionless -no current ascendency -no error ascendency or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug12smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing mastery -finish to finish flow mastery udp: -connectionless -no flow mastery -no wrongdoing mastery or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug13smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error restraint -end to end menstruum restraint udp: -connectionless -no menstruum restraint -no error restraint or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug14smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error command -end to end period command udp: -connectionless -no period command -no error command or retransmission -maybe used with broadcast/multicast and teem",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug15smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug16smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendancy -end to end course ascendancy udp: -connectionless -no course ascendancy -no error ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug17smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendance -end to end flow ascendance udp: -connectionless -no flow ascendance -no wrongdoing ascendance or retransmission -maybe used with broadcast/multicast and pour",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug18smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -fault ascendancy -end to end feed ascendancy udp: -connectionless -no feed ascendancy -no fault ascendancy or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug19smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error mastery -finish to finish flux mastery udp: -connectionless -no flux mastery -no error mastery or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug20smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -error ascendence -end to end flux ascendence udp: -connectionless -no flux ascendence -no error ascendence or retransmission -maybe used with program/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug21smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -wrongdoing ascendance -terminate to terminate flow ascendance udp: -connectionless -no flow ascendance -no wrongdoing ascendance or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug22smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection point -error ascendence -end to end flow ascendence udp: -connectionless -no flow ascendence -no error ascendence or retransmission -maybe used with broadcast/multicast and streaming",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug23smp0832q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp: -connection oriented -mistake ascendance -end to end flow ascendance udp: -connectionless -no flow ascendance -no mistake ascendance or retransmission -maybe used with broadcast/multicast and pour",
        "answer_feedback": "the response states differences between tcp and udp while the question requirement is to identify differences between udp and tcp headers.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "tcp: -connection oriented -error control -end to end flow control udp: -connectionless -no flow control -no error control or retransmission -maybe used with broadcast/multicast and streaming",
        "original_sample_id": "smp0832q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0836q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is a fast, unreliable, unconnected and message-oriented transport protocol... which has no flow or error control. but can be used with broadcasting/multicasting and streaming. udp is mainly ip with a short transport header. the udp header format contains: 1. sender port: an optional 16 bit identification of the sender. when used, but when not used, it will be (000000000000000000000). 2. receiver port: it is the receiver identification and it is also 16 bits. 3. package length: it is in bytes (including the udp header). the minimum length is 8 (byte), i.e. the header without data. 4. checksum: from the header (not the package) and data for error detection.",
        "answer_feedback": "the response is correct, but apart from the differences between the tcp and udp headers, it also contains general differences between the two transport layer protocols, which were not required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "udp is a fast and simple, unreliable, connectionless, and message-oriented transport protocol. that has no flow or error control. but may be used with broadcast/multicast and streaming.\nudp is mostly ip with a short transport header. the udp header format contains: \n1. sender port: an optional 16 bit sender identification. when used the response may be sent there, but when not used it will be (0000000000000000).\n2. receiver port: it is receiver identification and it's also 16 bit. \n3. packet length: it is in bytes (including udp header). the minimum length is 8 (byte), i.e., header without data.\n4. checksum: of the header (not the packet) and data for error detection. use of checksum optional.\n\ntcp is a connection-oriented and reliable bidirectional in-order end-to-end byte stream (socket: sock_stream) transport protocol. the connections in tcp established and torn down. there are multiplexing and demultiplexing ports at both ends. and tcp provides error control (users see correct, ordered byte sequences), end-to-end flow control (avoid overwhelming the machines at either end), and also provides congestion avoidance (avoid creating traffic jams within the network).\nthe tcp header format same as the udp header format contains source and destination ports (sender and receiver ports in udp) which are 16 bit each, and it contains checksum like the udp. but it is more complicated than the udp and it contains:\n1. sequence number. \n2. acknowledgment number (ack. no.). \n3. hl/resv/flags. \n4. advertised window.\n5. urgent pointer. \n6. and it can contain some other options…",
        "original_sample_id": "smp0836q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0829q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number: to uniquely identify each tcp package, udp does not have this header recognition number: to recognize that the package with the previous sequence number has been transmitted correctly, and it is expected that the next package. tcp has this while udp does not have. window size announced: the remaining size of the reception buffer used in the tcp flow control. udp does not have this functionality. urgent pointer: used to indicate the priority to process data in tcp, while udp treats all packages with the best effort mode without any specific priority and command.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "sequence number: to uniquely identify each tcp packet, udp does not have this header \n\nacknowledgement number: to acknowledge that the packet with the previous sequence number has been successfully transmitted, and the next packet is expected. tcp has this one while udp does not. \n\nadvertised window size: the remaining size of receiving buffer used in flow control by tcp. udp does not have this functionality. \n\nurgent pointer: is used to indicate the priority to process data in tcp, while udp treats all packets with the best effort manner without any specific priority and order.",
        "original_sample_id": "smp0829q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1633q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.x.x.x -> host or meshwork reference\n127.0.0.1 - 127.255.255.254 -> loopback  \nx.0.0.0 -> gateway (in all types of meshworks)\nn.255.255.255 -> broadcast (in all types of meshworks)here: n is meshwork reference\nx means number between 0 and 255.\nfor class a meshworks the first digit must be zero",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "0.x.x.x -> host or network address\n127.0.0.1 - 127.255.255.254 -> loopback  \nx.0.0.0 -> gateway (in all types of networks)\nn.255.255.255 -> broadcast (in all types of networks)here: n is network address\nx means number between 0 and 255.\nfor class a networks the first digit must be zero",
        "original_sample_id": "smp1633q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0219q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p=9/10=0.9 n=10 p_b=[(1-p)p^10]/1-p^11=0.051 a=less than 10 packages p(a)=1-p_b=0.49",
        "answer_feedback": "the response correctly states how the blocking probability is calculated. the calculated non-blocking probability is incorrect and the response does not calculate the non-blocking time.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "p=9/10=0.9 \n n=10 \np_b=[(1-p)p^10]/1-p^11=0.051\n a=less than 10 packets \np(a)=1-p_b=0.49",
        "original_sample_id": "smp0219q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1008q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the techniques ensure a free loop rotation of multicast packages. reverse-path-forwarding: a node that receives a package of node b on the same line as the node to send its packages to b, thinks that the packages have taken the shortest path, and distribute it to all the other neighbors. if the package is received on another route, the package will be discarded.",
        "answer_feedback": "the purpose of rpf and rpb is not just limited to multicast but also broadcast. rpf's explanation is correct, please note the packet is not forwarded to the edge from which it was received. no explanation for rpb is provided.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the techniques ensure a loop-free forwarding of multicast packets. reverse-path-forwarding: a node that receives a package of node b on the same line as node a would send his packages to b, thinks that the packages took the shortest way, and will distribute it to all other neighbors. if the package is received on another path, package will be discarded.",
        "original_sample_id": "smp1008q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0862q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption is not supported for real Internet traffic because people usually use their connection in some time frames (e.g. watching netflix) and then it is not used for some time (e.g. while sleeping) regularly. if there is a first package more generally follow after that. so the time slot after a package has a higher probability of containing also a package.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption doesn't hold for real internet traffic because people usually use their connection in some time frames (for example watching netflix) an then don't use ist fore some time (for example while sleeping) regularly.if there is a first packet more usually follow after that. so the time slot after a packet has a higher probability to also contain a packet.",
        "original_sample_id": "smp0862q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an unreliable bit stream. it is the most basic type of transfer overhaul, without sequence errors.\nl2 overhaul is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical joining is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration direction.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an undependable bit stream. it is the most basic type of transfer overhaul, without sequence errors.\nl2 overhaul is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow mastery, error mastery and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 help is an unreliable bit stream. it is the most basic type of transferral help, without sequence errors.\nl2 help is a reliable and efficient datum transferral between two adjacent stations. transferral could occur between more than 2 stations, but a physical connection is required.\nl2 functions is datum transferral via frames with flow control, error control and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul is an unreliable bit stream. it is the most basic type of conveyance overhaul, without episode errors.\nl2 overhaul is a reliable and efficient data conveyance between two adjacent stations. conveyance could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data conveyance via frames with flow control, error control and correction and configuration management.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug06smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0666q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors. the l2 service is a reliable and efficient data transfer between two adjacent stations. the transfer can occur between more than 2 stations, but a physical connection is required.",
        "answer_feedback": "the response does not identify the services correctly and also the differences between them. the response enumerates the difference between layer 1 and 2 services, but the question asks for the differences between the types of services in layer 2 only.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service is an unreliable bit stream. it is the most basic type of transfer service, without sequence errors.\nl2 service is a reliable and efficient data transfer between two adjacent stations. transfer could occur between more than 2 stations, but a physical connection is required.\nl2 functions is data transfer via frames with flow control, error control and correction and configuration management.",
        "original_sample_id": "smp0666q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less avail: reception of data whole acknowledged.\n2.unconfirmed conn.less avail:transmission of isolated , independent whole.\n3.connection-oriented avail: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug01smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data unit acknowledged.\n2.unconfirmed conn.less overhaul:transmission of apart , independent unit.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug02smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data units acknowledged.\n2.unconfirmed conn.less overhaul:transmission of apart , independent units.\n3.connection-orient overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of data units acknowledged.\n2.unconfirmed conn.less overhaul:transmission of isolated , sovereign units.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug04smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less avail: receipt of data whole acknowledged.\n2.unconfirmed conn.less avail:transmission of isolated , independent whole.\n3.connection-oriented avail: connection over fault free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0646q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.confirmed conn.less overhaul: receipt of datum whole acknowledged.\n2.unconfirmed conn.less overhaul:transmission of isolated , independent whole.\n3.connection-oriented overhaul: connection over error free channel.",
        "answer_feedback": "the response is partially correct because there is no common theme of the differences between the three services.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "1.confirmed conn.less service: receipt of data units acknowledged.\n2.unconfirmed conn.less service:transmission of isolated , independent units.\n3.connection-oriented service: connection over error free channel.",
        "original_sample_id": "smp0646q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1525q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "if you use pingbacking in the protocol of the sliding window, the receiver waits for a certain period of time to attach the sequence number and the next sequence number of ack to the next table. for this, the additional delay time must be taken into account and the sender must be informed of the fact, which probably there are no independent ack frames transmitted. also, the sender must attach the ack to the data itself.",
        "answer_feedback": "the response does not identify the underlying requirement for piggybacking. the above points are related to the implementation of piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "if you use piggbacking on the sliding window protocol, \nthe receiver waits for a given time period to attach the sequence number\nand the next ack-sequence number to the next frame.\n\nin order to do that, additional time delay has to be considered and the \nsender has to be informed about the fact, that there are probably no \nstandalone ack frames transmitted. also, the sender has to attach the \nack to the data himself.",
        "original_sample_id": "smp1525q024",
        "is_augmented": "true",
        "question_id": "q024",
        "audit": "uncertain",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer size is 10, so only nation where not less than 10 mailboat in the queue is nation 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich entail ca 5 % of the time the system is in the nation 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the buffer size is 10, so only country where not less than 10 packets in the queue is country 10.\nthis is according to slide 31 the probability that the organisation is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the clip the organisation is in the country 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug02smp0227q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the cowcatcher size is 10, so only province where not less than 10 packets in the queue is province 10.\nthis is according to slide 31 the chance that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the province 10\n-> 3 s of the monitored minute",
        "answer_feedback": "the response only states the first step of calculating the blocking probability and calculates the blocking time. however, the question asked for the complement, i.e. the non-blocking time, and how it is calculated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the buffer size is 10, so only state where not less than 10 packets in the queue is state 10.\nthis is according to slide 31 the probability that the system is full.\nrho = 9/10 = 0,9\nso p(10) = 0,0508  \nwhich means ca 5 % of the time the system is in the state 10\n-> 3 s of the monitored minute",
        "original_sample_id": "smp0227q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1629q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "from  0.0.0.0 to 0.255.255.255 : the current meshwork\n127.0.0.0 to 127.255.255.255 : loopback destination ( program )",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "from  0.0.0.0 to 0.255.255.255 : the current network\n127.0.0.0 to 127.255.255.255 : loopback addresses ( broadcast )",
        "original_sample_id": "smp1629q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0858q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, the hypothesis of independence (for each interval of the gap) does not apply to the real world. suppose video traffic in the form of viewing netflix: there will be much more video traffic in the evening than in the morning. therefore, it is dependent from the hour of the day and not independent as assumed in the fish process.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like more video traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, the assumption of independence (for each interval ∆t) does not apply to the real world. assume video traffic in the form of watching netflix: there will be significant more video traffic in the evening than in the morning. therefore, the it is dependent from the time of the day and not independent as assumed within the poisson process.",
        "original_sample_id": "smp0858q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0858q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, the hypothesis of independence (for each interval of the gap) does not apply to the real world. suppose video traffic in the form of viewing netflix: there will be much more video traffic in the evening than in the morning. therefore, it is dependent from the hour of the day and not independent as assumed in the fish process.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like more video traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, the assumption of independence (for each interval ∆t) does not apply to the real world. assume video traffic in the form of watching netflix: there will be significant more video traffic in the evening than in the morning. therefore, the it is dependent from the time of the day and not independent as assumed within the poisson process.",
        "original_sample_id": "smp0858q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0869q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the hypothesis does not correspond perfectly to the real internet traffic, because in real traffic, there is often a continuous flow of data, when transmitting a file. If a file is for example divided into 3 packages and transmitted over a network, then these 3 packages will arrive relatively close to each other in relation to the packages of another transfer. Thus, in a transmission, delta t is usually much lower than between different transmissions, which means that delta t are not really independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption doesn't fit real internet traffic perfectly, because in real traffic, there often is a continuous flow of data, when transmitting a file. if a file is for example split into 3 packets and transmitted over a network, then these 3 packets will arrive relatively close to each other in comparison to the packets of another transfer. so within a transmission, delta t is usually a lot lower than between different transmissions, which means the delta t's are not really independent.",
        "original_sample_id": "smp0869q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0851q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, it does not hold the assumption. the arrivals are more or less bundled because the package are arriving after each other when you use the cyberspace. they are arriving more or less in a small timespan. therefore the arrival of two package is not sovereign.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, it does not hold the assumption. the arrivals are more or less bundled because the packages are arriving after each other when you use the internet. they are arriving more or less in a small timespan. therefore the arrival of two packages is not independent.",
        "original_sample_id": "smp0851q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0849q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "in the poisson process, the number of incoming packages follows the poisson distribution, is easier to control than in the actual Internet traffic. observation by using the poisson process requires conservative operating point, which does not involve with the actual Internet traffic.",
        "answer_feedback": "the conclusion \"no\" is correct but the explanation does not explain why these conservative operating conditions do not hold true for the real internet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "in the poisson process, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet traffic. observation by using poisson process requires conservative operating point, that does not imply with real internet traffic.",
        "original_sample_id": "smp0849q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0849q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "in the poisson summons, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet dealings. observation by using poisson summons demand conservative operating point, that does not imply with real internet dealings.",
        "answer_feedback": "the conclusion \"no\" is correct but the explanation does not explain why these conservative operating conditions do not hold true for the real internet.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "in the poisson process, the number of incoming packets follows the poisson distribution, it is easier to control than in real internet traffic. observation by using poisson process requires conservative operating point, that does not imply with real internet traffic.",
        "original_sample_id": "smp0849q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0870q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption is not a good model in the real cyberspace traffic, since the packets come in bursts over a range of metre scales in the real network traffic, but not independently in a certain metre separation. so this process is just mathematically.",
        "answer_feedback": "the response is partially correct because it is true that arrivals are not independent as real internet traffic comes in bursts. however, the explanation does not elaborate on why that is.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this assumption is not a good model in the real internet traffic, since the packets come in bursts over a range of time scales in the real network traffic, but not independently in a certain time interval. so this process is just mathematically.",
        "original_sample_id": "smp0870q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless service, the data link layer of the sending auto sends an independent frame to the data link layer on the receiving auto.\nacknowledged connectionless service, there is no ordered connection is set up between the host autos, however, each frame was sent is acknowledged by the destination auto.\nacknowledged connection-orientate service, a ordered connection is set up on the two autos and the data is transmitted along the ordered path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug03smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connectionless overhaul, the datum link layer of the sending machine sends an independent frame to the datum link layer on the receiving machine.\nacknowledged connectionless overhaul, there is no logical connection is set up between the host machines, however, each frame was post is acknowledged by the destination machine.\nacknowledged connection-oriented overhaul, a logical connection is set up on the two machines and the datum is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug05smp0682q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unacknowledged connexionless service, the data link layer of the sending machine charge an autonomous frame to the data link layer on the receiving machine.\nacknowledged connexionless service, there is no logical connexion is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connexion-oriented service, a logical connexion is set up on the two machines and the data is transmitted along the logical path.",
        "answer_feedback": "the response answers differences correctly but the other part regarding the name is partially correct. instead of “acknowledged” one should use “confirmed”.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "unacknowledged connectionless service, the data link layer of the sending machine sends an independent frame to the data link layer on the receiving machine.\nacknowledged connectionless service, there is no logical connection is set up between the host machines, however, each frame was sent is acknowledged by the destination machine.\nacknowledged connection-oriented service, a logical connection is set up on the two machines and the data is transmitted along the logical path.",
        "original_sample_id": "smp0682q010",
        "is_augmented": "true",
        "question_id": "q010"
    },
    {
        "id": "aug00smp1529q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "for this to work, first you need a duplex mode of operation. in the normal concept of the sliding window, each incoming data unit is recognized as soon as the receiver receives it. for the recognition to be temporarily delayed, until the previous incoming data is processed and the network layer passes the next package to be sent back. the delayed recognition is now attached to the outgoing package.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in the piggybacking extension, outgoing acknowledgements are hooked onto the next outgoing packet. for this to work, you first need a duplex operation mode. in the normal sliding window concept, every incoming data unit is acknowledged as soon as the receiver gets it. for piggybacking, the acknowledgement needs to be temporarily delayed, until the previous incoming data is processed and the network layer passes the next packet to be sent back. the delayed acknowledgement is now attached to the outgoing packet.",
        "original_sample_id": "smp1529q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence number, recognition number, flag and alternative.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence numeral, acknowledgment numeral, flagstone and options.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug02smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence numeral, acknowledgment numeral, pin and options.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0795q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence number, recognition number, flag and pick.",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number, acknowledgement number, flags and options.",
        "original_sample_id": "smp0795q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1063q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an extension tree is a subset of subnets that includes all routers and does not contain loops. as soon as each router knows which lines belong to the extension tree, it can transmit / multicast all the packets on those lines except the one that came in. it is quite easy and makes efficient use of bandwidth as it generates only a minimum number of copies of packets. in the routing of the link state, all intermediate stations send liaison status packets periodically. they contain information about the distances to the neighbors. to build an extension tree, this information has to be expanded by information about the existing multicast groups. those packages will be transmitted and each of them will calculate, as is known, the best routes, but also the multicast tree and its outgoing lines.",
        "answer_feedback": "the response correctly states the attractive spanning-tree property and explains how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree is a subset of subnets which includes all routers and contains no loops. as soon as every router knows which lines belong to the spanning tree, it can broadcast/multicast all packages on those lines except the one it arrived on. it is quite easy and makes efficient use of bandwidth since the is generates only a minimum number of packet copies. in link state routing, all intermediate stations send link state packets periodically. they contain information about the distances to the neighbours. to construct a spanning tree, this information has to be expanded by the information on existing multicast groups. those packets will be broadcasted and every is will then calculate, as known, the best routes, but also the multicast tree and its outgoing lines.",
        "original_sample_id": "smp1063q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1063q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "an extension tree is a subset of subnets that includes all routers and does not contain loops. as soon as each router knows which lines belong to the extension tree, it can transmit / multicast all the packets on those lines except the one that came in. it is quite easy and makes efficient use of bandwidth as it generates only a minimum number of copies of packets. in the routing of the link state, all intermediate stations send liaison status packets periodically. they contain information about the distances to the neighbors. to build an extension tree, this information has to be expanded by information about the existing multicast groups. those packages will be transmitted and each of them will calculate, as is known, the best routes, but also the multicast tree and its outgoing lines.",
        "answer_feedback": "the response correctly states the attractive spanning-tree property and explains how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "a spanning tree is a subset of subnets which includes all routers and contains no loops. as soon as every router knows which lines belong to the spanning tree, it can broadcast/multicast all packages on those lines except the one it arrived on. it is quite easy and makes efficient use of bandwidth since the is generates only a minimum number of packet copies. in link state routing, all intermediate stations send link state packets periodically. they contain information about the distances to the neighbours. to construct a spanning tree, this information has to be expanded by the information on existing multicast groups. those packets will be broadcasted and every is will then calculate, as known, the best routes, but also the multicast tree and its outgoing lines.",
        "original_sample_id": "smp1063q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1492q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "in this position can piggybacking be used:\n 1）the communication between sender and liquidator is duplex communication.\n 2)  the acknowledgements are contained in data frame. this means the acknowledgements don’t be sent alone.",
        "answer_feedback": "the response is correct. in absence of data on the receiver side, acknowledgments can be sent separately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in this situation can piggybacking be used:\n 1）the communication between sender and receiver is duplex communication.\n 2)  the acknowledgements are contained in data frames. this means the acknowledgements don’t be sent alone.",
        "original_sample_id": "smp1492q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "loveliness is the problem，the data reserve is not count on the placement, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "equity is the problem，the data reservation is not calculate on the location, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data backlog is not count on the localization, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "uncertain",
        "confidence": 0.3
    },
    {
        "id": "aug04smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data backlog is not depending on the positioning, some have more frame than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the datum reserve is not reckon on the emplacement, some have more frames than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0741q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "fairness is the problem，the data reserve is not bet on the localisation, some have more figure than others",
        "answer_feedback": "the response identifies the fairness problem in dqdb. however, it states that it is not dependent on the location and that is incorrect. the fairness problem of reserving transmission rights depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "fairness is the problem，the data reserve is not depending on the location, some have more frames than others",
        "original_sample_id": "smp0741q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0835q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. tcp has a champaign for the acknowledgement issue, but udp does not, as it is unreliable and does not check if the packet was received.\n2. tcp has a champaign for the advertised window, which is a way for the receiver to tell the sender how much he is still able to send without overflowing the receiver’s buffer. udp does not have this, because udp does not implement flow control.\n3. tcp has a champaign for the sequence issue, providing information about the correct order of packets, udp does not handle about the order the packets arrive.\n4. tcp has champaigns for flags like syn/fin for connection establishment and ack, which udp also does not have, because it is connectionless and does not use acknowledgements.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1. tcp has a field for the acknowledgement number, but udp does not, as it is unreliable and does not check if the packet was received.\n2. tcp has a field for the advertised window, which is a way for the receiver to tell the sender how much he is still able to send without overflowing the receiver’s buffer. udp does not have this, because udp does not implement flow control.\n3. tcp has a field for the sequence number, providing information about the correct order of packets, udp does not care about the order the packets arrive.\n4. tcp has fields for flags like syn/fin for connection establishment and ack, which udp also does not have, because it is connectionless and does not use acknowledgements.",
        "original_sample_id": "smp0835q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0804q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "In the udp checksum header is optional while in the tcp header is mandatory for retransmission. The tcp header has a &lt; &gt; &gt; part announced, to avoid congestion while the udp header does not have a field for flow control. to ensure that the received byte sequences are correct and ordered, tcp; tcp; &lt; sequence number &gt; and &lt; &lt; recognition number &gt; , while the usp does not have a field for error control &lt; &lt; tcp &gt; &gt; has &lt; &gt; fields to help control the &gt; &gt; transmission, while the usp does not have a field for error control &lt; &lt; tcp &gt; &gt; .",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "in udp header checksum is optional while in tcp header is obligatory for retransmission.\ntcp header has a part “ advertised window” for congestion avoidance while udp header has no field for flow control.\nto make sure that the received byte sequences are correct and ordered, tcp sets the fields “sequence number” and “acknowledgment number”, while udp has no field for error control\ntcp has fields “flags” to help control the transmission, while udp has no field for it.",
        "original_sample_id": "smp0804q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp1069q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "property : 1.use sink tree (or other spanning tree)  for router initiating broadcast  2.subset of subnets including all routers with no loops  all is send link state mailboat periodically  -containing entropy  -distance to neighbor  -expanded by entropy on  multicast groups  -by broadcast to all the others    each is calculates a multicast tree  -from the now locally available and  complete state entropy    based on the entropy about the  multicast tree  -is determines the outgoing lines  -on which mailboat have to be transmitted",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "property : 1.use sink tree (or other spanning tree)  for router initiating broadcast  2.subset of subnets including all routers with no loops  all is send link state packets periodically  -containing information  -distance to neighbors  -expanded by information on  multicast groups  -by broadcast to all the others    each is calculates a multicast tree  -from the now locally available and  complete state information    based on the information about the  multicast tree  -is determines the outgoing lines  -on which packets have to be transmitted",
        "original_sample_id": "smp1069q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1093q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property that makes a tree that covers quite attractive for transmission and multicast applications is that there is a minimum number of copies on the network. plus, a tree that covers does not contain any loop. trees that span can be used with status link as follows: all intermediate systems (s) transmission link status packages containing distances to neighboring nodes, as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines in which packages will be transmitted.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is also correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the property which makes a spanning trees quite appealing for broadcast and multicast applications is that there exists a minimal amount of copies in the network. furthermore, a spanning tree does not contain any loops. spanning trees can be used with link state routing in the following manner: all intermediate systems (is) broadcast link state packets containing distances to neighbor nodes as well as information on multicast groups at regular intervals. with the help of this information each node can calculate a multicast tree and use it to determine the outgoing lines on which packets will be transmitted.",
        "original_sample_id": "smp1093q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0338q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop 2 :\n(b,c,driblet) not on unicast course from a to c \n(b,e,forward)\n(c,b,driblet)  not on unicast course from a to b\n(c,d,driblet)  not on unicast course from a to d \n(c,e,driblet)  not on unicast course from a to e\n(c,f,forward)\n(d,c,driblet) not on unicast course from a to c \n(d,f,driblet) not on unicast course from a to f\nhop 3:\n(e,c,driblet)not on unicast course from a to c \n(e,f,driblet) not on unicast course from a to f\n(e,g,forward)\n(f,d,driblet) not on unicast course from a to d\n(f,e,driblet) not on unicast course from a to e \n(f,g,driblet) not on unicast course from a to g\nhop 4:\n(g,f,driblet)not on unicast course from a to f\n(g,h,forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a,c,forward)\n(a,b,forward)\n(a,d,forward)\nhop 2 :\n(b,c,drop) not on unicast path from a to c \n(b,e,forward)\n(c,b,drop)  not on unicast path from a to b\n(c,d,drop)  not on unicast path from a to d \n(c,e,drop)  not on unicast path from a to e\n(c,f,forward)\n(d,c,drop) not on unicast path from a to c \n(d,f,drop) not on unicast path from a to f\nhop 3:\n(e,c,drop)not on unicast path from a to c \n(e,f,drop) not on unicast path from a to f\n(e,g,forward)\n(f,d,drop) not on unicast path from a to d\n(f,e,drop) not on unicast path from a to e \n(f,g,drop) not on unicast path from a to g\nhop 4:\n(g,f,drop)not on unicast path from a to f\n(g,h,forward)",
        "original_sample_id": "smp0338q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0152q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it look on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is expectant than the nexus's capacities.",
        "answer_feedback": "the correct encoding in this scenario is binary encoding as it provides better band utilization and in this case, there is no requirement for self-clocking.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it depends on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is greater than the link's capacities.",
        "original_sample_id": "smp0152q002",
        "is_augmented": "true",
        "question_id": "q002",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0152q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the differential sleeveless encoding should be used, because - it is not sensitive to noise, it depends on the polarity of the signal, not absolute values - it has a good function of self-watching, so it is synchronous, which is useful for when the traffic is greater than the capacities of the link.",
        "answer_feedback": "the correct encoding in this scenario is binary encoding as it provides better band utilization and in this case, there is no requirement for self-clocking.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding should be used, because \n- it is not susceptible to noise, it depends on signal polarity, not absolute values\n- it has a good self-clocking feature, so it is synchronous, which is useful for when the traffic is greater than the link's capacities.",
        "original_sample_id": "smp0152q002",
        "is_augmented": "true",
        "question_id": "q002",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding technique should be used as it has honest utilization of the bandwidth. thus there will be less traffic in the meshwork.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug02smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has good employment of the bandwidth. thus there will be lesser traffic in the web.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug03smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption technique should be used as it has right utilization of the bandwidth. thus there will be less traffic in the network.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug04smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encryption proficiency should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the net.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug06smp0197q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding proficiency should be used as it has good usage of the bandwidth. thus there will be lesser traffic in the meshwork.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "binary encoding technique should be used as it has good utilization of the bandwidth. thus there will be lesser traffic in the network.",
        "original_sample_id": "smp0197q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug00smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug02smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug03smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug04smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "l1 overhaul\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, intromission, changing of bits possible\n\nl2 overhaul \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and period control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug05smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug06smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug07smp0701q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The l1 service serves the function of transmission of bit flow limited loss of data flow, insertion, possible bit change reliable transfer of service data l2 can between more than 2 disappoint connection by a physical channel l3 functions data transmitted in the images includes error detection and correction and flow control",
        "answer_feedback": "the response answers no parts of the question correctly. the correct class names are unconfirmed connection-less, confirmed connection-less and connection oriented.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "l1 service\nserves the function of the transmittion of the bit stream\nlimited data rate\nloss, insertion, changing of bits possible\n\nl2 service \nreliable data transfer\nmay between more than 2 devives\nconnection by one physical cannel\n\nl3 funkctions\ndata ist transmitted in frames\nincludes error detection and correction and flow control",
        "original_sample_id": "smp0701q010",
        "is_augmented": "true",
        "question_id": "q010",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp1098q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The transmission along a cover tree is also free of loop and therefore more efficient than the transmission of the link state in all directions for all nodes (flood). To implement a cover tree in the routing of the link state, all nodes must know the common cover tree. To achieve this, all nodes periodically send connecting state packets, which contain information about distance to its neighbours as well as information about multicast groups. These packets are broadcast to all nodes. So, all nodes can calculate (and improve later) the multicast tree with the completed state information, which then determines the outgoing lines for subsequent transmission.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "spanning trees, which form a subset of all subnets including all routers have the main posivite property that they do not include any loops. so transmission along a spanning tree is also loop-free and therefore more efficient than a “wild” transmission in all direction for all nodes (flooding).  to implement a spanning tree in link state routing, all nodes have to know the common spanning tree. to achieve this, all nodes send link state packets periodically, which include information about the distance to its neighbours as well as multicast-group information. those packets are broadcasted to all nodes. then, all nodes can calculate (and later improve) the multicast tree with the completed state information, which then determines the outgoing lines for further transmission.",
        "original_sample_id": "smp1098q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1058q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the most important property of the spanning tree is that they do not contain loops, this is appealing to the broad- and multicasting , because the amount of outgoing lines will be reduced , making also the number of mailboats smaller and the number of repeated mailboats will decrease. in the case of the multicast, all is belonging to the group have to know the multicast tree, that is why connexion state routing is appropriate. it is important to know that the basis of this kind of routing is that all neighbors send each other their own connexion state mailboat in which they have information about the costs that their own adjacent connexions have.",
        "answer_feedback": "the response is missing how link-state routing can be modified to construct a spanning tree. to calculate the spanning trees, you have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the most important property of the spanning trees is that they do not contain loops, this is appealing to the broad- and multicasting , because the amount of outgoing lines will be reduced , making also the number of packets smaller and the number of repeated packets will decrease. in the case of the multicast, all is belonging to the group have to know the multicast tree, that is why link state routing is appropriate. it is important to know that the basis of this kind of routing is that all neighbors send each other their own link state packet in which they have information about the costs that their own adjacent links have.",
        "original_sample_id": "smp1058q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0369q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(a,b,forward), (a,c,forward), (a,d,forward) (a,d,forward) (b: (b,c,drop) <=car b knows that c does not receive unicast packages via c (b,e,drop) (c,b,drop) <=car c knows that b does not receive unicast packages via c (c,d,drop), <=car c knows that d does not receive unicast packages via c (c,e,drop), <=car c knows that d does not receive unicast packages via c (c,f,drop) (d,c,drop),<=car d knows that c does not receive unicast packages via d (d,f,drop) <=car d knows that f does not receive unicast packets via d hop 3: message (e,c,drop), <=because c does not receive unicast packages via e (f,drop), <=d knows that f does not receive unicast packets via d hop 3: message (e,c,drop), <=c does not receive unicast packets via d over (f), <=",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1: from a: (a,b,forward),(a,c,forward ),(a,d,forward)\n\nhop 2:from b:\n(b, c, drop) <=because b knows that c does not receive unicast packets via c\n(b, e, forward)from c: \n(c, b, drop) <=because c knows that b does not receive unicast packets via c\n(c, d, drop),  <=because c knows that d does not receive unicast packets via c\n(c, e, drop),  <=because c knows that d does not receive unicast packets via c\n(c, f, forward) \nfrom d: \n(d, c, drop),<=because d knows that c does not receive unicast packets via d\n (d, f, drop)  <=because d knows that f does not receive unicast packets via d\nhop 3:from e: \n(e, c, drop), <=because e knows that c does not receive unicast packets via e\n(e, f, drop),  <=because e knows that f does not receive unicast packets via e\n(e, g, forward) \nfrom f: \n(f, d, drop), <=because f knows that d does not receive unicast packets via f\n (f, e, drop),  <=because f knows that e does not receive unicast packets via f\n(f, g, drop) <=because f knows that g does not receive unicast packets via f\nhop 4:from g: \n(g, f, drop),  <=because g knows that f does not receive unicast packets via g\n(g, h, drop)<=because h has only one neighbor from which it got the message, h does not forward the message.",
        "original_sample_id": "smp0369q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1011q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the forwarding path (rpf) is a technique used in modern routers in order to ensure the unlooped forwarding of multicast packets in multicast routing and to help prevent the IP Spoofing address in unicast routing. Network administrators can use the unicast or forwarding path (unicast rpf) to help limit malicious traffic in a business network. This security feature works by allowing a router to verify the accessibility of the source address in packages that are forwarded. the return package of the forwarding interface is each sender has its own data tree but it is not necessary to know the trees that extend. each router has the information that it would use in (unicast)-packages. the rpf algorithm is as indicated below. the forwarding package of the forwarding interface is not the only one in the forwarding route: the packets for this station/source are generally also: the return package uses the best route until now the return action (more likely).",
        "answer_feedback": "the stated purposes are correct but they are not limited to unicast and multicast instead used widely in broadcast too. the response correctly explains both rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) is a technique used in modern routers for the purposes of ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent ip address spoofing in unicast routing. network administrators can use unicast reverse path forwarding (unicast rpf) to help limit the malicious traffic on an enterprise network. this security feature works by enabling a router to verify the reachability of the source address in packets being forwarded. the principle of rpf is each sender has its own spanning tree but is does not need to know the spanning trees. each router has information which path it would use for (unicast)-packets. algorithm of rpf is as below: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: assumption: packet used the best route until now action: resend over all edges (not including the incoming one) no: assumption: packet did not use this route (it is not the best route) action: discard packet (most likely duplicate reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path in relation to the interface on which the multicast packets are received, but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to make the decision about forwarding, the routers must be informed about the shortest paths. trpb routing is an extension of rpb routing. it ensures that the multicast packets do not get into subnets in which there are no current group members. the principle of rpb is every router forwards a broadcast packet to every adjacent router, except the one where it received the packet. a router u accepts a broadcast packet p originating at router s only if p arrives on the link that is on the direct (unicast) path from u to s. the algorithm of rpb is as below: has this packet arrived at the is entry over which the packets for this station/source s are usually also sent?  yes: packet used the best route until now?   yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction)  no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf)  no: discard packet (is most likely a duplicate)",
        "original_sample_id": "smp1011q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1011q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the forwarding path (rpf) is a technique used in modern routers in order to ensure the unlooped forwarding of multicast packets in multicast routing and to help prevent the IP Spoofing address in unicast routing. Network administrators can use the unicast or forwarding path (unicast rpf) to help limit malicious traffic in a business network. This security feature works by allowing a router to verify the accessibility of the source address in packages that are forwarded. the return package of the forwarding interface is each sender has its own data tree but it is not necessary to know the trees that extend. each router has the information that it would use in (unicast)-packages. the rpf algorithm is as indicated below. the forwarding package of the forwarding interface is not the only one in the forwarding route: the packets for this station/source are generally also: the return package uses the best route until now the return action (more likely).",
        "answer_feedback": "the stated purposes are correct but they are not limited to unicast and multicast instead used widely in broadcast too. the response correctly explains both rpf and rpb.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding (rpf) is a technique used in modern routers for the purposes of ensuring loop-free forwarding of multicast packets in multicast routing and to help prevent ip address spoofing in unicast routing. network administrators can use unicast reverse path forwarding (unicast rpf) to help limit the malicious traffic on an enterprise network. this security feature works by enabling a router to verify the reachability of the source address in packets being forwarded. the principle of rpf is each sender has its own spanning tree but is does not need to know the spanning trees. each router has information which path it would use for (unicast)-packets. algorithm of rpf is as below: has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: assumption: packet used the best route until now action: resend over all edges (not including the incoming one) no: assumption: packet did not use this route (it is not the best route) action: discard packet (most likely duplicate reverse path broadcast (rpb) is an improvement on rpf. rpb not only evaluates the shortest path in relation to the interface on which the multicast packets are received, but also influences the forwarding of the data to the interface of the router. as a result, the multicast packets are only forwarded to the interfaces at which the next router is in the opposite direction on the shortest path to the data source. to be able to make the decision about forwarding, the routers must be informed about the shortest paths. trpb routing is an extension of rpb routing. it ensures that the multicast packets do not get into subnets in which there are no current group members. the principle of rpb is every router forwards a broadcast packet to every adjacent router, except the one where it received the packet. a router u accepts a broadcast packet p originating at router s only if p arrives on the link that is on the direct (unicast) path from u to s. the algorithm of rpb is as below: has this packet arrived at the is entry over which the packets for this station/source s are usually also sent?  yes: packet used the best route until now?   yes: select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction)  no: do not send over all edges (without the incoming one), i.e., not as in reverse path forwarding (rpf)  no: discard packet (is most likely a duplicate)",
        "original_sample_id": "smp1011q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp1064q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees are interesting for broad- and multicasting because they represent a subset of a graph that contains all nodes but no loops. if every router in the network knows about the structure of the sweep tree, it can simply forward a received broadcast to the remaining sweep tree lines without creating duplicates or not using the bandwidth optimally. in the link state algorithm all stations have information about the subsist other stations and can create a model of the topology by themselves. this model can then be used to create a sweep tree that fulfills the reward mentioned above.",
        "answer_feedback": "to calculate the spanning trees, you have to know which nodes belong to which groups. the link-state packets have to be expanded with multicast group information so other nodes can construct multicast trees by themselves.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "spanning trees are interesting for broad- and multicasting because they represent a subset of a graph that contains all nodes but no loops. if every router in the network knows about the structure of the spanning tree, it can simply forward a received broadcast to the remaining spanning tree lines without creating duplicates or not using the bandwidth optimally. in the link state algorithm all stations have information about the existing other stations and can create a model of the topology by themselves. this model can then be used to create a spanning tree that fulfills the advantages mentioned above.",
        "original_sample_id": "smp1064q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0878q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "could not be on the real Internet. on the real Internet if a package is lost or has error, it needs to be retransmitted. obviously it could affect the next arrivals. means that time intervals cannot be independent.",
        "answer_feedback": "“no” is the correct answer. while the example is correct, it limits the dependency of packet arrival to only retransmission.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it couldn’t be in the real internet. in the real internet if a packet is lost or has error, it needs to be retransmitted. obviously it could affect the following arrivals. it means the time intervals could not be independent.",
        "original_sample_id": "smp0878q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0878q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "could not be on the real Internet. on the real Internet if a package is lost or has error, it needs to be retransmitted. obviously it could affect the next arrivals. means that time intervals cannot be independent.",
        "answer_feedback": "“no” is the correct answer. while the example is correct, it limits the dependency of packet arrival to only retransmission.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "it couldn’t be in the real internet. in the real internet if a packet is lost or has error, it needs to be retransmitted. obviously it could affect the following arrivals. it means the time intervals could not be independent.",
        "original_sample_id": "smp0878q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0732q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "it works with eminent-force in order to work very performant with a eminent amount of data.\nproblem is that it is not that good, when there is less data.",
        "answer_feedback": "the response is incorrect. there is a fairness issue with the distribution of transmission rights between stations that depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "it works with high-power in order to work very performant with a high amount of data.\nproblem is that it is not that good, when there is less data.",
        "original_sample_id": "smp0732q011",
        "is_augmented": "true",
        "question_id": "q011",
        "audit": "uncertain",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0830q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "compare to udp, the tcp header is overleap the \"packet length\" field.\ncompare to tcp, \"sequence number\", \"acknowledgment number\" and \"advertised windowpane size\" are some of the fields that are overleap in the udp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "compared to udp, the tcp header is missing the \"packet length\" field.\ncompared to tcp, \"sequence number\", \"acknowledgment number\" and \"advertised window size\" are some of the fields that are missing in the udp header.",
        "original_sample_id": "smp0830q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp1085q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the central node of the spanning tree can generate a copy of a packet for each required outgoing line, therefore minimzing the overhead/network load. every node measures the distance to its adjacent is and distributes this local link province entropy thrive by entropy on multicast groups in a packet to all is. therefore, each node can calculates a multicast tree and complete province entropy. based on the entropy about the multicast tree the is determines the outgouing lines on which packets have to be transmitted.",
        "answer_feedback": "there is a unique path to reach all nodes from another node, so only a central node generating a copy of the packet and that leading to reduced load is not correct. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "the central node of the spanning tree can generate a copy of a packet for each required outgoing line, therefore minimzing the overhead/network load. every node measures the distance to its adjacent is and distributes this local link state information expanded by information on multicast groups in a packet to all is. therefore, each node can calculates a multicast tree and complete state information. based on the information about the multicast tree the is determines the outgouing lines on which packets have to be transmitted.",
        "original_sample_id": "smp1085q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1631q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "diffusion: x.255,255,255 network identifier: x.0.0.0",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast: x.255.255.255\nnetwork identifier: x.0.0.0",
        "original_sample_id": "smp1631q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1631q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "diffusion: x.255,255,255 network identifier: x.0.0.0",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast: x.255.255.255\nnetwork identifier: x.0.0.0",
        "original_sample_id": "smp1631q026",
        "is_augmented": "true",
        "question_id": "q026",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1006q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Both share the objective of inundating a network with a message while they cause as few duplicates as possible. Inverse diffusion: a sender sends a message to another node through the shortest path. the recipient sends a message back to the sender through all its adjacent nodes. If the original sender now receives the package back from several routes and releases each package received from a path different from the shorter one to the original receiver because these packages are considered duplicated. Inverse diffusion: all nodes inspect the sender and receiver of incoming packets and check whether these messages have been returned in the past. based on the historical information that they can now decide to be part of the shortest route between the sender and the recipient of the inspected package. The inspected package is not sent beyond the nodes for which the inspection node is part of the shortest route.",
        "answer_feedback": "the response correctly answers the purpose and explanation of rpf and rpb broadcastings.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both share the goal of flooding a network with some message while causing as few duplicates as possible. reverse path forwarding: a sender sends a message to another node via the shortest route. the receiver sends a message back to the sender via all of its adjacent nodes. if the original sender now receives the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. reverse path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such messages in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "original_sample_id": "smp1006q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1006q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "both share the goal of flooding a network with some substance while causing as few duplicates as possible. vacate path forwarding: a sender sends a substance to another node via the shortest route. the receiver sends a substance back to the sender via all of its adjacent nodes. if the original sender now incur the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. vacate path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such substances in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "answer_feedback": "the response correctly answers the purpose and explanation of rpf and rpb broadcastings.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both share the goal of flooding a network with some message while causing as few duplicates as possible. reverse path forwarding: a sender sends a message to another node via the shortest route. the receiver sends a message back to the sender via all of its adjacent nodes. if the original sender now receives the returnings packet from multiple routes and drops every packet that was received from a route other than the shortest one to the original receiver because those packages are considered duplicates. reverse path broadcast: all nodes inspect the sender and receiver of incoming packets and check if they have forwarded such messages in the past. based on the historical information they can now decide if they are part of the shortest route between sender and receiver of the inspected packet. the inspected packet is only forwarded further to nodes for which the inspecting node is part of the shortest path.",
        "original_sample_id": "smp1006q016",
        "is_augmented": "true",
        "question_id": "q016",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp1060q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a traverse tree is a tree that connects all edges in a graph with the minimum number of possible edges. in this way, traverse trees help in avoiding loops while unite all the edges in a graph that makes them good for building networks for broad and multicasting.  the already existing lsr can be used to construct a traverse tree for multicasting, first, each node must find the shortest path to all other nodes(linked state path/lsp), and every clip the network changes, this must be repeated and new lsps must be calculated. these lsps wil be the only paths used to communicate between the nodes.",
        "answer_feedback": "the response correctly answers why using a spanning tree is a good idea in multicast and broadcast. the provided explanation just states the original link-state algorithm with no information about how it should include the new multicast group information and how each node will form part of the multicast spanning tree.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a spanning tree is a tree that connects all edges in a graph with the minimum number of possible edges. in this way, spanning trees help in avoiding loops while connecting all the edges in a graph that makes them good for building networks for broad and multicasting.  the already existing lsr can be used to construct a spanning tree for multicasting, first, each node must find the shortest path to all other nodes(linked state path/lsp), and every time the network changes, this must be repeated and new lsps must be calculated. these lsps wil be the only paths used to communicate between the nodes.",
        "original_sample_id": "smp1060q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1625q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.0—10.255.255.255 (individual habit)\n127.x.x.x (loopback tryout)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0,
        "original_answer": "10.0.0.0—10.255.255.255 (private use)\n127.x.x.x (loopback test)",
        "original_sample_id": "smp1625q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp0208q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "of the question we know that this is a model m/m/1/n. of “buffer of size is 10 ” we know that n=10. the average rate of arrival of packages is",
        "answer_feedback": "the calculation steps are given correctly in the response but the final number of seconds where the system has less than 10 packets is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "from the question we know that this is a m/m/1/n model.\nfrom “buffer of size is 10 ” we know that n=10.\nthe average rate of packets arrival is  λ = 9/s.\nthe average rate of service is  μ = 10/s.\ntherefore, the average probability of the service being occupied is ρ =  λ/μ = 9/10 = 0.9.\nwe know that blocking probability is pb=pn=[(1-ρ)ρ^n]/[1-ρ^(n+1)]. \nwe substitute the above known quantity into blocking probability formula for calculation, we can get the pb.\nthe expected time of the system to be in a state in which there are less than 10 packets waiting in the queue in one minute after the system reaches equilibrium = 60 seconds*(1-pb).",
        "original_sample_id": "smp0208q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex surgery\n3.the initial succession no.should be 0.\n4.the next succession no. what is estimated is pay.\n5.the next ack-succession no. that is expected is also pay.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1490q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial episode no.should be 0.\n4.the next episode no. what is gauge is dedicate.\n5.the next ack-episode no. that is expected is also dedicate.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains additional requirements. point 1 is true but it refers to what happens in piggybackig and is not a requirement. points 3, 4, and 5 are incorrect as they are only relevant to a specific example in the lecture.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "requirement for piggybacking are:\n1.frames may contain implicit acks(acknowledgements)\n2.it should be duplex operation\n3.the initial sequence no.should be 0.\n4.the next sequence no. what is estimated is given.\n5.the next ack-sequence no. that is expected is also given.",
        "original_sample_id": "smp1490q024",
        "is_augmented": "true",
        "question_id": "q024",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp0206q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "By dividing the rate of arrival of the maintenance rate and with n=10, we can continue to calculate the probability of blocking p_b. by subtracting that of 1 we get the probability in which the buffer is not fully full.Once we calibrate this probability up to a full minute, we can calculate the amount of seconds in which the buffer contains less than 10 packets.In this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "by dividing the arrival rate from the servicing rate and with n=10, we can go on to calculate the blocking probability p_b. by subtracting that from 1 we get the probability in which the buffer is not entirely full. once we scale that probability up to a full minute, we can calculate the amount of seconds in which the buffer holds less than 10 packets. in this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "original_sample_id": "smp0206q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0206q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "By dividing the rate of arrival of the maintenance rate and with n=10, we can continue to calculate the probability of blocking p_b. by subtracting that of 1 we get the probability in which the buffer is not fully full.Once we calibrate this probability up to a full minute, we can calculate the amount of seconds in which the buffer contains less than 10 packets.In this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "by dividing the arrival rate from the servicing rate and with n=10, we can go on to calculate the blocking probability p_b. by subtracting that from 1 we get the probability in which the buffer is not entirely full. once we scale that probability up to a full minute, we can calculate the amount of seconds in which the buffer holds less than 10 packets. in this case, we can expect the system to have less than 10 packets in the buffer for ~57 seconds.",
        "original_sample_id": "smp0206q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0815q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header includes several different fields that are not included in the upp headers, such as: -sequence number: the following from the first data byte of this tcp package, which is used to reorganize the tcp segments, as they can arrive in a different order from the receiver. -recognition number: the following of the following expected tcp-segment segments: the flag field indicates which other parts of the header should be considered. examples are: recognition flag, urgent flag or syn flag (connection establishment) -window: how many bytes can receive the package sender. -option field: the option field can be used to enlarge the header with data that is not included in the tcp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the tcp header includes multiple different fields that are not included in the udp headers, such as: -sequence number: the seqno of the first data-byte of this tcp-packet, which is used to reorganize the tcp segments, as they may arrive in a different order at the receiver. -acknowledgment number: the seqno of the next expected tcp-segment -flags: the flag field states which other parts of the header have to be considered. examples are: acknowledgement flag, urgent flag or syn flag (connection establishment) -window: how many bytes the sender of the packet is able to receive. -options field: the options field can be used to extend the header with data that is not included in the tcp header.",
        "original_sample_id": "smp0815q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0235q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "you add up all the prolabiertes of the buffer nation from 0 to 9 (94,91%) . you reproduce this percentage with the time (60 sec). you get the expected time in which there are less than 10 mailboat in the buffer -->57 sec.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you add up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the time (60 sec). you get the expected time in which there are less than 10 packets in the buffer -->57 sec.",
        "original_sample_id": "smp0235q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0235q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "you sum up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the meter (60 sec). you get the await meter in which there are less than 10 packets in the buffer -->57 sec.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "you add up all the prolabiertes of the buffer state from 0 to 9 (94,91%) . you multiply this percentage with the time (60 sec). you get the expected time in which there are less than 10 packets in the buffer -->57 sec.",
        "original_sample_id": "smp0235q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0340q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1:\n(a, b, frontwards)\n\n(a, c, frontwards)\n\n(a, d, frontwards)\n\nhop2:\n\n\n(b, e, frontwards)\n\n(c, f, frontwards)\n\nhop3:\n\n(e, g, frontwards)\n\nhop4:\n(g, h, drop) -> packet drib because it only has one neighbour and node h does not frontwards the content",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.5 for reasoning (a,d, drop), (c, f, drop)  ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8,
        "original_answer": "hop1:\n(a, b, forward)\n\n(a, c, forward)\n\n(a, d, forward)\n\nhop2:\n\n\n(b, e, forward)\n\n(c, f, forward)\n\nhop3:\n\n(e, g, forward)\n\nhop4:\n(g, h, drop) -> packet drops because it only has one neighbour and node h does not forward the message",
        "original_sample_id": "smp0340q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0848q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption does not concord in the real world, because, in the real world, networks must deal with bursty dealings, as well as times when there is no or very less dealings, and this change in dealings is dependent on a number of factors. \nfor eg. when using a streaming service, the probability of seeing packets arrive continuously is very high as opposed to downloading a pdf file, and the reaching of the packets is very much dependent on the activity or dealings at previous and future time intervals.",
        "answer_feedback": "the response is correct as it correctly associates the probability of an arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "this assumption does not hold in the real world, because, in the real world, networks must deal with bursty traffic, as well as times when there is no or very less traffic, and this change in traffic is dependent on a number of factors. \nfor eg. when using a streaming service, the probability of seeing packets arrive continuously is very high as opposed to downloading a pdf file, and the arrival of the packets is very much dependent on the activity or traffic at previous and future time intervals.",
        "original_sample_id": "smp0848q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0223q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the process still changes nations when it is in equilibrium. however, the steady-nation probability pk to find the process in nation k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability catamenia, also called flux, into nation k equals the probability catamenia out of nation k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "answer_feedback": "the response is incorrect because it states a description of the system's equilibrium state. however, the question requirement is to calculate the number of expected seconds where the system has less than 10 packets waiting in the queue.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the process still changes states when it is in equilibrium. however, the steady-state probability pk to find the process in state k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability flow, also called flux, into state k equals the probability flow out of state k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "original_sample_id": "smp0223q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0223q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the process still changes provinces when it is in counterbalance. however, the steady-province chance pk to find the process in province k does not change anymore, thus dpk (t )/dt = 0. \n\nin counterbalance, it follows from dpk (t )/dt = 0 that the chance flow, also called flux, into province k equals the chance flow out of province k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "answer_feedback": "the response is incorrect because it states a description of the system's equilibrium state. however, the question requirement is to calculate the number of expected seconds where the system has less than 10 packets waiting in the queue.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "the process still changes states when it is in equilibrium. however, the steady-state probability pk to find the process in state k does not change anymore, thus dpk (t )/dt = 0. \n\nin equilibrium, it follows from dpk (t )/dt = 0 that the probability flow, also called flux, into state k equals the probability flow out of state k. this yields the global balance equations:\n(sum starting from k=0 until infinity) => pk =1",
        "original_sample_id": "smp0223q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0852q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "not this hypothesis is not supported for the real Internet traffic. real Internet traffic has built in congestion and flow control mechanisms, therefore, if the packages fall due to the overflow of queue buffer at high rate of arrival, the ack messages would not be detected on the sender side. therefore, the transmission speed of the sender will be reduced or reduced to compensate the slow receiver. in this sense, the arrivals in each time interval are not really independent.",
        "answer_feedback": "while the congestion does affect the arrival dependency at a node,  the main cause is how data is sent normally, which is in bursts.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow control mechanisms, therefore if the packets get dropped due to queue buffer overflow from high arrival rate, there would be missing ack messages detected at the sender side. therefore the rate of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "original_sample_id": "smp0852q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0852q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow ascendency mechanisms, therefore if the mailboat get dropped due to queue buffer overflow from high arrival pace, there would be missing ack messages detected at the sender side. therefore the pace of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "answer_feedback": "while the congestion does affect the arrival dependency at a node,  the main cause is how data is sent normally, which is in bursts.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no this assumption does not hold for real internet traffic. real internet traffic has built in congestion and flow control mechanisms, therefore if the packets get dropped due to queue buffer overflow from high arrival rate, there would be missing ack messages detected at the sender side. therefore the rate of transmission from sender will drop or slow down to compensate for slow receiver. in this sense the arrivals at each time interval are not really independent.",
        "original_sample_id": "smp0852q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0241q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the answer is 56.952s\n\nρ = 9/10 = 0.9\nthe blocking chance, is also the chance of that the buffer is full, is:\n     p(b) = 0.0508,\nwhich means that in one minute, the chance of that there're exact 10 mailboat is 0.0508\nso the chance of that there're less than 10 mailboat waiting in the queue is 1-0.0508 = 0.9492.\nso, the time that there're less than 10 mailboat irrigate in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the answer is 56.952s\n\nρ = 9/10 = 0.9\nthe blocking probability, is also the probability of that the buffer is full, is:\n     p(b) = 0.0508,\nwhich means that in one minute, the probability of that there're exact 10 packets is 0.0508\nso the probability of that there're less than 10 packets waiting in the queue is 1-0.0508 = 0.9492.\nso, the time that there're less than 10 packets watering in the queue in 1 minute is 60 s *0.0942 = 56.952 s.",
        "original_sample_id": "smp0241q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp0233q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "We know: 1 tail buffer is 10 9 pkts/s arrive on average → lambda = 9 10 pkts/s served on average → mu = 10 clock for 1 minute after the equilibrium ro = lamb101010101010,1010,1010,1010,101010,1010,101010,1010,101010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,1010,10,1010,10,10,10,10,0,0,1010,10,10,1010,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10, p3,10,10, p3,10,10,10,10,10, p3,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "we know:\n1 queue\nbuffer is 10\n9 pkts/s arrive on average → lambda = 9\n10 pkts/s serviced on average → mu = 10\nwatch for 1 minute after equilibrium\n\nro = lamba / mu = 9/10 = 0,9\nwith the help of the formula on slide 30, we can calculate the probabilities of each buffer size:\np0 = (1-ro)/ (1-ro^(n+1)) = 0,146\npn = ((1-ro)*ro^n)/(1-ro^(n+1))\np1 = 0,131\np2 = 0,118\np3 = 0,106\np4 = 0,096\np5 = 0,086\np6 = 0,077\np7 = 0,070\np8 = 0,063\np9 = 0,056\np10 = 0,051\nsum(p0 - p10) = 1.\n\nlooking for n being smaller than 10. p(x less than 10) = 1- p(x=10) = 1 - 0,051 = 0,949 so 94,9% of the time the time the buffer is smaller than 10. → 60 seconds * 0,949 around 56,94 so around 57 seconds the buffer is smaller than 10 on average.",
        "original_sample_id": "smp0233q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1516q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "1.first, it must be duplex performance.\n2.the data underframe and the confirmation underframe use the same formatting.",
        "answer_feedback": "both points are correct as the acknowledgment field is contained within the outgoing data frame.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "1.first, it must be duplex operation.\n2.the data frame and the confirmation frame use the same format.",
        "original_sample_id": "smp1516q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. purpose of temporarily valid tsaps:\n2. indentify association singly\n3. identify pdus singly:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug01smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use of temporarily valid tsaps:\n2. indentify association severally\n3. identify pdus severally:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug03smp0451q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. habit of temporarily valid tsaps:\n2. indentify joining separately\n3. identify pdus separately:",
        "answer_feedback": "only names mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33,
        "original_answer": "1. use of temporarily valid tsaps:\n2. indentify connections individually\n3. identify pdus individually:",
        "original_sample_id": "smp0451q006",
        "is_augmented": "true",
        "question_id": "q006"
    },
    {
        "id": "aug00smp1517q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "Both parties have to agree to the protocol before and therefore consider the additional access field in a data transmission framework. Both parties have to have a buffer and should be able to reflect on their status. in the data frames are the buffer size, ack and subsequent sent fields - in both directions.",
        "answer_feedback": "the response is correct as a separate field for acknowledgment in the data frame is a must.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "both parties have to agree on the protocol before and therefore consider the additional ack-field in a data transmission frame.both parties have to have a buffer and must be able to reflect on its status. \nin the data frames are the fields buffer size, ack and seq sent - in both directions.",
        "original_sample_id": "smp1517q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0388q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n\n(a, b, forth)\n\n(a, c, forth)\n\n(a, d, drop) => d does not forth the package because it is not the next hop on the shortest unicast path to a of any neighbor (mailboat came from a, c transport directly to a, f transport over c)\n\n \n\nhop 2:\n\n(b, e, forth)\n\n(c, f, drop) => f does not forth the package because it is not part of the shortest unicast path to a of any neighbor (mailboat came from c, d transport directly to a, e transport over b, g transport over e)\n\n \n\nhop 3:\n\n(e, g, forth)\n\n \n\nhop 4:\n\n(g, h, drop) => h's only neighbor is g from which it got the mailboat",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n\n(a, b, forward)\n\n(a, c, forward)\n\n(a, d, drop) => d does not forward the package because it is not the next hop on the shortest unicast path to a of any neighbor (packet came from a, c sends directly to a, f sends over c)\n\n \n\nhop 2:\n\n(b, e, forward)\n\n(c, f, drop) => f does not forward the package because it is not part of the shortest unicast path to a of any neighbor (packet came from c, d sends directly to a, e sends over b, g sends over e)\n\n \n\nhop 3:\n\n(e, g, forward)\n\n \n\nhop 4:\n\n(g, h, drop) => h's only neighbor is g from which it got the packet",
        "original_sample_id": "smp0388q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0791q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp and tcp have both the port of origin, the destination port and a check sum for the header. udp also has a package length tcp has more information to make the connection completely orderly and totally reliable: sequence number recognize number hl/resv/fags announced again.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the udp and tcp have both source port, destination port and a checksum for the header.\nudp also has a package length\ntcp has more information to make the connection fully ordered and fully reliable:\nsequence number \nacknowledge number\nhl/resv/fags\nadvertised winred again.",
        "original_sample_id": "smp0791q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug00smp0810q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- episode number: tcp needs a connection setup to jibe on a starting episode number, which is then incremented. - reference number: tcp messages contain the episode number of the last acknowledged message. - advertised win: widow size dermines how much unacknowledged data the sender can send - urgent pointer: tcp thus signals that there is important data at a certain position in the data stream which should be read immediately. the field is only read if the urgent flag is also set. - sender port is optional in udp - udp header contains a packet length field",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "- sequence number: tcp needs a connection setup to agree on a starting sequence number, which is then incremented. - acknowledgment number: tcp messages contain the sequence number of the last acknowledged message. - advertised win: widow size dermines how much unacknowledged data the sender can send - urgent pointer: tcp thus signals that there is important data at a certain position in the data stream which should be read immediately. the field is only read if the urgent flag is also set. - sender port is optional in udp - udp header contains a packet length field",
        "original_sample_id": "smp0810q012",
        "is_augmented": "true",
        "question_id": "q012"
    },
    {
        "id": "aug01smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug05smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug06smp0392q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hops 1: (h,g,advance) hops 2: (g,f,advance), (g,e,advance) hops 3: (e,b,advance), (e,c,advance), (e,f,fall)=== in duplicate (f,c,fall)=== in duplicate, (f,d,advance) hops 4: (b,c,fall)== = = = = =============================================================================================================================================================================================================================================================================================================================================================================================================================",
        "answer_feedback": "the flow starts from a  as sender not h. packets are dropped for being not on the best route, not for being duplicate as the sole reason.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "hop 1:\n(h,g, forward)\nhop 2:\n(g,f, forward), (g,e, forward)\nhop 3:\n(e,b, forward), (e,c, forward), (e,f, drop)<=  because of duplicate\n(f,c, drop)<= because of duplicate, (f,d, forward)\nhop 4:\n(b,c, drop)<= becuase of duplicate, (b,a, forward), (c,a drop)<= becuase of duplicate, (d,a, drop)<= becuase of duplicate",
        "original_sample_id": "smp0392q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0367q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hub 1: (a, b, before) (a, c, before) (a, d, before) hub 2: (b, c, fall) <= b knows that he is not on the best path of c to a (b, e, before) (c, b, fall) <= c is not on the best path of b (c, e, fall) <= c is not on the best path of e (c, f, before) (c, d, fall) <= c is not on the best path of d (d, c, fall) <= d is not on the best path of c (d, f, fall) <= d is not on the best path of f hub 3: (e, f, fall) <= e is not on the best path of f (e, c, fall) <= e is not on the best path of c (e, g, before) (f, e, fall) <= f is not on the best path of e (f, d, fall) <= g is not on the best path of f (f, d, fall) <= g is not on the best path of c (e, f is not on the best path of f is before",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, drop) <= b knows it is not on c's best path to a\n(b, e, forward)\n(c, b, drop) <= c is not on best path of b\n(c, e, drop) <= c is not on best path of e\n(c, f, forward)\n(c, d, drop) <= c is not on best path of d\n(d, c, drop) <= d is not on best path of c\n(d, f, drop) <= d is not on best path of f\nhop 3:\n(e, f, drop) <= e is not on best path of f\n(e, c, drop) <= e is not on best path of c\n(e, g, forward)\n(f, e, drop) <= f is not on best path of e\n(f, d, drop) <= f is not on best path of d\n(f, g, drop) <= f is not on best path of g\nhop 4:\n(g, h, forward)\n(g, f, drop) <= g is not on best path of f",
        "original_sample_id": "smp0367q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0884q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because dealings can be dependent on the time or previous arriver. for video streaming, arriver are more probable to occur during the evening than during the morning, and are also dependent on previous arriver (it’s probable for streaming that an arrival follows another arriver, meaning the user continues to stream).",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because traffic can be dependent on the time or previous arrivals. for video streaming, arrivals are more likely to occur during the evening than during the morning, and are also dependent on previous arrivals (it’s likely for streaming that an arrival follows another arrivals, meaning the user continues to stream).",
        "original_sample_id": "smp0884q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0884q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because traffic can be dependent on the time or previous reaching. for picture streaming, reaching are more likely to occur during the evening than during the morning, and are also dependent on previous reaching (it’s likely for streaming that an arrival follows another reaching, meaning the exploiter continues to stream).",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale behavioral patterns like having more traffic in the evening. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "no, because traffic can be dependent on the time or previous arrivals. for video streaming, arrivals are more likely to occur during the evening than during the morning, and are also dependent on previous arrivals (it’s likely for streaming that an arrival follows another arrivals, meaning the user continues to stream).",
        "original_sample_id": "smp0884q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0886q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "the assumption of independent arrivals for each time interval is not maintained for real Internet traffic. if we use streaming as an example for Internet traffic, we will see that arrivals for each time interval are not independent. the video buffer may be on or off for some time, so if your ignition we receive the next video segment and then stops for some time and starts again. so it is not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the assumption of independent arrivals for each time interval δt doesn’t hold for real internet traffic. if we use streaming as an example for internet traffic, we will see that the arrivals for each time interval aren’t independent. the video buffer can be on or off for some time, so if its on we receive the next video segment and then it stops for some time and starts over again. so its not independent.",
        "original_sample_id": "smp0886q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1083q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "sweep trees avoid loops in the subnets which make them pretty useful for multicast, as the sweep tree already mitigates any loops in the multicast forwarding. to work with link state routing, the link state packets have to be broadcasted to all other knob to be able to cipher a sweep tree on each node separately. the distance information are updated periodically with the distances to the neighbors by the other is.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast, but the same reasoning also holds for broadcast. the response only describes the classic link-state algorithm without mentioning any details on how the packet is expanded with multicast group information and how it is used to construct a  multicast spanning tree by each node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "spanning trees avoid loops in the subnets which make them pretty useful for multicast, as the spanning tree already mitigates any loops in the multicast forwarding. to work with link state routing, the link state packets have to be broadcasted to all other nodes to be able to calculate a spanning tree on each node separately. the distance information are updated periodically with the distances to the neighbors by the other is.",
        "original_sample_id": "smp1083q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0783q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "different from udp, tcp also includes the following headers: recognition issue sequence issue urgent cursor advertised window",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "different from udp, tcp also includes the following headers: acknowledgement number sequence number urgent pointer advertised window",
        "original_sample_id": "smp0783q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "incorrect",
        "confidence": 0.2
    },
    {
        "id": "aug00smp0126q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the use of differential sleeveter encoding (dme) would be applicable in this situation. it has a good auto-clock function that allows a good way to identify bits. Moreover, it has a low sensitivity to noise because dme only records the polarity of signals. it is great when there is a lot of traffic on a link.",
        "answer_feedback": "incorrect response as we already have perfect clock manchester is not required. secondly, binary encoding provides better bandwidth utilization.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to identify bits. furthermore it has a low susceptibility to noise because dme only records the polarity of signals. this is great when there is a lot of traffic on a link.",
        "original_sample_id": "smp0126q002",
        "is_augmented": "true",
        "question_id": "q002",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug01smp0126q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to key bits. furthermore it has a low susceptibility to noise because dme only memorialise the polarity of signals. this is great when there is a lot of traffic on a connexion.",
        "answer_feedback": "incorrect response as we already have perfect clock manchester is not required. secondly, binary encoding provides better bandwidth utilization.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "the use of the differential manchester encoding (dme) would be applicable in this situation. it has a good self-clocking feature which allows a good way to identify bits. furthermore it has a low susceptibility to noise because dme only records the polarity of signals. this is great when there is a lot of traffic on a link.",
        "original_sample_id": "smp0126q002",
        "is_augmented": "true",
        "question_id": "q002",
        "audit": "incorrect",
        "confidence": 0.0
    },
    {
        "id": "aug00smp0354q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1: (a,b,forward) (a,c,forward) (a,d,forward) hop2: (b,c,drop) heating not located on the unicast path of c a (b,e,forward) (c,b,drop) not located on the unicast path of b a (c,e,drop) not located on the unicast path of c a (d,f,drop) not located on the unicast path of f to a hop3: (e,c,drop) < = not located on the unicast path of c to a (d,f,drop) < = not located on the unicast path of f to a hop3: (e,c,drop) < = not located on the unicast path of c to a (e,f,drop) to a (e,f,no located on the unicast path of f to a hop3: (e,c,drop)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop1:\n(a,b,forward)\n(a,c,forward)\n(a,d,forward)\nhop2:\n(b,c,drop) <= not located on the unicast path from c to a\n(b,e,forward)\n(c,b,drop) <= not located on the unicast path from b to a\n(c,e,drop) <= not located on the unicast path from e to a\n(c,f,forward)\n(c,d,drop) <= not located on the unicast path from d to a\n(d,c,drop) <= not located on the unicast path from c to a\n(d,f,drop) <= not located on the unicast path from f to a\nhop3:\n(e,c,drop) <= not located on the unicast path from c to a\n(e,f,drop) <= not located on the unicast path from f to a\n(e,g,forward)\n(f,d,drop) <= not located on the unicast path from d to a\n(f,e,drop) <= not located on the unicast path from e to a\n(f,g,drop) <= not located on the unicast path from g to a\nhop4:\n(g,f,drop) <= not located on the unicast path from f to a\n(g,h,forward)",
        "original_sample_id": "smp0354q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "succession number \nacknowledgment number (ack. no.)   \nhl/resv/flag \npressing pointer",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number recognition number (pack no) hl/resv/emergency pointer flags",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug02smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence routine \nacknowledgement routine (ack. no.)   \nhl/resv/pin \nurgent pointer",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug03smp0823q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "Sequence number recognition number (pack no) hl/resv/emergency pointer flags",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp. also, whenever uncommon abbreviations like hl/resv are used, it is better to explain what they stand for.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "sequence number \nacknowledgment number (ack. no.)   \nhl/resv/flags \nurgent pointer",
        "original_sample_id": "smp0823q012",
        "is_augmented": "true",
        "question_id": "q012",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug00smp1095q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a sweep tree has only one connection to every node of the network. if it is used for broadcasting, no unnecessary extra are needed since every duplicate reaches a destination node. this means unlike flooding under any portion only on packet arrives at each node. if you have a sweep tree containing all nodes of a multicast, the same works for multicasting.   link state routing usually uses flooding to find the shortest path to a certain node in this case you use flooding to find a sweep tree by only returning paths to nodes which have not been found yet.",
        "answer_feedback": "the modification description of the link-state algorithm to construct a  multicast spanning tree is not correct as the is nodes are not aware of all multicast group members. this information needs to be shared along with other link-state information. so the spanning tree constructed out of only the classic link-state algorithm is only useful for unicasting, not multi-/broadcast.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "a spanning tree has only one connection to every node of the network. if it is used for broadcasting, no unnecessary duplicates are needed since every duplicate reaches a destination node. this means unlike flooding under any circumstances only on packet arrives at each node. if you have a spanning tree containing all nodes of a multicast, the same works for multicasting.   link state routing usually uses flooding to find the shortest path to a certain node in this case you use flooding to find a spanning tree by only returning paths to nodes which have not been found yet.",
        "original_sample_id": "smp1095q017",
        "is_augmented": "true",
        "question_id": "q017",
        "audit": "partially correct",
        "confidence": 0.5
    },
    {
        "id": "aug01smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There are certain requirements that must be met as: ack is sent by the receiver if the frame is identified as correct and is correctly transmitted to the network layer. also frames stored in the receiver are unrecognized frames not sent to the sender and the maximum number is the size of the receiver window. and frames stored in the sender are not yet recognized by the receiver. expected order if the window size is 1 then the sequence must always be correct, or if the window size is n then the size is limited by the size of the window. frames may contain implicit jacks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1483q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There are certain requirements that must be met as: ack is sent by the receiver if the frame is identified as correct and is correctly transmitted to the network layer. also frames stored in the receiver are unrecognized frames not sent to the sender and the maximum number is the size of the receiver window. and frames stored in the sender are not yet recognized by the receiver. expected order if the window size is 1 then the sequence must always be correct, or if the window size is n then the size is limited by the size of the window. frames may contain implicit jacks for duplex operation.",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains points related to the sliding window mechanism in general and not specifically to piggybacking.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there are certain requirements that needs to be met as:\n\nack is sent by the receiver if the frame is identified as being correct and transmitted correctly to the network layer.\nalso the stored frames at receiver are the unacknowledged frames not sent to sender and max number is the receivers window size.\nand the stored frames at the sender are not yet acknowledged by receiver.\n\nexpected order if the window size is 1 then the sequence should always be correct, or if window size is n then size is limited by window size.\n\nframes might contain implicit acks for duplex operation.",
        "original_sample_id": "smp1483q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1081q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link province routing can be modified by expanding the contained entropy of the periodically send link province packets with entropy on multicast groups. because these link province packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete province entropy. based on the entropy about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link state routing can be modified by expanding the contained information of the periodically send link state packets with information on multicast groups. because these link state packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete state information. based on the information about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "original_sample_id": "smp1081q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug01smp1081q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the extension tree is a subset of subredes including all routers without loops. this leads to a generation of a minimum number of copies of packets. the routing of the link state can be modified by extending the information contained in the link status packets to be sent periodically with information about multicast groups. because these link status packages are transmitted to all others is, each can be calculated a multicast tree from the state information now available locally and complete. based on the information about the multicast tree, the outgoing lines in which the packages have to be relayed are determined.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "the spanning tree is a subset of subnets including all routers with no loops. this leads to a generation of a minimum number of packet copies. link state routing can be modified by expanding the contained information of the periodically send link state packets with information on multicast groups. because these link state packets are broadcasted to all the other is, each is can calculate a multicast tree from the now locally available and complete state information. based on the information about the multicast tree the is determines the outgoing lines on which the packets have to be retransmitted.",
        "original_sample_id": "smp1081q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1537q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "-packs or naks and data are not sent separately. ack or nak is attached to the next data frame and then sent with data together on the other side. -the data link layer of a station must get a new package of the top layer before the end of the wait time interval. then theack or nak is copied into the data frame and sent together. otherwise, the data link layer only sends ack or nak frame.",
        "answer_feedback": "the response answers no parts of the question correctly. the response contains only the description of what happens in piggybacking.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "-acks or naks and data are not sent separately. ack or nak is attached to the next data frame and then sent with data together to the other side.\n\n-the data link layer of one station must get a new packet from the upper layer by the end of the timeout interval. then the ack or nak is piggybacked on the data frame and sent together. otherwise, the data link layer sends only ack or nak frame.",
        "original_sample_id": "smp1537q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0919q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains entries with a direction, a lan and a time mark. the bridge receives a frame in any of its lans and creates a corresponding entry. the table is scanned periodically to see changes in topology and the old entries are purged if no update has occurred for some time (usually several minutes).",
        "answer_feedback": "the response only states the information contained in the bridge table correctly. the response does not mention how this entry is used in backward learning and for forwarding packets selectively. no benefit is stated.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25,
        "original_answer": "the table contains entries with an address, a lan and a timestamp. the bridge receives a frame on any of its lans and creates an entry correspondingly. the table is scanned periodically to see changes in topology and old entries are purged if no update happened for some time (usually several minutes).",
        "original_sample_id": "smp0919q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1080q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "The properties of the tree extension is subset of subset including any router without loop and to provide link redundancy while at the same time avoiding undesirable loops avoiding transmission storms keeping the global load at a low level to modify the link status routing to build an extension tree for multicasting, all is to send link status packets periodically per transmission to all others containing information such as the distance to neighbors, expanded by information about multicast groups. then each one is calculated a multicast tree from the now locally available and complete status information. based on the information about the multicast tree, is to determine the outgoing lines and on which the packages have to be transmitted.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast except that it does not provide link redundancy. on the contrary, the spanning-tree algorithm blocks forwarding on redundant links by setting up one preferred link between nodes. the description of modification related to the link state algorithm to construct a  multicast spanning tree is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the properties of spanning tree is subset of subset including all router with no loop and to provide link redundancy while simultaneously preventing undesirable loops prevent broadcast storms maintain the overall load at a low level   to modify link state routing to construct a spanning tree for multicasting, all is send link state packets periodically by broadcast to all the others containing information like distance to neighbors, expanded by information on multicast groups. then each is calculates a multicast tree from the now locally available and complete state information. based on the information about the multicast tree, is determines the outgoing lines and on which packets have to be transmitted.",
        "original_sample_id": "smp1080q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp0909q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges receive all the frames of all the connected lan, and keeps the table for the packet flowing from the station to lan. receive any frame in your lan so you know how you can get to a source with the source direction of lan frames. check if the source and the destination lans are identical, then the packages fall or redirect to the lan and if it is unknown then flood. also use the flood when the system is silent for several time. offer control over the flow of data.",
        "answer_feedback": "the response does not mention the benefit of selective forwarding derived from using the bridging table. also note that if lans of the source and the destination are identical, the packet is dropped \"else\" it is rerouted. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the transparent bridges receive all the frames of all connected lan, and keeps the table for packet flowing from station to lan.\nit receives any frames on its lan so it knows how a source can be reached with the source address from lan frames.\nit checks if the source and the destination lans are identical then the packets are dropped or rerouted to the lan and if unknown then flooded.\nalso flooding is used when system is quiet for several time.\noffers the control over the data flow.",
        "original_sample_id": "smp0909q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp0355q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, cliff) not the inadequate path from a-c (not the best route)\n(b, e, forward)\n(c, b, cliff) not the inadequate path from a-b (not the best route)\n(c, e, cliff) not the inadequate path from a-e (not the best route)\n(c, f, forward)\n(c, d, cliff) not the inadequate path from a-d (not the best route)\n(d, c, cliff) not the inadequate path from a-c (not the best route)\n(d, f, cliff) not the inadequate path from a-f (not the best route)\nhop 3:\n(e, c, cliff) not the inadequate path from a-c (not the best route)\n(e, f, cliff) not the inadequate path from a-f (not the best route)\n(e, g, forward)\n(f, d, cliff) not the inadequate path from a-d (not the best route)\n(f, e, cliff) not the inadequate path from a-e (not the best route)\n(f, g, cliff) not the inadequate path from a-g (not the best route)\nhop 4:\n(g, h, forward)",
        "answer_feedback": "the flow appears more akin to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, c, drop) not the shortest path from a-c (not the best route)\n(b, e, forward)\n(c, b, drop) not the shortest path from a-b (not the best route)\n(c, e, drop) not the shortest path from a-e (not the best route)\n(c, f, forward)\n(c, d, drop) not the shortest path from a-d (not the best route)\n(d, c, drop) not the shortest path from a-c (not the best route)\n(d, f, drop) not the shortest path from a-f (not the best route)\nhop 3:\n(e, c, drop) not the shortest path from a-c (not the best route)\n(e, f, drop) not the shortest path from a-f (not the best route)\n(e, g, forward)\n(f, d, drop) not the shortest path from a-d (not the best route)\n(f, e, drop) not the shortest path from a-e (not the best route)\n(f, g, drop) not the shortest path from a-g (not the best route)\nhop 4:\n(g, h, forward)",
        "original_sample_id": "smp0355q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1033q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "rearward path forwarding and rearward path broadcast prevent loops in networks. every router knows all road to the other nodes but blocks all of them besides the shortest. if a packet now arrives at an intermediate system, it will be checked if the packet has used the shortest path so far by comparing the incoming direction with the usual direction packets with the same sender come from. in case it is the same direction it will be forwarded over every other edge besides the one where it has arrived. if it has arrived from another direction the packet will be discarded since it is most likely a duplicate. rearward path broadcast uses rearward path forwarding in an algorithm to send a packet to everyone with less duplicates than deluge.",
        "answer_feedback": "the purpose of both is to avoid forwarding of broadcast packets in loops/ duplicates like stated in the rpb explanation, not prevent loops in networks as stated in the first sentence. the description of the rpb algorithm is incorrect. rpb works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree. in rpf, if it followed the same route as the outgoing packet from the is is the correct explanation instead of stating the same direction.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.4,
        "original_answer": "reverse path forwarding and reverse path broadcast prevent loops in networks. every router knows all routes to the other nodes but blocks all of them besides the shortest. if a packet now arrives at an intermediate system, it will be checked if the packet has used the shortest path so far by comparing the incoming direction with the usual direction packets with the same sender come from. in case it is the same direction it will be forwarded over every other edge besides the one where it has arrived. if it has arrived from another direction the packet will be discarded since it is most likely a duplicate. reverse path broadcast uses reverse path forwarding in an algorithm to send a packet to everyone with less duplicates than flooding.",
        "original_sample_id": "smp1033q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0385q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forrard)\n(a, c, forrard)\n(a, d, forrard)\n\nhop 2:\nfrom b: \n(b, e, forrard)\n\nfrom c: \n(c, e, drop) <= e jazz that isnt receiving unicast mailboat via c , \n(c, f, forrard)\n\nfrom d: \n(d, f, drop) <= f jazz that isnt receiving unicast mailboat via d \n\nhop 3:\nfrom e: \n(e, g, forrard)  \n\nfrom f: \n(f, g, drop) <= g jazz that isnt receiving unicast mailboat via f\n\nhop 4:\nfrom g: \n(g, h, drop) <=  h jazz that isnt receiving unicast mailboat via g\n\n\nhint: mailboat which aren't considered to be forrarded rpb are left out explicitly.",
        "answer_feedback": "(a,d, drop) and subsequent flow will change accordingly. also (c, f, drop).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\nfrom b: \n(b, e, forward)\n\nfrom c: \n(c, e, drop) <= e knows that isnt receiving unicast packets via c , \n(c, f, forward)\n\nfrom d: \n(d, f, drop) <= f knows that isnt receiving unicast packets via d \n\nhop 3:\nfrom e: \n(e, g, forward)  \n\nfrom f: \n(f, g, drop) <= g knows that isnt receiving unicast packets via f\n\nhop 4:\nfrom g: \n(g, h, drop) <=  h knows that isnt receiving unicast packets via g\n\n\nhint: packets which aren't considered to be forwarded rpb are left out explicitly.",
        "original_sample_id": "smp0385q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0839q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no since arrivals are not always independent. there are a lot of services, which send packages depending on when the last one arrived and was hacked.",
        "answer_feedback": "the response is partially correct because it is true that the assumption doesn’t hold for real internet traffic. however, the stated explanation is incorrect because the arrival at a node is independent of whether a packet is acknowledged or not.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "no since the arrivals are not always independent. there are lots of services, that send the packets dependent on when the last one arrived and was acked.",
        "original_sample_id": "smp0839q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0839q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no since arrivals are not always independent. there are a lot of services, which send packages depending on when the last one arrived and was hacked.",
        "answer_feedback": "the response is partially correct because it is true that the assumption doesn’t hold for real internet traffic. however, the stated explanation is incorrect because the arrival at a node is independent of whether a packet is acknowledged or not.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "no since the arrivals are not always independent. there are lots of services, that send the packets dependent on when the last one arrived and was acked.",
        "original_sample_id": "smp0839q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp0939q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table contains the information: lan outputs/out-line. and receives each frame of each connected lan. it receives all images or all connected lan's. the bridge contains the images with a source address and the lan from where they come from. this information is stored as table entries, with a time stamping (arrical time of the image). once an image is received, the time stamping of an entry receives an update. this way, the system and the network adapt to changes in topology. after a period, the table gets a scan and the old entries are deleted. the table is used for the decision procedure. if the source and the destination are identical, it is not necessary to send a frame, it is abandoned. if the source and the destination are different, the frame is resented and rerouted to the Lan destination (given by the table). if the destination is unknown in the table, the flood will be applied to the network.",
        "answer_feedback": "the response does not mention how a packet q received over lan l is interpreted as “q can be reached over l”. also, the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "table holds the information: lan outputs/out-line. and receives every frame of each connected lan.\n\nit receives all frames o all lan's connected. the bridge contains frames with a source address and the lan where it comes from.\nthese informations are stored as table entries, with a timestamp (frame arrical time).\nonce a frame is received the timestamp of an entry gets an update.in that way the system and network adapts to changes in topology.\nafter a period the table get a scan and old entries are deleted. \n\nthe table is used for decision procedure. if source and destination lan's are indentical, there is no need to send a frame, it is dropped.\nif the source and destination lan's differ, the frame is resent and rerouted to the destination lan (given by the table).\nif the destination is unknown in the table, flooding will be applied to the network. (flooding means that every packet is sent through all the outgoing links except\nthe one the packet arrived on.\n\nbridges have the advantage transparency. so, it simplifies other components because a bridge is not visible for other components of the network.",
        "original_sample_id": "smp0939q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1071q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "globally knowledge of multicast group's spanning tree is what cause it appealing for broad/multicasting. nexus land routing is modified to construct spanning tree for multicasting by: 1. all is send nexus land periodically, and it contains the distance to neighbours, expanded by information of multicast groups 2. each is calculates a multicast tree, from the now locally available and complete land information 3. is determines the outgoing lines and on which packets have to be transmitted based on the information of the multicast tree",
        "answer_feedback": "the stated property of a spanning tree is incorrect. there is a single unique path between every pair of nodes in the spanning tree which makes it appealing for the broad and multicast.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "globally knowledge of multicast group's spanning tree is what makes it appealing for broad/multicasting. link state routing is modified to construct spanning tree for multicasting by: 1. all is send link state periodically, and it contains the distance to neighbours, expanded by information of multicast groups 2. each is calculates a multicast tree, from the now locally available and complete state information 3. is determines the outgoing lines and on which packets have to be transmitted based on the information of the multicast tree",
        "original_sample_id": "smp1071q017",
        "is_augmented": "true",
        "question_id": "q017"
    },
    {
        "id": "aug00smp1037q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "overthrow track forwarding : it is for broadcasting, it is for fowarding and transmission packages in multicast routing without getting false ip addresses. it is a variation of the spanning tree, where every sender node has its own spanning tree and track. the intermediate systems in between don't need to know those. if the packages arrive at an is, the package used the best route available at that time. this is done by a resend over all edges, but not for the incoming one. if no package arrived at the is, the package didn't use that route being not the best route. this is done by dismissing packages. overthrow track broadcast : it is for broadcasting. it is an improvement of overthrow track forwarding. it works like overthrow track forwarding but with a specific selection of the outgoing links. the \"rpf\" has the disadvantage of resending over all edges. it would be better to forward packages over suitable edges. so if a package arrived at the is over which the packages for this station are usually sent before and the package has used the best route until now, the suitable edges are selected at which the packages arrived. from those packages they are rerouted and resent to the source c. otherwise the packages are not send over all edges. if no package arrived, discard the packages.",
        "answer_feedback": "the main purpose of rpf and rpb is to reduce redundant packets/duplicates in broadcast or multicast, ip address spoofing is also correct but that is not the primary purpose.the response correctly explains both rpf and rpb.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8,
        "original_answer": "reverse path forwarding : it is for broadcasting, it is for fowarding and transmission packets in multicast routing without getting false ip addresses. it is a variation of the spanning tree, where every sender node has its own spanning tree and path. the intermediate systems in between don't need to know those. if the packets arrive at an is, the packet used the best route available at that time. this is done by a resend over all edges, but not for the incoming one. if no packet arrived at the is, the packet didn't use that route being not the best route. this is done by dismissing packets. reverse path broadcast : it is for broadcasting. it is an improvement of reverse path forwarding. it works like reverse path forwarding but with a specific selection of the outgoing links. the \"rpf\" has the disadvantage of resending over all edges. it would be better to forward packets over suitable edges. so if a packet arrived at the is over which the packets for this station are usually sent before and the packet has used the best route until now, the suitable edges are selected at which the packets arrived. from those packets they are rerouted and resent to the source c. otherwise the packets are not send over all edges. if no packet arrived, discard the packets.",
        "original_sample_id": "smp1037q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0380q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward), (a, c, forward), (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) inflict in hop 1, (b, e, forward)\nfrom c: (c, b, drop) inflict in hop 1, (c, d, drop) inflict in hop 1, (c, e, drop) inflict in hop 2, (c, f, forward)\nfrom d: (d, c, drop) inflict in hop 1, (d, f, drop) inflict in hop 2\n\nhop 3:\nfrom e: (e, c, drop) inflict in hop 1, (e, f, drop) inflict in hop 2, (e, g, forward)\nfrom f: (f, d, drop) inflict in hop 1, (f, e, drop) inflict in hop 2, (f, g, drop) inflict in hop 3\n\nhop 4:\nfrom g: (g, f, drop) inflict in hop 2, (g, h, drop) no new neighbors",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6,
        "original_answer": "hop 1:\n(a, b, forward), (a, c, forward), (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) visited in hop 1, (b, e, forward)\nfrom c: (c, b, drop) visited in hop 1, (c, d, drop) visited in hop 1, (c, e, drop) visited in hop 2, (c, f, forward)\nfrom d: (d, c, drop) visited in hop 1, (d, f, drop) visited in hop 2\n\nhop 3:\nfrom e: (e, c, drop) visited in hop 1, (e, f, drop) visited in hop 2, (e, g, forward)\nfrom f: (f, d, drop) visited in hop 1, (f, e, drop) visited in hop 2, (f, g, drop) visited in hop 3\n\nhop 4:\nfrom g: (g, f, drop) visited in hop 2, (g, h, drop) no new neighbors",
        "original_sample_id": "smp0380q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0217q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this is always the eccentric, because the arrival pace (9) is lower than the serving pace (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. the correct answer is 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "this is always the case, because the arrival rate (9) is lower than the service rate (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "original_sample_id": "smp0217q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug01smp0217q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "this is always the suit, because the arrival rate (9) is lower than the serving rate (10). \nso on average the buffer is always below its maximal capacity of 10.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. the correct answer is 56.95 seconds.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0,
        "original_answer": "this is always the case, because the arrival rate (9) is lower than the service rate (10). \nso on average the buffer is always below its maximum capacity of 10.",
        "original_sample_id": "smp0217q003",
        "is_augmented": "true",
        "question_id": "q003"
    },
    {
        "id": "aug00smp1016q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "Reverse path forwarding and reverse path transmission help reduce unwanted duplication of transmission packages. Reverse path forwarding works by checking the incoming edge of a transmission package: if it is not the border used to send a package to the emission source, the package is discarded (because packages using any non-optimal route are considered duplicates). Otherwise it is sent over all borders except the incoming one. Reverse path transmission works similar to rpf, but a package is not sent to an adjacent node if the current is not part of the optimal unicast route from the node adjacent to the emission source.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast help to reduce unwanted duplication of broadcast packets. reverse path forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because packets using any non-optimal path are considered duplicate). otherwise it is sent over all edges except the incoming one. reverse path broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast path from the adjacent node to the broadcast source.",
        "original_sample_id": "smp1016q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug01smp1016q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse course forwarding and reverse course broadcast help to reduce unwanted duplication of broadcast package. reverse course forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because package using any non-optimal course are considered twin). otherwise it is sent over all edges except the incoming one. reverse course broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast course from the adjacent node to the broadcast source.",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "reverse path forwarding and reverse path broadcast help to reduce unwanted duplication of broadcast packets. reverse path forwarding works by checking the incoming edge of a broadcast packet: if it is not the edge that this is would use for sending a packet to the broadcast source, the packet is discarded (because packets using any non-optimal path are considered duplicate). otherwise it is sent over all edges except the incoming one. reverse path broadcast works similar to rpf, but a packet is not forwarded to an adjacent node if the current is is not part of the optimal unicast path from the adjacent node to the broadcast source.",
        "original_sample_id": "smp1016q016",
        "is_augmented": "true",
        "question_id": "q016"
    },
    {
        "id": "aug00smp0328q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(a, c, forward) (a, d, forward) (b, c, forward) (a, d, forward) (b: (b, c, fall) = > (already covered with a) (c, e, fall) = > (already covered with b and shorter track) (c, f, forward) (c, d, fall) = > (already covered with a) (c, a, fall) = > (already covered with a) (c, e, e, fall) = > (already covered with b and shorter track) (c, f, fall) (d, a, drop) = > (already covered with a) (d, c, c, drop) = ) (d, c, f, already covered with )",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4,
        "original_answer": "hop 1:\nfrom a: (a, b, forward) (a, c, forward) (a, d, forward)\n\nhop 2:\nfrom b: (b, c, drop) => (c was already covered) (b, e, forward) (b, a, drop) => (a was already covered)\nfrom c: (c, b, drop) => (already covered from a) (c, e, drop) => ( e was already covered from b and shorter way) (c, f, forward) (c, d, drop) => ( already covered from a) (c, a, drop) => ( a was already covered)\nfrom d: (d, c, drop) => (already covered from a) (d, f, drop) => ( f was covered from c and shorter way) (d, a, drop) => ( a was covered already)\n\nhop 3:\nfrom e: (e, c, drop) => (already covered from a) (e, f, drop) => (already covered from c) (e, g, forward) (e, b, drop) => ( b was already covered)\nfrom f: (f, g, drop) => (g was already covered)  (f, e, drop) => (e was already covered) (f, c, drop) => (c was already covered) (f, d, drop) => (d was already covered)\n\nhop 4:\nfrom g: (g,f, drop) => ( f was already covered) (g,e, drop) => (e was already covered) (g,h,forward)\n\nhop 5:\nfrom h: (h, g, drop) (g was already covered)",
        "original_sample_id": "smp0328q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp0882q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This is not true for the real internet, because we often have a rampant traffic. First of all, there could be long-line traffic, which for example is caused by the user's behavior as people watching video streams more likely at night. then we also have long-range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high brightness until it is full.",
        "answer_feedback": "the first example in the response is partially correct because the arrival process' parameters can be time-dependent. that can model such intra-day variations like more video traffic during the evening. knowing previous arrivals no longer has to capture this information for us, thus making the inter-arrival times independent in this regard. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this doesn't hold true for the real internet, because we often have bursty traffic. first of all there could be long-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have long range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high burst until it's full.",
        "original_sample_id": "smp0882q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug01smp0882q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this doesn't hold true for the real internet, because we often have outbursty traffic. first of all there could be farsighted-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have farsighted compass dependencies. video streaming for example is implemented with buffers where the buffer is filled with high outburst until it's full.",
        "answer_feedback": "the first example in the response is partially correct because the arrival process' parameters can be time-dependent. that can model such intra-day variations like more video traffic during the evening. knowing previous arrivals no longer has to capture this information for us, thus making the inter-arrival times independent in this regard. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "this doesn't hold true for the real internet, because we often have bursty traffic. first of all there could be long-tail traffic, that for example be caused by user behavior like people watching video streams more likely in the evening. then we also have long range dependencies. video streaming for example is implemented with buffers where the buffer is filled with high burst until it's full.",
        "original_sample_id": "smp0882q013",
        "is_augmented": "true",
        "question_id": "q013"
    },
    {
        "id": "aug00smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on receiver side, the receiver will attach ack with bundle and send them both at the same sentence to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down sentencekeeper. if sentencekeeper reaches 0, even it has no data to send, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "On the side of the receiver, the receiver will attach ack with packet and send them at the same time to save bandwidth. But if it has nothing to send, if it cannot be handed over to the sender. So the requirement here is that the receiver must have something to return. If it has nothing to send, it must have an account chronometer. if timer reaches 0, even it does not have data to send, theack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on receiver side, the receiver will attach ack with packet and station them both at the same metre to save bandwidth. but if it has nothing to station, so ack also can not be rescue back to stationer.\n\nso the requirement here is that the receiver must have something to station back. if it has nothing to station, it must have a count down metrer. if metrer reaches 0, even it has no data to station, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "On the side of the receiver, the receiver will attach ack with packet and send them at the same time to save bandwidth. But if it has nothing to send, if it cannot be handed over to the sender. So the requirement here is that the receiver must have something to return. If it has nothing to send, it must have an account chronometer. if timer reaches 0, even it does not have data to send, theack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1481q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "on recipient side, the recipient will confiscate ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the recipient must have something to send back. if it has nothing to send, it must have a count down timekeeper. if timekeeper reaches 0, even it has no data to send, the ack must be sent.",
        "answer_feedback": "the response answers the requirement partially because even if both sides have data, the network channel needs to be duplex.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "on receiver side, the receiver will attach ack with packet and send them both at the same time to save bandwidth. but if it has nothing to send, so ack also can not be delivered back to sender.\n\nso the requirement here is that the receiver must have something to send back. if it has nothing to send, it must have a count down timer. if timer reaches 0, even it has no data to send, the ack must be sent.",
        "original_sample_id": "smp1481q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp1623q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "broadcast (255.255.255.255), local host speech (0.0.0.0) and web host speech (0.x.x.x) and loopback",
        "answer_feedback": "what is the loopback address?",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast (255.255.255.255), local host address (0.0.0.0) and network host address (0.x.x.x) and loopback",
        "original_sample_id": "smp1623q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug01smp1623q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "broadcast (255.255.255.255), local host speech (0.0.0.0) and net host speech (0.x.x.x) and loopback",
        "answer_feedback": "what is the loopback address?",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5,
        "original_answer": "broadcast (255.255.255.255), local host address (0.0.0.0) and network host address (0.x.x.x) and loopback",
        "original_sample_id": "smp1623q026",
        "is_augmented": "true",
        "question_id": "q026"
    },
    {
        "id": "aug00smp1478q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "duplex datum transfer (both face should be able to send and get datum)",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "duplex data transfer (both sides should be able to send and receive data)",
        "original_sample_id": "smp1478q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0330q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forrad)\n(a, c, forrad)\n(a, d, pearl) because c is already reached and f will be reached faster via c.\n\nhop 2:\n(b, e, forrad)\n(c, f, pearl) because d is already reached and e,g will be reached faster via b.\n\nhop 3:\n(e, g, forrad)\n\nhop 4:\n(g, h, pearl) because no further thickening could be reached.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0,
        "original_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) because c is already reached and f will be reached faster via c.\n\nhop 2:\n(b, e, forward)\n(c, f, drop) because d is already reached and e,g will be reached faster via b.\n\nhop 3:\n(e, g, forward)\n\nhop 4:\n(g, h, drop) because no further node could be reached.",
        "original_sample_id": "smp0330q005",
        "is_augmented": "true",
        "question_id": "q005"
    },
    {
        "id": "aug00smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would happen. so the liquidator may not wait too long. if no frame appears powerful in time, piggybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug01smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug02smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug03smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "there has to be a duplex communication because the meter period by which the response is to be delayed (to await for a inning to piggyback the acknowledgement onto) must not exceed the meterout period of the sender whose inning is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not await too long. if no inning appears right in meter, piggybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug04smp1496q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "There must be a duplex communication because the period of time for which the response must be delayed (wait until a frame to cergyback the acknowledgement of receipt in) must not exceed the waiting period of the sender whose frame must be recognized. Otherwise, a broadcast would occur. so the receiver cannot wait too long. if no frame appears just in time, cergybacking is not possible.",
        "answer_feedback": "the response correctly identifies a duplex connection as a requirement. however, the reasoning behind it is not correct as a dedicated timer can also be used on the receiver side. when no data is there at the receiver side for piggybacking, a timeout occurs and an acknowledgment is sent separately.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5,
        "original_answer": "there has to be a duplex communication because the time period by which the response is to be delayed (to wait for a frame to piggyback the acknowledgement onto) must not exceed the timeout period of the sender whose frame is to be acknowledged. otherwise, a retransmission would occur. so the receiver may not wait too long. if no frame appears right in time, piggybacking is not possible.",
        "original_sample_id": "smp1496q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0940q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "The tables contain information where the frame of a node in a lan must send to the node of another lan and the table is modified by doing and learning, so at the start if a bridge gets a frame and does not know the destination that are flooding, if the origin and the destination lans are identical then the frame where they fell and if the origin and the destination lans where the frame differs have been redirected to the lan destination, so the bridge learns from traffic and constructs its table of diversion from this learning process. e.g., the bridge receives frames with direction of origin qon lan l, which can be reached on the, create the entrance of the table accordingly. the profit is, more learning traffic, so that the efficiency depends on the intensity of the traffic.",
        "answer_feedback": "the stated benefit presents the scenario when the bridge works best but the question asked for the benefit derived once the bridge table is available, i.e. fewer duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75,
        "original_answer": "the tables hold information where the frame from node in one lan should send to the node of other lan and the table is modified by doing and learning, so at the beginning if a bridge get a frame and they don’t know the destination they do flooding, if the source and destination lans are identical then the frame where dropped and if the source and destination lans where differ the frame were rerouted to destination lan, so the bridge learns from traffic and builds up their for-warding table from this learning process. \nfor example, bridge receives frames with source address q on lan l, q can be reached over l, it will create table entry accordingly.\nthe benefit is, more traffic more learning, so the efficiency depends on the intensity of traffic.",
        "original_sample_id": "smp0940q014",
        "is_augmented": "true",
        "question_id": "q014"
    },
    {
        "id": "aug00smp1488q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "datum frames contain an additional ack discipline which contains the sequence bit.",
        "answer_feedback": "the response is correct as an additional field is required in the frame for acknowledgment. moreover, a duplex channel is required.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0,
        "original_answer": "data frames contain an additional ack field which contains the sequence number.",
        "original_sample_id": "smp1488q024",
        "is_augmented": "true",
        "question_id": "q024"
    },
    {
        "id": "aug00smp0102q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding is the estimable option because of its good self-clocking lineament which is important in a congested network. it also provides fault detection.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding is the best option because of its good self-clocking feature which is important in a congested network. it also provides error detection.",
        "original_sample_id": "smp0102q002",
        "is_augmented": "true",
        "question_id": "q002"
    },
    {
        "id": "aug01smp0102q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encryption is the best option because of its good self-clocking feature which is crucial in a congested network. it also provides error sensing.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0,
        "original_answer": "differential manchester encoding is the best option because of its good self-clocking feature which is important in a congested network. it also provides error detection.",
        "original_sample_id": "smp0102q002",
        "is_augmented": "true",
        "question_id": "q002"
    }
]
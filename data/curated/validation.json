[
    {
        "id": "smp0209q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption is not realistic for real internet traffic. it is different between day and night. for example in video traffic, a window buffer may be on to fetch the next segments of video, then off to deplete it, and then on again to fetch the next further segments of video.",
        "answer_feedback": "one can use a function instead of a constant to model the arrival rate to reflect such large-scale, day-night behavioral patterns. the arrivals would not depend on previous arrivals then, only on the time of the day, which is known. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0028q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "because it is given that all users have pefect clocks, we can use a simple and cheap binary encoding technique. it will also be a very efficient use of the given bandwidth.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0310q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "with csma/cd, if the speed of the network increases by a factor of 10, the collision domain diameter shrinks. the distance decreases by a factor of 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0051q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used, since all users have perfect code and all frequency modulation is utilized (users have access to selected frequencies at all times)",
        "answer_feedback": "the response is incorrect as under the given scenario binary encoding is better suited.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0205q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "there are the differences between tcp and udp headers:\n1. tcp has a at least 20 bytes variable length header while udp has an 8 bytes fixed length header.\n2. tcp provides extensive error checking mechanisms since it uses checksum but also provides flow control and acknowledgement of data while udp has only basic error checking mechanisms using checksum. in tcp, erroneous packets are retransmitted from the source to the destination.\n3. tcp header contains the sequence number of data but udp does not contain the sequence number. there is no sequencing of data in udp.\n4. tcp header has urgent pointer to show receiver where urgent data ends but udp does not have this urgent pointer.\n5. tcp contains information for not only compulsory but also optional functions while udp has only the information for compulsory function.\n6. udp is comparatively faster, simpler and more efficient than tcp. however, tcp is reliable since it guarantees delivery of data to the destination.\n7. tcp is heavy-weight, since tcp requires three packets to set up a socket connection, before any user data can be sent. tcp handles reliability and congestion control. however, udp is lightweight. there is no ordering of messages, no tracking connections, etc.\n8. udp is connectionless, but tcp is connection-oriented. therefore, tcp header has fields used for connection setup and maintenance, specifically the flags. udp does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. the response contains extra points, but they are general differences between the tcp and udp protocol.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0081q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=d doesn't foward a message from a to f, because f doesn't receive unicast packets via d.\nhop 2:\n(b,e,forward)\n(c,f,drop)<=f doesn't foward a message from a to g, because g doesn't receive unicast packets via f.\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the message, vertex h does not forward the message.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0231q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table of transparent bridges holds the frame with address on every connected lan and the frame arrival timestamp, including sender and receiver.\nduring the backwards learning phase because of learning in the promiscuous mode the bridge can know any frame from any connected lan and can trace back to the source address on the lan of the received frame to create a table entry in the bridge table. in the forwarding process if the source and destination lans are identical, the frame will be dropped, otherwise(if they are different), the frame will be forwarded. if the destination lan is unknown, the frame will be flooded. \nthe benefit is forwarding frames without considering types of lans and without changing the configuration tables to achieve transparency.",
        "answer_feedback": "the bridge table does not contain both sender and receiver information; it only maps the destination station to the incoming lan. the stated benefit is not correct as the response mentions the benefit of transparent bridges in general, not of using transparent bridge table information in forwarding. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0368q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the communication needs to be duplex.\nadditionally, there should be a time period, within this time period, data link layer should wait for the next packet, and attach the acknowledgement to the outgoing data frame and then send the frame.\nwhen time expires and there is no packet to be sent, link layer sends a separate acknowledgement frame.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0179q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\nin this service, the data that is sent by the sender is expected to arrive at the receiver, however, there is no feedback from the receiver's side. due to a lack of acknowledgement from the receiver side, there exists a possibility of data units getting lost. furthermore, in this service there is no flow control taking place and neither is there a possibility of connect/disconnect. this form of service is best suited for l1 communication channels with a very low error rate.\n\nconfirmed connectionless service:\nthis service is a form of bi-directional communication, where upon sending information the receiver responds with an acknowledgment of whether the information has been received or not. it is particularly used in applications where a high error rate is expected, such as for moving devices. similar to the unconfirmed connectionless service, no flow control or a connect/disconnect phase takes place. due to the additional acknowledgement here, no data loss is possible, however, duplication and sequencing errors are still possible\n\nconnection-oriented service:\nas opposed to the connectionless services, the connection-oriented service operates with flow control, achieved by a 3-phase bi-directional communication (connect, transfer, disconnect). this prevents data loss, duplication of data or sequencing errors. this form of service requires some sort of connection management as both the sides agree to perform the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0376q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "frames may contain an implicit acks.\nduplex operation. \nit has to have an initial seqno. of 0",
        "answer_feedback": "apart from the correct answer of duplex operation, the response also contains other requirements. the first point is true, but it refers to what happens in piggybacking in general. the last point is incorrect as it is specific to the example given in the slides.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0110q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "one method to resolve the problem of duplicate packets is to use temporarily valid tsaps for only one connection. on paper, this reduces the problem of duplicates since each tsap is only used once and therefore reduces the number of duplicates to the ones occuring in that one connection. however, a disadvantage is that some tsaps always exist and are well-known. hence, it is not possible to realize this approach and generate temporary tsaps for each connection. \n\nanother method would be to make connections unique and identify them individually. an advantage is that duplicates from different connections do not occur anymore since each is unique. however, this is not possible with connection-less systems. additional knowledge is needed to realize this approach since end systems need to remember the sequence numbers even after being turned off so that they remain unique for each connection. \n\nthe third approach to solve duplicates is to identify each packet individually with unique sequence numbers. an advantage is that it easily allows the receiver to identify and discard duplicate packets since it can just compare sequence numbers to check if it already received a packet with that number. however, this approach requires that the range of sequence numbers are chosen wisely so that they do not repeat before each packet is delivered and processed. furthermore, this approach requires more bandwidth/memory due to the overhead of the sequence numbers.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0367q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the initial seqno needs to be known + the next seqno and the next ack-seqno needs to be known.\notherwise, piggybacking is not possible.",
        "answer_feedback": "the response is incorrect as the main requirement for piggybacking is a two-way/duplex channel. the points stated in the response are an implementation detail of the sliding window protocol.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0306q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "collision domain diameter means the maximum length of line between two nodes in the network which you can use in respect to the length of used frames, the sending speed and the fact, that you want to be able to detect any kind of data collision during transmission. if we now increase the speed of transmission with all other factors remaining the same - especially the frame length -, the time of transmission for each node decreases. so there is less time of data frames travelling on the line during which the stations could detect a collision. to keep the function of collision detection, the maximum length of line - a.k.a. the collision domain diameter - in the network has to decrease to the same factor. so an increase of transmission speed from 10 mbit/s to 100 mbit/s - factor 10 - causes a reduction of collision domain diameter to the factor of 10, too. for example, in ethernet 802.3 this means a reduction from 3000m to 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0190q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem is the \"fairness\" - the nodes in the beginning of the bus can reserve way more data than in the end, to send it to the other bus. this is only based of their position, which is unfair to the other nodes",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb which depends on the station location in bus.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0182q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb has a fairness problem. the likelihood to access the medium (reserve a slot on other bus) is not the same for all stations because it depends on the location. that means that a station that is wired at the beginning (or end) of the bus, sometimes has an advantage and sometimes a disadvantage compared to other stations at different locations. this is not fair.",
        "answer_feedback": "the response correctly identifies the fairness problem in dqdb and also provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0115q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps:\n-need large numbers of names because it should be unique -> not usable in reality\n+very potent, because tsap is valid for one connection only\n\n2. to identify connections individually:\n-endsystems must be capable of storing this information\n+if there is a duplicate from another connection they don't interact with each other\n\n3. to identify pdus individually:\n-perfect time has to be known by everybody\n+one can reuse the seqno after a certain time",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0248q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "purpose of rpf and rpb: avoid receiving duplicate packets * rpf: use unicast routing information to decide if an incoming packet is dropped or sent further via the outgoing links: * send further if incoming packet used path in unicast routing info * drop if incoming packet did not use path in unicast routing info * rpb: select outgoing edges: * select edge if a packet coming from the connected node to the sender would use this edge. * sent incoming packet via selected edges (not including the incoming edge).",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. the purpose is to avoid forwarding duplicate packets not receiving but it is acceptable.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0317q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "if the speed got ten times faster, we have to decrease the maximum collision domain diameter by 90%, that is the distance between the nodes, so that a collision can still be detected while sending. so there is basically a tradeoff between distance and efficiency.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0084q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop2:\n(b, e, forward)\n(b, c, drop) <= c doesn't send any packets to a, over b\n(c, d, drop) <= d doesn't send any packets to a, over c\n(c, e, drop) <= e doesn't send any packets to a, over c\n(c, f, forward)\n(d, c, drop) <= c doesn't send any packets to a, over d\n(d, f, drop) <= f doesn't send any packets to a, over d\n\nhop 3:\n(f, e, forward)\n(f, g, forward)\n(e, f, drop) <= f doesn't send any packets to a, over e\n(e, g, forward)\n\nhop 4:\n(g, h, drop) <= h doesn't have any adjacent nodes other than g",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0111q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "one method to avoid duplicate packets is to make the time-out time of the packets larger. the advantage of that is that the sender has enough time to receive the acknowledgment of the packets. the disadvantage is that if the time-out time is too large and the sender has only a certain window size to send unacknowledged packets, it could results that the sender is sending the data too slow and the receiver has to wait.\n\nanother method is that the receiver can ignore/ discard the same packets by using sequence numbers. the advantage is that the receiver will not be full of duplicate packets and knows via sequence number which packet should arrive next. the disadvantage is that the packets send with sequence numbers are larger.\n\nanother method is to use temporarily valid tsaps. the advantage is that the tsap is only valid for one connection only. a disadvantage is that server addressing is not possible because the server is reached via a designated/known tsap.",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be resolved.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67
    },
    {
        "id": "smp0406q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 and 127.x.y.z",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0412q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - start address\n127.0.0.0/8 through 127.255.255.255/8 are reserved for loopback addresses",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0425q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved for loopback : 127.0.0.0 - 127.255.255.255\nclass a reserved range : 10.0.0.0 to 10.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0424q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.0 to 10.255.255.255 are reserved",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5
    },
    {
        "id": "smp0417q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 to 0.255.255.255 is for current network and 127.0.0.0 to 127.255.255.255 for loop-back addresses",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0037q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding:\n- because the users have perfect synhronized clocks, they can aggree on a time window that is used to send one single bit. so the self clocking of the manchester encoding is not needed.\n- because we have only 3 interconnected users, we also don't need the high susceptibilty to noise, that would bring the differential manchester encoding",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0421q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved addresses:\n127.0.0.0 – 127.255.255.255 (for loop-backs)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0207q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "this assumption mostly does not hold for real internet traffic as packets are not sent independently and in a steady way. rather, internet traffic is very bursty. data and messages are not sent via individual and independent packets so a single packet most likely is part of a larger message with which it is sent together.",
        "answer_feedback": "it is correct that the assumption does not hold because of bursty traffic. however, the explanation for why the traffic is bursty only refers to packet fragmentation which is only a small reason for bursty traffic.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0106q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "method 1: to use temporarily valid tsaps\ngenerate unique (transport) service access point (tsap) for each communication and they are valid for one connection only\nadvantages:\nyou can always generate new tsaps disadvantages:\nsome tsaps are standardized(\"well-known ports\") and cannot be usedmethod 2: to identify connections individually\neach connection is assigned a new sequence number and endsystems story assigned sequence number and remember them\n\nadvantages:\nduplicates from another connection with a  sequence number doesn't interact with other connection with a different sequence number.disadvantages:\nonly works with connection-oriented servicemethod 3: to identify pdus individually: individual sequential numbers for each pdu\n\nadvantages:\nbetter usage of bandwidth and memory because you have individual sequence numbers for each packet and they almost never get resetdisadvantages:\nsequential number range depends on packet rate and packet probable \"lifetime\"",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0088q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(a, b, forward)(a, c, forward)(a, d, drop) <= d knows that either c nor f are routing to a over dhop 2:(b, e, forward)(c, f, drop) <= f knows that either c nor d or f are routing to a over fhop 3:(e, g, forward)hop 4:(g, h, drop) <= h has no neigbors except g (no links except the incoming link)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0230q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds information about which station is attached on which lan. it includes a timestamp, adress of station and lan. \nwhenever the bridge receives a frame from a station, it can determine in which lan the station is attached. from this information the bridge builds an entry for the station in the bridging table. the advantage from backwards learning is, that the bridge does not have to flood the frames, therefore decreasing the network traffic. additionally, the bridge can drop frames, that are adressed for a receiver in the same lan as the sender station. \nthe entries are deleted, if they haven‘t been updated for a set time (usually several minutes).",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0064q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the likelihood of the less than 10 packets waiting in the queue is one minus the blocking probability, which is about 5,08%. \ngiven this information, 94,92% of the time, you would expect less than 10 packets to wait in the queue. \nin one minute, this would be about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0082q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop2:\n(b; c, drop) <= b knows that c does not receive unicast packets via b\n(b, e, forward)\n(c, b, drop)<= c knows that b does not receive unicast packets via c\n(c, d, drop)<= c knows that d  does not receive unicast packets via c\n(c, e, drop)<= c knows that e does not receive unicast packets via c\n(c, f, forward)\n(d, c, drop)<= d knows that c does not receive unicast packets via d\n(d, f, drop)<= d knows that f does not receive unicast packets via d\nhop3:\n(e, c, drop)<= e knows that c does not receive unicast packets via e\n(e, f, drop)<= e knows that f does not receive unicast packets via e\n(e, g, forward)\n(f, e, drop)<= f knows that e does not receive unicast packets via f\n(f, g, drop)<= f knows that g does not receive unicast packets via f\n(f, d, drop)<= f knows that d does not receive unicast packets via f\nhop4:\n(g, h, forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0263q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees allows to reach all other nodes of a network with a small subset of links. a spanning tree therefore \"provides\" information for broad- and multicasting to send the packets through the \"best\" route (e.g. minimum hops).",
        "answer_feedback": "the response incorrectly describes the reason why a spanning tree is attractive for broadcast and multicast. although the number of links is reduced, they also need to connect without loops, reducing duplicates. the modification related to the link state algorithm to construct a  multicast spanning tree is not provided.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0217q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "initially, the bridge table, containing fields for the sender, the receive timestamp and the used lan, is empty and as a result the bridge will simply use flooding to reach an unknown destination. during the backwards learning phase the bridge works in promiscuous mode - receives all frames from all its lans - and uses the information of those frames in order to build its table. the information from the table then allows the bridge to forward incoming packets to the correct lan in order for it to reach its destination. the benefit of this method is that the bridge learns and adapts over time and does not have to rely on flooding, therefore optimizing bandwidth usage.",
        "answer_feedback": "the response does not state which information is learned from the received packet and how it is used while selectively forwarding packets. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0206q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- the tcp header has a sequence number to enable reliable communication, the udp header doesn't.\n- the tcp header has a acknowledgment number, which is used in the 3-way handshake. it is also necessary for the reliable communication. udp doesn't need this field, because it is a connectionless protocol.\n- the tcp header has some flags, which are used for connection management. for example syn for connection establishment and fin for connection release.\n- the tcp header has a field for the advertised window, it is used for flow control. udp doesn't have any flow or congestion control.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0048q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding. \nbecasue if the clocks are perfect in the local newtwork, there in no need to do self-clocking. and the binary coding has better utilization (almost 200%) to bandwidth than other techniques, which is important when the traffic is heavy.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0062q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p10 = ((1 - rho) * rho^n) / (1 - rho^(n+1)) = ((1 - 0.9) * 0.9^10) / (1 - 0.9^(11)) = 0.0508\n\nseconds with 10 packets in queue = p10 * 60 = 3.048\n\nseconds with less than 10 packets in queue = 60 - 3.048 = 56.952\n\nso the system is expected to have 10 packets in it's queue for about 3 seconds and less than 10 packets for the remaining 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0223q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges maintain a table that maps each station to an output line or lan the bridge is connected to. initially the table is empty, the bridge reads packets from all its output lines and learns where the stations are located. this phase is called the backwards learning phase. during the forwarding process, the bridge uses the table to make the following decisions. if the source and destination are known and are from the same lan, the packet is dropped. if the source and destination are known and are from different lans, the packet is forwarded to the correct output line. if the destination is not known, then the packet is flooded on all its lines. benefits of such a forwarding process is, only frames that need to cross the bridge are forwarded. they also reduce collisions by creating a separate collision domain on each line of the bridge.",
        "answer_feedback": "by observing packets, the bridge learns through which lan a station can be reached, not where the station is located. this information is used in selective forwarding. apart from this, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0314q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter, the maximal distance where collisions can be recognized decreases tenfold. if the collision domain diameter was 3000 meters before, it now is 300 meters.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0180q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\n  -  units are transmitted isolated and independently. errors are detected by upper layers.\n\nconfirmed connectionless service:\n  -  the receiver acknowledges received data with a receipt for data units\n  -  in comparison to unconfirmed c. s. data units can be retransmitted if they are missing/not acknowledged. retransmitted packages may lead to duplications and sequence errors\n\nconnection-oriented service\n  -  no package loss, no duplication, no error sequences due to flow control\n  -  the sender sends connection request, to make sure the receiver is ready to get data\n -  data is transferred and the connection is closed after that",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0103q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(a, b, forward)(a, c, forward)(a, d, forward)hop 2:\n(b, c, drop) <= c already has packet from a from hop #1(b, e, forward)(c, b, drop) <= b already has packet from a from hop #1(c, d, drop) <= d already has packet from a from hop #1(c, e, drop) <= e has packet from b with better metric from route abe (2+1=3) vs. ace (2+2=4)(c, f, forward)(d, c, drop) <= c already has packet from a from hop #1(d, f, drop) <= f has packet from c with better metric from route acf (2+1=3) vs. adf (2+3=5)hop 3:\n(e, c, drop) <= c already has packet from a from hop #1(e, f, drop) <= f already has packet from c from hop #2(e, g, forward)(f, d, drop) <= d already has packet from a from hop #1(f, e, drop) <= e already has packet from b from hop #2(f, g, drop) <= g has packet from e with better metric from route abeg (2+1+1=4) vs. acfg (2+1+2=5)hop 4:\n(g, f, drop) <= f already has packet from c from hop #2(g, h, drop) <= h has only one neighbor (g) from which it got the message",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0029q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i think, binary encoding should be used in this network. the reasons are following:\n1. all users are interconnected and have perfect clocks, so we don't need to worry about synchronization problem between receiver and sender, i.e self-clocking feature is not necessary in this case.\n2. to mitigate network congestion causing by excessive traffic, we need to improve bit rate. using binary encoding can provide double wideband compared to manchester encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0264q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees have all nodes covered with the minimum number of edges, so there can't be any loops. that makes them appealing for broad- and multicasting. if we modify link state routing so that each is calculates a multicast tree. all is send link state packets periodically and from the now locally available and complete state information each is calculates a multicast tree.",
        "answer_feedback": "the response correctly answers why a spanning-tree usage is ideal in multicast and broadcast. the provided information for modifying link state to construct a multicast spanning group is not complete as it does not state what additional information is added in each link-state packet apart from the regular information.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0405q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 \n127.255.255.255\nthe first adress and the last adress of each subnet are reserved",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0035q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i think they should use binary encoding. compare to other encoding techniques, binary encoding has good utilization of bandwidth. also, the encoding is simple and cheap.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0094q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop) d will not forward the packet, because a is the origin and d is not part of a unicast route a-c or a-f.\nhop 2:\n(b,e,drop) b is origin, routes g-a, f-a, c-a do not go through e(c,f,forward)\n\nhop 3:\n(f,g,forward)\n\nhop 4:\n(g,h,drop) g is origin of the packet, no further neighbors",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0380q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "both parties must be able to send data and acknowledge information",
        "answer_feedback": "the response answers the underlying requirement, i.e. duplex connection, correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0101q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 2: \nfrom b: \n(b, c, drop), (b, e, forward) \nfrom c: \n(c, b, drop), \n(c, d, drop), \n(c, e, drop), \n(c, f, forward) \nfrom d: \n(d, c, drop), \n(d, f, drop) \nhop 3:\n from e: \n(e, c, drop), \n(e, f, drop),\n(e, g, forward) \nfrom f:\n(f, d, drop), \n(f, e, drop), \n(f, g, drop) \nhop 4: \nfrom g: \n(g, f, drop), \n(g, h, drop) \nbecause vertex h has only one neighbor from which it got the message, vertex h does not forward the message.\nin total 19 messages are sent during the broadcast.",
        "answer_feedback": "hop 1 not given and (c, f, drop) occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0383q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "both parties have to advertise their window sizes to each other to avoid the received data to be thrown away (so the receiving buffer was full). therefore, they need to introduce a new field to the frames which holds this value. alternatively, they agree upon first communication to some static window size and afterwards send their data (and hope the free buffer sizes of both remain the same). in both cases it would be recommandable not to send huge data chunks upon first communication, because both parties don't know the window sizes of the other one yet. with each frame they send a sequence number (even if no data is sent, so the receiver is able to acknowledge it), the ack-number (even if no new data has been received, so the receiver can use this as base for their sequence number), and lastly the window size.",
        "answer_feedback": "the response is incorrect. all the stated points are correct but are related to the window sliding mechanism in general and how the initial setup occurs.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0415q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 and 127.255.255.255",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0195q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "while both (udp and tcp headers) have source and destination port fields, every other part of their headers differ. for udp only a packet length and a checksum field follows the two previously mentioned fields. tcp needs more information. so after the source and destination port the header is followed by a sequence number field as well as a field for the ack number. the tcp header also stores information on hl/resv/flags, window size, checksum (as in udp), urgent pointer and options.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0032q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i would use a binary encoding as the bandwidth is limited. binary encoding makes good use of the given bandwidth as it has 1 bit/baud, with both types of manchester encoding having only 0.5 bits/baud. additionally given a perfect clock the manchester encodings are not needed, as their main advanteges are self clocking in unsynchronized networks.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0061q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "calculate the probability that there are 0, 1, 2, 3, 4 .. 9 packets in the queue.  sum these probabilities and multiply that by 60 seconds.\n\nprobabilities can be calculated with these formulas where pn is the probability the queue has n packets in it:\np0 = (1-r)/(1-r^(n+1))\npn = (1-r)r^n/(1-r^(n+1))\nr = 9/10 = 0.9\n\nprobability of 0 to 9 packets in the buffer = 0.9492\nseconds = 56.96",
        "answer_feedback": "the response correctly explains how the number of expected seconds can be calculated. however, the number of expected seconds or the probability is rounded incorrectly. the correct value is 56.952 instead of 56.96 seconds.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0213q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for real internet traffic. if somebody for example streams videos on the internet, the probability that after the first packet another packet will arrive is much higher than the probability for the first packet. if you increase the interval δt there is the possibility the assumption become true again, but it’s not a realistic case.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0210q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no the assumptions does not hold, since the arrivals depend on each other. for example one request to a server leads to multiple packets being sent back. also the answer of the server then might lead to multiple requests afterwards. thus the packets come in stacks with time in between, since the server and the client need to process the packets.",
        "answer_feedback": "the response is correct except that it attributes the bursty nature of the internet traffic to the request/response model which is not always the case.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0372q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "-it has to be a full-duplex operation\n-frames must contain implicit acknowledgments",
        "answer_feedback": "the response answers the underlying requirement correctly. both points are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0052q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "with perfect clock we can use binary encoding as the problem with  long sequence of 0/1s wouldn't cause clock synchronization issue. moreover, it's simpler and makes an efficient use of the bandwidth which could be helpful with heavy network traffic.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0056q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "with the poisson process, we can calculate p0 to pn. if p0 = 0.5, this means, 50% of the time the system is empty. \nin this exercise, we have a λ=9, µ=10 and n=10. the blocking probability (the probability that the system is full) p10 is 0.051. so, 5.1% of the time, the buffer is full. the complementary probability (the buffer has less than 10 packets waiting) is 0.949. as a result, in one minute we expect that in 0.949*60s = 56,94s less than 10 packets are waiting in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0109q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. sequence numbers: + discards duplicates\n2. par: + doesn't block at loss of both frames and acks; - long wait possible\n3. nak: + discards bad frame, can reduce additional traffic",
        "answer_feedback": "the problem of duplicate packets on the transport layer in a connection-oriented service needs to be explained.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.17
    },
    {
        "id": "smp0218q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "a bridge connects some different lans the bridge table contains the information which lan needs to be accessed to reach a certain destination address. at the beginning the bridge does not know the topology and uses flooding to forward packets to the right destination. once a correct route is found a new table entry with this new information is added to the table. this process of slowly getting to know the topology is called backwards learning. when a packet arrives at the bridge and its destination address is already in the bridge table there is no need for flooding the packet can be forwarded directly according to the table entry.",
        "answer_feedback": "the response does not mention what is learned and interpreted on receiving a packet from source s over link l, i.e. s can be reached over l. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0382q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking in sliding window allows to send the acknowledgment of a received frame together with data.\n- sender and receiver needs two sequence counter. one for its own frames and one for the acknowledgment of the received frames.\n- benefits the most from a duplex connection\n- when a frame is send, the seqno of the frame and the seqno of the last received frame (for acknowledgment) are send together.\n- the seqno is initialized with 0 and is increased before a new frame is sent.",
        "answer_feedback": "the response is correct as it identifies duplex connection as one of the requirements, but the sequence number need not be initialized with 0.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0102q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,f)\n(a,c,f)\n(a,d,f)\n\nhop 2:\n(b,e,f)\n(b,c,d) <- a,c is faster, not minimal spanning tree\n(c,b,d) <- a,b is faster, not minimal spanning tree\n(c,e,d) <- b,e is faster, not minimal spanning tree\n(c,f,f)\n(c,d,d) <- a,d is faster, not minimal spanning tree\n(d,c,d) <- a,c is faster, not minimal spanning tree\n(d,f,d) <- a,c,f is faster, not minimal spanning tree\n\nhop 3:\n(e,c,d) -> a,c is faster, not minimal spanning tree\n(e,g,f)\n(e,f,d) -> a,c,f is faster, not minimal spanning tree\n(f,e,d) -> a,b,e is faster, not minimal spanning tree\n(f,g,d) -> a,b,e,g is faster, not minimal spanning tree\n(f,d,d) ->a,d,f is faster, not minimal spanning tree\n\nhop 4:\n(g,f,d) -> a,c,f is faster, not minimal spanning tree\n(g,h,f)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0381q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the participant, who sends the ack, has to have data, which he wants to send. if there is no data to \"biggyback\" the ack on, the participant will wait infinitly for data to send with the ack and therefore the piggyback extension would not work.",
        "answer_feedback": "the response is incorrect because a dedicated timer can be used on the receiver side to overcome the above problem of no data on the receiver side. after the timeout, an acknowledgment is sent independently.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0083q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2:\n(b, e, forward)\n(b, c, drop) <= a->c is shorter\n(c, b, drop) <= a->b is shorter\n(c, e, drop) <= a->b->e is shorter\n(c, f, forward)\n(c, d, drop) <= a->d is shorter\n(d, c, drop) <= a->c is shorter\n(d, f, drop)  <= a->c->f is shorter \n\nhop 3: \n(e, c, drop) <= a->c shorter\n(e, f, drop) <= a -> c-> f is shorter\n(e, g, forward)\n(f, d, drop) => a->d is shorter\n(f, e, drop) => a -> b-> e is shorter\n(f, g, drop) => a -> b -> e -> g is shorter\n\nhop 4:\n(g, f, drop) => a->c->f is shorter\n(g, h, forward)",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0189q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "to build a metropolitan area network (man), which can combine asynchronous data traffic(ieee 802.x mac) and isochrounous traffic (atm-b-isdn), the dqdb (ieee 802.6) was designed.\ntherefore, two unidirectional buses are used. one bus is in the opposite direction of the other. a node is connected to both buses, on one bus data can be requested, on the other one data is sent.\nthe main problem with this architecture is, that a node can request more data than others depending on its position in the network.  so fairness is the issue with dqdb. \nto sum up:\n\"for a light-to-medium load, dqdb is somewhat unfair.\", fairness issues of the dqdb protocol,",
        "answer_feedback": "the response states the correct problem in dqdb architecture, including the proper explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0181q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connection-less service, confirmed connection-less service, and connection-oriented service.\nan unconfirmed connection-less service offers no feedback, if the sent frame was received. a confirmed connection-less service offers this feedback with a simple acknowledgment per frame, therefore no loss occurs. but the acknowledgment can also lead to duplicates because the sender may have not received the ack yet and retransmits the frame. in contrast to other two, a connection-oriented service provides a connection without duplication or sequencing errors and provides flow control, because the connection is setup (exchange of parameters, i.e. sequence number) and teared down afterwards.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0224q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "each entry in the bridge table holds: a destination address s, which lan (link) l is to be used to reach s, and a timestamp t of when last the frame from s arrived.\n\nwith backward learning, the bridge learns from an incoming frame and the lan connected to the link through which the frame was received that the frame's source s can be reached via lan l (directly or through other bridges) and stores/updates this information (s, l and frame arrival time t) on any arrival of a frame with s as the source address (and purge it by another process if it is too old, that's why t is stored).\n\nthe forwarding process uses the bridge table by looking up the entry for a given destination address s to decide what to do with an incoming frame addressed for s: if an entry is found then the frame is either rerouted via the destination link l if that link is different from the incoming link or discarded (as it should not leave the lan), else flooding is used as a fallback (destination lan unknown).\n\nthe benefit is a reduced network load (compared to flooding the network) if an entry exists for a destination because then only the relevant outgoing link is used and no needless copies of the frame are created and flooded into the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0211q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "after all, this is not less and not more than a simple model. the details of internet traffic including bursty traffic situations, streams like video (e.g. youtube, netflix) or audio (e.g. internet telephony) or the traffic depending on daytime or season cannot be modelled accurately using a poisson process. there is some derivatives of the poisson process to better model the bustiness, e.g. the compound poisson process.\nhowever, the poisson process has some nice mathematical features allowing a simpler math and therefore allowing to analytically describe queueing systems. therefore it is widely used for a first analysis or for more mathematical modelling. if a system needs to be analyzed in more detail, simulations tools (e.g. opnet) can be used. this does not lead to a mathematical formula but delivers more precise numerical results and enables the modelling of a wide variety of data source models.",
        "answer_feedback": "the question asks whether it is true that the arrivals at a node depend on previous arrivals for real internet traffic instead of whether the poisson process is a realistic model. the reasoning is correct for both questions, but the definitive answer to arrival independence is missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0185q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem is the fairness, because it can depend on the location of the station if you have an advantage or disadvantage in getting access to the bus and send data. this is, because to send data a station has to make a reservation on one bus and after the reservation arrives on the other bus, the station can send its data on that other bus (so reservation on one and sending on the other). therefore the location of a station has influence on the fairness because for example if the station is at the beginning it could be more likely to get a reservation to send some data than it is when the station is at the end of the bus.",
        "answer_feedback": "the response answer is correct because it identifies the correct problem in dqdb including an appropriate explanation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0184q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb describes a man structure, where every node (mostly lans) is connected with two unidirectional buses, which have a frame generator at the end. a node can reserve on one bus and then send one the other one. the problem is the reservation is depending on the location of the node and therefore you sometimes have an advantage and sometimes a disadvantage and so it is not fair.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and provides an appropriate explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0033q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "as there is no global clock, i would not suggest binary encoding. as there is much traffic i would choose differential manchester encoding, rather than the normal one which is more susceptible to noise.",
        "answer_feedback": "as the perfect clocks are already provided, self-clocking is not required.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0201q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header contains four parts, the sender port, the receiver port, the packet length and the checksum. the sender port is optional and the checksum also. the packet length minimum is 8 byte.\nthe tcp header also contains a source and destination port and a checksum but has some other contents too. so four fields which are different from the udp header are the sequence number, the acknowledgment number, the hl/resv/flags and the advertised window. additional there is an urgent pointer field and some space for options. the tcp header is also larger than the udp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0042q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding.\n1. since all users have perfect clocks, self-clocking isnt needed.\n2. good utilization of the bandwidth, so congestion is less of an issue.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0120q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "one possibilty to adress the problem of duplicate packets is to use temporarily valid tsaps. these tsap are valid for one connection only and are unique for this connection. some ports are relied to as well-known tsaps, which can cause duplicates again.\nanother possibility is to identify connections individually with a seqno. so duplicates are avoided by assigning a seqno to every connection. a disadvantage is the need to store this information in the endsystems even if they are switched of.\nanother possibility is to identify the different packets individually. so a sequential number is assigned to each pdu individually. this makes it easy to identify duplicates. a disadvantage is the higher usage of memory and bandwidth.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0418q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.0 to 10.255.255.255 private ip addresses\n\n127.0.0.0 to 127.255.255.255 reserved for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0034q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding because the link's capacities is limited in this senario and differential/manchester encoding require more bandwidth (0.5 bit / baud). each user have the perfect clock, therefore encoding with binary encoding is possible in this case.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0259q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees includes all routers with no circles, so the packets are not sended (infinitely) often around.\n\nif the frequently sended packets of the link state routing also contains informations on multicast groups, every is has enough information to construct a spanning tree for multicasting.",
        "answer_feedback": "the explanation behind using a spanning tree for multicast and broadcast is partially correct because though the network is loop-free, using the tree results in the minimum number of message copies required to be forwarded and not just the prevention of forwarding loops.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0315q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter (cdd) is reduced to 1/10th of the original. in the given example cdd is reduced from approximately 3000m to about 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0204q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- tcp has no packet length header, which udp does. this is not needed for tcp, because it is connection-based and once all packets have been acknowledged by the receiver, the connection is terminated. - tcp has a sequence number header, which udp does not. it is used to identify the current packet and ensure the correct order when reassembling the data at the receiver - tcp has an acknowledgement number header, which udp does not. it is used to confirm packet reception and connection setup and termination confirmation - tcp has an advertised window header, which udp does not. it is used by the receiver for flow control, indicating how much data the receiver can currently receive",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0031q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "in the described scenario binary endcoding should be used, because it provides a higher data throughput than manchester encoding for a given baudrate. the missing \"self-clocking\" feature is no problem, since all users have perfect clocks.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0043q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "since all users have perfect clocks. the binary encoding technique would be the most suitable one. on the strength of its efficient use of the bandwidth, this type of encoding will be very practical in congested networks.\nfurthermore it is easier and simpler method to encode the bitstreams.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0036q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "for the given scenario binary encoding should be used.\nsince the users all have perfect clocks, the encoding does not need to to provide a self clocking feature.\nbecause the network is often congested and the links are more than saturated, a encoding with a high baud rate is preferable.\nhowever, if the network is prone to interference and noise, manchester encoding or differential encoding could be the better choice, even though it provides only half the baud rate.\nmanchester encoding could provide the benefit of \"built-in integrity codes\". this means you could identify overlapping transmissions, that interfere with each other.\nsince noise is not stated in the scenario and assuming, that a mechanism for medium access control is used to prohibit overlapping transmissions, my encoding scheme of choice would be binary encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0099q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= (c to f is shorter than d to f)\nhop 2:\n(b, e, forward),\n(c, f, drop) <= (e to g is shorter than f to g)\nhop 3: \n(e, g, forward)\nhop 4: \n(g, h, drop) <= (h is the last node)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0041q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding is the best option in my opinion as it offers a good utilization of the bandwidth which is especially useful as the network is often congested and furthermore because the local network has a perfect clock it doesn't need self clocking. another reason would be that it's quite simple and cheap to implement.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0252q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose of reverse path forwarding and reverse path broadcast is to send (loop-free) multicast packets in multicast routing. reverse path forwarding is more reliable (it can compensate if one router of the network has an error). reverse path broadcast is more efficient, it relieves links, which are not the best path and therefore not necessary. reverse path forwarding: if the router gets a packet, it looks where the packet comes from. if it is from a link, which its (unicast) routing table would also suggest to send via this link, this link is the best path and the router distributes the packet. otherwise the packet is discarded. reverse path broadcast: if the router b gets a packet, it also looks in the routing table, if the packet comes from the best path. if it is the best path (from router a), the router looks in the routing table whether a packet is ever send from c to a. if this is not the case, the link to c is not the best path and b doesn’t send it to c. so not necessary links are relieved.",
        "answer_feedback": "the response is partially correct because both rpf and rpb explanations didn't clearly explain how the packets are forwarded in a network. additionally, the is would also look whether packets are sent from a to c in reverse path broadcast. the algorithms avoid loops not only in multicast but also in broadcast.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6
    },
    {
        "id": "smp0375q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking means the acks are not sent separately but are inside the header of the next package that the party who is acknowledging the last package wants to send.\nso piggybacking only makes sense when both partners are sending and receiving data, i.e. we have a duplex transfer operating mode.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0305q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "then the maximum segment length becomes 2000m, which is too long for collision recognition.",
        "answer_feedback": "the collision diameter decreases by a factor of 10 rather than becoming 2000m for a collision to be still detected.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0197q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp header: 1.reliable bidirectional in-order byte stream 2.connections established and torn down 3.multiplexing/ demultiplexing 4.ports at both ends 5.end-to-end flow control 6.congestion avoidance udp 1.udp is a simple transport protocol 2.unreliable 3.connectionless 4.message-oriented 5. no flow control 6. no error control",
        "answer_feedback": "the question requirement is to identify differences between tcp and udp headers instead of general differences.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0221q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds the information which output lines/lans to use to get to a certain station. the bridge inspects the traffic (backward learning) and when the bridge receives frames with source address q on lan l it learns that q can be reached over l and creates a table entry accordingly so it can adapt to changes in topology. when the bridge gets a frame with the identical source and destination lans in its table, the frame can be immediately dropped since it was already on the right lan. when the source and destination lans differ, the frame is rerouted to the destination lan. the frame is only flooded when the destination is unknown; with this decision procedure unnecessary flooding or forwarding is prevented.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0171q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\n-this service has no flow control and the data unit does not get acknowledged from receiver. so there are no timeouts.\nconfirmed connectionless service:\n-this service has no flow control and the data unit does get acknowledged from receiver. so there could be timeouts and retransmits.\n\nconnection-oriented service:\n-this service has flow control. is implemented in a 3-phased communication.\n1. connection\n2. data transfer\n3. disconnection",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0085q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, forward)\nhop2:\n(b, e, forward)(c, f, forward)\nhop3:(e, g, forward)hop4:\n(g, h, forward)",
        "answer_feedback": "the reason also needs to be provided when a packet is not forwarded to other nodes i.e. dropped by the receiver as stated in the question \"list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes.\" packets will be considered dropped if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop) ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7
    },
    {
        "id": "smp0250q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path broadcast are both broadcast algorithms that attempt to minimize the number of duplicates packets in the network compared to other algorithms like the simple flooding algorithm. the idea of reverse path forwarding is that each sender/node has an own spanning tree, but the other iss do not need to know them. the algorithm is based on a simple condition for each node. the node has to decide, whether the received packet sent over the best route, i.e. it used the edge the node would use to send it back to the sender/author or not. if this is true, the node resends this packet over all other edges, i.e. excluding the incoming one, otherwise, the packet is most likely a duplicate and it will be discarded. the reverse path broadcast goes a little further and the is sends the packet from the best route only to the nodes it is responsible for/the sender used before. if the is is on the best path between the sender and his neighbor node, i.e. it is responsible for it, it learns over time.",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0379q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "sending must be possible in both directions in order to send data and acks (two-way-communication) and the frames must be able to contain acks.",
        "answer_feedback": "the response states both the requirements correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0030q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used because it is overall more complex. \n\nsimilarly to manchester encoding, dm encoding takes advantage of splitting the interval into two, where a voltage level shift takes place (either from high voltage to low voltage or vice versa). however, manchester encoding is still too similar to binary encoding in that a 1 will always be equivalent to a voltage shift from high --> low and a 0 will always be low --> high voltage. instead, if the voltage shift occurs between intervals (either high -> low or low -> high), a 0 will be encoded. likewise, if there is no voltage shift between intervals then a 1 is encoded. by comparing the current interval to the previous interval's voltage level, a more accurate encoding technique can be realized.\n\nand unlike the binary encoding system, dm encoding does not rely on binary voltage levels to encode a bit stream. instead, merely a change in voltage level between intervals encodes the bit stream. (ex. a lack of voltage level change between the first and second interval would mean that the second bit in the stream is a 1) therefore, because the voltages only need to differ between intervals, the bit stream is less susceptible to noise/error.",
        "answer_feedback": "the preference is always for a simple solution. further self-clocking is not required here and manchester provides lower bandwidth utilization which can further complicate the congestion problem.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0095q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, f, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, forward)",
        "answer_feedback": "the reasoning behind which packets are dropped is not stated.  please go through the model solution. packets will be considered drop if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7
    },
    {
        "id": "smp0261q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "the property is, if each router knows which of its lines belong to the spanning tree, it can copy an incoming broadcast packet onto all the spanning tree lines except the one it arrived on. there is no loop in a tree. therefore in order to build a spanning tree by modifying link state routing, the loops need to be cut. assuming that a router is a vertice and when two routers are connected, there is an edge between them. after five steps of lsr, it can be abstracted as a weighted directed graph. below is the basic idea. divide the vertices in the graph into two groups, s and u. s contains vertices that has already computed shortest path. u contains vertices that the shortest path is uncertain. add following steps after regular lsr. a. originally, s only contains source vertice v, u contains the rest of them. b. pick up vertice k from u, which has shortest distance from v, put k into s. c. let k be the new intermediate vertice, changing the distances from k to the rest vertices in u. d. repeat step a and b until all vertices are in group s",
        "answer_feedback": "the response is not correct about how the link-state algorithm is modified. the link-state packet is expanded to contain multicast group information and exchange it with other nodes to calculate their multicast spanning tree. dividing the graph into two parts and calculating the shortest distance does not help in sharing the needed multicast group information of each node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0411q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - dummy address\n10.0.0.0/8 - private network\n127.0.0.0/8 - loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0191q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "depending on the location a station may not be able to make a reservation. the further a station is at the bus-head end, the less reservating frames is possible due to fifo - first in first out scheduling. the main issue is fairness as the stations do not have the same chance to access the bus.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and also provides an explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0176q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service: transmission of isolated, independent units which are called frames. data loss is possible. l2 doesn’t correct this and only transmit correct frames.\n\nconfirmed connectionless service: no data loss, because each frame is acknowledged. timeout and retransmit is possible when a sender doesn’t receive an acknowledgement within a certain time frame.\n\nconnection-oriented service: connection over error free channel. theres no loss, duplication or sequencing errors. it also features flow control.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0046q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding should be used, because this has the highest baud rate in comparison to the other and so we can keep the congestion the lowest. further we can implement with the bits on a higher layer a congestion control.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0308q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter decreases by factor 10. the increased  bit rate leads to a reduced bit duration but the transfer speed remains the same. the result of that is a shorter maximal distance between two stations which is allowed so that collisions can still be detected.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0193q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem with this system was the fairness. some nodes had better chanes to reserve bandwith for themselves than other nodes.",
        "answer_feedback": "the response is partially correct as it states the issue in dqdb but lacks an explanation of why some nodes have better chances of reservation rights. the possibility to reserve bandwidth depends on the distance between a station and the frame generator or the slave frame generator.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0203q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is missing the sequence number, the acknowledgement number, the hl/resv/flags, and the urgent pointer fields. tcp has this fields.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers. however, the terms hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0089q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1: \n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\n\nhop 2: \n(b, e, forward)\n(c, f, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) -> packet drops because it only has one neighbour and node  h does not forward the message.",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.5 for reasoning (a,d, drop), (c, f, drop)",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.8
    },
    {
        "id": "smp0091q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=because f does not forward a broadcast packet from a to d)\nhop 2:\n(b,e,forward)\n(c,f,drop)<=because g does not forward a broadcast packet from c to f)\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=because there is no more receiver after h",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0251q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "the purpose is to reduce packet duplicates due to flooding. * reverse path forwarding: the receiving router checks, if the incoming packet used the usual (proboably best) path to it. if it is the case, the packet will be forwarded to all links except the one at which the packet arrived. if a packet arrives at an unusual path (probably not the best path and a duplicate), the incoming packet will be ignored (discarded) and not forwarded any farther. * reverse path broadcast: similiar to _reverse path forwarding except _that a node gains information about the best paths between neighbouring nodes due to observation. that is, a packet will not be forwarded via every link but only via those links, which are unlikely to create more duplicates. for example a node a will not forward a packet to x coming from a node z, if it knows (due to obeservation), that there exists a best path between x and z for that packet.",
        "answer_feedback": "the response identifies the purpose of rpf and rpb correctly. the rpf explanation is partially complete because it is unclear what the \"usual path\" means and how it is determined. if a node x receives a broadcast packet from source s, node x checks its routing table to see if it would have used the same route to send a unicast packet to s, if yes the incoming packet followed the best route. the rpb explanation is also not complete as it also does not explain how nodes learn the best path between nodes, namely through the unicast routing algorithm (e.g. link state) or observing previous unicast traffic.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.6
    },
    {
        "id": "smp0199q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. tcp header size is 20 bytes, but udp header size is 8 bytes.\n2. tcp does flow control, but udp does not have an option for flow control.\n3. tcp does error checking and error recovery, but udp does error checking but simply discards erroneous packets.\n4. tcp has sequence number field, but udp does not.",
        "answer_feedback": "the first point is partially correct as the tcp header length varies from 20 to 60 bytes and does not have a fixed size. the second and third points are incorrect as there is no context provided for the header field related to them. the fourth point is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.38
    },
    {
        "id": "smp0371q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a relieable in-order delivery of packets (like data link layer 2 in osi)\n\nat least an acknowledged connectionless service or an acknowledged connection-oriented service (for feedback if the packets / frames are received).",
        "answer_feedback": "the response is not directly related to the piggybacking but to sliding window protocol in general.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0065q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0416q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "in the host block two adresses are reserved:\n- all 1´s as host acts a a broadcast address\n- all 0´s as host acts as the network",
        "answer_feedback": "missing: loopback",
        "verification_feedback": "partially correct",
        "max_score": 0.5,
        "normalized_score": 0.5
    },
    {
        "id": "smp0313q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "collision domain diameter is the distance between the two furthest nodes. if i use csma/cd, then the distance limitation for collision domain diameter will be one tenth as large as before when i increase the speed of a network by a factor of 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0049q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encoding, since it has good utilization of bandwidth which could solve the traffic problem. on the other hand, the 3 users have already perfect clocks, the no \"self-clocking\" feature of binary coding could be neglected.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0254q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "using reverse path forwarding ensures loop-free forwarding of multicast packets. the idea behind this algorithm is: if a packet station x arrives at an is over an entry point over which the packets for station x are usually sent, this might probably be the correct and fastest route. therefore only if this is the case packets distributed over all edges. if the packet is received over another entry point it will be discarded. reverse path broadcast is a refined version of this algorithm. it differs from reverse path forwarding by the fact, that if the packets have taken the best route until their arrival at a certain node they will be forwarded to the best next edge taken from the routing table. if not, they are not sent over all edges. this is achieved by the knowledge, which other nodes usually receive their unicast packets via this note.",
        "answer_feedback": "the answer is partially correct as the purpose of rpb is not explicitly mentioned. in rpf, the optimal/best route may or may not be the \"fastest\".  in both algorithms, the packet is also not forwarded to the edge from which it was received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8
    },
    {
        "id": "smp0024q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "tcp should be used because it has a bidirectional bitstream. furthermore it provides a flow control in order to handle too musch traffic.",
        "answer_feedback": "the response is not related to the theme of the encoding type.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0188q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "a node a close to the frame generator can pick up a “free” token and transmit data with a higher probability than a node b far away from the frame generator if the network is highly loaded. therefore, node a has a preference when trying to send a packet compared with node b which is a fairness problem. research to improve the dqdb protocol includes bandwidth balancing schemes to increase the fairness of bandwidth allocation.",
        "answer_feedback": "the response correctly states the fairness issue in dqdb and provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0212q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no this assumption does not holds for the real internet traffic because in real scenarios whenever the packet arrives then it is expected that much more packets will be received and if pick a time duration for that such as the night or day then there will be a variance in the packets arrival as we will be checking for packets during the day and which will be more also similarly for a video buffering application, the interval at which we request the packets will be different and infrequent.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0183q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the mentioned problem with distributed queue dual bus is fairness. each node when it wants to send something, it has to make “reservation” on one side of a bus and then when allocated at the other side of other bus, it is able to send something. for this reason, some nodes which is located near either one or two ends of the two buses might have too much advantage and disadvantage when it comes to transmission reservation (near and far ends). only nodes which are in between may have average fairness to reach both ends of the two bus.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and also provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0304q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter reduces by the same factor for example for a network with 10mb/s has a collision domain diameter of 3000m and when we increase the speed of the network by 10 to 100mb/s, the collision domain diameter will become 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0175q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "the 3 service classes of the data link layer are the unconfirmed connectionless service, the confirmed connectionless service and the connection-oriented service.\nthe connection-oriented service has a 3-phased communication. first the entities have to connect, then they can transmit data and after this they disconnect. there is a data flow in both directions. the sender gets an acknowledgement if the receiver receives the data, so there is no loss of data. this service offers also flow control and prevents duplication or sequencing error. \nthe other services have no connect or disconnect and no flow control. \nthe confirmed connectionless service can only ensure that there will be no loss of data because the receiver sends an acknowledgement. \nthe unconfirmed connectionless service cannot because only the sender can send data and the receiver sends nothing back.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0027q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding\n1. 3 users have perfect clocks. they  don't need a good \"self-clocking\" feature.\n\n2.binary encoding is simple, cheap and has good utilization of the bandwidth (1 bit per baud)， all users generate more traffic than the link’s capacities， so we need better  utilization of the bandwidth than manchester encoding and differential manchester encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0196q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header has some additional data fields for: acknowledgment number, flags, advertised win. or urgent pointers.\nit needs more information in the header to include more features than udp.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0053q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the differential manchester encoding might be the best option here. both manchester and differential manchester encoding have a self-clocking feature which enables users to know if a tansmission is happening at the moment (every clock cycle a change if there is an active transmission). the differential variant has a low susceptibility to noise which might be beneficial in a multi-user environment because it might lower the chances of e.g. retransmissions.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0194q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. tcp has a flag for indicating that finished\n2. udp has no sequence number\n3. udp has no acknowledgement number\n4. tcp has a flag, if the data is urgent",
        "answer_feedback": "there are different types of flags available in the tcp header, but they are all within the flag header field. therefore, points 1 and 4 are similar and count as one.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0086q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)(a, c, forward)(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, e, drop) not minimal spanning tree(c, f, forward)(d, f, drop) not minimal spanning tree(b, c, drop) not minimal spanning tree(c, b, drop) not minimal spanning tree(c, d, drop) not minimal spanning tree(d, c, drop) not minimal spanning tree\nhop 3:\n(e, c, drop) not minimal spanning tree(e, f, drop) not minimal spanning tree(e, g, forward)(f, d, drop) not minimal spanning tree(f, g, drop) not minimal spanning tree(f, e, drop) not minimal spanning tree\nhop 4:\n(g, h, forward)(g, f, drop) not minimal spanning tree",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0117q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps\n   + easiest realization\n   - too many tsaps will quickly use up all the limited port numbers\n2. to identify connections individually\n   + each individual connection has a individual sequence number\n   - assigned sequence number are saved in endsystems. if endsystem switched off, the information disappear\n3. to identify pdus individually\n   + sequence numbers basically never gets rest\n   - higher usage of bandwidtrh and memory",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0118q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary valid tsaps: +tsap valid for one connection only -not always applicable because of process server addressing method\n2. identify connections individually with unique sequence numbers: +unique identification of connections remembered by ess -ess must be capable of reliably storing this information\n3. identify pdus individually with individual sequential numbers for each pdu: +seqno basically never gets reset -higher usage of bandwidth and memory\n(f.23, 24)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0208q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no it does not hold for real internet traffic. take video traffic as an example. client fetches data from server and fill them in its buffer. data could come more and more if the previous of them has been transmitted and filled successfully. if not successfully, the retransmission can happen. therefore each time interval are dependent on others, i.e. they are not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0301q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the size of \"collision domain diameter\" is dreduced by about 10 times, e.g. from ca.3000m to ca.300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0374q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "duplex operation",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0100q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\nfrom a:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= forward over b is not part of unicast a > c and a-> f\n\nhop 2:\nfrom b:\n(b, e, forward)\nfrom c:\n(c, f, drop) <= forward over c is not part of unicast a -> d, a->e and a-> g\n\nhop 3:\nfrom e:\n(e, g, forward)\n\nhop 4:\nfrom g:\n(g, h, drop) <= only link is the receiving link",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0384q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "every transmission must contain an ack.",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. a duplex connection is needed, so that data and acknowledgments can be sent both ways.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0116q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. using temporarily valid tsaps:\nthis method uses tsap that are valid for only one connection which makes it easy to identify duplicates. this method is not always possible, e.g. with process server addressing the server needs a designated/known tsap\n\n2. identify connections individually:\neach connection is assigned a new seqno and end-systems remember already assigned seqno. it does not work with connectionless oriented systems and end-systems have to be capable of storing the already assigned seqno. it's easy to implement this method.\n\n3. individual sequential numbers for each pdu:\neach pdu gets a seqno assigned which results in higher usage of bandwidth and memory. they are enough seqno so that they basically never get reset.",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0038q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the binary encoding technique should be used. because the chosen scenario doesn't need a self-clocking mechanism. the binary encoding also provides a good utilization in the network.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0247q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and revers path broadcast are used to forward multicast packages without using loops (and therefore not creating duplicates on the way). in reverse path forwarding every node has its own spanning tree. when a package is received by an intermediate station, the station checks if it would send packages to the sender over the used link. if that is the case, then it should be the best route and the intermediate station forwars the package to all connected nodes (except the incoming edge). if it is not the case, then it gets discarded, because it is very likely a duplicate, from another node. reverse path broadcast is an improvement on reverse path forwarding. instead of forwarding packages to every node (if conditions for forwarding are met) it only forwars it to the node, from where packages would normally arrive from.",
        "answer_feedback": "the purpose of reverse path forwarding and reverse path broadcast is not limited to the multicast but also used in broadcast. in reverse path forwarding, only the sender needs to know the spanning tree, and it makes use of unicast information to forward the broadcast package. the explanation of rpb is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8
    },
    {
        "id": "smp0174q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.\tunconfirmed connection less service: has no flow control, connect or disconnect; sender’s frames are transmitted as it is without taking in account possible loss during transmission with no acknowledgement from receiver. suitable with communication channels with very low error rate.\n2.\t confirmed connection less service: sender’s transmitted frames get acknowledged by receiver, may result in duplicate and sequence errors; still no flow control, connect or disconnect. better reliability than unconfirmed connection less service.\n3.\tconfirmed connection oriented service: starts with connect, then data transfer and end with disconnect. uses flow control to synchronize frame sequence and prevent loss due to speed mismatch. reliable compared to 2 types of connection less services.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0192q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "depending on where a node is connected to the two busses at some spots it is more likely to be able to reserve a time slot and send something than at other spots. making fairness the biggest problem of this solution for connecting subnetworks since the probability to be able to send depends on the position in the queue.",
        "answer_feedback": "the response correctly answers the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0093q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward); (a, c, forward); (a, d, forward).\nhop 2:\n(b, e, forward);  (b, c, drop) from a to  c ,via b is not the shortest; \n(c, b, drop),from a to b ,via c is not the shortest; (c, d, drop), from a to d ,via c is not the shortest; (c, e, drop), from a to e ,via c is not the shortest; \n(c, f,  forward).  \n(d, c, drop) ,from a to c ,via d is not the shortest; (d, f, drop) ,from a to f ,via d is not the shortest.\nhop 3:\n(e, c, drop), from a to c ,via e is not the shortest; (e, f, drop), from a to f ,via e is not the shortest; (e, g, forward).",
        "answer_feedback": "the provided flow appears more similar to rpf than to rfb.  in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0227q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table possesses information about the stations and in which  lan they are located.the bridge works in promiscuous mode, that means that it receives any frame on any of its lans and with the information stored on these frames of how the stations can be reached, it will create a table entry. in the forwarding process if the source and destination lans differ the frame will be rerouted to the destination lan (the information of where this destination is found is on the table).",
        "answer_feedback": "the response does not mention that if a packet arrived over link l from source s, it would use the same link l to forward packets destined for s. the response does not state the benefit of using the bridge table information. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0092q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, e, drop) <= because e never send a packet to a from c\n(c, f, forward)\n(d, f, drop) <= because f never send a packet to a from d\nhop 3:\n(e, g, forward)\n(e, f, drop) <= because f never send a packet to a from e\n(f, e, drop) <= because e never send a packet to a from f\n(f, g, drop) <= because g never send a packet to a from f\nhop 4:\n(g, h, drop) <= h is the last node and there is no other link",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0370q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the receiver must have data to send back to the sender so he can attach the ack information to that data. if he has no data to send, the service can be jammed. to prevent this, a receiver timeout can be added so that after the timeout has expired and no data was sent, an ack packet is sent independently",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. the response states a possible situation in piggybacking and how to overcome it.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0063q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "from the problem we recognise that the number of packets arriving is lambda=9 pkts per second and number of packets being serviced is µ=10 pkts per second. dividing the lambda by µ gives us the utilization. in the case of an equilibrium in a finite buffer, the probability of having less than 10 packets can be calculated from the formula of the blocking probability (slide 31). as this formula would give us the probability of the system being full, we would then need to subtract it from 1. finally, this would then be multiplied by 60 (as 1 minute contains 60 seconds) to give the number of seconds in which we expect the system to have less than 10 packets in the queue. the calculated blocking probability is 5,08% and therefore the probability of the system not being blocked 94,92%. 94,92% of 60 seconds is 56,952 seconds which is the estimated time of the system having less than 10 packets in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0058q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the given example is a finite buffer case, so a m/m/1/10 queue. with the given numbers, the utilization rate is 9/10 = 0,9. so if on an average 9 packets arrive and 10 can be served, there should never be 10 packets waiting in the queue. however, by calculating the blocking probability (the probability that the system is full) with the given formula, pb = 0,0508 which is ca. 5%. so there is a 5% probability, that the system is full and 10 packets are waiting in the queue. for 1 minute (60 seconds) 5% are 3 seconds. if i say that the system is in a state with 10 packets waiting in the queue for 3 seconds, i would expect the system to be in a state with less than 10 packets waiting for 57 seconds.\nif i take a look at the system throughput and insert the values in the formula, the result is 8,5428‬. this means 9-8,5428 = 0,4572 packets don't make it per second and therefore 0,4572*60 = 27,432 packets are dropped per minute. if 9 packets arrive per second, 27,432/9 = 3,048 seconds in which the system is full. this leads to the same conclusion as above, that the system is for ca. 57 seconds in a state with less than 10 packets waiting.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation. the additional validation is also correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0225q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges store destination addresses and start with an empty forwarding table.this table is populated by using backward learning (once the bridge receives a frame from an unknown source over router x, it stores the address information of the source). whenever a frame is sent to an unknown destination (no table entry), that frame is then flooded and the destination responds to the bridge to create a table entry. transparent bridges are invisible to other components during the forwarding process, thus simplifying other components.",
        "answer_feedback": "the response has the following errors a) transparent bridges store not just the destination but also the corresponding outgoing lan along with the timestamp. b) the stated backward learning process is incorrect. c)yes, the transparent bridges are invisible but that is not the benefit derived from using selective forwarding instead of flooding.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0097q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "(sender, receiver, drop) \nhop 1:\n(a, b, forward)(a, c, forward) \n(a, d, forward)\nhop 2:\nnode b: \n(b, c, drop) <= c is not on the best path to a\n(b, e, forward)\nnode c:\n(c, b, drop) <= b is not on the best path to a\n(c, d, drop) <= d is not on the best path to a\n(c, e, forward)\n(c, f, forward)\nnode d:\n(d, c, drop) <= c is not on the best path to a\n(d, f, forward)\nhop 3:\nnode e:\n(e, f, drop) <= f is not on the best path to a\n(e, g, forward)\nnode f:\n(f, e, drop) <= e is not on the best path to a\n(f, g, forward)\nhop 4:\n(f, h, forward)",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0258q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "-the property of spanning trees, that it is a subset of subnets including all routers with no loops, makes them appealing for broad- and multicasting.   -if link state routing is used and each is/router knows the complete topology, including which hosts belong to which groups,then the spanning tree can be pruned  from bottom of each path to root, all routers are removed that do not belong to the group.",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast. the second part does not answer how the link-state is modified. it assumes hosts have already discovered which nodes belong to which group, which is not correct. in the link-state additional multicast-group information is added and send to all other nodes.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0229q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the forwarding table maps stations to lans and has a timestamp for each of its entries.\nwhen the bridge receives a frame with the source address q on lan l in the backward learning phase, it adds a table entry q can be reached over l. if this entry already exists, the timestamp is updated, the timestamps are used to regularly delete old entries.\nwhen the bridge receives a frame in the forwarding process, it looks up the lan of the destination. if the source lan and the destination lan differ it reroutes the frame to the destination lan. if the destination address is not available in the forwarding table the packet is flooded.\nthe benefit of this is that the bridge is not visible to other components in the network, this simplifies the other components.",
        "answer_feedback": "the stated benefit is related to transparent bridges in general, but the question asked for the benefit of using bridge table information during forwarding, which is reducing duplicates. additionally, there is one more condition during forwarding where the packet will be dropped when the source lan = destination lan. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0200q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "sequence number, acknowledged number, urgent pointer, advertised window",
        "answer_feedback": "the response is partially correct as it does not state whether these fields exist in udp or tcp.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0216q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds information about which device/system can be reached on which lan. the table initially is empty and during backwards learning, the bridge monitors each frame, checks its source address and creates a new entry in the table with the source address and the lan from which the frame arrived (if necessary).  when receiving a frame, the bridge checks its table to determine if the receiver is on the same lan as the sender. if that is the case, the frame is dropped by the bridge, because bridging in not needed. if the receiver is on a different lan, the bridge forwards the frame to the correct lan, if the bridge doesnt know which lan the receiver is on, it tries to find that out by using flooding.",
        "answer_feedback": "the response does not mention the benefit of using the bridge table in selective forwarding. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0044q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding. beacause it has a good utilization of the bandwidth.",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0366q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "if you send data in both direcions, you can add the acknowledgment ,for earlier packages, on the next data package.",
        "answer_feedback": "the response identifies the underlying requirement duplex connection correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0186q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem with dqdb is fairness. while stations in the middle might have a chance of 50% to send data, stations at the beginning or at the end can have advantages/disadvantages depending on the situation.",
        "answer_feedback": "the response correctly identifies the fairness problem in dqdb which is due to the station location.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0413q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "class a:\n1.0.0.0 up to 127.255.255.255\nreserved addresses:\n(1-126).0.0.0\n(1-126).255.255.255\n127.0.0.0 to 127.255.255.255 (loopback adresses)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0060q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "if the equilibrium has been already reached then assuming that the packets during this 1 minute are evenly distribute, the system would be most of the time in the state where less than 10 packets wait in the queue.\nwe calculate the probability that there are packets p(0) for 0 -9 using this (1-r)^n-1\nthen we",
        "answer_feedback": "the first step of calculating probabilities for 0, 1, …, 9 packets to be in the queue is correct, but it is incomplete. additionally, the final step of multiplying it with the time frame to receive the expected number of seconds is missing in the response.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0222q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table assigns each adress the bridge knows about to a network. when the bridge is asked to forward a packet to a receiver, it looks at the table to see to which network it has to send the packet. that way packets that have the same source and destination network can be ignored by the bridge and packets with a different source network can be sent on the direct path to that network. initially the table is empty, but the bridges listens to all packets of the networks it is connected to and  whenever a packet is sent, the bridges wirtes an entry into its forwarding table containing the sender adress and the its network. if the bridge is asked to send a packet to an adress it has no entry for, it floods the packets in all other connected networks.",
        "answer_feedback": "the response does not mention the benefit. additionally, the table contains station, outgoing lan, and the timestamp which is not clear from the first line. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0220q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the information to what lan/other bridge a package should be send to in order to reach its destination. \n\nif a frame is received and\n- its destination lies in, or is routed over the over the same lan from where it is received it is dropped.\n- the destination is unknown the network is flooded\n- otherwise the package is rerouted to the next lan according to the table.\n\nthis makes the bridge self sufficient and other components of the network does not need to know about the bridge. \n\nwhenever a frame is received the bridge knows that the source can be reached over the incoming lan and creates a table entry or updates its table accordingly. \nto update for changes in the topology a timestamp is used for each entry and refreshed for each corresponding received frame. if a timestamp gets to old it is assumed that the entry is valid anymore and flooding is used the next time a frame with a corresponding destination is received.",
        "answer_feedback": "the response does not mention the benefit of using the bridge table in forwarding packets, i.e. fewer duplicates. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0262q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "properties of spanning tree for broad- and multicast:  * the spanning tree does not have any cycle  * a connected graph can have more than one spanning tree  * all possible spanning trees of the graph have the same number of edges and vertices  * the spanning tree is minimally connected, means it generates less complexity modifying link state routing to construct a spanning tree:  * all is sent link state packets periodically containing information on distance to neighbours, information on multicast groups, which will be broadcasted to all others  * each is calculating a multicast tree from the now locally available and complete state information  * based on the information about the multicast tree is determines the outgoing lines and on which packets have to be transmitted",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0198q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-    since udp is a simple protocol that actually sends ip packets with limited header additions to the receiver where the packet is forwarded to the application directly, i.e. w/o reordering, etc. the udp header consists only of \n     essential needs for data transmission, i.e. a sender and receiver port, packet length, and an optional checksum.\n-    in difference to that tcp it is more complicated, since the goal is to receive exactly the same data as transmitted by the sender, i.e. fully complete and in the right order of the packets. to achieve a reliable connection some \n     additional parameters vs. udp have to be added in the header:\n      o\tsequence number: to get the right order of the packets\n      o\tacknowledgment number: needed together with sequence number for connection setup to get the starting sequence number (3-way handshake)\n\t        o\tvarious flags, e.g. syn-flag for 3-way handshake\n      o\tadvertised win. or win: needed for flow control",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0177q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "the data link layer offers these :\n\n-unconfirmed conn.less service ->  no flow control , no connect or disconnect , sender will never get an acknowledgement from receiver (radio/broadcast).\n\n-confirmed conn.less service -> no flow control, no connect or disconnect , duplicates and sequence errors may happen due to “retransmit”\n\n-the connection oriented service -> no loss, no duplication, no sequencing error ,flow control  (3phased communication : connection, data transfer and disconnection)",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0215q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table bridge holds information of the following: table: station → lan. this means it stores information on how to reach a certain source address and over which lan it can be reached. this table is updated with backward learning. the bridge works in promiscuous mode and receives any frame on any of its lans. the bridge receives frames with source address q on lan l. this means q can be reached over l. this information is then stored in the table. in the forwarding process this can be used to forward it to the next bridge which then can forward it according to its own table. the benefit of that is that an urgent packet can be directly forwarded without any routing required.s",
        "answer_feedback": "the response incorrectly explains how this information is used in the selective forwarding and the stated benefit is also incorrect. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0173q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service (=frames are transmitted as independent units --> data can be lost)\nconfirmed connectionless service (=frames still transmitted independently but with acknowledgement)\nconnection oriented service (=3 phases: connection --> data transfer --> disconnection)",
        "answer_feedback": "the response answers the services' names and differences correctly.  but there is no common theme of the differences between them. the last point should also discuss the presence or absence of acknowledgment.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0409q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 - 0.255.255.255\n\n10.0.0.0 - 10.255.2555.255\n\n100.64.0.0 - 100.127.255.255\n127.0.0.0 - 127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0113q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "-1- to use temporarily valid tsaps (unique ports).\nadvantage:  it can eliminate the need for duplicate because we use unique port each time.  \ndisadvantage: require large number of unique ports (names) for some period of time.\n\n-2- to identify connections individually.\nadvantage: git rid of duplicate between different connections by assigning each of them a sequence number.   \ndisadvantage: end systems must be capable of storing  sequence numbers (need storage for that ) as well as it is more complicated because if the connection is lost we need to remember what happened in the past (store information)\n\n-3- to identify pdus individually:\nadvantage:  assign a seqno for each packet for certain time, after this time i can reuse this seqno and drop  any duplicate packets. \ndisadvantage: higher usage of bandwidth and memory",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0059q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "less than 60 seconds, more than 50 seconds (50-60 seconds),\nbecause the buffer size has 10 and 9 packets go in 10 packets go out. the buffer size of 10 is never exceeded.\n\n- steps involved :\n1.arrival process: how customers/requests arrive?(time between requests ,inter-arrival time)\n2.service process: how much demand do requests generate?(service time of single requests)\n3.how many places in queue?\n4.how many service stations?\n5.how are queues processed?(first-come-first-serve (fcfs), shortest job first, priority queue, and so on)",
        "answer_feedback": "the required justification is missing and a broad time interval is provided but the precise time in seconds was expected.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0369q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "before using piggybacking extension, there should be duplex operation. furthermore, a new packet should arrive quickly then the acknowledgement is piggybacked onto it; otherwise, if no new packet has arrived by the end of this time period, the data link layer just sends a separate acknowledgment frame. \n\nalso, the sliding windows protocol will utilize the bandwidth of the communication channel with piggybacking, frames may contain implicit acknowledges. for example, the intuitive seqno. is 0, then the next seqno. and the next ack-seqno to be expected is given.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0025q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "um die bandbreite des überfüllten netzwerks perfekt auszunutzen, sollte binary encoding verwendet werden. dieses ist einfach und günstig zu realisieren und ermöglicht 1 bit per baud. voraussetzung ist dabei der perfekte takt der nutzer, da binary encoding kein self-clocking-feature besitzt. (diffenrential) manchester encoding ist komplexer und ermöglicht nur 0,5 bit per baud.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0302q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter decreases by the factor of 10. that means:\nnew collision diameter = old colision diameter / 10",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0107q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporarily valid tsaps\nadvantage: simple to implement almost no additional overhead\ndisadvantage: “well-known” tsap's exist with which the server is addressed, so changing tsap's is not possible in this situation\n\n2. identify connections individually\nadvantage: distinction is made at connection level and not at packet level, so less overhead\ndisadvantage: the end system has to reliably keep a record of connecion-seqno pair\n\n3. identify pdus individually\nadvantage: able to handle duplicates and ordering of packets \ndisadvantage: the range of sequence numbers could be insufficient and cause duplicates if the packet rate is very high and/or the \"lifetime\" of packet is very long.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0098q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n\n(b, e, forward)\n\nb would not forward the packet from s to c because b knows that from c to s the packet would never go through b\n(c, f, forward)\nsimilar reason, c would not forward the packet from s to d and s to b\nd would not forward the packet from s to c and s to f\nhop 3:\n\n(e, g, forward)\ne would not forward the packet from s to c and s to f\nf would not forward the packet from s to c and s to e\nhop 4:\n(g, h, forward)\ng would not forward the packet from s to f",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop) and (g, h, drop) will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.4
    },
    {
        "id": "smp0307q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is decreased by the same factor, the network speed is increased by, i.e. if the collision domain diameter in a 10mb/s network was 100m, the collision domain diameter in the same network with 100mb/s would be 10m. \n\nthis is because the sender still must be able to recognize a collision during simultaneous sending.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0377q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "we require atleast a (semi)duplex data transfer",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0090q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, forward)\nhop 2:\n(b, e, forward)\n(c, f, forward)\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= h has only one neighbor (g) from which it got the message",
        "answer_feedback": "in  rfb, (a,d, drop) and subsequent flow will change accordingly. also (c, f, drop)  will occur. please consult the model solution.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0119q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporarily valid tsaps\n+ easy and quick\n- does not identify the unique packets inside a connection.\n\nfolie 23 / 10 transport layer",
        "answer_feedback": "only one method mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.33
    },
    {
        "id": "smp0087q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= c will forward to f because c has a shorter distance to f than d to f\nhop 2:\n(b, e, forward)\n(c, f, drop) <= e will forward to g because e has a shorter distance to g than f to g\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= h can not forward anywhere",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0414q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "according to slide 45 of the lecture \"internet protocol: ip addressing – interior and exterior gateway protocols\", following adresses are reserved:\nreserved for current network:0.0.0.0 - 0.255.255.255\nreserved for loopback adresses to the local host:127.0.0.0 - 127.255.255.255\nmoreover, the first and last adress of every network can't be used, because they are for network and broadcast: (1-126).0.0.0 and (1-126).255.255.255.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0226q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the infromation which source can be reached over which lan. during the backwards learning process the bridge creates table entries, when it recieved a frame. when it gets a frame from source x over lan y, a new entry will be created that x can be reacher over y. during the forwarding process the bridge deciedes based on the information table over which lan the frame should be routed (in case the source an the destination lan are the same, the packet can be dropped). if the table does not hold any information about the destination point, it will be flooded. since the bridge keeps track of which lan contains which station (mac address) it usually only has to forward a frame to the destination lan containing this station without having to send it to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0319q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter will be increased.",
        "answer_feedback": "the response is incorrect as it states that the diameter increases. instead, for collisions to be detected, the diameter decreases by a factor of 10.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0187q011",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem with \"distributed queue dual buses\" is the fairness problem. the question that comes up here is how it can be fair, that everybody gets the same access to the data, or respectively depending on the location does it makes a difference in terms of fairness.",
        "answer_feedback": "the response correctly answers the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0257q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees are appealing to broad- and multicasting scenarios, because they allow the packets to only travel one path (except travling backwards). this removes the need for looking up specific tables as in rpf / rpb.",
        "answer_feedback": "it is true that there is a unique path between nodes but that not only does away with the need to look at routing tables in rpf/rpb but reduces duplicates by removing loops(unnecessary links). no explanation was provided for modifying the link-state algorithm to construct a  multicast spanning tree for nodes.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25
    },
    {
        "id": "smp0104q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. tsap only valid for one connection; some tsap are well known\n2. identify each connection by seqno; endsystem must store this information\n3. identify each pdu by seqno; higher usage of bandwidth and memory",
        "answer_feedback": "few advantage and disadvantage are missing.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.67
    },
    {
        "id": "smp0039q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding should be used here. \nthere is no need for \"self-clocking\" when the users have perfect clocks.\nit utilizes the full bandwith.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0057q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first we note down some parameters: there is\na buffer size of n = 10,\nan arrival rate of λ = 9 packets per second,\na serve rate of μ = 10 packets per second,\na utilization of ρ = λ / μ = 0.9\n\nnow we can use n and ρ with the very last formula on slide 30 to calculate the probability p_n of the system being in a state where there are n packets waiting in the queue. we're interested in the sum of all probabilities except for the case n = 10, i.e. we can either calculate p_0 + p_1 + ... + p_9 or simply calculate 1 - p_10. finally we have to multiply the result by 60 seconds to find out to how many seconds of a minute this percentage corresponds to. so the system spends\n(1 - p_10) * 60 seconds = circa 56.951 seconds\nin a state in which there are less than 10 packets waiting in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0047q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "cdma\nin cdma, all the stations can transmit data simultaneously. it allows each station to transmit data over the entire frequency all the time. multiple simultaneous transmissions are separated by unique code sequence. each user is assigned with a unique code sequence. which means the rate of data is high.",
        "answer_feedback": "the question asks for the type of encoding to be used, not for access types.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0320q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the “collision domain diameter” is the distance two station can have and still detect a collision while sending. it depends on the minimum frame size, the speed of the signal through the medium and the bit rate of the network. if the bit rate increases while nothing else changes in csma/cd a frame is transmitted in less time than before. in this time the signal travels a shorter distance thus decreasing the “collision domain diameter”. if the speed of the network increases by a factor of 10 the “collision domain diameter” shrinks by a factor of 1/10",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0202q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. udp is connectionless and the tcp is connection oriented.\n2. udp does not control the errors, this means that if there was a with the order of the packets or one of them got lost, the udp won´t correct anything and will send it exactly the same to the application layer. instead, the tcp corrects all the errors and transmit the packets reliably.\n3. the udp needs few resources. the tcp instead has higher resource requirements for buffering, status information and timer usage.\n4. the udp transmission is fast because it is connectionless. the tcp instead needs to wait for the connection establishment and the disconnection to send any message.",
        "answer_feedback": "the response is incorrect as the question asked for the differences between headers, but the answer enumerates differences between tcp and udp protocol instead.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0385q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "to be able to take advantage of the piggybacking extension in the sliding window protocol, a full duplex communication channel with both parties actively sending messages is required. otherwise, the implicit acks cannot be added to outgoing data frames.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0256q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "all intermediate stations periodically have to send link state packets via broadcast to all others. the link state packets contain the distance to the neighbors and additional information about the multicast group.  each is then calculates a multicast tree on the locally available data and determines the lines on which packets must be sent.",
        "answer_feedback": "the response does not mention the spanning-tree property that makes it appealing for broadcast and multicast. the explanation for modifying the link-state algorithm to construct a  multicast spanning tree for nodes is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0026q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding due to the good utilization of the bandwidth",
        "answer_feedback": "the response does not provide the second reason behind using the binary encoding in the given scenario which is the lack of need of self-clocking making binary encoding a better option.",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.6
    },
    {
        "id": "smp0096q005",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forw.)(a, c, forw.)(a, d, forw.)\nhop 2:\n(b, e, forw.)(c, f, forw.)\nhop 3:\n(e, g, forw.)\nhop 4:\n(g, h, forw.)",
        "answer_feedback": "packets will be considered dropped if it is not forwarded further by the receiver node.(-0.75 for reasoning (a,d, drop), (c, f, drop) and (g, h, drop) ).",
        "verification_feedback": "partially correct",
        "max_score": 2.5,
        "normalized_score": 0.7
    },
    {
        "id": "smp0378q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "we need a duplex operation. this means that sender and receiver both sends and receives frames. then ack and data can be merged into one frame and sent together.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0316q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the maximal distance between stations reduces by a factor of 10.\n\nex. : 64 byte sent with 10 mb/s: max distance of 5.12 km\n        64 byte send with 100 mb/s: max distance of 112 km",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0228q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table contains information, which source addresses can be reached via which output line. \nwhenever a bridge receives a frame from one of its lans, it extracts the source address and updates its entry for this address with the corresponding lan and time stamp. \nafter some amount of time all entries, which have not been renewed are purged to prevent outdated information from being used. \n\nknowing via which output line to forward a frame, the bridge does not have to resort to flooding thus reducing the total network load. \n\nan advantage of transparent bridges is that the bridge is invisible to the network which simplifies other components.",
        "answer_feedback": "the response does not mention how a packet from source s received over lan l can be interpreted as \"destination s can be reached over l\" which forms the base for backward learning. also, a benefit of the transparent bridges in general is stated which was not required. apart from that, the response is correct.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0108q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "there are two separate problems that need to be considered here: duplicates within a single connection or duplicate connections. as duplicate packets within a connection are easily handled by seqeunce numbers and the focus of the lecture seemed to be on duplicate connection, i will focus on those.\n1. different port(tsap) for each connection: kind of defeats the purpose of ports as multiple ports would be bound to a single thread. also servers that communicate on a well known port cannot use this methode. solves the problem of duplicate connections without using additional bandwidth\n2. count prior connections: requires endsystems to keep track of this counter. low effort as this would only be required in the connection establishment stage\n3. count prior packets: requires a realtively high bandwidth and memory. could replace the already used sequence number within the protocol to avoid for example out-of-order packets",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0255q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding :  purpose:variation of the spanning tree,each sender has its own spanning tree,but is do not need to know the spanning trees algorithm:has this packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: -assumption: packet used the best route until now   action: resend over all edges (not including the incoming one) no: -assumption: packet did not use this route (it is not the best route)     action: discard packet (most likely duplicate)   reverse path broadcast: purpose:has packet arrived at the is entry port over which the packets for this station/source are usually also sent? yes: -packet used the best route until now -resend over all edges(not including the incoming one) no: discard packet did not use this route (it is not the best route)   algorithm: packet from s(ource) to d(estination) like reverse path forwarding with specific selection of the outgoing links has this packet arrived at the is entry over which the packets for this station/source s are usually also sent? yes: packet used the best route until now?      yes: select the edge at which the packets arrived and from which they                 are then rerouted to source s (in reversed direction)       no:  do not send over all edges (without the incoming one), i.e., not as              in reverse path forwarding (rpf) no: discard packet",
        "answer_feedback": "the response correctly explains  rpf and rpb but the stated purpose is incorrect. it should be to reduce the number of duplicates and unnecessary packets in flooding/broadcasting by inspecting the optimal unicast paths.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.8
    },
    {
        "id": "smp0114q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary valid tsaps\nfor each new connection, a new, unique, temporary valid tsap only for this connection is created and thrown away at disconnection and never used again.\nadvantage: simple and effective (transport process just can't be reached by delayed duplicates)\ndisadvantage: does not work if the service should be reached via a designated, known tsap.\n2. identify connections individually\neach connection is assigned a unique identifier and identifiers that have already been used are remembered by the end systems, so that when the connection is initiated it can be checked whether the identifier has already been assigned before (= duplicate).\nadvantage: designated tsaps possible (e.g. for well-known services).\ndisadvantage: storage requirements: end systems must permanently store the necessary information and have it available again, for example after a shutdown or crash.\n3. identify pdus individually\neach pdu is assigned an individual sequence number.advantage: fixed tsap possible, no persistent backup of information necessary.\ndisadvantage: more complex, lifetime of packet must be estimated well, because too small a value range for identifiers (sequence number) leads to duplicates not being recognized.",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0054q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "56.95 seconds.\nthis is m/m/1/n finite buffer case and n = 10. the question is asking about the time length that the system to be in a state in which there are less than 10 packets waiting in the queue, which also means that system is not full. therefore, we should calculate the probability that system is full first, which is pb = pn = p10. then, we can know the probability that less than 10 packets waiting in the queue which is 1-p10. in the case, we monitor exactly one minute after the system reaches equilibrium. with the probability (1-p10) we get, we would expect 56.95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0055q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "assuming 9 packets arrive each second and 10 are served. on average the buffer should never be full leading to a 60s time where there are less than 10 packets in the queue.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0410q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "class a:\n0.0.0.0. - 127.255.255.255",
        "answer_feedback": "not all addresses in class a are reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0214q013",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, because sometimes many users want to access the server at the same time, while at other times, only few request the server. for example a livestream of a football match: everybody sends requests to the server at kickoff, but only few do after the game (to watch the highlights). that means that the arrivals are not independent. they can depend on other events.",
        "answer_feedback": "while the response explains the event point of view, internet traffic is generally bursty, independently of specific events. this makes the packet arrival at a node depend on the previous arrivals.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.75
    },
    {
        "id": "smp0318q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "when the speed of a network is increased by a factor of ten, while letting everything else remain the same, the collision domain diameter reduces by the same factor. so, the diameter will decrease by a factor of 10 (that is, divide by 10)",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0420q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "according to rfc 6890 the following address blocks are reserved (https://datatracker.ietf.org/doc/html/rfc6890#section-2.2.2):\n127.0.0.0/8 with the range 127.0.0.0 - 127.255.255.255 loopback adresses\n100.64.0.0/10 with the range   100.64.0.0–100.127.255.255 if carrier-grade nat is used this is the shared address space between a service provider and its subscribers\n\n10.0.0.0/8  with the range 10.0.0.0 - 10.255.255.255 private network adresses\n\n0.0.0.0/8 with the range 0.0.0.0 - 0.255.255.255 host adresses at this network with 0.0.0.0 being this host\n\nadditionally these adresses are reserved:\nx.0.0.0 network adresses, where x is 0-127 (excluding 0.0.0.0 and 127.0.0.0 as reserved rfc addresses)\nx.255.255.255 broadcast adresses, where x is 0-127 (excluding 0.255.255.255 and 127.255.255.255 as reserved rfc addresses)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0050q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the users can use both manchester or differential manchester encoding. the reason behind as fol:\n1. both of them uses .5 bit per baus so channel capacity is reduced.\n2. less susceptible to noise due to interfearance.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0312q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter would be 10 times smaller which would have many collisions as a consequence, making it inadvisable to choose these dimensions.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0112q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "method 1: to use temporarily valid t saps\ngenerate unique (transport) service access point (tsap) for each communication and they are valid for one connection only\nadvantages:\n- you can always generate new tsaps\ndisadvantages:\n- some tsaps are standardized(\"well-known ports\") and cannot be used\nmethod2: to identify connections individually\neach connection is assigned a new sequence number and end systems story assigned sequence number and remember them\n\nadvantages:\n- duplicates from another connection with a sequence number does not interact with other connection with a different sequence number\ndisadvantages:\n- only works with connection-orinted service\n\nmethod 3: to identify pdus individually: individual sequential numbers for each pdu",
        "answer_feedback": "disadvantage of third method not mentioned.",
        "verification_feedback": "partially correct",
        "max_score": 1.5,
        "normalized_score": 0.83
    },
    {
        "id": "smp0422q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0\n127.0.0.0 to 127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0408q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "for each x ∈ {1,...,127} the network address x.0.0.0 and the broadcast address x.255.255.255 are reserved.\naccording to rfc 6890addresses 10.0.0.0-10.255.255.255 are reserved for private-use networks\naddresses 100.64.0.0-100.127.255.255 are reserved for shared address space\naddresses 127.0.0.0-127.255.255.255 are reserved for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0105q006",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporarily valid tsap \n+ easy to implement (just need a new tsap per connection that can be chosen during handshake)\n- cant use temporarily valid tsap because server uses \"well-known\" tsaps that cant change\n- only very limited tsap space \n\n2. identify connections individually\n+ multiple individual (distinguishable) connections are possible in parallel over the same tsap \n- endsystems must store the chosen sequence numbers for each connection for the duration of the whole connection\n- only for connection-oriented systems\n\n3. identify pdusindividually\n+ high flexibility, due to fine-grained detection of duplicates independent of a connection or tsap\n- high seqnr space needed (prerequisite: how big should the initial space even be? is the connection alive for years or just seconds?) -> higher usage of bandwidth and memory",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0423q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0419q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0–0.255.255.255\n127.0.0.0 - 127.255.255.255\n10.0.0.0–10.255.255.255 (reserved for private networks, not routed through the internet)\n100.64.0.0–100.127.255.25 (reserved for private networks, not routed through the internet)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0253q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path broadcast are used for broadcast routing (a sender send a message to all recievers(1:all communication)). the sender has its own spanning tree to calculate the routes. the receivers however do not. so they have to deciede how to handle the received packets. so they check if the received packet was received through the edge, which is usually used by packets from the sender. if this is not the case, the packet will be discarded. however if it is the case, in reverse path forwarding, the packet will be resend over all edges.  with broadcast routing on the other hand the receiver checks if the received packet used the best route until this point and only forwards it over those edges which belong to the best routes,",
        "answer_feedback": "the response correctly explains rpf and rpb. however, the response lacks the purpose which is to minimize the number of duplicate packets during broadcasting. in both algorithms, the packet is also not forwarded to the edge from which it was received.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.7
    },
    {
        "id": "smp0249q016",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are techniques used in routers. they enable loop-free forwarding of multicast packets in multicast routing. reverse path forwarding:  in this procedure, each node i checks whether an incoming packet from source q has been received on the connection on which node i also transmits its packets to q. if this is the case, then the packet is assumed to have been transmitted on the shortest route and it is forwarded on all other lines. if, on the other hand, a packet was received on a line other than the one on which data is transmitted to the sender, then it is assumed that it is a duplicate that did not take the shortest route. this duplicate is then discarded instead of being forwarded. reverse path broadcast:  rpb is an improvement on rpf. rpb not only evaluates the shortest path with respect to the interface where the multicast packets are received, but also influences the forwarding of data to the interface of the router. as a result, multicast packets are only forwarded to the interfaces where the next router is located in the reverse direction on the shortest path to the data source. rpb specifically checks whether the incoming packet arrives at the is through which the packets for this station/source are normally also sent.  if not, the packet is discarded directly. if yes, it will be further checked if the packet has taken the best path so far. if yes → select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction) if not → do not send over all edges (without the incoming one)",
        "answer_feedback": "the purpose of reverse path forwarding and reverse path broadcast is not limited to the multicast but also used in broadcast. the explanation of rpf and rpb is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0303q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the possible distance is reduced by factor 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0311q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is shortened by factor 10. assuming the collision domain diameter is 3000m at 10mb/s. if the speed is increased to 100mb/s, the collision domain diameter will be 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0178q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe first class offers no flow control or feedback if a frame arrived to its destination. the second class offers no flow control, but the sender resends the frame, if an error occured, which is noticable due to implicit acknowledments. the third class resends the frames, too, but detects additionally duplicates and offers flow control due to \"states\" of sender and receiver and 3-phased communication.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0045q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the encoding technique is binary encoding. \nall users have perfect clocks, so no need for \"self-clocking\". \nbinary encoding has good utilization.",
        "answer_feedback": "need to specify which utilization.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0219q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "-the table holds the next hop, i.e. the next lan (output line), for each station. is the station not known or the table is initialized flooding will be used.\n-\tbackward learning: bridge can learn about the other lans with every received frame from each lan it is connected to.\n-\tthe decision procedure is as follows: if the \n      o\tsource and destination lans are identical, the frame is dropped, if the\n      o\tsource and destination lans differ, the frame is rerouted to destination lan and if the\n      o\tdestination is unknown, flooding is applied.\n-\tbenefit: the network is transparent and adaptive.",
        "answer_feedback": "the response correctly states what information the bridge table contains and how the selective forwarding uses this information. in the backward learning process, the bridge learns about the mapping between outgoing lans and stations, not just about connected lans. the stated benefit is not related to the selective forwarding process.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.5
    },
    {
        "id": "smp0426q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "the host itself:\n0.0.0.0 (00000000.00000000.00000000.00000000)\n\na host at the same network:\n0.x.x.x (00000000.yyyyyyyy.yyyyyyyy.yyyyyyyy)\n\nbroaodcast on another network:\nx.255.255.255 (yyyyyyyy.11111111.11111111.11111111) for x in range [0,127]\n\nloopback:\n127.x.x.x",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0373q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "data and acknowledgements are send in both directions (sender to receiver and receiver to sender). the data and acknowledgements are bundled into one package.",
        "answer_feedback": "the response is correct as it implicitly answers the requirement of duplex communication.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0172q010",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "-unconfirmed connection less service\n-confirmed connection less service\n-connection-oriented service \n\nfor unconfirmed data is send by data request (data.req) and receiver gets the data stating an indication.\nthe data is send immediately on the contrary to the connection-oriented service. in unconfirmed conn. less service, you have to expect that \nthe sent packet arrives but you have no feedback acknowledge-signal (ack) whether the packet arrived. \n\nfor confirmed conn. less service, when data is send via data request and arrived (data indication), the receiver answers to the sender by an \nacknowledgement (ack) , so there is a feedback signal stating that data arrived successfully. \n\nso far (for unconfirmed and confirmed connection less service), data is send and acknowledged (for confirmed conn. less) immediately. \nthere is no difference for connection, data or disconnection phases. by using connection-oriented service, you have requests and indications for connection\nestablishment, data transfer and the disconnection. instead of just sending data, you send a request first for establishing a connection, then\nthere is an indication (=able to receive) on the receiver and the receiver sends a response back, after that the sender has a confirmation.\nthere is the same principle for the phases 'data transfer' and 'disconnection'. \nwith connection-oriented service the system is able to send more than 1 bit bidirectional\nbetween sender and receiver and vice versa.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "smp0407q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved for host\n0.0.0.0/8 - 0.255.255.255/8 \nreserved for loopback addresses/broadcast\n127.0.0.0/8 - 127.255.255.255/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0040q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "because it is given that all users have pefect clocks, we can use a simple and cheap binary encoding technique. it will also be a very efficient use of the given bandwidth.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "smp0309q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter will be increased to 10times compared with the distance in 10mb/s.",
        "answer_feedback": "the diameter is decreased by a factor of 10 instead of increased.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0260q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "a spanning tree has no loops, includes all routers (of the subnet) and has a root is (intermediate system). this is appealing for broad- and multicasting, because you only need to send the data to the root is. from there every node (or a specific set of nodes) can be reached. link state routing constructs a spanning tree. for multicast routing, the information, which systems belong to one group, must be provided. therefore the link state packets are expanded to contain the information on multicast groups. these are then propagated from a predefined root is to calculate the tree. a spanning tree has no loops. link state routing constructs a spanning tree, it needs to know which systems belong to a group.therefore the link state packets are expanded to contain the information on multicast groups. these are then propagated from a predefined root is to calculate the tree.",
        "answer_feedback": "the stated property may be correct for specific types of spanning trees but is not the general property of a spanning tree. not all spanning trees need to have a root node. the reason why a spanning tree is used in multicast and broadcast is the lack of loops, which reduces the number of duplicates needed. the modification description of the link-state algorithm is correct, except that it does not need to be propagated from the root node.",
        "verification_feedback": "partially correct",
        "max_score": 1.0,
        "normalized_score": 0.25
    }
]
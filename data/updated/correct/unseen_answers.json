[
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "I would recommend using non-persistent CSMA for the following reasons:\n1) The channel is expected to have a high load and non-persistent CSMA ensures a low number of collisions compared to other protocols and works thus better on high loads.\n2) More systems will be added to the LAN in the future so scalability is very important. Non-Persistent CSMA is perfect in this case, because it requires no changes no matter how many systems are added in the channel.\n\nOne Potential weakness of using non-persistent CSMA is that the throughtput will be low if only a few Systems are trying to use the channel. It can happen that multiple stations wait, even when the channel is idle.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "Non-persistent CSMA would be recommended in this case for 2 reasons. At first, CSMA avoid collision as much as possible by checking the channel before sending anything. Non-persistent CSMA provides the highest throughput in case the channel load is high. However, it has a potential weakness, the channel will be delayed longer than other MAC procedures. Other MAC procedures are not sufficient in terms of channel load and efficiency.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "The company should go with a standard CSMA/CD MAC procedure. The main reason for this is that it is possible to add stations easily to an existing network. Furthermore, it is a cost efficient MAC procedure which is a benefit due to the tight funding. A possible weakness is that the througput could be poor due to collisions due to high channel load.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "I would recommend the non-persistent CSMA.\nFirst, it has high efficiency and high throughput. From a rate of about 5 attempts per packet time, it beats most of the other systems in terms of throughput.\nSecond, the normalized throughput increases with increasing attempts per packet time. This enables and even supports expandability.\nA potential weakness is the throughput at low attempt rates. In these cases the non-persistent CSMA is inefficient.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "Based on the channel utilization slide of the lecture I would recommend the use of p-persistent CSMA (with a low value for p), because it has a high channel utilization that:\n(1) scales well for more systems sharing the channel\n(2) reduces the amount of collisions with the use of fixed time slots and medium sensing before sending (wait until medium is not busy)\n\nOne disadvantage is that it can not terminate the sending when a collision occurs, instead, it waits until a random time interval, senses the channel and retransmit the frame if the medium is not busy.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "I would recommend CSMA/CD.\nThe reason is that CSMA/CD checks the channel before and during sending frames.\nAlso if the sending station detects a collision it immediately interrupts the transmission, which saves time, bandwidth and avoids wasteful transmissions.\nAnd because of the collision detection, its efficiency is better than the \"simple\" CSMAs.\nFurthermore, the advantage in contrast to coordinated access like Token Ring is if more and more systems are added it takes more time until a station that wants to send gets the token.\n\nA weakness of CSMA/CD would be if more systems are added the performance decreases.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "Not sure what is meant with \"... expect the channel load to be high compared to the hardware they can provide.\"\n\nToken Ring: \n+ Good throughput even if the utilization is high and scalable for the future growth of the company.\n- It can come to some delays because of the waiting time for the token.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "For this use case I would recommend CSMA/CD as MAC. The reasons for this are 1. that due to the high channel load collisions are expected and terminating the sending after an detected collision minimizes the time the channel is clogged up compared to CSMA without collision detection or even ALOHA. 2. CSMA is easier scalable than contention free access MACs since there is no need to authorize a sender in any form before sending, every sender checks the channel on its own and can send data when the channel is free. A potential weakness could be, depending on the access mode used by CSMA. Since currently the channel load is high compared to the hardware capacities using the non-persistent access mode with its higher efficiency could further strain the hardware. Although this could change in future when the system is expanded.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "CSMA/CD is recommended because 1) it provides better throughput than other MAC procedures in overall, especially when the number of systems sharing the same channel is expected to increase further. This is important because the channel load is high due to the limited provided hardware. Secondly, 2)  CSMA / CD saves time and bandwidth due to interrupting the transmission when a collision is detected (which is highly probable ). A potential weakness of CSMA \\ CD's ability of collision detection depends on the maximum distance between the stations within the network. If the LAN network expands further there's a risk that CSMA / CD won't be possible anymore.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "I would recommend non-persistent CSMA. It does not need a precise timer which is great for a tight budget and it has a high efficiency at the cost of longer delays for single stations. It can be expanded pretty easily by just adding new stations.\nALOHA is not a good choice here, because of its low channel usage and CSMA/CD needs a reliable collision checking while 1-persistent CSMA has a low throughput at higher load and p-persistent CSMA needs a precise timer.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "A company is planning to set up a new LAN at one of their locations and is looking for an appropriate medium access procedure. However, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. Currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. Which of the MAC procedures introduced in the lecture (Polling, TDMA with or without Reservation, Token Ring, Pure or Slotted ALOHA, 1-persistent CSMA, p-persistent CSMA, non-persistent CSMA or CSMA/CD) would you recommend?Give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 P for a sensible choice out of: Token Ring, p-persistent or non-persistent CSMA, CSMA/CD or TDMA with reservation 1P for the drawback and 1P for an advantage.The following properties may be considered: Scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "CSMA/CD will be better.\nBecause it's random access procedures and can add new systems more easily than coorinated ones. Using a collision detection will save more time and bandwidth than ALOHA and other CSMA procedure.\nThe weakness is that the station in CSMA/CD procedure cannot send and receive frame at the same time, so  this procedure is only suitable for Half-duplex commnuication.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Because the network has a perfect clock, we don't need an encoding technique with the self-clocking feature.\nBecause the network is often congested we need a good utilization of the bandwidth (1 bit per Baud).",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "The network should use binary encoding:\n- Because of the perfect clocks there is no need for a self-clocking encoding\n- Binary encoding has better bandwith utilization than Manchester/differential Manchester encoding which is important because this network is often congested",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Recommended encoding technique: Binary Encoding (NRTZ).\nReasons:\n1. Of all the encoding techniques presented in the lecture, binary encoding offers the best use of bandwidth (1 bit per baud versus 0.5 bits per baud for (differential) Manchester encoding) for the scenario described (heavy link utilization).\n2. Since all participants have perfect clocks, there is no risk of clock drift/deviation.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary encoding.\n1.All users have perfect clocks, so good \"self-clocking\" feature is not necessary.\n2.It is mentioned that all users generate more traffic than the link\u2019s capacities. But the utilization of the bandwidth of Manchester Encoding or Differential Manchester Encoding is 0.5 bit/Baud, only half of the utilization of Binary encoding.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary Encoding as it is simple to implement and uses the bandwidth well. It's also easily doable as all parties have a perfect clock and therefore there is no problem receiving and differentiating multiple bits of the same type after another.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "In this scenario, the simple Binary Encoding technique should be used. That is, because it has the best utilization of the bandwidth among the presented techniques, which is important to use such a congested network as efficiently as possible. Furthermore, the downside of the technique not having a self-clocking feature is not a problem here since all users are interconnected and have perfect clocks.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary encoding should be used in this network because all three end systems have perfect clocks wherefore a self-clock feature isn't necessary. It also provides better utilization of the bandwidth than Manchester encoding or differential Manchester encoding.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "They should use \"Binary Encoding\" because of the perfekt timed clocks and furtermore this mechanism has the best transfer rate (1 bit per Baud).",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Bianry Encoding, since it has good utilization of bandwidth which could solve the traffic problem. On the other hand, the 3 users have already perfect clocks, the no \"self-clocking\" feature of binary coding could be neglected.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "I would use Binary Encoding. It is efficient since it uses 1 bit per baud. It has no self-clocking feature but that is not needed since all user have perfect clocks.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary encoding can be used. It has the highest bandwidth (1 bit per Baud) and is simple and cheap. The 'self-clocking' feature of the more complex manchester encoding and differential manchester encodings is not necessary since the users have perfect clocks.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "I would use the binary encoding in this network. The \"self-clocking\" feature of the Manchester Encoding isn't an advantage in this scenario since all users have perfect clocks. Therefore the perfect clocks can even out the Binary Encoding's disadvantage of not having a \"self-clocking\" feature and only the advantages of being cheap, simple and the good utilization of the bandwidth remain.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Because all users have a perfect clock, the binary encoding is best to be used. It is simple, cheap and the bandwith is with 1 bit/Baud well utilized. (The Manchester encodings in comparison have only 0.5 bit/Baud.)",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary Encoding als Non-return to zero-level (NRZ-L) w\u00e4re zu empfehlen, da es hierbei eine gute Ausnutzung der Bandbreite (1 Bit pro Baud) bereitgestellt werden kann. Des Weiteren erfordert diese Kodierung eine sehr akurate Zeitmessung der Teilnehmer, da kein self-clocking stattinden kann (bei einer Abfolge gleicher Werte ver\u00e4ndert sich die Kurve nicht), dies ist aber gegeben.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "I would suggest to use binary encoding, because they are all interconnected and have perfect clocks, that is why they do not need a self-clocking encoding and it is simple and cheap, so it has a good utilization of the bandwidth ( 1 bit per Baud), what helps against congestion.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary Encoding. Because the Binary Encoding uses the least bandwidth among these three techniques. And the local network with 3 users is tolerant of frequency errors happened in Binary Encoding.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Since we want to transmit with as high of a baud rate as possible we first look at binary encoding. For binary encoding we need perfectly synchronous clocks. Since all our users have perfect clocks, binary encoding is better, since the baud rate is twice as high.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "I would use binary encoding, since the premise is that all users have perfect clocks. This makes the \"self-clocking\" feature of the other two encoding methods not necessary. Binary encoding also makes good utilization of the bandwidth (1bit per baud) which is good, since the 3 users generate lots of traffic.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "In this local network with 3 users, the encoding technique Binary Encoding should be used.\nThis technique is simple, cheap, and has a good utilization of the bandwidth. The disadvantage of the no \"self-clocking\" feature is compensated through the fact that the users have perfect clocks.\nIn contrast, the Manchester and Differential Manchester Encoding have a worse utilization of the bandwidth  (0.5 bit/baud) than Binary Encoding (1 Bit/Baud) and the \"self-clocking\" feature is unnecessary in this case.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "A binary encoding would be most beneficial. Since all clients have perfect clocks, it doesn't need a self clocking feature as used by Manchester encoding and differential Manchester Encoding. It also can transmit a double of the data, effectively increasing the channels capacity",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Assume you have a local network with 3 users that are all interconnected and have perfect clocks. Typically the network is often congested as all users generate more traffic than the link\u2019s capacities. Which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? Give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "Binary Encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. Additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. Therefore, self-clocking / clock recovery is not as necessary. Simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "Binary encoding should be used. \nPerfeclty clocked users do not need any self-clocking encoding such as Manchester.\nMore traffic would benefit from more efficient encoding technique.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Consider a single server queueing system with a buffer of size 10. Let us assume that 9 packets arrive per second and 10 packets are served per second on an average. Assume you monitor the system for exactly one minute after the system reaches equilibrium. How many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? You need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "Since we have a buffer size (N) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. Therefore, we first calculate the probability of the system being full/having 10 packets in the queue. This is also called \u201cblocking probability\u201d or P_B.\nP_B = ((1 - utilization) * utilization^N) / 1 - utilization^(N+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nAlternatively to the blocking probability, it is also valid to directly calculate P(X less than 10) = (1 -P_B) by summing up the probabilities for 0, 1, \u2026, 9 packets to be in the queue. To calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with P(X less than 10) or the complement of P_B (0.25p) = 60 * (1-P_B) = 56.9512 seconds",
        "provided_answer": "We expect the system to be in a state with less than 10 packets in the queue for 56.94s during the measured interval of one minute. \nFirst we calculated the utilization: (9pkt/s)/(10pkt/s) = 0.9\nThen, we calculated the probability for the system to be in state 10, i.e. the probability that the system is full. p_10=((1-0.9)*0.9^10)/(1-0.9^11) = 0.051\nNext, we calculated the counter probability of p_10 as we actually want to know with which probability the system is not in state 10. 1-p_10 = 1-0.051 = 0.949\nTo get the number of seconds the system is not in state 10, we calculated 60s * 0.949 = 56.94s as we measure the system for 60 seconds.",
        "answer_feedback": "The response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider a single server queueing system with a buffer of size 10. Let us assume that 9 packets arrive per second and 10 packets are served per second on an average. Assume you monitor the system for exactly one minute after the system reaches equilibrium. How many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? You need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "Since we have a buffer size (N) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. Therefore, we first calculate the probability of the system being full/having 10 packets in the queue. This is also called \u201cblocking probability\u201d or P_B.\nP_B = ((1 - utilization) * utilization^N) / 1 - utilization^(N+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nAlternatively to the blocking probability, it is also valid to directly calculate P(X less than 10) = (1 -P_B) by summing up the probabilities for 0, 1, \u2026, 9 packets to be in the queue. To calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with P(X less than 10) or the complement of P_B (0.25p) = 60 * (1-P_B) = 56.9512 seconds",
        "provided_answer": "We need to calculate the probability that the system has 9 or less packets. To do that we calculate 1 \u2013 p_10.  p_10  is the blocking probability P_B which can be calculated using the formula on page 31 from the performance evaluation slides. \nWith a utilization of 9/10 we have a probability of around 1 \u2013 0.05 = 0.95.\nWhich means we expect the system to spend around 0.95 * 60s = 57s seconds in a state with less than 10 packets.",
        "answer_feedback": "The response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider a single server queueing system with a buffer of size 10. Let us assume that 9 packets arrive per second and 10 packets are served per second on an average. Assume you monitor the system for exactly one minute after the system reaches equilibrium. How many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? You need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "Since we have a buffer size (N) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. Therefore, we first calculate the probability of the system being full/having 10 packets in the queue. This is also called \u201cblocking probability\u201d or P_B.\nP_B = ((1 - utilization) * utilization^N) / 1 - utilization^(N+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nAlternatively to the blocking probability, it is also valid to directly calculate P(X less than 10) = (1 -P_B) by summing up the probabilities for 0, 1, \u2026, 9 packets to be in the queue. To calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with P(X less than 10) or the complement of P_B (0.25p) = 60 * (1-P_B) = 56.9512 seconds",
        "provided_answer": "We expect the system to be in a state where there are less than 10 packets in the queue roughly 57 seconds of the 1 minute we observe.\nFirst we need to calculate the mean load of the system (ro) as 9/10 as we can serve 10 packets while 9 arrive per sec.\nThen we can use the formulas from the lecture to compute with what percentage the system is in the state where 10 packets are waiting in the queue. \nThis is roughly 5% of the time, which means there are 10 packets waiting roughly 3 seconds of our observed minute.\nWhich means there are less than 10 packets waiting ~57 seconds of our minute.",
        "answer_feedback": "The response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider a single server queueing system with a buffer of size 10. Let us assume that 9 packets arrive per second and 10 packets are served per second on an average. Assume you monitor the system for exactly one minute after the system reaches equilibrium. How many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? You need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "Since we have a buffer size (N) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. Therefore, we first calculate the probability of the system being full/having 10 packets in the queue. This is also called \u201cblocking probability\u201d or P_B.\nP_B = ((1 - utilization) * utilization^N) / 1 - utilization^(N+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nAlternatively to the blocking probability, it is also valid to directly calculate P(X less than 10) = (1 -P_B) by summing up the probabilities for 0, 1, \u2026, 9 packets to be in the queue. To calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with P(X less than 10) or the complement of P_B (0.25p) = 60 * (1-P_B) = 56.9512 seconds",
        "provided_answer": "With a buffer of size 10, the probability of less than 10 packets in the queue is the probability that there is any other number of packets in the system than 10. With the utilization being 9 / 10, the probability for this case after reaching equilibrium is 1 - p(10) = 0,9492 (rounded).\nWhen monitoring the system for one minute (60 s), I would therefore expect the system to be in a state with less than 10 waiting packets for 0,9492 * 60 s = 56,952 s",
        "answer_feedback": "The response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "Yes. When low utilization makes it more likely that the corresponding path is used, the load on this path rises and a state might occur where the routing path starts oscillating. This will lead to inconsistency of the routing table of sender and receiver.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "During the transmission of the data, the most favorable path could change, causing the second part of the data to take a different path.\n\nIf the second part of the data arrives at the destination first, the receiver must wait for the second part and arrange the two parts correctly again.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "One problem can be that the selected path utilized so that it will have to take another path. This path will be longer and will need more traffic.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "it certainly could, firstly, evaluating currend load without taking path transfer capacity into consideration could lead to misjudges.\nSecondly, avoiding certain busy path could lead to more hops, for example, a packet may take the path A-B-D-E-C-F-I-J-H-G, the packet may have avoid a few busy pathway but the total routing time could be longer.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "Nein, denn dies f\u00fchrt zu Schwankungen, wenn es mehr als einen Pfad zwischen einem beliebigen Paar\u00a0 von Endsystemen im Netzwerk gibt. Das bedeutet, dass das Routing instabil ist und es gibt uneffiziente Paketumlagerungen.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following network topology from the lecture:With routing, we want to find the best path for our packets. For this, we first need to define a metric to evaluate the quality of a path. One possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. Assume that A wants to send data to G, could this routing strategy cause any problems at the receiver end? Please explain your answer in 1-2 sentences.",
        "reference_answer": "Yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: CF and EI). This can cause packet reorderings at the receiving side.",
        "provided_answer": "Yes, because the path load is then reduced for the chosen path and if \nthe receiver needs a certain path on which throughput is critical (e.g. G\n to F), it can not use it properly, because the load is higher at the time of receiving. For example F to G is on the path \nfrom A to G, then the load on F to G is reduced at the time of \nreceiving. If at the time of receiving the receiver G wants to send \ncritical data fast to F, it cannot use the path G to F properly and \nneeds maybe to elude to path G to H to F.",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following topology from the exercise. This time, node A wants to distribute a packet using Reverse Path Broadcast (RPB). Assume that every IS knows the best path to A and also whether they are the next hop of their neighbors on the unicast path to A.Please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. Use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. Please group these tuples according to the number of hops the packets have travelled so far. For dropped packets, please specify the reason why the packet has been dropped in a few words.Example for the notation:Hop 1:(C, A, forward)(C, B, drop) <= describe reason hereHop 2:(A, D, drop) <= describe reason here",
        "reference_answer": "Hop 1 :(A, B, forward),(A, C, forward), (A, D, drop) <= reason: remaining neighbors C and F do not use D as the next hop to get to A Hop 2 :(B, E, forward),(C, F, drop), <= reason: remaining neighbors D, E, G do not use F as the next hop to get to A Hop 3 :(E, G, forward)Hop 4 :(G, H, drop) <= reason: H is only connected to G, packet is not forwarded to incoming link",
        "provided_answer": "Hop 1:(A, B, forward)(A, C, forward)(A, D, drop) // C and F do both not send packets to A over D\u00a0Hop 2:(B, E, forward)(C, F, drop) // E and G do both not send packets to A over D\u00a0Hop 3:(E, G, forward)Hop 4:(G, H, drop) // no destination other than G is left for H",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following topology from the exercise. This time, node A wants to distribute a packet using Reverse Path Broadcast (RPB). Assume that every IS knows the best path to A and also whether they are the next hop of their neighbors on the unicast path to A.Please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. Use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. Please group these tuples according to the number of hops the packets have travelled so far. For dropped packets, please specify the reason why the packet has been dropped in a few words.Example for the notation:Hop 1:(C, A, forward)(C, B, drop) <= describe reason hereHop 2:(A, D, drop) <= describe reason here",
        "reference_answer": "Hop 1 :(A, B, forward),(A, C, forward), (A, D, drop) <= reason: remaining neighbors C and F do not use D as the next hop to get to A Hop 2 :(B, E, forward),(C, F, drop), <= reason: remaining neighbors D, E, G do not use F as the next hop to get to A Hop 3 :(E, G, forward)Hop 4 :(G, H, drop) <= reason: H is only connected to G, packet is not forwarded to incoming link",
        "provided_answer": "Hop 1:\n(A, B, forward)\n(A, C, forward)\n(A, D, drop) <= D can't forward packet further because costs would be higher than on other routes\nHop 2:\n(B, E,\u00a0forward)\n(C, F,\u00a0drop) <= F can't forward packet further because costs would be higher than on other routes\nHop 3:\n(E, G,\u00a0forward)\nHop 4:\n\n(G, H, drop) <= H can't forward packet further, no further nodes there",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following topology from the exercise. This time, node A wants to distribute a packet using Reverse Path Broadcast (RPB). Assume that every IS knows the best path to A and also whether they are the next hop of their neighbors on the unicast path to A.Please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. Use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. Please group these tuples according to the number of hops the packets have travelled so far. For dropped packets, please specify the reason why the packet has been dropped in a few words.Example for the notation:Hop 1:(C, A, forward)(C, B, drop) <= describe reason hereHop 2:(A, D, drop) <= describe reason here",
        "reference_answer": "Hop 1 :(A, B, forward),(A, C, forward), (A, D, drop) <= reason: remaining neighbors C and F do not use D as the next hop to get to A Hop 2 :(B, E, forward),(C, F, drop), <= reason: remaining neighbors D, E, G do not use F as the next hop to get to A Hop 3 :(E, G, forward)Hop 4 :(G, H, drop) <= reason: H is only connected to G, packet is not forwarded to incoming link",
        "provided_answer": "Hop 1:\n(A, B, forward)\n(A, C, forward)\n(A, D, drop) because A sends to D, but D doesn't forward anywhere else (neither to C or F, because those nodes are reached over other links)\n\nHop 2:\n(B, E, forward)\n(C, F, drop) because F won't forward the packet anywhere else (F / E / G, because those nodes are )\nHop 3:\n(E, G, forward)\n\nHop 4:\n(G, H, drop) because H is only connected to G and receives the packet from G, so it doesn't need to forward it anywhere else",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following topology from the exercise. This time, node A wants to distribute a packet using Reverse Path Broadcast (RPB). Assume that every IS knows the best path to A and also whether they are the next hop of their neighbors on the unicast path to A.Please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. Use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. Please group these tuples according to the number of hops the packets have travelled so far. For dropped packets, please specify the reason why the packet has been dropped in a few words.Example for the notation:Hop 1:(C, A, forward)(C, B, drop) <= describe reason hereHop 2:(A, D, drop) <= describe reason here",
        "reference_answer": "Hop 1 :(A, B, forward),(A, C, forward), (A, D, drop) <= reason: remaining neighbors C and F do not use D as the next hop to get to A Hop 2 :(B, E, forward),(C, F, drop), <= reason: remaining neighbors D, E, G do not use F as the next hop to get to A Hop 3 :(E, G, forward)Hop 4 :(G, H, drop) <= reason: H is only connected to G, packet is not forwarded to incoming link",
        "provided_answer": "Hop 1:\n(A, B, forward)\n(A, C, forward)\n(A, D, drop): Because D recognize that F and C won't receive packets via D.\n\n\nHop 2:\n(B, E, forward)\n(C, F, drop):\u00a0Because F recognize that E,D and G won't receive packets via F.\n\n\nHop 3:\n(E, G, forward)\n\n\nHop 4:\n(G, H, drop): There is only one possibility for\u00a0 H to receive the packet (via G ) and it can't be send it anywhere else.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Consider the following topology from the exercise. This time, node A wants to distribute a packet using Reverse Path Broadcast (RPB). Assume that every IS knows the best path to A and also whether they are the next hop of their neighbors on the unicast path to A.Please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. Use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. Please group these tuples according to the number of hops the packets have travelled so far. For dropped packets, please specify the reason why the packet has been dropped in a few words.Example for the notation:Hop 1:(C, A, forward)(C, B, drop) <= describe reason hereHop 2:(A, D, drop) <= describe reason here",
        "reference_answer": "Hop 1 :(A, B, forward),(A, C, forward), (A, D, drop) <= reason: remaining neighbors C and F do not use D as the next hop to get to A Hop 2 :(B, E, forward),(C, F, drop), <= reason: remaining neighbors D, E, G do not use F as the next hop to get to A Hop 3 :(E, G, forward)Hop 4 :(G, H, drop) <= reason: H is only connected to G, packet is not forwarded to incoming link",
        "provided_answer": "Hop 1:\n(A, B, forward)\n(A, C, forward)\n(A, D, drop) <= There is no edge over which it is the best route to send packets over D to A\n\nHop 2:\n(B, E, forward)\n(C, F, drop) <= There is no edge over which it is the best route to send packets over F to A\n\nHop 3:\n(E, G, foward)\n\nHop 4:\n(G, H, drop) <= H does not have any other neighbor to send the packet to",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. TSAPs\nAd: TSAPs only\u00a0 for one connection\u00a0\nDis: process server addressing method not possible\n\n2.identify connections individually\nAd:each individual connection has a new Seq\nDis: End system will be switched off\n\n3. identify PDUs individually\nAd: Seq never gets reset\nDis:higher usage of bandwidth and memory",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid TSAPs\nMethod: TSAP only valid for one conntection, generates always a new TSAP\nAdvantage: complete unique connection\nDisadvantage: too many connections will be generated in worst case, in general not always applicable\n\n\n2. to identify connections individually\nMethod: each individual connection is assigned a new SeqNo\nAdvantage: each connection relies on SeqNo and will be remembered from endsystems because of the assigned SeqNo\nDisadvantage: endsystem must be capable of storing this information\n\n\n3. to identify PDUs individually\nMethod: individual sequential numbers for each PDU,\u00a0SeqNo basically never gets reset\nAdvantage: packets have a \"lifetime\" within the network\nDisadvantage: higher usage of bandwith and memory",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1)Temporarily valid TSAPs\nAdvantage: Easy to implement\nDisadvantage: Doesn't work for Connections that use a static and known TSAP.(server addressing)\n\n\n2)Identifying the connections individually with SeqNo\nAdvantage: Each connection gets its own SeqNo making it unique and easily idnetifiable.\nDisadvantage: The End Systems has to remember already assigned SeqNo.\n\n\n\n3)Identifying the packets individually with SeqNo\nAdvantage: Makes it easy to identify duplicates, as each packet has its own SeqNo.\nDisadvantage: Requires a lot of bandwidth and memory.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. To identify each connection, i.e., Each connection is assigned\u00a0 an unique number and endsystems remember already those number.\u00a0\nPro: + not complicate\nCon: - endsystems need largememory capacity to save this information.\n\n2. To identify PDUs individually: Assign individual seq number for each PDU.\nPro: + higher usage of bandwidth and memory.\nCon: - hard to choose a suitable sequential number range because of different packet rate and the limited lifetime of a packet within the network.\n\n3. To use temporarily valid TSAPs\nPro: + high availiablity\nCon: - not always applicable , sometimes no possible to address method",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid TSAPs,\u00a0\u00a0TSAP valid for one connection only,but\u00a0process server addressing method not possible\n2.\u00a0to identify connections individually,\u00a0\u00a0each individual connection is assigned a new SeqNo and\u00a0endsystems remember already assigned SeqNo, but\u00a0endsystems must be capable of storing this information\n3. to identify PDUs individually,\u00a0individual sequential numbers for each PDU,\u00a0SeqNo basically never gets reset, but\u00a0higher usage of bandwidth and memory",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "Temporarily valid TSAPs\nIdentify connections individually\nIdentify PDUs individually\nPros\nTSAP valid for one connection only\neach individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo\nSeqNo never gets reset\nCons\nserver is reached via a designated/known TSAP\nendsystems must be capable of storing this information\nhigher usage of bandwidth and memory",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1) use a unique TSAP from the beginning till the end of the connection\n+ ensures there won't be problem with misinterpreting connections at the same port\n- requires large name size of TSAP\n- practically impossible, because there exist \"well-known\" TSAP that exist always\n\n2) define unique connection sequence number, with end systems also remembering previous sequence numbers\n+ by remembering the previous connections too, the end systems can differentiate all the incoming data\n- can't work easily for connectionless services\n- end systems need enough space for storing this information\n\n3) use sequence numbers for packets\n+ you don't need to get bothered for resetting the sequence numbers, because for example (also stated in the lecture), a 48 bit number will practically never reach to an end\n- however, the bandwidth and the memory you need to send a packet gets increased, because the sequence numbers never get reset and need a number with many digits (e.g. 48 bits)",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid TSAPs\nadv:simple\ndisadv:may cause some comflict with some \"well-known\" TSAPs\n\n2. to identify connections individually\nadv: reliable\ndisadv: end systems must be able to store SeqNos\n\n3. to identify PDUs individually: individual seq num for each PDU\nadv: higher usage of bandwidth and memory\ndisadv: higher cost",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. Use of temporarily valid TSAPs\n[\u2013] not applicable in most cases as TSAP must be known to address the correct process\n[+] in case of always changing TSAPs which are known to sender and receiver (i.e. through a known sequence) an attacker has a harder time tracing/interrupting the targeted traffic in case there are multiple senders/receivers\n2. Identify connections individually by assigning new SeqNo\n[\u2013] requires state / storing SeqNo (connection oriented system)\n[+] easy differentiation of connections\n3. Identify PDUs individually with SeqNo's\n[\u2013] a notion of a \"lifetime\" of a packet in the network is needed\n[\u2013] higher usage of bandwidth and memory\n[+] works with connectionless system",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid TSAPs.\n\u00a0pro: sure would solve the duplicate problem\n\u00a0contra: some servers should be reached through a known TSAP, which should not be discarded after single usage.\n2.to identify connections individually\npro: better than temporarily valid TSAPs, at least can be used to solve duplicate problem in a connection-oriented system.\ncontra: in a connection-less system it does not work.\n3.to identify packets individually\npro:solve the duplicate problem with dexterity, man can choose the sequence number range for individual case.\ncontra: the usage of bandwidth and memory will be higher due to the packet sequence number.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "Unique TSAP for each connection:\n\u00a0+ addresses duplicated across connections (e.g. after a crash)\u00a0- usually limited number of TSAPs\u00a0- some TSAPs are well known and therefore not usable (e.g. for HTTP)- doesn't address duplicates within the same connection\n\nSequence Number for each connection:\n\u00a0+ solves problems specific to unique TSAPs\u00a0- but also doesn't address duplicates within one connection\u00a0- endsystems need to store sequence numbers, even after switching off\n\nSequence Number for each PDU:\n\u00a0+ addresses duplicates between and within connections\u00a0+ only need info about last few used SeqNrs\u00a0- higher usage of bandwidth/memory\u00a0- have to choose a range for SeqNrs",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "Discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid TSAPs -method: -TSAP valid for one connection only -generate always new TSAPs -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via\u3000a designated/known TSAP - some TSAPs always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new SeqNo and -endsystems remember already assigned SeqNo -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify PDUs individually: individual sequential numbers for each PDU -method: -SeqNo basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1.\u00a0to use temporarily valid TSAPs\nAdvantages: TSAP valid for\u00a0one\u00a0connection only(always newly generated)\nDisadvantages: in general not always applicable:\u00a0\nprocess server addressing method not possible, because:\u00a0\n-\u00a0server is reached via a designated/known TSAP\n- some TSAPs\u00a0always exist as \u201cwell-known\u201d\n\n\n2.\u00a0to identify connections individually\nAdvantages:\u00a0\neach individual connection is assigned a new SeqNo and endsystems remember already assigned SeqNo\n\nDisadvantages:\u00a0endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed\n\n3.to identify PDUs individually:\nindividual sequential numbers for each PDU\n\nAdvantages: SeqNo basically never gets reset\nDisadvantage: higher usage of bandwidth and memory",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "question": "In the lecture you have learned about congestion control with TCP. Name the 2 phases of congestion control and explain how the Congestion Window (cwnd) and the Slow Start Threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences .",
        "reference_answer": "Slow start (cwnd less than ss_thresh): \nIn the slow start phase, cwnd is incremented by one every time a segment is acknowledged. This results in an exponential growth as cwnd is essentially doubled after each Round Trip Time (RTT). This is done until either a packet is lost or ss_thresh is reached. When cwnd >= ss_thresh, the congestion avoidance phase is entered. \nAfter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. Then cwnd is reset to 1. \n\nCongestion Avoidance (cwnd >= ss_thresh):: \nIn the congestion avoidance phase, cwnd is incremented more slowly. There are different incrementation strategies, but they usually grow linearly, e.g. only increment cwnd by 1 after all sent segments have been acknowledged. This is done until a packet is lost. Typically, this means that cwnd less than ss_thresh and the slow start phase is entered again. \nAfter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. Then cwnd is reset to 1.",
        "provided_answer": "The two phases are:\n1. slow start\n2. congestion avoidance\n\nAfter initialization (cwnd = 1, ss_thresh = advertised window size), during the slow start, cwnd is incremented by one each time a segment is acknowledged, so that cwnd grows quickly (cwnd = 1, 2, 4, 8; so in effect, it is doubled every round-trip time).\nIn case of packet loss (congestion) ss_thresh is reset to the half of cwnd, cwnd is then reset to 1 and the slow start phase is started from the beginning, otherwise cwnd is incremented as long as the condition cwnd less than ss_thresh holds.\nWhen ss_thresh is reached, the second phase (congestion avoidance) is entered and cwnd is now increased more slowly (linear versus exponential increase in the first phase: cwnd = 9, 10, 11...; it is increased by one every round-trip time) until a timeout (congestion) occurs.\nIn case of timeout (congestion), ss_thresh is reset to the half of cwnd, cwnd is then reset to 1 and the slow start phase is started again.",
        "answer_feedback": "The response is correct and complete as it provides the phases' names and changes in the value of the congestion window and threshold correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "In the lecture you have learned about congestion control with TCP. Name the 2 phases of congestion control and explain how the Congestion Window (cwnd) and the Slow Start Threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences .",
        "reference_answer": "Slow start (cwnd less than ss_thresh): \nIn the slow start phase, cwnd is incremented by one every time a segment is acknowledged. This results in an exponential growth as cwnd is essentially doubled after each Round Trip Time (RTT). This is done until either a packet is lost or ss_thresh is reached. When cwnd >= ss_thresh, the congestion avoidance phase is entered. \nAfter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. Then cwnd is reset to 1. \n\nCongestion Avoidance (cwnd >= ss_thresh):: \nIn the congestion avoidance phase, cwnd is incremented more slowly. There are different incrementation strategies, but they usually grow linearly, e.g. only increment cwnd by 1 after all sent segments have been acknowledged. This is done until a packet is lost. Typically, this means that cwnd less than ss_thresh and the slow start phase is entered again. \nAfter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. Then cwnd is reset to 1.",
        "provided_answer": "Two phases of congestion control: slow start and congestion avoidance \n\nCongestion Window (cwnd) and the Slow Start threshold (ss_thresh) changes in: \n- Slow start: cwnd starts with 1 and then after every successful ACK, 2 packets are sent instead of just one, so that cwnd increases exponentially with the power of two, as doubles after every round-trip time (RTT). When cwnd >= ss_thresh, congestion avoidance phase begins. Otherwise when a timeout (congestion) occurs during the slow start phase, cwnd is reset to 1 again (cwnd = 1) and the ss_thresh is set to half of the cwnd (ss_thresh = cwnd / 2). Then slow start repeats with the new ss_thresh value. \n- Congestion avoidance: cwnd is not doubled after every RTT anymore, but only incrementally increases until a timeout (congestion) taking place again. Congestion avoidance is terminated and it gets back to slow start phase with the ss_thresh = cwnd / 2 and cwnd is now reset to 1 again.",
        "answer_feedback": "The response is correct and complete as it provides the phases' names and changes in the value of the congestion window and threshold correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "In the lecture you have learned about congestion control with TCP. Name the 2 phases of congestion control and explain how the Congestion Window (cwnd) and the Slow Start Threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "Slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd Congestion Avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "1. Phase: Slow start\n2. Phase: Congestion Avoidance\nIn the first phase Congestion Window is doubled until there is a time out or the Slow Start Threshold is reached. \nIf there isn't any time out, the Congestion Window is incremeted by one.\nAfter a timeout the Congestion Window will be set to one and the ss_thresh willl be set to the half cwnd.\nThis process continues at the begining Congestion Window size of 1.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "In the lecture you have learned about congestion control with TCP. Name the 2 phases of congestion control and explain how the Congestion Window (cwnd) and the Slow Start Threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "Slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd Congestion Avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "The first phase, slow start, will double cwnd every round-trip time by increasing it by 1 for each received ACK. When cwnd reaches ss_thresh, the congestion avoidance phase is entered. The congestion avoidance phase will additively increase cwnd by 1 every round-trip time.If congestion is encountered in any of the phases, ss_thresh is set to half the value of cwnd, cwnd is set to 1 and the slow start phase is entered.",
        "answer_feedback": "Correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "By calculating using the binomial distribution probability formula, it can be concluded that the probability of event C occurring is 0.2765. \nThe probability of event A occurring is: P[event A]=P[you see exactly three H\u2019s]+P[you see four H\u2019s]+P[you see five H\u2019s]+P[you see six H\u2019s] =P(k=3)+P(k=4)+P(k=5)+P(k=6)= 0.2765+0.311+0.1866+0.0467=0.8208 (P is the binomial distribution)\nThe probability of event B occurring is 0.6*0.6*0.6*0.4*0.4*0.4=0.013824. \nTherefore the order is event B to event C to event A.",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "B -> C -> A \nA: 0.6^3 * 0.4^3 * 20 + 0.6^4 * 0.4^2 * 15+ 0.6^5 * 0.4 * 6 + 0.6^6 = 0.8208\nB: 0.6^3 * 0.4^3 = 0.013824\nC: 0.6^3 * 0.4^3 * 20 = 0.27648",
        "answer_feedback": "The response states the correct order of events with the calculation of all event probabilities.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Event B: 0.6^3 * 0.4^3 = 0.013824 = 1.3824%\nEvent C: P(X=3) = 20\u00d70,6 ^3\u00d7 (1-0,6)^3 = 0.27648 = 27.648%\nEvent A: P(X>= 3) = P(X=3) + P(X=4) + P(X=5) + P(X=6) = 0.8208 = 82.08 %",
        "answer_feedback": "The response does not explicitly state the events' order, but it contains the correct probabilities of all events, which is sufficient to identify the correct order.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "- Event B (lowest probability because there is only one sequence fulfilling this property)\n- Event C (superset of Event B and additionally containing all other sequences containing three H's)\n- Event A (superset of Event C and additionally containing all sequences with four H's, five H's and six H's)",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Order: Event B, Event C, Event A\n\nReason: Actually , Event B is a subset of C, and C is a subset of A, so the order must be  B -> C -> A.\n              P(Event B) =  0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 216/15625 = 0.013824\n              due to the equation of the binomial distribution\n              P(Event C) = 864/3125 = 0.27648\n              P(Event A) = 5213/625 = 0.8208",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Event A ist the most probable event, because there are many sequences that accomplish it. So all the probabilities of these sequences can be added to calculate the probability of Event A.\nEvent C iss less proabable than A, because there are less sequences to accomplish ist than there are to accomplish A. For example A sequence with 4 H's would fulfill A but not C. But all of the sequences that fulfill C also would fulfill A. So C has the same probabilities that are beeing added to calculate the probability of A, but A has additional probabilities.\nEvent B ist the least probable, because the only sequence that fulfills it, is HHHTTT. And since this sequence also fulfills A and C, the probability of the occurrence of this sequence is just one of the probabilities that are been added to calculate the probability of A and C.",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Event B = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 * 0.4 = 0.013824\nEvent C = P(k = 3) = 6 \u00fcber 3 * (0.6)^3 * 0.4^3 = 0.27648\nEvent A = P(k >= 3) = 6 \u00fcber 3 * (0.6)^3 * 0.4^3 + 6 \u00fcber 4 * (0.6)^4 * 0.4^2 + 6 \u00fcber 5 * (0.6)^5 * 0.4^1 + 6 \u00fcber 6 * (0.6)^6 = 0.8208\n\nFrom least to most probable = B,C,A",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Event B as it is 0.6^3*0.04^3 ~ 0.0138\nEvent C as it is 6 over 3 * 0.6^3 * 0.4^3 ~0.276\nEvent A as it is 6 over 3 * 0.6^3 * 0.4^3 + 6 over 4 * 0.6^4 * 0.4^2 + 6 over 5 * 0.6^5 * 0.4^1 + 6 over 6 * 0.6^6 * 0.4^0 ~ 0.82\nB is a specific sequence and c is different permutations of the same amout of hits so it B + the other combinations, A is all combinations to get 3 plus all the ones to get 4 5 and 6.",
        "answer_feedback": "The response correctly answers the order of the events and justifying it with probability calculations.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "B:\nP(HHHTTT) = 0,6^3 * 0,4^3 = 0,013824\n\nC:\nP(X = 3) = (6 \u00fcber 3) * (0,6)^3 * (0,4)^3 = 20 * (27/125) * (8/125) = 0,27648\n\nA: (most likely)\nP(X >=  3) = 1 - P (X less than equal to 2) = 1- P(X = 0) + P(X = 1) + P(X = 2)\n= 1 \n- ((6 \u00fcber 0) * (0,6)^0 * (0,4)^6\n+ (6 \u00fcber 1) * (0,6)^1 * (0,4)^5\n+ (6 \u00fcber 2) * (0,6)^2 * (0,4)^4\n= 1- (0,004096 + 0,03686 + 0,13824) =0,8208",
        "answer_feedback": "The response does not explicitly state the order of the events, but it contains the correct calculation of all events probabilities, which is sufficient to identify the correct order.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "B -> least likely \nC -> in between\nA -> most likely\n\nAll three Events have the same minimum amount of H's in their sequence which indicates that the probability order is based on the number of permutation. \nB has least likelihood because it has the least amount of possible permutations (exactly one).\nA has the most amount of permutation because it also allows permutations with more than 3 H's. So the permutations of C are a proper subset of the permutations of Event A. \nIn this case the probability of H is larger than 0.5 so that is even more likely that there are permutations with more than three H's. But it would also hold true if this was not the case.",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Let us assume that you flip a coin 6 times where the probability of heads (H) showing up is 0.6. Please arrange the following events in the increasing order of their likelihood (i.e., least probable \u2192 most probable): \u25cf Event A: you see at least three H\u2019s \u25cf Event B: you see the sequence HHHTTT \u25cf Event C: you see exactly three H\u2019s Include justification in your answer headers.",
        "reference_answer": "The correct sequence is BCA , where B is the least probable. One of the following justifications should be given:\n\t\t\u25cf Event B is a subset/part/special case of C, and C is a subset/part/special case of A\n\t\t\u25cf Event B is more specific/strict than C and C is more specific/strict than A\n\t\t\u25cf An actual, correct calculation of the probabilities:\n\t\t\u25cb P(B) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t\u25cb P(C) = (6 choose 3) * P(B) = 0.27648 \n\t\t\u25cb P(A) = P(C) + P(Y=4) + P(Y=5) + P(Y=6) = 1 - P(Y=0) - P(Y=1) - P(Y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t\u25cb The answer may be rounded to up to 2 decimal places, e.g. P(B) = 0.01 or\n\t\tP(B) = 0.014\n\t\t\u25cb It is also sufficient to give a formula without the actual calculation, if it is apparent that P(B) less than P(C) less than P(A), e.g. by stating P(C) = 20 * P(B)",
        "provided_answer": "Order: B-C-A\nThe probability of having HHHTTT is the lowest because its the most specific outcome. Only one possible path. \nThe probability of seeing exactly three H\u2019s is the second lowest. It includes the probability of HHHTTT and all other possible orders to achieve exactly three H\u2019s. \nHaving at least three H\u2019s is the most probable outcome of those three. It includes the probability of B and C plus all outcomes with more than three H\u2019s.",
        "answer_feedback": "The response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- Unconfirmed Connectionless Service \nThe Unconfirmed Connectionless Service sends data to the receiver, without announcing it (building up a connection) first in data frames without any flow control. Because of the missing connection and flow control, it is possible that complete data frames can get lost.  \n- Confirmed Connectionless Service \nWheras the confirmed connectionless service sends the data frames and waits for an acknowledgement of the corresponding recipient. If the recipient confirms the data frame, the next data frame is being sent. If the recipient doesn\u2019t answer for a long time, the data frame is being resent. If for some reason, the ackknowledgement gets lost, the recipient will eventually get a data frame twice, and will not be able to detect the duplication. The correction has to be made on a higher level. It is much slower than the unconfirmed, because of waittime for timeouts and ackknowledgement messages. \n- Connection Oriented Service \nIn the connection oriented service, the overhead is a lot higher, but the advantages are a detailed flow control, in which the recipient can detect duplicates, ask for a certain frame and can align the frames in the right order. And if the recipient reads slower than the sender transmit, it is possible to make a transmission. The participants first exchange a handshake and afterwards are transferring data. Afterwards the connection is disconnected.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "\"Uncomfirmed Conn.less Service\", \"Confirmed Conn.less Service\", \"Connection-Oriented Service\"\n\"Uncomfirmed Conn.less Service\":\nData is just send, without any feedback, that it is received. Both partys assume that no bit is missing. There is no Flow Control or a connect and disconnect feature. This way of sending data is only used on L1 communication channels with very low error rate.\n\n\"Confirmed Conn.less Service\":\nEverytime data is send, the receiver sends an ACK flag, that he received it. If he doesnt send an ACK flag in a given time frame, the transmission times out and the data is retransmitted. There also is no Flow control or a connect and disconnect feature, duplicates and sequence errors can happen because of a retransmission. This service is used on L1 communication channels with high error rate.\n\n\"Connection-Oriented Service\":\n3-phased communication: 1. Connection(initializing the counters/variables of the sender and receiver) 2. Data Transfer 3. Disconnect. The data sent in setp two of this class is bidirectional, sequentiell and acknowledged, which means no data loss, no duplicates and no errors.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1. Unconfirmed Connectionless Service \n2. Confirmed Connectionless Service\n3. Connection-Oriented Service \n\nIn the 1. service, transmission of the data happens isolated and independent. A loss of data is possible. \nWith service 2. if the receiver do not answer, the data is retransmit after a certain time, so there are no loss. In both is no connection or disconnection. \nIn the 3. service, first a connection is initialized, data is transfered and then the connection is abort.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Data Link Layer service classes:\n- Unconfirmed Connectionless Service\n- Confirmed Connectionless Service \n- Connection-oriented Service\n\nIn Unconfirmed Connectionless and Confirmed Connectionless services there is no established connection between the sender and the receiver, while in Connection-oriented service, the data is only transferred when a connection is established between the sender and the receiver. In Connection-oriented there is also a disconnect phase.\n\nIn Unconfirmed Connectionless service when the sender sends a frame, it hopes the frame reachs the receiver without a problem. The sender does not receive any confirmation, from the receiver, that the frame was received. This is not what happens in Confirmed Connectionless and Connection-oriented services. When a message is received on the receiver side, the receiver sends a confirmation message to the sender. So, in this two services the sender has the confirmation that the message reached the receiver.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed Connectionless Service: You send data without a steady connection and without any feedback if the data arrived and if it arrived correctly.\n\nConfirmed Connectionless Service: You do not use a steady connection between sender and receiver, but you get a feedback whenever data is received.\n\nConnection-Oriented Service: You use a steady connection between sender and receiver. Each transmission process consists of 3 phases, at first you establish a connection then you send the data and at the end you disconnect.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.Unconfirmed Conn.less Service\n2.Confirmed Conn.less Service\n3.Connection-Oriented Service\n\nDifferences: \n1.Unconfirmed Conn.less Service and Confirmed Conn.less Service have no flow control. But Connection-Oriented Service has no flow control.\n2.confirmed Conn.less Service and Confirmed Conn.less Service have no connect or disconnect. But Connection-Oriented Service has connect or disconnect.\n3. Connection-Oriented Service has no loss, no duplication, no sequencing error. But Confirmed Conn.less Service has loss, duplication,sequencing. And Unconfirmed Conn.less Service has more errors than Confirmed Conn.less Service.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed connectionless service (UCS), confirmed connectionless service (CCS) and connection-oriented service (COS). UCS doesn\u2019t have correction mechanism and flow control. The data probably gets lost. CCS reply ACK when receiving the correct data and it has timeout-and-retransmit mechanism. It is more reliable than CCS but probably incurs some sequence errors. COS has connection and disconnection mechanism. It can achieve flow control, no loss and no sequencing error.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.Unconfirmed Conn.less Service \n Features\n   No flow control\n   No connect or disconnect \n 2.Confirmed Conn.less Service\n Features\n   No flow control\n   No connect or disconnect\n   Duplicates and sequence errors may happen due to \u201cretransmit\u201d\n 3.Connection-Oriented Service\nConnection over error free channel\n  No loss, no duplication, no sequencing error\n   Flow control\n3-phased communication\nThey are different in features.",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The three classes:\n\nUnconfirmed Connectionless Service\n-Transmits isolated independent units\n-Data units may be lost\n-No flow control\n-No connecting or disconnecting\n\nConfirmed Connectionless Service\n-Transmits independent data units \n-Receiver acknowledges the reception of each single frame\n-Timeout + Retransmission if sender does not receive acknowledgment within a certain amount of time \n-Thereby no loss of data, but duplicates and sequence errors may occur\n-No flow control\n-No connecting or disconnecting  \n\nConnection-Orientated Service \n-Transmits data over error free channel (through acknowledgments)\n-No loss of data, no duplications, no sequencing errors\n-Flow control\n-3-phased communication: connect, data transfer, disconnect",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed Connectionless Service: no flow control\nConfirmed Connectionless Service: no flow control, duplication and sequencing error may happen\nConnection-Oriented Service: flow control, no loss, no duplication, no sequencing error",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Here are the 3 service classes the data link layer offers: \n\n1) Unconfirmed connectionLess Service: there is no \"connect and disconnect\" between sender and receiver. There is no flow control or error management\n\n2) Confirmed connectionLess Service: There is no \"connect and disconnect\", there is no flow control but there is an acknowledgment for each frame sent. \n\n3) Connection oriented Service: there is a flow control and a \"connect and disconnect\" protocol between the sender and the receiver",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "Unconfirmed Connectionless Service:\n-sends data without establish a connection\n-if data units get lost, didn\u2019t get any feedback\n-no flow control and no disconnect \n\nConfirmed Connectionless Service:\n-if data units get received, the receiver send an acknowledgement, so no loss\n-if sender does not receive an ack within a certain time, then retransmit, it can lead to duplicates and sequence errors\n-no flow controls\n-didn\u2019t establish a connection or disconnection with the receiver\n\nConnection-Oriented Service:\n-3-phased Communication: 1. Establish a connection, 2. Transfer data, 3. Disconnect\n-Flow control, no loss of data units, no duplication and no sequencing error",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The three classes: \nUnconfirmed Connectionless Service\nConfirmed Connectionless Service\nConnection Oriented Service\n\nIn Unconfirmed Connectionless no confirmation of data transmitted is received, loss of data units is possible and also no flow control is present.\nIn Confirmed Connectionless  acknowledgement of data transmitted is received, no loss of data units because of retransfer and timeout mechanisms and also no flow control is present.\nIn Connection Oriented data is transferred over an error free channel, no loss of data units possible and flow control is also present,",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "The 3 service classes are: Unconfirmed connectionless service (1), Confirmed connectionless service (2) and Connection-oriented service (3). The main difference between this services is the handling of the loss. While in (1) data packets are only send to the receiver, packets can get lost and loss is not being corrected. In service (2) data packets has to be acknowledged by the receiver and packets will be resend after a certain timeout. This leads to inefficient communication and can be done on a higher level. Service (3) consists of 3 phases (Connection establishment, data transfer, Disconnect). Just like in service (2) we have no loss, but Flow Control is possible in contrast to services (2) and (1).",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Name the 3 service classes the Data Link Layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ACK, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ACK, no loss of data (timeout and retransmit instead\u2192 duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. Instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "(1) \u201cUnconfirmed Connectionless Service\u201d: Transmission of isolated, independent units (loss of data units possible)\nis a good choice on communication medium with very low error rate\n\n(2) \u201cConfirmed Connectionless Service\u201d: Receipt of data units get acknowledged by receiver, therefore no loss, but duplicates and sequence errors may happen due to retransmit if no acknowledgement within a certain time.\nis a good choice on communication medium with high error rate e.g. wireless communication\n\n(3) \"Connection-Oriented Service\u201d: This service has flow control. Consists of 3-phases of communication, with Connection Initialization, Data Transfer and Disconnection. \nis a good choice if bi-directional communication is needed\nand is a good choice for an error free communication medium (therefore no loss, no duplication, no sequencing error)",
        "answer_feedback": "The response answers the services' names and differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem with DQDB is that if we have several participants in the network and they want to exchange data, the distance between them and the propagation delay causes a fairness issue. This is because when stations are closer together, they can communicate over the bus faster than stations further away, this would still be acceptable for normal data packets, but network control packets are also sent over the bus and so network changes can spread much slower than in other architectures.",
        "answer_feedback": "The response correctly states the fairness issue in DQDB and also provides an appropriate reason for it.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem with DQDB is that there is a difference in fairness depending on the location, as not everyone has the same access to data.",
        "answer_feedback": "The response correctly identifies the fairness issue in DQDB which is due to the location of station.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem with the \u201cDistributed Queue Dual Buses\u201d is that it does not ensure fairness. The location of the node has an influence on its likelihood of gaining access to the data or acquiring the right to send, which results in an inequality between the nodes.\n\nAt the beginning of a bus all frames generated by the frame generator are empty. So the first node can reserve however many frames it wants. At the end of the bus it can happen that all frames are already reserved so the last nodes may not be able to send anything.",
        "answer_feedback": "The response is correct as it correctly explains the fairness problem with Distributed Queue Dual Buses.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The Distributed Queue Dual Bus (DQDB) architecture uses two unidirectional buses for sending and receiving data. The main challenge here ist to guarentee fairness between all participating nodes as different nodes may have advantages (if at the beginning of the bus) or disadvantages (if at the end of the bus) in write access depending on their position in the bus.",
        "answer_feedback": "The response correctly states and explains the fairness problem of reserving transmission right in DQDB.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "Depending on the stations location in the network, they might be able to more easily reserve bandwidth on the BUS for sending data. Stations which are farther back will have less opportunities for reserving a BUS than stations at the front.\nThis can be fixed by introducing some formulas describing how often each station can reserve a BUS.",
        "answer_feedback": "The response is correct as it correctly states the issue with Distributed Queue Dual Buses.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem that was discussed in the lecture is fairness. The nodes reserve slots on one bus and send on the other bus. One node might reserve a lot of the available slots which makes it hard for the following nodes to reserve the space they need.",
        "answer_feedback": "The response correctly identifies the problem associated with Distributed Queue Dual Buses based on the station location.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "Distributed Queue Dual Buses have a fairness problem, meaning that dependent on the position of the node it will be advantaged or disadvantaged for certain comunications, as each bus only works in one direction and frames have to be requested.",
        "answer_feedback": "The response correctly states the problem in DQDB and gives an appropriate reason for it.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "The problem with DQDB Architecture is that the waiting time for a node to be allowed to send is heavily dependant on its location in the queue.If you are location on any far end of a bus (extrem right  or extrem left) then you will have to wait the most before you can send, if you want to send in the opposite direction.",
        "answer_feedback": "The response correctly explains the fairness problem with Distributed Queue Dual Buses.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Please explain the problem with \"Distributed Queue Dual Buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "Depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "Distributed Queue Dual Buses = 2 buses (transfer data in opposing directions), every node connected to both buses\n\nDistributed Queue Dual Buses is an architecture whereby every node is connected to 2 buses (write and read access). These buses are responsible for data transmission in opposing directions. The problem is because of transmission of data:\n\nBoth buses are connected to a frame generator which generate a fixed size frame every 125 milliseconds. Depending on the position of the nodes in the bus they can reserve the bus for sending data with a higher probability. E.g. for a node in the middle we have a probability of 50% to successfully reserve a bus. As a consequence, fairness is a problem due to the bus topology: Depending on the position of the node the node may be more or less successful in reserving a bus for data transmission.",
        "answer_feedback": "The response correctly explains the fairness problem of reserving transmission rights in DQDB.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "The UDP header is a short header (only contains Receiver Port, Packet Length and optional Sender Port, Checksum). \nThe header of the TCP is more complicated. Additionally to Sender Port, Receiver Port and Checksum, it has a sequence number (to identify the segment or the starting sequence number). It also has an acknowledgement number (which is needed i.a. for the connection setup). In the TCP header you can also set flags (like FIN for the disconnection). You can also add further information in the options field.",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers. Also, note that the ACK field is not just limited to connection setup.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "Some additional features which are present in the TCP header are: sequence number, acknowledgement number, options, urgent pointer and flags (the TCP header contains possible additional information and has protocol specific services). The UDP header has a size of 8 bytes, while the size of the TCP header is at least 20 bytes.",
        "answer_feedback": "The response correctly states four differences between TCP and UDP headers.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "The UDP header includes the packet length (header + data) whereas the TCP header only includes the header length. The TCP header includes an acknowledgement number, advertised window and a sequence number which you do not find in the UDP header. The acknowledgement number states the sender which packets have arrived yet. The advertised window field gives the sender a feedback about how many more bytes the receiver will accept using the sliding window protocol. And the sequence number is necessary to be able to compute the packets in order.",
        "answer_feedback": "All the stated differences between a TCP header and a UDP header are correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "UDP: sender and receiver port, packet length, checksum, data\nTCP Headers are much longer than UDP Headers. There are some fields in the TCP header, which an UDP header doesn't contain:\n- Sequence Number\n- Acknowledge Number\n- Flags\n- Advertised window size\n- Options",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "UDP-headers include:\n- source port\n- destination port\n- packet length\n- (optional to use) checksum\nEach of the fields is 16 Bit long (in sum 8 Bytes). UDP does not need much header-informations, since its a fast, connectionless protocol.\n\nTCP-headers also include a checksum, source and destination port, but also much more information, like:\n- a sequence number\n- an acknowledgement number\n- different control flags\n- the data offset\n- the window size\n- an urgent pointer\nThe much larger (min. 20 Byte) header is needed since TCP is a connection-oriented protocol, which sets more on reliability than speed.",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "UDP: Header consists of three mandatory and one optional header.\nSource-port, destination-port, packet length are mandatory, checksum is optional and just calculated for the header\n\nTCP: The checksum is calculated over header and user data, to ensure correct transmission.\nTo ensure reliablity, the TCP-Header has additionally fields for a sequence number, the acknowledgement number and certain flags to reduce/avoid congestion and enable flow control.\n\nThe TCP header is more complex but ensures reliable transmission at the cost of speed and use of bandwidth.\nThe UDP header just contains necessary information, is very fast but unreliable.",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "UDP headers do not include the followings: 1. sequence number 2. acknowledgement number 3. HL/RESV/Flags 4. advertised window 5. urgent pointer",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers. However, the terms HL and Resv should be properly named.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "In TCP there is a Sequence Number field to identify packets individually for reliability. There is no Sequence Number in UDP. The UDP header does not have an options field, while the TCP header does. In TCP there is an Advertised Window field for the Sliding Window Protocol for Flow Control. There is no Flow Control and therefore no Advertised Window field in UDP. In TCP there there is only a Data Offset field that specifies the header length. In UDP the whole Packet Length is transmitted.",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "State at least 4 of the differences shown in the lecture between the UDP and TCP headers.",
        "reference_answer": "Possible Differences :\nThe UPD header (8 bytes) is much shorter than the TCP header (20-60 bytes)\nThe UDP header has a fixed length while the TCP header has a variable length\nFields contained in the TCP header and not the UDP header :\n-Sequence number\n-Acknowledgment number\n-Reserved\n-Flags/Control bits\n-Advertised window\n-Urgent Pointer\n-Options + Padding if the options are\nUDP includes the packet length (data + header) while TCP has the header length/data offset (just header) field instead\nThe sender port field is optional in UDP, while the source port in TCP is necessary to establish the connection",
        "provided_answer": "TCP-Header has the following information in his header that UDP not have: \nSequence Number (to identify the lost segments and maintain the sequencing in transmission), \nAcknowledgment Number (to send a verification of received segments and to ask for the next seg-ments), \nUrgent (Used to point any urgent data in segment), Flags, Window size (Used to set the number of segments that can be sent before waiting for a confirmation from the destination), Options",
        "answer_feedback": "The response correctly identifies four differences between TCP and UDP headers. However, there is a slight correction of Urgent Pointer instead of Urgent.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption does not hold in real internet traffic. In case of a video streaming service for example the packages are send in big burst. So the arrival of the first package does indicate the arrival of more packages and the more packages are received in a short time the more likely it gets that no more package will arrive for some time because the buffer for the video stream is full and the streaming service stops sending.",
        "answer_feedback": "The response is correct as it associates the probability of a packet arrival happening at a node with previous arrivals at the node. The extent of the probability of receiving a packet after receiving several packets depends on many factors and may differ from client to client.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption does not hold true for the internet as when someone uses the internet he will continue using it for a certain time and not just have a single request and then nothing for a while. Also a lot of traffic is in a burst like nature so some requests until a certain buffer is filled and then again when it is somewhat deplenished. So in general the previous state or states can hold information for future states.",
        "answer_feedback": "The response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, since the real internet traffic is complicated and there are dynamic behaviors of real-world service. For example, real internet TCP traffic has high burstiness and exhibits long range dependence properties at large time-scales. The arrivals for each interval are not independent and there are dependence and correlation of the traffic arrival process in the internet. Meanwhile, the real internet traffic has self-similar characteristics, thus, this assumption cannot hold for real internet traffic.",
        "answer_feedback": "The response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node. Take note that the burstiness is more a general nature of internet traffic, not just limited to TCP traffic.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No this assumption does not hold for real internet traffic. Internet traffic is often very bursty, e.g. if we load a website we need to load a lot of resources at once, while we won't load nearly as much if we just look at the website. This means the probability that traffic arrives, if traffic arrived in the previous interval is greater than if there was no traffic in the previous interval.",
        "answer_feedback": "The response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, this assumption of the arrivals being \u201cmemoryless\u201d does not hold for real internet traffic. \nIf \u0394t = 1ms, for example, that means every of these time intervals has to be considered independent from each other. So in each of these intervals it is a \u201ccoin flip\u201d whether data is sent or not. \nObviously this is not true for real internet traffic because while streaming a movie or playing an online game, for example, the arrivals are connected and dependent on each other.",
        "answer_feedback": "The response is correct as it correctly associates the probability of an arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "No, this assumption will most likely not hold true for real internet traffic. This has multiple reasons:\n\nPackets on the internet are grouped into frames for sending, making lone packets being sent separately rather unlikely.  \nThe nature of data transfer on the internet also makes lone packets very unlikely. When making a request for data through the internet (for example loading a web page), the response includes a lot of data (markup, text, images) which are all sent in a short amount of time, and after the page has been loaded the user will most likely spend some time browsing the page before making another request.  \nTherefore we cannot treat arriving packets as independent from one another, because there is a very high chance that an arriving packet is related to the previous packet.",
        "answer_feedback": "The response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "To model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval \u0394t are independent. Does this assumption hold for real INTERNET traffic? Explain your answer in 2-5 sentences. ",
        "reference_answer": "No. Real internet traffic often comes in bursts. Therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. For example, on-demand video streams selectively load the next video segments when needed. This means the actual network utilization depends on the current playback state on the client-side. The packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "This assumption is a simplification, that makes it easier to work and calculate with. In reality, there is seldomly only one packet is send and then nothing happens afterwards, but communication consists of multiple packets. Therefore, if there is one packet, then it is very propable, that there will be a lot following packets. I.E. if someone is streaming in the afternoon and causing a number of packets, the propability of the packets will concentrate on one timeframe. And this (and the behaviour of the other participants) causes the propability for a larger timeframe like the morning to be different then in the evening.",
        "answer_feedback": "The response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Transparent bridges manage a bridge table for the forwarding process. Please describe what information the table holds and how it is modified during the backwards learning phase. How is the table used in the forwarding process and what is one benefit of that? Please answer the question in 2-5 sentences. ",
        "reference_answer": "1.A mapping between destinations/stations (MACs) and outgoing LAN interfaces.\n2.This table is initially empty and received packages are flooded on every line. When a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its LAN links) with source address Q on LAN L, it adds the timestamped entry \u201cQ can be reached over L\u201d to the table and the next time a packet with destination Q arrives, it is forwarded on link L. The time-stamp is used to update or purge old entries. Therefore, it learns by observing the incoming traffic.\n3.To do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "table holds infromation that a certain address can be reached by a certain LAN. During backwards learning the bridge updates its table by the incoming traffic knowing that the source of the received packet is reachable over the LAN form where the packet came. Look if the address is in the table if yes then send it to the LAN over which it is reachable if not use flooding. No longer need to flood if the path is known. Another one would be that it is a rather simple approach.",
        "answer_feedback": "The response answers all the four requirements of the question correctly. Also note that if the source and destination LAN is the same, the packet is dropped.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "In mobile routing autonomous systems are not stationary or in fixed location unlike fixed and wired networks. Autonomous system is free to come and join one network at one time and later leave and join another network while maintain same communication session between sender and receiver and vice versa. Two challenges: 1. Reconnecting sender and receiver when they try to connect through different intermediary networks while being on motion. 2. At user application level awareness by the sender that receiver has left, so save the user session, so that when receiver reconnects, sender is automatically notified and previous user session is resumed.",
        "answer_feedback": "Both challenges are correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "CSMA/CD does not work for wireless transmission. Main issue is the broadcast nature of mobile transmission. * Hidden Terminal Problem: Firstly, carrier sense fails because a station that want to send cannot \u201csee\u201d another station already  sending to its destination as it is not in the transmission range of the other sending station. Secondly, there is no collision detection after the collision arised. This leads to a higher amount of collisions, a wastage of resources and unreliability. For example: * station A sends to station B; station C is not in the range of A, thus, does not receive A\u2019s signal * C performs carrier sensing as it wants to send to B, senses a free medium * C sends to B which causes collision at B; A cannot detect the collision (as it is a wireless scenario) * station A and C are hidden from each other\n\t * Exposed Terminal Problem: The \u201cexposed\u201d station is waiting to transmit a signal, as it hears a signal from another transmitting station. Thus, it tries to prevent a collision which actually will not occur as the receiver of the other sending station is outside of its range. This leads to underutilization of the channel and a decreased effective throughput. For example: * station B sends to station A; station C wants to send to another station outside of B\u2019s transmission range * C performs carrier sensing and senses a busy medium, thus it has to wait * A is outside of C\u2019s transmission range, thus, C actually does not need to wait as it would not cause a collision at A; C is exposed to B",
        "answer_feedback": "The response correctly states two challenges of mobile routing.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "Two of the many challenges of mobile routing compared to fixed / wired networks are Hidden Terminals and security issues. Hidden Terminal can occur, when the nodes are quite far apart, while some nodes are not able to detect nodes anymore, while more centered nodes are able to detect messages from both the distant nodes. Then the distant nodes are not able to detect collisions occuring in the \u201emiddle\u201c of the network at the centered nodes, because the signal is not transmitted over all network nodes. One of the security issues can be, that wifi is set up inside of a building. A normal ethernet network over cable would connect all the nodes inside, and then can be configured to discard all the internal packages at the outgoing router to the internet. A wifi network cannot be configured, to only nodes inside of the building are able to receive the packages. If the network is available outside of the building, then any node outside will be able to detect the network.",
        "answer_feedback": "Both the stated challenges are correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "(Due to the question in the forum, i will relate to slide 3, not to Challenges in Mobile Communications, which are on slide 10ff).\n\nOne basic challenge in Mobile Networking is the Power control: mobile devices have only a limited amount of power which should be used wisely and as little as possible.\n\nIn addition, the routing in Mobile Networking has to deal with a high amount of dynamic so it needs to find new routes as nodes move or conditions change.",
        "answer_feedback": "The response correctly states and describes two challenges of mobile routing.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "Hidden Terminals: Two nodes may be out of range for each other, but want to send to a third node that is in range for both of them. The first two nodes don't know when/if the other one is sending, so if both just send whenever they want, there might be a collision at the third node that can't be detected by the first two nodes. Exposed Terminals: When two nodes, that are in range for each other, want to send to nodes that are in range for them, but out of range for the other, they could, in theory, both send at the same time, because each of the receiving nodes will only receive a signal from the corresponding sending node (because the other one is not in range). However, without additional communication, the two sending nodes can not know that they aren't interfering with they other node. That's why one of the nodes will wait for the other to finish \u2192 underutilization.",
        "answer_feedback": "The response correctly states and describes the hidden and exposed terminal problems in wireless networks.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "ADAPTATION OF ROUTING PROTOCOLS due to the inherent variability of a mobile network: the packets must be routed despite convergence problems due to frequent changes in topology and environment due to mobile nodes, i.e. frequent routing table updates, unreliable/unavailable links due to receiving/transmitting problems (near and far terminals, energy saving, insufficient transmission power), so THE PATH FROM SOURCE TO DESTINATION IS MUCH MORE SHORT-LIVED OR SUBJECT TO CHANGES MUCH MORE OFTEN THAN IN FIXED NETWORKS. * ADDRESSING (AUTO-CONFIGURATION): the automatic configuration of the end systems IS DIFFICULT DUE TO ROAMING and this obviously also affects routing. When roaming at Layer 2, the IP address can be retained, but the packet must be routed via an appropriate access point: if there is a handover, the old AP would have to forward the packets to the new one; when roaming at Layer 3, a subnet change may result in the assignment of a new IP address.",
        "answer_feedback": "The response correctly states and describes the challenges faced in wireless network routing.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "One issue for mobile networks is the hidden terminal problem: When there are two stations A and C out of reach of each other want to send to a station B in reach of both stations, A and C will not hear the signal of the other sender, assume the medium is free and start sending. However, at station B, both signals will collide. A second issue for mobile networks that cannot occur in wired networks is the exposed terminal problem: Sending from one station A to another station B might be blocked because of A receiving a signal from another sender C in reach of station A, despite the signal of this sender C not reaching the proposed receiver B. This issue can reduce the utilization of a link between two nodes unessessarily.",
        "answer_feedback": "The response correctly explains the hidden and exposed terminal challenges.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "Hidden Terminals is one challenge in Mobile Routing. The problem is that nodes can only comunicate in a certain range and  those ranges overlap with others, leading to nodes receiving data from others, which do not know about one and another. This leads to data coalition. Another Challenge is Exposed Terminals. The problem again lies in the nature of the overlapping data transmission. To solve the previously mentioned problem only one can send at a time in their range, however this can lead to blocking communication to outside nodes which would not be effected by having communication with another one outside of the receivers range.",
        "answer_feedback": "The response correctly states and describes the hidden and exposed terminal problems in wireless networks.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "Hidden Terminals: Two nodes (A and B) that are out of each other's range can not detect transmissions from either node to a third node (C) which is within their ranges. This can cause A and B to simultaneously attempt to transmit to C. Hence, A and C are \u201chidden\u201d from each other. This leads to more collisions and reduced efficiency. Exposed Terminals: When two nodes are too close to each other it can interfere with their transmissions. When one node is transmitting, it signals to all other nodes in its vicinity that a medium (destination node) is in use and therefore the other nodes should wait before transmitting themselves. This becomes a problem when the other node in its vicinity has to delay its transmission to an entirely different node outside of the transmitting node's range. This leads to an underutilization of the channels.",
        "answer_feedback": "The response correctly states and describes two challenges of mobile routing.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "1- Hidden terminals [Tobagi75]: it occurs when \u201cfor example\u201d we have three nodes A, B, C. Nodes A and C cannot hear each other, and the transmissions by nodes A and C can collide at node B. That makes nodes A and C are hidden from each other. And that can cause more collisions, unreliability as a result, and waste of resources.\n\n2- Exposed terminals: it happens when \u201cfor example\u201d we have four nodes A, B, C, D. Node B sends to node A, and node C wants to send to another node like D (not A or B), node C has to wait and it is prevented from sending packets to other nodes because of co-channel interference with a neighboring transmitter (medium in use). But node A is outside the radio range of node C, therefore waiting is not necessary, and node C is \u201cexposed\u201d to B. That can cause underutilization of channels and lower effective throughput.",
        "answer_feedback": "The response correctly states and describes the hidden and exposed terminal problems in wireless network.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT are the challenges of Mobile Routing compared to routing in fixed and wired networks? Please NAME and DESCRIBE two challenges.",
        "reference_answer": "Possible Challenges:\n1.Adaptation: The network has to handle the dynamic positioning of the nodes/topology changes. Additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.Security: Interception of packets or injection of faulty packages is easily possible in wireless networks. This may necessitate encryption and authentication.\n3.Medium Access Control: Wireless networks feature new possibilities for inference and collisions of the transmitted signals. See the following correct example challenges:\ni)Hidden Terminal: Nodes\u2019 transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (A and C in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)Exposed Terminal: Nodes (C in this example) may not realize they could send collision-free, because a node in their detection range (B) is sending and they, therefore, detect the medium as busy, but the sending node (B) is out of the detection range of the destination node (D) so that no collision would occur.\niii)Near and Far Terminals: Signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.Quality of Service (QoS): Due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired QoS. Additionally, signal quality may also decline due to noise and occlusion.\n5.Scalability: Since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.Heterogeneity: Nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.Dependability: Providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.Power Consumption: As most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "1.Hidden Terminals: it is when two stations simultaneously transmit data to one of the stations is unaware that reception is already receiving data from another station and a collision occurs at the receiving station. E.g.  We have three station A,B,C -A sends to B, C cannot receive A   -C senses a \u201cfree\u201d medium (carrier sense fails) , C sends to B   -Collision at B, A cannot detect the collision (collision detection fails)  -A is \u201chidden\u201d for C and vice versa  2.Near and Far Terminals: it's when a weak signal drowns out a strong signal. Terminals A and B send, C receives  -Signal strength decreases proportionally to square of distance  -Stronger signal of B therefore drowns out A\u2019s weaker signal  -C cannot receive A",
        "answer_feedback": "The response correctly explains the hidden and near and far terminal challenges.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT is the purpose of Reverse Path Forwarding and Reverse Path Broadcast? HOW do they work?",
        "reference_answer": "Purpose: Both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nReverse Path Forwarding:  Each node has a routing table stemming from unicast routing algorithms. When receiving a packet of sender S from neighbor N at node X, check the routing table and only forward the packet to all adjacent nodes (except for N) when you would send packets to S over N \u2192 the assumption is that the packet used the BEST route until now.\nReverse Path Broadcast: Nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node X knows that is on the best path between two nodes A and B if it receives unicast packets coming from A and going to B or visa versa. In other words, each node knows which spanning trees it is part of in the network. Reverse Path Broadcasting works identical to Reverse Path Forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to N).",
        "provided_answer": "Reverse Path Forwarding and Reverse Path Broadcasting are both algorithms used for loop-free multi- and broadcast communication and therefore aim to be more efficient than simple attempts like flooding or individual sending of packets to every destination in the network. The idea of both algorithms is the use of so called \u201cspanning trees\u201d for each individual node in the network, which contain routes to every subnode in every subnetwork. Since one intermediary system does only know his own spanning tree, but not the ones of the surrounding nodes, each router has to use its knowledge of optimal routing for certain destinations as a criterion for further transmission. For Reverse Path Forwarding this means, that each node has to check the link on which an incoming packet is received. If this link is the optimal one, over which packets for this station are also usually sent, then node can assume that the packet has taken an optimal way up to it. As a consequence, it then re-sends the packet over all of its edges, but not the one on which the packet was received. If the packet on the other hand does not come over such an \u201coptimal\u201d link it gets discarded.  Since re-sending over all edges seems not to be the most efficient way of multicast-routing, Reverse Path Broadcast introduces a further check for packets that arrive over the optimal link as well as a limited re-transmission of packets: If a packet has taken the optimal path until this station, the station reroutes the packet over the optimal incoming link to the Source in reversed direction. This means, that the receiving node looks up in its routing table over which link such a packet would normally be received. Exactly this link is then used for rerouting the packet to the source instead of using all links as it is done before in Reverse Path Forwarding. Otherwise (so to say if the packet is not received on an optimal link or received on an optimal link, but has not taken an optimal path so far), the packet is not resent. This mechanism is implemented to limit the number of duplicates in the network - while Reverse Path Forwarding retransmits over all edges (excluding the one on which the packet was received), Reverse Path Broadcasting chooses the most suitable link for retransmission.",
        "answer_feedback": "The response correctly explains RPF and RPB and their purpose.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT is the purpose of Reverse Path Forwarding and Reverse Path Broadcast? HOW do they work?",
        "reference_answer": "Purpose: Both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nReverse Path Forwarding:  Each node has a routing table stemming from unicast routing algorithms. When receiving a packet of sender S from neighbor N at node X, check the routing table and only forward the packet to all adjacent nodes (except for N) when you would send packets to S over N \u2192 the assumption is that the packet used the BEST route until now.\nReverse Path Broadcast: Nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node X knows that is on the best path between two nodes A and B if it receives unicast packets coming from A and going to B or visa versa. In other words, each node knows which spanning trees it is part of in the network. Reverse Path Broadcasting works identical to Reverse Path Forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to N).",
        "provided_answer": "The PURPOSE of these two algorithms is the EFFICIENT (e.g. compared to flooding) execution of BROADCAST ROUTING, i.e. the sending of packets to all other hosts in the subnet. MODE OF OPERATION: Both are based on the idea of the Spanning Tree to use the shortest possible paths from the sender to the receivers. _RPF_ FORWARDS A BROADCAST PACKET arriving on one link over all other links ONLY IF IT ARRIVES OVER A LINK OVER WHICH, according to its own routing table, PACKETS ARE ALSO ROUTED TO THE SENDER OF THE BROADCAST (i.e. it is assumed that the packet arrived on the best path), OTHERWISE THE PACKET IS DISCARDED. _RPB_ differs from _RPF_ in the way it forwards packets: A PACKET IS ONLY FORWARDED TO A DIRECT NEIGHBOURING NODE IF THE FORWARDING NODE WOULD ALSO BE LOCATED ON A UNICAST PATH BETWEEN THE SENDER AND THAT NEIGHBOURING NODE. For example, if a node B receives a broadcast packet from A and B has links with C and D, but has previously learned that no packets are routed from A to C via B, but to D via B, then it will not forward the packet to C (unlike _RPF_), but only to D. This further reduces the number of messages compared to _RPF_.",
        "answer_feedback": "The response correctly answers the purpose and the explanation for both broadcast types.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT is the purpose of Reverse Path Forwarding and Reverse Path Broadcast? HOW do they work?",
        "reference_answer": "Purpose: Both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nReverse Path Forwarding:  Each node has a routing table stemming from unicast routing algorithms. When receiving a packet of sender S from neighbor N at node X, check the routing table and only forward the packet to all adjacent nodes (except for N) when you would send packets to S over N \u2192 the assumption is that the packet used the BEST route until now.\nReverse Path Broadcast: Nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node X knows that is on the best path between two nodes A and B if it receives unicast packets coming from A and going to B or visa versa. In other words, each node knows which spanning trees it is part of in the network. Reverse Path Broadcasting works identical to Reverse Path Forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to N).",
        "provided_answer": "Reverse Path Forwarding and Reverse Path Broadcast are used in broadcasting, to enable loop-free by verifying the reachability of the destination. That way each IS will know its multicast tree RPF :  ALGORITHM : Check if the packet that arrived at the IS entry port over which the packets for this source are usually also sent. If yes, an assumption can be made that the packet used the best route. Then the packets will be resent over other edges (not including the incoming one) if no, assume the packet did not use the best route. Then this packet will be discarded. RPB : ALGORITHM :  Check if the packet that arrived at the IS entry port over which the packets fort this source are usually also sent. If yes, check if the packet used the best route. * If yes, select the edge at which the packets arrived and from which they are then rerouted to the source * If no, do not send over all the edges (without the incoming one) If no, the packet is discarded.",
        "answer_feedback": "The response correctly explains RPF and RPB and their purpose.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHAT is the purpose of Reverse Path Forwarding and Reverse Path Broadcast? HOW do they work?",
        "reference_answer": "Purpose: Both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nReverse Path Forwarding:  Each node has a routing table stemming from unicast routing algorithms. When receiving a packet of sender S from neighbor N at node X, check the routing table and only forward the packet to all adjacent nodes (except for N) when you would send packets to S over N \u2192 the assumption is that the packet used the BEST route until now.\nReverse Path Broadcast: Nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node X knows that is on the best path between two nodes A and B if it receives unicast packets coming from A and going to B or visa versa. In other words, each node knows which spanning trees it is part of in the network. Reverse Path Broadcasting works identical to Reverse Path Forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to N).",
        "provided_answer": "Reverse Path Forwarding: - Purpose: reduce traffic in broadcasting compared to flooding. In Reverse Path Forwarding, a sender only sends an incoming packet to all of its adjacent nodes if it has arrived over the edge that is considered to be part of the shortest path between that node and the source. Otherwise, the packet is ignored. Reverse Path Broadcasting: - Purpose: further reduce traffic compared to Reverse Path Forwarding. In Reverse Path Broadcasting, if a packet has arrived over the edge which is usually used for sending packets to the source, it is only forwarded to those neighbors, which usually route unicast messages to the sender via that node. So a router only spreads packets to a neighbor if it is on the shortest path between that neighbor and the source.",
        "answer_feedback": "The response correctly answers all three parts of the question. However, the purpose of minimizing the number of duplicate packets in the network is not explicitly stated in the response.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHICH PROPERTY of spanning trees makes them appealing for broad- and multicasting? EXPLAIN how you can modify Link State Routing to construct a spanning tree for multicasting.",
        "reference_answer": "Property: There is a single unique path between every pair of nodes in the tree. Alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. This means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nSpanning Tree with Link State Routing: Each intermediate system knows which multicast groups it belongs to, but initially doesn\u2019t know which other IS belong to the groups. Therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with Prim or Kruskal)",
        "provided_answer": "A Spanning tree consists of a loop free topology including all nodes with minimum number of possible edges. It finds a minimal subnet and enables the network to minimize duplicates and reduce traffic. Modification of Link State Routing: The link state packet which contains information about the distance to neighbors can be enhanced by adding information on multicast groups. As the link state packets are broadcasted to all other nodes, every node is able to calculate a local multicast tree due to the fact that all nodes have the complete state information locally available.  Based on the multicast tree a node decides on which outgoing links a packet has to be forwarded.",
        "answer_feedback": "The response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHICH PROPERTY of spanning trees makes them appealing for broad- and multicasting? EXPLAIN how you can modify Link State Routing to construct a spanning tree for multicasting.",
        "reference_answer": "Property: There is a single unique path between every pair of nodes in the tree. Alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. This means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nSpanning Tree with Link State Routing: Each intermediate system knows which multicast groups it belongs to, but initially doesn\u2019t know which other IS belong to the groups. Therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with Prim or Kruskal)",
        "provided_answer": "Spanning trees have the following property, they connect all nodes in a graph with minimum possible edges. Since all nodes in the network are addressed by the source node that builds the spanning tree, an IS has to generate the minimum number of packet copies to broadcast or multicast to this sub-net. Each IS initially knows which multicast group it belongs to. This additional multicast information is added to the link state packets that are periodically sent out by the node. Once the complete state information is obtained, each IS calculates a spanning tree for multicast.",
        "answer_feedback": "The response correctly states the attractive spanning-tree property and explains how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "WHICH PROPERTY of spanning trees makes them appealing for broad- and multicasting? EXPLAIN how you can modify Link State Routing to construct a spanning tree for multicasting.",
        "reference_answer": "Property: There is a single unique path between every pair of nodes in the tree. Alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. This means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nSpanning Tree with Link State Routing: Each intermediate system knows which multicast groups it belongs to, but initially doesn\u2019t know which other IS belong to the groups. Therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with Prim or Kruskal)",
        "provided_answer": "Property: -no cycles / minimal path / connect only needed path for the transmitting   All IS send link state packets periodically, containing information about distance to neighbors and expanded by information on multicast groups and by broadcast to all the others. Each IS calculates a multicast tree from the now locally available and complete state information. Based on the information about the multicast tree IS determines the outgoing lines, on which packets have to be transmitted.",
        "answer_feedback": "The response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers in IPv6 are optional fields that cab specify additional options in an IP package. They are located between the actual IPv6 header abd the package payload. Compared to IPv4, they have the advantage of being more flexible as they are optional and can be used to add additional options to a package without being limited by the limited header size.",
        "answer_feedback": "The response correctly answers all three parts of the question.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers allow to append further options not covered by the fixed header and are located between the fixed header and the payload. \nIn contrast to IPv4 options the extension headers are entirely optional and can adapt to changing circumstances without touching the protocol itself.",
        "answer_feedback": "The response correctly answers all three parts of the question.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers are pieces of additional information that can be placed between the main header of an IP packet and the actual payload. They allow implementation of additional functionalities, for example predefining a static route through the network, but also information about fragmentation of larger packages. Therefore, they are the successor of the fragmentation- and options-field of an IPv4 header. In comparison, the new system with extension headers is much more flexible and adaptive to the wanted additions, because the extension headers are only optional, and also help to overcome the size limitations that were defined by the sizes of the fields in IPv4. What is more, the extension header idea is better for future developments, because new extension headers can be easily developed and attached to the existing system without changing the fixed header of an IPv6 packet.",
        "answer_feedback": "The response answers all three parts of the question correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information.\n\nIf present, they are located between the fixed header and the payload data.\n\nThe main advantage of the extension headers compared to IPv4 is the simplicity and flexibility of their use: unlike IPv4, there is no limitation on the size of the option area (40 bytes) and in the future further extension headers can be specified without having to change anything in the IPv6 packet format. The extension headers allow, for example, to use the options from IPv4 packets (such as fragmentation) that are omitted in the fixed IPv6 header.",
        "answer_feedback": "The response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers are optional extensions to the fixed header. This provides flexibility to implement new features in the protocol. For such extensions, it is not necessary to change the fixed headers. Each header points to a next header and therefore this forms a header chain. The last header points to \u201cno next header\u201d and the payload, e.g. TCP or UDP, follows. Therefore, extension headers are located between the fixed header and the payload. Examples for extension headers are hop-by-hop options, destination options, encapsulating security payload (ESP) or mobility.\nAs a main advantage vs IPv4, optional extension headers provide a high degree of flexibility, overcome the size limitations of a highly predefined header in IPv4 and grant the potential for future extensions.",
        "answer_feedback": "The response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers in IPv6 are placed between fixed header and payload. The advantages compared to IPv4 is that these are optional, it helps to overcome size limitation and allow to append new options without changing the fixed header.",
        "answer_feedback": "The response answers the location and advantages of extension headers correctly and implicitly gives a description.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension Headers are additional information like Routing and Fragmentation for network device to decide how to process the IPv6 packet.\n\nExtension Headers are located between fixed header and payload.\n\nmain advantages:\n- optional\n- help to overcome size limitation\n- append new options without changing the fixed header",
        "answer_feedback": "The response answers all three parts of the question. However, the \"optional\" advantage is more a description of the extension header.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extensions Header in IPV6 contain supplementary information used by network devices (such as routers ,switches , and endpoint hosts) to decide how to direct or process an IPV6 packet and they are located between fixed Header and payload. The main advantage of extension headers compared  to IPV4 to allow to append new options without changing the fixed header.",
        "answer_feedback": "The response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "Extension headers carry optional header information which are important for IP routing.\nThey are placed between fixed headers and the payload in a packet.\nAdvantages compared to IPv4:\n-Extension headers help to overcome size limitations for options\n-Allow new options to be implemented without changing the header",
        "answer_feedback": "The response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are extension headers in IPv6 and where are they located in a packet? What is the main advantage of extension headers compared to IPv4?",
        "reference_answer": "Extension headers are used to extend the fixed IPv6 header with additional, optional network layer information. If present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nMain advantage: One of the following advantages are considered fully correct:\n1. It allows the appending of new options without changing the header.\n2. IPv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except \u201cHop-by-Hop Extension\u201d) while they are processed by all routers in IPv4 unless ordered otherwise.",
        "provided_answer": "The extension headers are optional headers placed between the fixed headers and the payload. Using these, the header information is no longer limited in size (like in ipv4) and thus can be extended based on future requirements.",
        "answer_feedback": "The response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "1. To support billions of end-systems\n2. To reduce routing tables\n3. To simplify protocol processing\n4. To increase security\n5. To support real time data traffic (quality of service)\n6. To provide multicasting\n7. To support mobility (roaming)\n8. To be open for a change\n9. To coexist with the existing protocol",
        "answer_feedback": "All objectives of IPv6 mentioned in the response are completely accurate.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "more/larger addresses; multicasting; mobility; better security; simplification of the protocol",
        "answer_feedback": "The response correctly answers objectives of IPv6.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "Here are 5 objectives of the IPv6: \n\n-To support billions of End systems (2^128), much more than IPv4 (2^32).\n-To simplify the protocol. For example, the header of the IPv6 is much simpler than the header of IPv4. \n-To coexist with the older protocol. For example, thanks to tunneling, IPv6 can coexist with IPv4. \n-To add more security in the network. \n-To be open for eventual future evolutions (for example with the extension headers).",
        "answer_feedback": "The response is correct because all stated objectives of IPv 6 are correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "To support billions of end-systems\nTo reduce routing tables\nTo simplify protocol processing\nTo increase security",
        "answer_feedback": "All four IPv6 objectives in the response are completely accurate.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "-support billions of end-systems (with specific addresses) \n-reduce routing tables\n-simplify protocol processing \n-increase security\n-support real time data traffic (QoS)\n-support mobility\n-be open for change in future with extension headers",
        "answer_feedback": "All the IPv6 objectives mentioned in the answer are completely accurate.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "IPv6 is able to support billions of end-systems because it is using much longer adresses than IPv4.\nSince IPv4 is still very popular and the internet protocols version can't be switched instantly IPv6 have to coexist with other protocols.\nThe extension headers used by IPv6 enable changes in the future.\nTo simplify protocol processing IPv6 uses simplified headers.",
        "answer_feedback": "The response is correct as all the IPv6 objectives are completely accurate.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "1. Enlarge the available address pool:\n    By increasing the IP address length from 32 bits to 128 bits, a greater number of addresses can be assigned to end systems.\n2. Simplify protocol processing:\n    Any previous shortcomings in IPv4 can be removed and optimized in IPv6.\n3. Provide Multicasting:\n    Packets can now be sent to multiple destination addresses, which makes multicasting possible.\n4. Better Security:\n    Security means are already integrated in IPv6.",
        "answer_feedback": "The response correctly states four objectives of IPv6 with explanations.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What are the objectives of IPv6? Please state at least 4 objectives. ",
        "reference_answer": "To support billions of end-systems.\nTo reduce routing tables.\nTo simplify protocol processing with Simplified header.\nTo increase security.\nTo support real time data traffic (quality of service).\nFlow label, traffic class.\nTo provide multicasting.\nTo support mobility (roaming).\nTo be open for change (future): extension headers for additional change incorporation.\nTo coexistence with existing protocols.",
        "provided_answer": "-Provide more adresses\n-simplify protocol processing\n-be usable while IPv4 is still in use\n-increase security",
        "answer_feedback": "All four IPv6 objectives mentioned in the response are completely correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter is reduced by the same factor, e.g. from 3km to 300m.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter decreases by a factor of 10. That means the maximum distance between two locations on the network has to be 10 times smaller.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "this \u201c collision domain diameter\u201d will decrease by a factor of 10",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter will shrink with the same factor,so when the original speed is 10Mb/s and the collision domain diameter is 3km, an increase of the speed by the factor 10 to 100Mb/s will decrease the collision domain diameter to 300m.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter have to shrink (divided by 10)",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The diameter gets smaller by the same factor.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The maximum distance has to shrink by the factor of 10 and the LAN also has to get smaller which is not possible or at some point not feasible.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter decreases by the factor 10.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "For doing so you have to shrink the maximal distance between two locations.\nIn the given example the speed of the network should be increased by factor 10 from 10 Mb/s to 100 Mb/s. To achieve this without changing everything else, you have to reduce the collision domain diameter by factor 10.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter will decrease by a factor of 10.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter will be reduced by the factor of 10.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter = 412m, i.e., ca. 300m instead of ca. 3000m",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The sender must still be able to detect collisions during simultaneous transmission and must also not exceed the maximum network extension. The collision domain diameter for 100 Mb/s is 10 times smaller than for 10 Mb/s if you use CSMA/CD => 3000m to 300m.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "With a speed increased by a factor of 10, the collision domain diameter does decrease by a factor of 1/10 when using the same minimum packet size (e.g. 64 byte with Ethernet). This is because the send does finish much quicker (10 times as quick) while the time the electricity change needs to travel from sender to receiver and backwards remains the same.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "It is divided by the same factor of 10.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What happens to the \"collision domain diameter\" if you use CSMA / CD and increase the speed of a network by a factor of 10, eg from 10Mb / s to 100Mb / s (all else being equal)?",
        "reference_answer": "Diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "The collision domain diameter will shrink, exactly by the same Factor Value we increase the speed of Transmission.\n\ni.e .. when we have with Transmission rate of 10 Mbps and a Distance of 3000m, then we gonna have by Transmission rate of 100Mbps just a distance of 300m between the locations the speed ist possible.",
        "answer_feedback": "The response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting artificially increases the length of sent frames without adding meaningless padding by concatenating multiple frames, which are then sent together. Using frame bursting higher network speeds can be realized while maintaining the collision domain diameter that leads to better efficiency. \nOn the downside the latency for the frames is increased since they must wait for the next burst.",
        "answer_feedback": "The response answers all three parts of the question correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting is a transmission technique used at the data link layer of the OSI model, It can be effectively deployed in Gigabit Ethernets to increase network throughput. This is achieved by allowing a sender to transmit concatenated sequences of multiple frames in a single transmission.\nAdvantage: better efficiency than the carrier extension since multiple frames are sent in a single transmission. But carrier extension wastes bandwidth by sending a single frame at a time.\nDisadvantage: the end to end delay is increased because frames need to wait until the buffer is full or a timeout occurs and transmission happens. In contrast, carrier extension each frame would be transmitted alone without waiting for other frames.",
        "answer_feedback": "The response gives a correct definition of frame bursting, including its benefits and drawbacks.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting is concatenated sequence of multiple frames sent in single transmission. Advantage: When many frames are waiting at sender, it can be efficient. Disadvantage: When there are too less frames at sender, the sender keeps waiting too much before sending or at timeout adds too much padding data to send to receiver (inefficient).",
        "answer_feedback": "The response answers all the three parts of the question correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting is a feature of the shared broadcast mode. It allows the sender to transmit concatenated sequences of multiple frames in a single transmission. For example, we have eight packets and a buffer. We have to wait for all these eight packets to come and put them together on the line. If something is wrong, all of the eight packets have to be repeated.\n\nDisadvantage: If we only have to send one or two packets, we have to wait for eight packets to arrive, it takes a long time. So we artificially increase the end to end delay.\nAdvantage: It allows us to \"burst\" a sequence of packets resulting in higher throughput without abandoning the transmission medium.\n\nThere is a trade-off between efficiency and the end to end delay we are going to send. If we introduce end to end delay at the lower layer, the upper layer cannot do anything about it; it cannot speed it up anymore even if desired. So, thus, this is possible but not entirely ideal.",
        "answer_feedback": "The response correctly states the definition of frame bursting, including its pros and cons.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting is a feature that allows for a higher throughput and efficiency. This works by allowing the sender to transmit a series of frames in succession in a single transmission without giving up control on the transmission medium. An advantage compared to carrier extension is that it has better efficency while a disadvantage is that it needs multiple frames waiting for transmission.",
        "answer_feedback": "The response answers the correct definition of frame bursting, its advantage and disadvantage.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting is one of IEEE 802.3z features of shared broadcast mode.It allows a sender to put several buffered frames together and transmit those concatenated frames in a single transmission to the receiver, without giving up the control over the transmission medium.\nThe advantage of frame bursting is the increased efficiency resulting from a higher throughput of individual data packets due to concatenation of single frames.\nThe disadvantage is, that this method can increase the waiting time of other senders (that are currently not sending) and the end-to-end delay.",
        "answer_feedback": "The response answers all three parts of the question correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting allows the sender to transmit concatenated sequence of multiple frames in single transmission , this is a solution to the problem of the improvement of the speed and its consequences to the length of the cable.\nAdvantage: It is more efficient than the carrier extension.\nDisadvantage: with this you artificially increase the end to end delay, which can be a problem when the frame is critical.",
        "answer_feedback": "The response correctly answers all three parts of the question.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "The Frame bursting is one of the features of Shared Broadcast Mode. It consists in, on the sender's side, to concatenate a sequence of multiple frames in one single transmission. \n\nComparing to the carrier extension (the other feature of Shared Broadcast Mode), it needs frames to wait for transmission (disadvantage) but it has a better efficiency (advantage)\n\nThis will lead to higher among of collision or we should decrease the LAN size.",
        "answer_feedback": "The response is correct as it states the frame bursting definition, including its advantage and disadvantage.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "To be able to transmit data over lager distances at higher speed and still avoiding collisions you send bigger sequences by collecting several packets and sending them all together.\n\nAdvantage: You have a higher efficiency compared to carrier extension. You have a minimum of 70 percent (frame size 64 byte and user data 46 byte) user data compared to a minimum 9 percent of.\n\nDisadvantage: You have a delay in time while waiting for other packets until you have collected enough to send.",
        "answer_feedback": "The response is answering all three parts of the question correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting allows the sender to concat frames in a single transmission to increase CSMA-CD distance.\nIt has a higher efficiency than Carrier extension (extending min. frame length),but frames are needed to wait for transmission. Also, carrier extension has a higher overhead.",
        "answer_feedback": "The response correctly answers all the parts of the question.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame bursting allows the sender to send many frames concatenated.\nIf the station has several frames buffered and it has already sent a frame on the carrier, it can send the next frame directly after getting the acknowledgement from the receiver, without a dedicated time between frames.\n\nAdvantages:\n\"Frame bursting\": Higher speed, due to less waiting time between sending frames.\n\"Carrier extension\": Simple to implement\n\nDisadvantages:\n\"Frame bursting\": Requires many frames to be sent simultaneously\n\"Carrier extension\": Low efficiency",
        "answer_feedback": "The response is correct. However, to substitute carrier extension, frame bursting with frame aggregation has to be used. In this case, frames are directly concatenated without waiting for acknowledgments in between.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "The sender buffers a number of frames and concatenates them, so they can be sent in a single transmission.\nThe disadvantage is, that the end-to-end delay is increased, because the sender buffers the frames instead of sending them out as soon as they are created.\nThe advantage is that no \"rubbish\" data has to be sent, like with carrier extension, so the data efficiency is much higher.",
        "answer_feedback": "The response correctly answers all three parts, the frame bursting definition, its advantage and disadvantage.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is \"frame bursting\"? Also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "Frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nAdvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\nDisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "Frame Bursting allows sender to transmit concentrated Sequence of multiple Frames in single transmission.\n\nAdvantage:\nThe rate of efficiency is increasing in Transmission\n\nDisadvantage:\nFrames needs to wait for Transmission.",
        "answer_feedback": "The response gives a correct definition of frame bursting, its advantage and disadvantage.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "Asynchronous: Each character is bounded by a start bit and a stop bit -> simple and  inexpensive, but low transmission rates\nSynchronous: several characters pooled to frames, defined by SYN or flag -> more complex, but higher transmission rates",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous: characters are bounded with a start and stop bit, the transmission rate is low with up to 200bit/sec\n\nsynchronous: characters are pooled in frames with a SYN or flag - this has a higher transmission rate and is also more complex",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "In an asynchronous transmission each byte is sent separately and has a start and an end bit.\nIn a synchronous transmission data is sent in frames which can lead to higher transmission rates but becomes more complex.",
        "answer_feedback": "The response correctly answers the differences between synchronous and asynchronous transmission mode.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "Asynchronous transmission sends single bytes which are bounded by a start bit and an end bit.\n\nIn comparison synchronous transmission is able to send a block of bytes (Frame). These blocks are defined by SYN or flag.",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "In the asynchronous transmission mode, there is a start bit and a stop bit for every single character (byte) [ START | BYTE | STOP ].The synchronous transmission mode packs several bytes into a frame and a synchronisation flag is used to mark the begin and end of a new frame [ SYN | BYTE 1 | ... | BYTE n | SYN ].",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "Asynchronous mode transmits characters separately and marks their boundary by using a start and stop bit, while synchronous mode groups multiple characters into frames where bounds are specified using control flags or a length field or invalid symbols of the physical layer.\nAsynchronous mode is simpler, but it's also slower than synchronous mode due to the increased overhead.",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "During asynchronous transmission each Byte of the transmission is bounded by a start and a stop bit. This makes it possible to transfer data at all time.\nWith synchronus transmission the sender has to wait for the reciever until he is ready, so a transmission has to start with SYN flags. After the SYN Flags all Bytes of the data can be transferred without being bounded with start and stop bits. This leads to a higher transmittion rate than with the asynchronus transmission.",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "The difference is that in synchronous transmission mode the information which is to be transmitted is packed in frames, whereas in asynchronous transmission mode a single character represents a frame, which is bounded by a so-called start bit and a stop bit. So the asynchronous transmission have low transmission rates but is simple and inexpensive, in contrast the synchronous transmission is more complex but has higher transmission rates.",
        "answer_feedback": "The response correctly answers the differences between synchronous and asynchronous transmission mode.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "While in asynchronous transmission every character is bounded by a start and a end bit, in synchronous transmission several character are bound to frames, these frames are bound by SYN or flag. The asynchronous transmission is simple and inexpensive, but has a low transmission rate, up to 200 bit/sec, while the synchronous transmission has a higher transmission rate, but is more complex.",
        "answer_feedback": "The response answers the differences correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "On the asynchronous transmission, we transmit character independently from each other. Each byte is delimited by a start bit and a stop bit. \n\nOne the Synchronous transmission, whereas, several characters are regrouped in a \"frame\". \n\nThe Synchronous transmission is generally more complex but faster.",
        "answer_feedback": "The response is correct as it correctly answers the differences between synchronous and asynchronous transmission mode.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the difference between asynchronous and synchronous transmission mode in the Data Link Layer.",
        "reference_answer": "Asynchronous transmission: Every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nSynchronous transmission: Several characters pooled to a continuous stream of data (frames), Frames defined by SYN or flag, higher complexity, but higher transmission rates. Requires synchronization between sender and receiver.",
        "provided_answer": "Synchronous transmission sends data in a sort of blocks or frames.\n\nIn Unsynchronous transmission the data is sended in form of byte and character.\nStart and  Stop-Bits are added.",
        "answer_feedback": "The differences mentioned in the response are completely correct.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks. It is used for simplified installation and configuration of end systems into network. Allows for manual or automatic assignment of IP addresses. May also provide additional configuration information like DNS server, netmask, default router, etc",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "DHCP is a protocol to centrally manage the distribution of ip addresses in a network.\nThe DHCP simplifies the installation and configuration of end systems. Moreover, it allows for manual and automatic IP address assignment and may provide additional configuration information such as DNS server, netmask, default router, etc.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on\nInternet Protocol networks whereby a DHCP server dynamically assigns an IP address and other\nnetwork configuration parameters to each device on a network.\n\n\nDHCP simplifies installation and configuration of end systems, and allows for manual and\nautomatic IP address assignment.\n\nEnd systems can broadcast DHCP DISCOVER packets to retrieve their IP from the DHCP server.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "DHCP has replaced RARP (and BOOTP) as it has Extended functionality. Its uses are: 1.Simplifies installation and configuration of end systems 2.Allows for manual and automatic IP address assignment 3.May provide additional configuration information like DNS server, netmask, default router, etc.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "DHCP is a network management protocol which extends the functionality of RARP and BOOTP. DHCP simplifies installation and cofiguration of end systems. It also allows for manual and automatic IP address assignment.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The Dynamic Host Configuration Protocol (DHCP) is Internet Protocol based on the special server that uses for manually or automatically IP addresses assignment and other network configuration parameters, such as subnet masks and default gateways, to each device on a network so they can communicate with other IP networks.\nThis server need not be on the same LAN as the requesting host. Since the DHCP server may not be reachable by broadcasting, a DHCP relay agent is needed on each LAN.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "DHCP is a protocol that provides quick, automatic, and central management for the distribution of IP addresses within a network. It simplifies installation and configuration of end systems, also allowing for manual and automatic IP address assignment.\n\nIt is used for providing configuration information such as DNS server, netmask, default router, etc)",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The Dynamic Host Configuration Protocol (DHCP) is a protocol designed as a replacement for the RARP and BOOTP protocols, with some additional functionality.\nAs such, it is is a protocol used for managing client IP addresses in a LAN.  \nWhen a client first joins a network, it sends out a so-called 'DHCP Discover packet', which is a way for the client to tell the DHCP server (usually the local router) that it needs a valid IP address.  \nThe DHCP server then responds, assigning an IP address and optionally some additional addresses (like the default netmask or router) to this host. The assigned address will be valid only for a certain duration specified by the host in the response.  \nThe client now has to renew its IP address (by sending out yet another DHCP Discover packet) before the assigned address expires.\n\nAs long as the address hasn't expired, it is safe for the client to assume that his current address is still valid, even after being disconnected from the network for some time.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The DHCP protocol is used to simplify the configuration of ip adresses of end systems. It is used to dynamically assign ip adresses to the participants of a network, while still enabling administrators to configure ip adresses manually. Every end system is able to configure itself with the help of the dhcp-server. The end system sends a dhcp discovery broadcast, the dhcp identifies itself and afterwards they negotiate the ip adress, as well as other parameters like time server, name server, domain name and subnet mask.",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What is the \u201cDynamic Host Configuration Protocol (DHCP)\u201d? What is it used for? ",
        "reference_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used in Internet Protocol (IP) networks, whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network. Further, DHCP has largely replaced RARP (and BOOTP)\n\t Uses of DHCP are: Simplifies installation and configuration of end systems. Allows for manual and automatic IP address assignment. May provide additional configuration information  (DNS server, netmask, default router, etc.)",
        "provided_answer": "The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol networks whereby a DHCP server dynamically assigns an IP address and other network configuration parameters to each device on a network so they can communicate with other IP networks. A DHCP server enables computers to request IP addresses and networking parameters automatically from the Internet service provider (ISP), reducing the need for a network administrator or a user to manually assign IP addresses to all network devices.\n\nDHCP is used for:\nSimplifies installation and configuration of end systems\nAllows for manual and automatic IP address assignment\nMay provide additional configuration information (DNS server, netmask, default router, etc.)",
        "answer_feedback": "The response answers the definition and the usage of DHCP correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or Frames must contain additional field for acknowledgement.",
        "provided_answer": "The requirement that has to be met that you can use the piggybacking extension to the sliding window protocol is, that we need the ACK field in the frame header that costs only a few bits. A seperate frame would need more costs: ACK, header and a checksum.",
        "answer_feedback": "The response is correct, a duplex connection is also required.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or Frames must contain additional field for acknowledgement.",
        "provided_answer": "Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver. Therefore, the ACK for a data frame from a sender is sent in one frame with the next data frame issued by the receiver. Thus, the requirement for piggybacking is a duplex connection (and the need of sending an ACK).",
        "answer_feedback": "The response identifies the underlying requirement duplex connection correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or Frames must contain additional field for acknowledgement.",
        "provided_answer": "The connection has to be duplex and both sides have to have data to send (Otherwise the frame is 0 characters + the acknowledgement, which would just be a confirmation and no piggybacking).",
        "answer_feedback": "The response answers the underlying requirement correctly. Instead of sending the whole frame with no data, a separate acknowledgment can also be sent after a timeout.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "What requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "Piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or Frames must contain additional field for acknowledgement.",
        "provided_answer": "To use the piggybacking extension to the sliding window protocol, we have to be in a duplex mode.",
        "answer_feedback": "The response answers the underlying requirement correctly.",
        "verification_feedback": "Correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver cant differentiate between a new correct package or an \"old\" duplicated package, which leads to multiple data processing.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "A receiver might not be able to distinguish a duplicate from a normal packet and so re-execute the given task.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The\u00a0duplicate packets\u00a0reduce effective tool bandwidth, waste tool processing power, and consume tool storage capacity, reducing their effectiveness.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver does not know which \"data\" it should use and will probably re-execute the transfer, which could lead to more network traffic.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Receiver might not be able to distinguish\u00a0between a real and a duplicate packet.",
        "answer_feedback": "The response is correct. The response can also state what will be the consequence in such a scenario.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The duplicate packets is a a problem due to the reducing of the bandwidth and the decreasing of the efficiency.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver cannot recognize the difference between correct data and duplicated data and would re-execute the transaction.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver may not be able to tell that the packet is a duplicate and re-executes an operation.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Duplicate packets can be false recognized as new data and then cause problems on higher network layers.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver cannot differential between the correct date and the duplicated date.",
        "answer_feedback": "The response is correct. The response can also state what will be the consequence in such a scenario.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver receiving the duplicate might not distinguish it from a real packet and could perform a wrong (unwanted) action.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Yes because the receiver will think they are different and process them multiple times, which leads to unexpected result.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Duplicate packets in a network can result in a network overload if all senders would send the same packets multiple times.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Besides increasing the traffic load duplicates can cause unwanted behavior when not handled properly.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The\nreceiver cannot differentiate between a correct packet and a duplicated one and\nwould process it again.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Duplicates of packages could lead to the reinitiation of a transaction, which was already considered finished by one part of the communicating party.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicate packets will waste the bandwidth",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "A receiver may not be able to differentiate between original and duplicated data and may so process wrong data.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Wenn der Empf\u00e4nger nicht in der Lage ist, zwischen g\u00fcltigen und duplizierten Paketen zu unterscheidenkann er auf dieselbe Information zweimal reagieren.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "Duplicates (e.g delayed. from previous sessions) can't be distinguished from packets of the current transmission and may cause problems because they can't be handled properly.",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "The receiver cannot distinguish\u00a0duplicate packets from\u00a0correct packets so it would re-excute the transaction .",
        "answer_feedback": "The response is correct.",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Why can duplicate packets be a problem in a network? Please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "If people doesn't use additional infomation to identify the packes, receiver cannot distinguish the first arrived packet and later pulicate packet, then it would re-execute the transaction.",
        "answer_feedback": "The response is correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "Class A contains all IP addresses with first octet from 0 to 127 (IP address format is octet1.octet2.octet3.octet4)\n\nAccording to slide 45 of Internet Protocols:\nAddresses in range 127.0.0.0 to 127.255.255.255 are reserved, because they are used for loopback testing.\nAddresses in range 0.0.0.0 to 0.255.255.255 are reserved, because they refer to hosts of the current network.\n\n(So, excluding these 2 groups, each network with starting octet X, 0<X<127 of Class A has address X.0.0.0 for the network, X.255.255.255 for broadcasting and the rest addresses between these 2 for hosts).",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "(0.0.0.0/8 Depends if 0 is countes as a class A network): Current Network\n10.0.0.0/8: Private networks\n127.0.0.0/8: Loopback\n\nQuelle: RFC 5735",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "0.0.0.0 to 0.255.255.255\n10.0.0.0 to\u00a010.255.255.255\n127.0.0.0 to 127.255.255.255",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "0.0.0.0/8: current network adresses\n127.0.0.0/8: loopback adresses",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "0.0.0.0 to 0.255.255.255: current network\n127.0.0.0 to 127.255.255.255: loopback adresses",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "127.X.X.X (127.0.0.0\uff5e127.255.255.255)",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "Just to note: originally I understood the task to mean reserved addresses within the network (i.e. concerning the host part), but then there was an official statement in the forum that the network part was meant. If it is indeed the host part, then *.0.0.0 and *.255.255.255 would be reserved within each Class A network.\nReserved addresses in Class A networks:\n0.0.0.0 - 0.255.255.255 (host at this network)10.0.0.0 - 10.255.255.255 (Class A private network range)127.0.0.0 - 127.255.255.255 (local host)",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "IP : 0.0.0.0\nIP Range: 127.0.0.1 to 127.255.255.255 are network testing addresses (also referred to as loop-back addresses)",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "IP Ranges:\n0.0.0.0 - 0.255.255.255\n127.0.0.0 - 127.255.255.255",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "127.0.0.0~127.255.255.255",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "0.0.0.0-0.255.255.255\n10.0.0.0-10.255.255.255,\n100.64.0.0-100.127.255.255\n127.0.0.0-127.255.255.255,",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "All 0 -> 0-127.0.0.0:\u00a0 Network Address (or excluding 0.0.0.0 and 127.0.0.0 in respect to reserved addresses according the IETF Special-Purpose IP Address Registries from RFC 6890)\nAll 1 -> 0-127.255.255.255: Broadcast Address\u00a0(or excluding 0.255.255.255 and 127.255.255.255\u00a0in respect to reserved addresses according the IETF Special-Purpose IP Address Registries from RFC 6890)\nAdditionally the following Class A Network (Parts) are reserved according to RFC 6890 https://datatracker.ietf.org/doc/html/rfc6890#section-2.2.2\n127.0.0.0/8 loopback adresses\n10.0.0.0/8 Private-Use\n0.0.0.0/8\u00a0 \u00a0\"This host on this network\"\n100.64.0.0/10\u00a0Shared Address Space",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "question": "Write-down all addresses in Class A networks that are reserved.",
        "reference_answer": "126 Class A nets can be addressed in classful IP addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in Class A)",
        "provided_answer": "0.x.x.x -> network address\n127.x.x.x -> Loopback\n(x.0.0.0 -> Gateway in all Types of network)\n(x.255.255.255 -> Broadcast in all Types of network)",
        "answer_feedback": "Correct",
        "verification_feedback": "Correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    }
]
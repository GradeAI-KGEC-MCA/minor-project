[
    {
        "id": "42a0f468c13e47bf86e5b4a7ccb0a07d",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "due to the expected channel load being high, there is not necessarily the bandwidth available to coordinate access to the channel. thus a medium access procedure based on random access should be chosen. with random access and a high channel load also the problem for collision arises and handling of collision detection becomes necessary.\ni would recommend using csma/cd as it has (1) a low overhead and (2) utilizes the bandwith to its fullest when possible. one weakness of csma/cd is the edge case of possible long waiting times when short frames are transmitted of very long distances which renders the built-in collision detection essentially useless.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "46e8a9c5c80b420cb80b222df30db224",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would choose csma/cd. you can easily add up stations, it is cost efficient and has practically no waiting time during low utilization. on the downside, if distance increases, efficiency of csma decreases.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "1757f48dd39b4ba9acd91badebf23d07",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "csma/cd saves time and bandwidth. furthermore csma/cd is used for ethernet so it is really compatible to a lot of products. the usage of csma/cd with p-persistent csma would be nearly perfect, so the channel usage would be very high. a problem could be the maximum distance to a station.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "173c3af77e8247148277418d53926124",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "p-persistent csma.\nbecause it make full use of the channel's free time, it can relieve the pressure of the hardware. on the other hand, it has less collisions at high load.\nthe weakness is, it is difficult to set the p-parameter.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "fd66d3b8808d44759c9386c3e1d99281",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would recommend tdma with reservation, since the throughput is especially good in the contention-free period after sending the reservation requests because the data can be sent continuously without collisions and the channel is fully used. \n\nfurthermore because of the reservation concept the provisioning of the line is highly adjustable because only stations with a reservation request use the channel which is extremely good for a network which should be expandable. \n\na potential weakness is that the stations need synchronized clocks which leads to an overhead.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "1af2de9481fa471ebf4b5280fcbddb8d",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would recommend using csma/cd. carrier sense is useful when the channel has a high load since the necessary overhead gets really small in comparison to the amount of prevented collisions. cd is also useful since it reduces the wasted time after a collision which is important since high load means more collisions. the weakness of the procedure is that it scales badly with range because the maximum range is dependend on the frame size and vice versa.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "6b4ac0dc4d5a408eb6dcb804dabca637",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "my choice would be csma/cd since it enables the ability to add up stations easily and also has almost no waiting time in times of low utilization. \none downside of csma/cd is, for increasing distances, the efficiency is deacreasing.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "f6589ab387a643a5841243e5cf794151",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "for this scenario i would recommend tdma with reservation, since it can provide a high throughput in the contention-free period while offering a more flexible provisioning with the reservation.\ndue to the use of slot reservation, this mac can also provide good service in an expending network.\ntdma needs synchronized clocks on all systems for the time slots to work.\neven though the reservation window is contention based possibly leading to collisions, this section makes up only a small fraction of the transmission process.\nhowever, if in the reservation phase to much collisions happen, the slots will stay unused meaning a low utilization.\nin this case a p-persistent csma (/cd) would be a better fit, while p depends on the current load and number of stations and whether collision detection should be used, depends on the cable length.\n\nreasons against the other protocols:\npolling would need a centralized controller.\ntdma without reservation possibly wastes slots for systems, that don't have anything to transmit, and isn't as flexible to an increasing network size.\na token ring is expensive and only provides low throughput.\naloha in both forms doesn't provide good throughput in a high load network, since many collisions will happen.\nin csma networks with high load have also a poor throughput due to collisions.",
        "answer_feedback": "then why do you not choose p-persistent if it is better? correct though",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "ef6f8a313732462d9d5f4eef6cdb67ab",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "personally i would recommend token ring\npro:\n1. the token ring can guarantee a good throughput during high utilization.\n2. even all stations wants to send at the same time, the maximal waiting time is fixed.\ncontra:\n1.it required a central moniter to avoid lost token, and costs more when adding new stations.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "6ee88d77e8a84d1b8c8f7773af05cad5",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would choose a token ring mac due to its great throughput during high net utilization and deterministic maximal waiting times. however, delays may occur while waiting for a token and it being a bit more expensive than csma.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "655e8c396328431eb8c629f90024a6ea",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would suggest using the non-persistent csma procedure. first of all, a procedure with contention should be used to provide the fastest data transmission for the possibly high amount of devices in the future even with a high channel load.\n\nwith the non-persistent csma, the hardware of the sender does not have to recheck the network continuously, which is good in order to reduce the load of the not-so-powerful device(according to the given info).\nsecond, the performance of the throughput is the second-highest even for a large number of attempts per packet, which is good for a highly loaded channel.\n\nproblem: there may occur longer delays for the single devices than necessary. in example: the network was congested, the random timer is started and awaited, even though the network was free again immediately after the timer was started.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "af571dfe226a458e9cfabc89cf7f2622",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i recommend csma/cd. due to \n1.cost efficient\n2.practically no waiting time during low utilization\n\npotential weakness :if all 20  systems try to sending，the utilization will be lower.  and as  the number of systems increases, the performance will get worse.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "5f4acfd78521424994091ab9343eadcb",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i recommend using the p-persistent csma procedure. as the channel load will be high, the company would profit from the high efficiency in terms of the overall throughput of this procedure. with a low p-value, the p-persistent csma could even reach perfect throughput efficiency. also, adding additional systems to the network is simple, as the single participants in this procedure do not need to be aware of each other and it the procedure works completely decentralized. this increases the extendability and maintainability with extending scale. however, one drawback of this approach is that it introduces the p-value as an additional fine-tuning parameter that needs to be adjusted to fit the application scenario at hand, which introduces additional complexity.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "d2c4d4e3a6524f12a7fdd2e1b937cc5f",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would recommend the company to set up their lan using csma/cd. i see this medium access procedure as the most suitable for this scenario because it is cost efficient, which is great if the funding is tight, and also it is possible to connect new stations in the future without any downtime. a weakness of this procedure however is that the more the system is used, the more collisions occur and therefore, the throughput decreases. accordingly, in addition to my recommendation i would tell the company to monitor the throughput as more stations join the system. in the future, they should consider changing to token ring at some point as the throughput with this method performs better with more stations.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "4acd9c8f1d254351bb04a5300a26774c",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "i would recommend using either the non-persistent csma or the p-persistent csma with a low value for p (e.g. 0.1 or 0.05). first of all both are cost efficient (budget is tight) and using these specific csma procedures also guarantees a good throughput during high channel load. in addition to that adding new systems to the network is no problem since the network does not have to be shut down to connect additional stations to it. \none downside of this procedure would be the higher delay for the single stations.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "98b2288ecc044472b0a553400e568c7e",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "ich würde tdma mit reservierung vorschlagen,da die auslastung bei dem konkreten beispiel hoch ist und es weniger kollisionen gibt, was insgesamt für einen höheren durchsatz sorgt. außerdem soll, wenn mehr systeme dazukommen, die wartzeit einzelner systeme durch ungenutzte slots nicht zu hoch sein. daher ist es von vorteil den tdma mit reservierung zu benutzen. ein nachteil von tdma mit reservierung ist, dass durch die steigende anzahl an geräten die anzahl der contention slots steigt, was zur folge hat, dass das mehr netzwerkkapazität den contention slots zufällt.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "2ea4471f0e7f4f21a96924552f71a5d6",
        "question": "a company is planning to set up a new lan at one of their locations and is looking for an appropriate medium access procedure. however, the funding is tight so they expect the channel load to be high compared to the hardware they can provide. currently, they would like to have 20 systems sharing the channel, but it should be expandable later on. which of the mac procedures introduced in the lecture (polling, tdma with or without reservation, token ring, pure or slotted aloha, 1-persistent csma, p-persistent csma, non-persistent csma or csma/cd) would you recommend?give 2 reasons for your decision and 1 potential weakness of your recommendation in 2-6 sentences.",
        "reference_answer": "0.5 p for a sensible choice out of: token ring, p-persistent or non-persistent csma, csma/cd or tdma with reservation 1p for the drawback and 1p for an advantage.the following properties may be considered: scalability, waiting time, extendability, cost effectiveness, constraints, hardware requirements, compatibility, throughput, overhead, complexity and prioritization capabilities",
        "provided_answer": "csma/cd:\n- attached systems, that are not sending for a long time, don't slow down the network. so the heavy load can be handled well, if only few systems at a time need a high transfer speed.\n- new systems can easily be added without altering the procedure of the router, like in polling or token ring. \n\ncon: \n- if the systems need to have some real time requirements, the procedure can't ensure it. in this case you could implement a tdma with reservation every given time only for this kind of data transfer.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 3.5,
        "normalized_score": 1.0
    },
    {
        "id": "1b127dabe7044ce18629311d4b86613e",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "um die bandbreite des überfüllten netzwerks perfekt auszunutzen, sollte binary encoding verwendet werden. dieses ist einfach und günstig zu realisieren und ermöglicht 1 bit per baud. voraussetzung ist dabei der perfekte takt der nutzer, da binary encoding kein self-clocking-feature besitzt. (diffenrential) manchester encoding ist komplexer und ermöglicht nur 0,5 bit per baud.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "03eb4af099764978934486bddfbdf35d",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding\n1. 3 users have perfect clocks. they  don't need a good \"self-clocking\" feature.\n\n2.binary encoding is simple, cheap and has good utilization of the bandwidth (1 bit per baud)， all users generate more traffic than the link’s capacities， so we need better  utilization of the bandwidth than manchester encoding and differential manchester encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "9396e88542694cc38ef358db103c182d",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "because it is given that all users have pefect clocks, we can use a simple and cheap binary encoding technique. it will also be a very efficient use of the given bandwidth.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "65c8f882fb3349d8a6bd3003fb2aae47",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i think, binary encoding should be used in this network. the reasons are following:\n1. all users are interconnected and have perfect clocks, so we don't need to worry about synchronization problem between receiver and sender, i.e self-clocking feature is not necessary in this case.\n2. to mitigate network congestion causing by excessive traffic, we need to improve bit rate. using binary encoding can provide double wideband compared to manchester encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "fc515f16584c4e13af24aa9a4f456ea6",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "in the described scenario binary endcoding should be used, because it provides a higher data throughput than manchester encoding for a given baudrate. the missing \"self-clocking\" feature is no problem, since all users have perfect clocks.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "51577070b985490781b5520cb368833e",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i would use a binary encoding as the bandwidth is limited. binary encoding makes good use of the given bandwidth as it has 1 bit/baud, with both types of manchester encoding having only 0.5 bits/baud. additionally given a perfect clock the manchester encodings are not needed, as their main advanteges are self clocking in unsynchronized networks.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "e86cec25bb9d414abd21a43109bc89af",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding because the link's capacities is limited in this senario and differential/manchester encoding require more bandwidth (0.5 bit / baud). each user have the perfect clock, therefore encoding with binary encoding is possible in this case.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "b623b29816e44591b3f7a6318094ffe5",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "i think they should use binary encoding. compare to other encoding techniques, binary encoding has good utilization of bandwidth. also, the encoding is simple and cheap.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "47c055ab51684068b8ba8080108ddaff",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "for the given scenario binary encoding should be used.\nsince the users all have perfect clocks, the encoding does not need to to provide a self clocking feature.\nbecause the network is often congested and the links are more than saturated, a encoding with a high baud rate is preferable.\nhowever, if the network is prone to interference and noise, manchester encoding or differential encoding could be the better choice, even though it provides only half the baud rate.\nmanchester encoding could provide the benefit of \"built-in integrity codes\". this means you could identify overlapping transmissions, that interfere with each other.\nsince noise is not stated in the scenario and assuming, that a mechanism for medium access control is used to prohibit overlapping transmissions, my encoding scheme of choice would be binary encoding.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "d34687d61ceb4387b779a98e5aef98e4",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding:\n- because the users have perfect synhronized clocks, they can aggree on a time window that is used to send one single bit. so the self clocking of the manchester encoding is not needed.\n- because we have only 3 interconnected users, we also don't need the high susceptibilty to noise, that would bring the differential manchester encoding",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "e238601a5c2a420f83e59ad3a0021c44",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the binary encoding technique should be used. because the chosen scenario doesn't need a self-clocking mechanism. the binary encoding also provides a good utilization in the network.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "de290ae492fb49749fa2d98ef2ae2288",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding should be used here. \nthere is no need for \"self-clocking\" when the users have perfect clocks.\nit utilizes the full bandwith.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "fa216ddcd8064e5a84a7ddc46e9fb53b",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "because it is given that all users have pefect clocks, we can use a simple and cheap binary encoding technique. it will also be a very efficient use of the given bandwidth.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "45b4c6f085c549ad8db708b795496861",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding is the best option in my opinion as it offers a good utilization of the bandwidth which is especially useful as the network is often congested and furthermore because the local network has a perfect clock it doesn't need self clocking. another reason would be that it's quite simple and cheap to implement.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "a3367e2cb8a84cdca16fd7a7b3addcc1",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding.\n1. since all users have perfect clocks, self-clocking isnt needed.\n2. good utilization of the bandwidth, so congestion is less of an issue.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "74e9c868295e4906916441af8c64ce34",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "since all users have perfect clocks. the binary encoding technique would be the most suitable one. on the strength of its efficient use of the bandwidth, this type of encoding will be very practical in congested networks.\nfurthermore it is easier and simpler method to encode the bitstreams.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "6a8024ab3bfa483abce8d5556167d5ea",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the encoding technique is binary encoding. \nall users have perfect clocks, so no need for \"self-clocking\". \nbinary encoding has good utilization.",
        "answer_feedback": "need to specify which utilization.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "c12ba353a4c5463b9d87681261701297",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary encoding should be used, because this has the highest baud rate in comparison to the other and so we can keep the congestion the lowest. further we can implement with the bits on a higher layer a congestion control.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "7684909cebef44928e0555f5309eee5a",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "binary coding. \nbecasue if the clocks are perfect in the local newtwork, there in no need to do self-clocking. and the binary coding has better utilization (almost 200%) to bandwidth than other techniques, which is important when the traffic is heavy.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "325d60e127f74e3e91aae6927621e096",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "bianry encoding, since it has good utilization of bandwidth which could solve the traffic problem. on the other hand, the 3 users have already perfect clocks, the no \"self-clocking\" feature of binary coding could be neglected.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "b8b6a6bc5b254f1fbbd90143350ec4ee",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "with perfect clock we can use binary encoding as the problem with  long sequence of 0/1s wouldn't cause clock synchronization issue. moreover, it's simpler and makes an efficient use of the bandwidth which could be helpful with heavy network traffic.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "fcdaabb02ec243e38aa7ac4a225de344",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "56.95 seconds.\nthis is m/m/1/n finite buffer case and n = 10. the question is asking about the time length that the system to be in a state in which there are less than 10 packets waiting in the queue, which also means that system is not full. therefore, we should calculate the probability that system is full first, which is pb = pn = p10. then, we can know the probability that less than 10 packets waiting in the queue which is 1-p10. in the case, we monitor exactly one minute after the system reaches equilibrium. with the probability (1-p10) we get, we would expect 56.95 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "70b89f0848d44a3eab45851d472843c6",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "with the poisson process, we can calculate p0 to pn. if p0 = 0.5, this means, 50% of the time the system is empty. \nin this exercise, we have a λ=9, µ=10 and n=10. the blocking probability (the probability that the system is full) p10 is 0.051. so, 5.1% of the time, the buffer is full. the complementary probability (the buffer has less than 10 packets waiting) is 0.949. as a result, in one minute we expect that in 0.949*60s = 56,94s less than 10 packets are waiting in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "4695d50b6a45458fb567dd42386176d0",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "first we note down some parameters: there is\na buffer size of n = 10,\nan arrival rate of λ = 9 packets per second,\na serve rate of μ = 10 packets per second,\na utilization of ρ = λ / μ = 0.9\n\nnow we can use n and ρ with the very last formula on slide 30 to calculate the probability p_n of the system being in a state where there are n packets waiting in the queue. we're interested in the sum of all probabilities except for the case n = 10, i.e. we can either calculate p_0 + p_1 + ... + p_9 or simply calculate 1 - p_10. finally we have to multiply the result by 60 seconds to find out to how many seconds of a minute this percentage corresponds to. so the system spends\n(1 - p_10) * 60 seconds = circa 56.951 seconds\nin a state in which there are less than 10 packets waiting in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "bcf8950636d34fbdb00219fa6a7e31b0",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the given example is a finite buffer case, so a m/m/1/10 queue. with the given numbers, the utilization rate is 9/10 = 0,9. so if on an average 9 packets arrive and 10 can be served, there should never be 10 packets waiting in the queue. however, by calculating the blocking probability (the probability that the system is full) with the given formula, pb = 0,0508 which is ca. 5%. so there is a 5% probability, that the system is full and 10 packets are waiting in the queue. for 1 minute (60 seconds) 5% are 3 seconds. if i say that the system is in a state with 10 packets waiting in the queue for 3 seconds, i would expect the system to be in a state with less than 10 packets waiting for 57 seconds.\nif i take a look at the system throughput and insert the values in the formula, the result is 8,5428‬. this means 9-8,5428 = 0,4572 packets don't make it per second and therefore 0,4572*60 = 27,432 packets are dropped per minute. if 9 packets arrive per second, 27,432/9 = 3,048 seconds in which the system is full. this leads to the same conclusion as above, that the system is for ca. 57 seconds in a state with less than 10 packets waiting.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation. the additional validation is also correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "eca315578cfa4cb18d9837f814212966",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "p10 = ((1 - rho) * rho^n) / (1 - rho^(n+1)) = ((1 - 0.9) * 0.9^10) / (1 - 0.9^(11)) = 0.0508\n\nseconds with 10 packets in queue = p10 * 60 = 3.048\n\nseconds with less than 10 packets in queue = 60 - 3.048 = 56.952\n\nso the system is expected to have 10 packets in it's queue for about 3 seconds and less than 10 packets for the remaining 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d572f3aab20c4ff98003d8347dfc4c08",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "from the problem we recognise that the number of packets arriving is lambda=9 pkts per second and number of packets being serviced is µ=10 pkts per second. dividing the lambda by µ gives us the utilization. in the case of an equilibrium in a finite buffer, the probability of having less than 10 packets can be calculated from the formula of the blocking probability (slide 31). as this formula would give us the probability of the system being full, we would then need to subtract it from 1. finally, this would then be multiplied by 60 (as 1 minute contains 60 seconds) to give the number of seconds in which we expect the system to have less than 10 packets in the queue. the calculated blocking probability is 5,08% and therefore the probability of the system not being blocked 94,92%. 94,92% of 60 seconds is 56,952 seconds which is the estimated time of the system having less than 10 packets in the queue.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f5dd678d42324d8caa83e929c9b1a568",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "the likelihood of the less than 10 packets waiting in the queue is one minus the blocking probability, which is about 5,08%. \ngiven this information, 94,92% of the time, you would expect less than 10 packets to wait in the queue. \nin one minute, this would be about 57 seconds.",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "06534fe07bfc4a6f815324c6cc291e6c",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "57s\nthe average arrival rate is 9 and the average service rate is 10. according to the limited buffer size 10 we can calculate pb, which means the probability that the system is full. so the probability that in the state there are less than 10 packets is 1-pb. based on the 1 minute monitoring time we can get the result 57s",
        "answer_feedback": "the response correctly states the non-blocking time and provides a valid justification for the calculation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "91b04f793e6748bea48033599ec810b7",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "the routing could have poor performance if the traffic volume change over time. it could also have a high delay when the shortest path is high-loaded.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6a6ad94a71c74b318b094cba260cf616",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "if all possible paths have the same load in the beginning (like a->b, a->e, a->d), then it can not be determined which path it should take for sending the packet, since all paths have the same quality, so the process may fail already. furthermore, one can argue with the fact, if both paths c->f and e->i have a current utilization of 0 packets/bytes, the packet would not even be sent to the other half of the network, which would lead to an infinite loop in the first half of the network. the destination, in our case g, therefore can't receive the packet at all.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "91d49b8219684495ba7516f6d5fd239f",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "on a network with strong load fluctuations, finding the best path can create a ping pong effect, when the load on a chosen path increases, maybe causing the routing to not terminate. this also can result in flipping paths. this is called oscillation.additionally, utilization with sent packets/bytes is not relative to the link capacity, meaning, e.g., a half used 10gbit/s link would be less likely choosen to a fully used 1gbit/s link.\nin low latency scenarios with low bandwidth need, a connection with many hops but with low current load would be preferred, resulting in a probably higher latency.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "5ee3f0d7e4a64246b51b60e8fc3d37d0",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "this would lead to problems, since this metric would lead to an oscillation of the loadadditionally, it would be a lot of computational overhead, since the paths have to be constantly evaluated",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "25ad584cda3c4db8bb9538cbb45b09a0",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "according to slide 78 current \"load\" should not be used as a metric because it may lead to an \"oscillation\" of the load (meaning sender flipping paths), which should be avoided. this would lead to frequently distribution of the local information all is.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "561f6744f9994955963f6e1477686c3e",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "the \"load-metric\": choose the path with the lowest utilization would lead to an oscillation between different path options. everytime a path is choosen and used afterwards its utilization goes up and thus a differet path is chosen. this requires a lot of computational overhead since the path will be constantly evaluated.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "50b96a3db7f440a4869531640d5aa5f9",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "the problem is in calculating the \"distance\" between nodes, which leads to \"oscillation\" of the load because of the links cf and ei.furthermore each node has a cpu overhead because of the changing routing tables due to \"oscillation\".",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "72ee96afa41e48f5ad9b077527740dab",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "yes, taking the current load into account can lead to route flipping, i.e. packets of the same connection take different paths to the same destination.\nif such a flip occurs while nodes a and g are communicating with each other, a higher delay due to packet reordering might be the case or - if the receive window is too small - retransmissions may be necessary.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b88e7d542d204a59a81ef1534fa46e81",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=d doesn't foward a message from a to f, because f doesn't receive unicast packets via d.\nhop 2:\n(b,e,forward)\n(c,f,drop)<=f doesn't foward a message from a to g, because g doesn't receive unicast packets via f.\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=vertex h has only one neighbor from which it got the message, vertex h does not forward the message.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "303709f1e1e94fff947619b67042c8ea",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= c will forward to f because c has a shorter distance to f than d to f\nhop 2:\n(b, e, forward)\n(c, f, drop) <= e will forward to g because e has a shorter distance to g than f to g\nhop 3:\n(e, g, forward)\nhop 4:\n(g, h, drop) <= h can not forward anywhere",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "9017711037734175bc522de6d6fc5444",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:(a, b, forward)(a, c, forward)(a, d, drop) <= d knows that either c nor f are routing to a over dhop 2:(b, e, forward)(c, f, drop) <= f knows that either c nor d or f are routing to a over fhop 3:(e, g, forward)hop 4:(g, h, drop) <= h has no neigbors except g (no links except the incoming link)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "a4d1796dacc54d6eb882c460e33fc628",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop)<=because f does not forward a broadcast packet from a to d)\nhop 2:\n(b,e,forward)\n(c,f,drop)<=because g does not forward a broadcast packet from c to f)\nhop 3:\n(e,g,forward)\nhop 4:\n(g,h,drop)<=because there is no more receiver after h",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "94f947b3d24d456f9d3f22bc0308f6d6",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a,b,forward)\n(a,c,forward)\n(a,d,drop) d will not forward the packet, because a is the origin and d is not part of a unicast route a-c or a-f.\nhop 2:\n(b,e,drop) b is origin, routes g-a, f-a, c-a do not go through e(c,f,forward)\n\nhop 3:\n(f,g,forward)\n\nhop 4:\n(g,h,drop) g is origin of the packet, no further neighbors",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "46d803aa9ed1493596a31c0570a1e5ed",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= (c to f is shorter than d to f)\nhop 2:\n(b, e, forward),\n(c, f, drop) <= (e to g is shorter than f to g)\nhop 3: \n(e, g, forward)\nhop 4: \n(g, h, drop) <= (h is the last node)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "4297612a576c44d18edcd254ee74c4ca",
        "question": "consider the following topology from the exercise. this time, node a wants to distribute a packet using reverse path broadcast (rpb). assume that every is knows the best path to a and also whether they are the next hop of their neighbors on the unicast path to a.please list all the packets which are sent together with the information whether they will be forwarded or dropped at the receiving nodes. use the following notation: (sender, receiver, drop) for dropped and (sender, receiver, forward) for forwarded packets. please group these tuples according to the number of hops the packets have travelled so far. for dropped packets, please specify the reason why the packet has been dropped in a few words.example for the notation:hop 1:(c, a, forward)(c, b, drop) <= describe reason herehop 2:(a, d, drop) <= describe reason here",
        "reference_answer": "hop 1 :(a, b, forward),(a, c, forward), (a, d, drop) <= reason: remaining neighbors c and f do not use d as the next hop to get to a hop 2 :(b, e, forward),(c, f, drop), <= reason: remaining neighbors d, e, g do not use f as the next hop to get to a hop 3 :(e, g, forward)hop 4 :(g, h, drop) <= reason: h is only connected to g, packet is not forwarded to incoming link",
        "provided_answer": "hop 1:\nfrom a:\n(a, b, forward)\n(a, c, forward)\n(a, d, drop) <= forward over b is not part of unicast a > c and a-> f\n\nhop 2:\nfrom b:\n(b, e, forward)\nfrom c:\n(c, f, drop) <= forward over c is not part of unicast a -> d, a->e and a-> g\n\nhop 3:\nfrom e:\n(e, g, forward)\n\nhop 4:\nfrom g:\n(g, h, drop) <= only link is the receiving link",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 2.5,
        "normalized_score": 1.0
    },
    {
        "id": "1d34f12206124c58bd90602a41ab4f47",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporarily valid tsap \n+ easy to implement (just need a new tsap per connection that can be chosen during handshake)\n- cant use temporarily valid tsap because server uses \"well-known\" tsaps that cant change\n- only very limited tsap space \n\n2. identify connections individually\n+ multiple individual (distinguishable) connections are possible in parallel over the same tsap \n- endsystems must store the chosen sequence numbers for each connection for the duration of the whole connection\n- only for connection-oriented systems\n\n3. identify pdusindividually\n+ high flexibility, due to fine-grained detection of duplicates independent of a connection or tsap\n- high seqnr space needed (prerequisite: how big should the initial space even be? is the connection alive for years or just seconds?) -> higher usage of bandwidth and memory",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "7592b9678e4e4297be9ab699c7c1d57c",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "method 1: to use temporarily valid tsaps\ngenerate unique (transport) service access point (tsap) for each communication and they are valid for one connection only\nadvantages:\nyou can always generate new tsaps disadvantages:\nsome tsaps are standardized(\"well-known ports\") and cannot be usedmethod 2: to identify connections individually\neach connection is assigned a new sequence number and endsystems story assigned sequence number and remember them\n\nadvantages:\nduplicates from another connection with a  sequence number doesn't interact with other connection with a different sequence number.disadvantages:\nonly works with connection-oriented servicemethod 3: to identify pdus individually: individual sequential numbers for each pdu\n\nadvantages:\nbetter usage of bandwidth and memory because you have individual sequence numbers for each packet and they almost never get resetdisadvantages:\nsequential number range depends on packet rate and packet probable \"lifetime\"",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "0e3bf1b60c08493184d946e8f759bd8a",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporarily valid tsaps\nadvantage: simple to implement almost no additional overhead\ndisadvantage: “well-known” tsap's exist with which the server is addressed, so changing tsap's is not possible in this situation\n\n2. identify connections individually\nadvantage: distinction is made at connection level and not at packet level, so less overhead\ndisadvantage: the end system has to reliably keep a record of connecion-seqno pair\n\n3. identify pdus individually\nadvantage: able to handle duplicates and ordering of packets \ndisadvantage: the range of sequence numbers could be insufficient and cause duplicates if the packet rate is very high and/or the \"lifetime\" of packet is very long.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "af7ff5ad885e4c51947734d5716fcf24",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "there are two separate problems that need to be considered here: duplicates within a single connection or duplicate connections. as duplicate packets within a connection are easily handled by seqeunce numbers and the focus of the lecture seemed to be on duplicate connection, i will focus on those.\n1. different port(tsap) for each connection: kind of defeats the purpose of ports as multiple ports would be bound to a single thread. also servers that communicate on a well known port cannot use this methode. solves the problem of duplicate connections without using additional bandwidth\n2. count prior connections: requires endsystems to keep track of this counter. low effort as this would only be required in the connection establishment stage\n3. count prior packets: requires a realtively high bandwidth and memory. could replace the already used sequence number within the protocol to avoid for example out-of-order packets",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "a2bfbb541ba74b7da2e05811f1ff2a3f",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "one method to resolve the problem of duplicate packets is to use temporarily valid tsaps for only one connection. on paper, this reduces the problem of duplicates since each tsap is only used once and therefore reduces the number of duplicates to the ones occuring in that one connection. however, a disadvantage is that some tsaps always exist and are well-known. hence, it is not possible to realize this approach and generate temporary tsaps for each connection. \n\nanother method would be to make connections unique and identify them individually. an advantage is that duplicates from different connections do not occur anymore since each is unique. however, this is not possible with connection-less systems. additional knowledge is needed to realize this approach since end systems need to remember the sequence numbers even after being turned off so that they remain unique for each connection. \n\nthe third approach to solve duplicates is to identify each packet individually with unique sequence numbers. an advantage is that it easily allows the receiver to identify and discard duplicate packets since it can just compare sequence numbers to check if it already received a packet with that number. however, this approach requires that the range of sequence numbers are chosen wisely so that they do not repeat before each packet is delivered and processed. furthermore, this approach requires more bandwidth/memory due to the overhead of the sequence numbers.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "a80eb0d153f842bca702924053e2e8cf",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "-1- to use temporarily valid tsaps (unique ports).\nadvantage:  it can eliminate the need for duplicate because we use unique port each time.  \ndisadvantage: require large number of unique ports (names) for some period of time.\n\n-2- to identify connections individually.\nadvantage: git rid of duplicate between different connections by assigning each of them a sequence number.   \ndisadvantage: end systems must be capable of storing  sequence numbers (need storage for that ) as well as it is more complicated because if the connection is lost we need to remember what happened in the past (store information)\n\n-3- to identify pdus individually:\nadvantage:  assign a seqno for each packet for certain time, after this time i can reuse this seqno and drop  any duplicate packets. \ndisadvantage: higher usage of bandwidth and memory",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "eaccfaa209814d65b3c41ec947645b48",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. temporary valid tsaps\nfor each new connection, a new, unique, temporary valid tsap only for this connection is created and thrown away at disconnection and never used again.\nadvantage: simple and effective (transport process just can't be reached by delayed duplicates)\ndisadvantage: does not work if the service should be reached via a designated, known tsap.\n2. identify connections individually\neach connection is assigned a unique identifier and identifiers that have already been used are remembered by the end systems, so that when the connection is initiated it can be checked whether the identifier has already been assigned before (= duplicate).\nadvantage: designated tsaps possible (e.g. for well-known services).\ndisadvantage: storage requirements: end systems must permanently store the necessary information and have it available again, for example after a shutdown or crash.\n3. identify pdus individually\neach pdu is assigned an individual sequence number.advantage: fixed tsap possible, no persistent backup of information necessary.\ndisadvantage: more complex, lifetime of packet must be estimated well, because too small a value range for identifiers (sequence number) leads to duplicates not being recognized.",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "10a979564d4a4f53a43702382f7df8fc",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps:\n-need large numbers of names because it should be unique -> not usable in reality\n+very potent, because tsap is valid for one connection only\n\n2. to identify connections individually:\n-endsystems must be capable of storing this information\n+if there is a duplicate from another connection they don't interact with each other\n\n3. to identify pdus individually:\n-perfect time has to be known by everybody\n+one can reuse the seqno after a certain time",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "c5a3b94bfcaf42a49038567b8f29b62f",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. using temporarily valid tsaps:\nthis method uses tsap that are valid for only one connection which makes it easy to identify duplicates. this method is not always possible, e.g. with process server addressing the server needs a designated/known tsap\n\n2. identify connections individually:\neach connection is assigned a new seqno and end-systems remember already assigned seqno. it does not work with connectionless oriented systems and end-systems have to be capable of storing the already assigned seqno. it's easy to implement this method.\n\n3. individual sequential numbers for each pdu:\neach pdu gets a seqno assigned which results in higher usage of bandwidth and memory. they are enough seqno so that they basically never get reset.",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "00739c93a61043f48a56c2dfcd6b0941",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. to use temporarily valid tsaps\n   + easiest realization\n   - too many tsaps will quickly use up all the limited port numbers\n2. to identify connections individually\n   + each individual connection has a individual sequence number\n   - assigned sequence number are saved in endsystems. if endsystem switched off, the information disappear\n3. to identify pdus individually\n   + sequence numbers basically never gets rest\n   - higher usage of bandwidtrh and memory",
        "answer_feedback": "the response is correct",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "d4aa496f5e024dcd908145800762d269",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "1. use temporary valid tsaps: +tsap valid for one connection only -not always applicable because of process server addressing method\n2. identify connections individually with unique sequence numbers: +unique identification of connections remembered by ess -ess must be capable of reliably storing this information\n3. identify pdus individually with individual sequential numbers for each pdu: +seqno basically never gets reset -higher usage of bandwidth and memory\n(f.23, 24)",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "887704ed04b8485db2f0c3b83355561a",
        "question": "discuss 3 methods (each with at least one advantage and disadvantage) that address the problem of duplicate packets on the transport layer in a connection-oriented service.",
        "reference_answer": "1. to use temporarily valid tsaps -method: -tsap valid for one connection only -generate always new tsaps -evaluation -in general not always applicable:-process server addressing method not possible, because -server is reached via　a designated/known tsap - some tsaps always exist as \"well-known\" 2. to identify connections individually -method: -each individual connection is assigned a new seqno and -endsystems remember already assigned seqno -evaluation -endsystems must be capable of storing this information -prerequisite: -connection oriented system (what if connection-less?) -endsystems, however, will be switched off and it is necessary that the information is reliably available whenever needed 3. to identify pdus individually: individual sequential numbers for each pdu -method: -seqno basically never gets reset -e.g. 48 bit at 1000 msg/sec: reiteration after 8000 years -evaluation -higher usage of bandwidth and memory -sensible choice of the sequential number range depends on -the packet rate -a packet's probable \"lifetime\" within the network",
        "provided_answer": "one possibilty to adress the problem of duplicate packets is to use temporarily valid tsaps. these tsap are valid for one connection only and are unique for this connection. some ports are relied to as well-known tsaps, which can cause duplicates again.\nanother possibility is to identify connections individually with a seqno. so duplicates are avoided by assigning a seqno to every connection. a disadvantage is the need to store this information in the endsystems even if they are switched of.\nanother possibility is to identify the different packets individually. so a sequential number is assigned to each pdu individually. this makes it easy to identify duplicates. a disadvantage is the higher usage of memory and bandwidth.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 1.5,
        "normalized_score": 1.0
    },
    {
        "id": "f973e386eb414e06bf1ad307200edccf",
        "question": "in the lecture you have learned about congestion control with tcp. name the 2 phases of congestion control and explain how the congestion window (cwnd) and the slow start threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences .",
        "reference_answer": "slow start (cwnd less than ss_thresh): \nin the slow start phase, cwnd is incremented by one every time a segment is acknowledged. this results in an exponential growth as cwnd is essentially doubled after each round trip time (rtt). this is done until either a packet is lost or ss_thresh is reached. when cwnd >= ss_thresh, the congestion avoidance phase is entered. \nafter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. then cwnd is reset to 1. \n\ncongestion avoidance (cwnd >= ss_thresh):: \nin the congestion avoidance phase, cwnd is incremented more slowly. there are different incrementation strategies, but they usually grow linearly, e.g. only increment cwnd by 1 after all sent segments have been acknowledged. this is done until a packet is lost. typically, this means that cwnd less than ss_thresh and the slow start phase is entered again. \nafter a packet is lost / congestion the following adaption is made in both phases: ss_thresh = cwnd / 2. then cwnd is reset to 1.",
        "provided_answer": "in congestion control with tcp there are the phases slow start and congestion avoidance. during the slow start phase the number of segments sent is doubled (cwnd *= 2) starting from cnwd = 1 packet until either a timeout is detected or the ss_tresh value is reached. when the ss_tresh value is reached the phase changes from the slow start phase to the congestion avoidance phase in which the number of sent packets is iteratively increased by 1 (cwnd += 1) until a timeout occurs. if a timeout occurs in one of the two phases the ss_tresh value is set to half of the current cwnd value and the packet transmission starts again with the slow start phase with cwnd = 1.",
        "answer_feedback": "the response is correct and complete as it provides the phases' names and changes in the value of the congestion window and threshold correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f5c948e8db1f4b2bb40636f0c730bf59",
        "question": "in the lecture you have learned about congestion control with tcp. name the 2 phases of congestion control and explain how the congestion window (cwnd) and the slow start threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd congestion avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "conjestion control with tcp has 2 phases: 1) slow start and 2) conjestion avoidance\n\nslow start -> after initialization, in each step, cwnd is increased exponentially (2^x), until it reaches(or surpasses) ss_thresh.\n conjestion avoidance -> then, it starts increasing only by 1 in each step.\nif we receive a timeout (congestion), the process starts again, but this time we set new ss_thresh = cwnd / 2 and cwnd = 1.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "03552f08b6cf48fb958205772dbb9728",
        "question": "in the lecture you have learned about congestion control with tcp. name the 2 phases of congestion control and explain how the congestion window (cwnd) and the slow start threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd congestion avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "phases of congestion control:\n1) slow start\n2) congestion avoidance\ncwnd is incremented by one when a segment is acknowledged and\nincreasing (exponentially bc more and more segments are sent in same time interval) until it reaches ss_thres or until a packet is lost. \nwhen ss_thresh is reached only one segment is sent per roundtrip time-> cwnd increses not as fast as before.\nwhen congestion occurs ss_thres is reduced by 50%of cwnd and cwnd is reset to one and slow start is repeated until proper sending rate is discovered.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e3fbd9b2d6ab4ecaa681397b61d71746",
        "question": "in the lecture you have learned about congestion control with tcp. name the 2 phases of congestion control and explain how the congestion window (cwnd) and the slow start threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd congestion avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "after the initialization, the \"slow start\" phase is entered. the cwnd is increased for every acknowledged packet, leading to an exponential increase. when cwnd >= ss_thresh, the \"congestion avoidance\" phase is entered in which the cwnd is only increased by one in every (error-free) roundtrip time. whenever a packet is lost, the ss_thresh is set to cwnd/2, cwnd to 1 and the \"slow start\" is entered again.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "85c3ef3ae5ee4fb1b16aa96c0dcdd995",
        "question": "in the lecture you have learned about congestion control with tcp. name the 2 phases of congestion control and explain how the congestion window (cwnd) and the slow start threshold (ss_thresh) change in each phase (after initialization, where cwnd = 1 and ss_thresh = advertised window size) in 1-4 sentences total.",
        "reference_answer": "slow start: ss_thresh is constant, increment cwnd by one every time a segment is acknowledged until ss_tresh is reached, then slowed increase of cwnd congestion avoidance: cwnd is reset to 1 after adjusting ss_tresh = cwnd / 2",
        "provided_answer": "the first phase is called slow start and there cwnd is initialized to 1 and increases exponentially fast (for each acknowledged segment: cwnd++) as long as  the congestion window is below the threshold and the acknowledgements arrive before their timeouts. once the window size exceeds the threshold, the congestion avoidance phase starts and there the congestion window grows lineary (incremented by one). in both cases, in case of a timeout, the threshold is set to half the value of the current congestion window and cwnd = 1.",
        "answer_feedback": "correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "76721a698a8b48aaa23b358a581e33c7",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "least probable -> b -> c -> a -> most probable\n\nevent b is a fixed sequence, so there are no variations possible to increase the likelihood of the event happening. it is therefore the least probable of the three events.  \nevent a has to be more probable than event c, because it includes all results of event c, and more.  \nc's sample space is a subset of a's sample space, and b's sample space is a subset of c's sample space, meaning that a is the most likely event and b the least likely.\nwith events a and c being more probable than event b, and event a being more probable than event c, the order is clear.",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "63e22be75c7c496cb9ab06e3d369e10d",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "least probable -> b -> c -> a -> most probable\nb: there is only one case of all possible sequences where event b occur. \ncalculation: p(b) = 0.6^3*0.4^3 = 0.014\nc: if event b occurs, event c occurs too. additionally event c includes several more cases (e.g. htthht)\ncalculation: p(c) = 6 over 3 * p(b) = 0.276 \na: event a includes every case of event c. additionally event a includes several more cases (e.g. hhhhtt)\ncalculation: p(a) = sum_x=3_n=6 (6 over x * 0.6^x * 0.4^(1-x)) = 0.821\nthe exact probability of h is not relevant in this case (except probability of h is 0 or 1 where the probabilities of some or all events becomes equal).",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "becc5f5e196f40238a88c56d6130983e",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "you can calculate the probabilities according to the binomial distribution.event b: p = 0,013\nevent c: p = 0,2765\nevent a: p = 0,82",
        "answer_feedback": "the response does not explicitly state the order of the events but it contains the correct probabilities of all events which are sufficient to identify the correct order.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "87d77b04bef64bdf829d397bbf89a35e",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "least probable to most probable \nb -> c -> a \n\nb: 0.6^3*0.4^3 = 0.013824\nc: (6 ncr 3) * (0.6^3*0.4^3) = 0.27648\na: p(x>=3)= (6 ncr 3) * (0.6^3*0.4^3)+ (6 ncr 4) (0.6^4*0.4^2)+ (6 ncr 5) * (0.6^5*0.4^1)+(0.6^6*0.4^0) = 0.8208",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "ba1e1b0f3b8d4a29a578a285f1f09adf",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "b → c → a\n    b includes only the sequence hhhttt.\n    c includes all sequences, where there are 3 h’s. in particular the\n    sequence contained in b.\n    a includes all sequences, where there are at least 3 h’s. so in\n    particular also all sequences contained in c.",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d9d28267be104404a93bc2b56eebf732",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "least probable --> most probable\nb,c,a\n\np(b) = 1 * 0,6^3 * 0,4^3 = 0,0138\np(c) = (6 over 3) * 0,6^3 * 0,4^3 = 0,2765\np(a) = p(k=3)+p(k=4)+p(k=5)+p(k=6) = 0,8208",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b3ed66e744ee47d4848f081e44147029",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "event b -> event c -> event a. if we were to draw a decision tree for the six throws, we could count the number of paths that fulfill each condition. condition b would only have a single path, because it has a precise outcome attached to each of the throws. if we compare events a and c, we will notice that c describes a subset of a, thus having fewer paths to fulfill the condition. every path with exactly three h’s is included in event a, but the paths that result in 4, 5 or 6 h’s are neglected for event c.",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6acb4cedd5174798979bc452456a9329",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "event a:\n- the number of h’s follows a binomial distribution with parameters n=6 and p=0.6\n- p[y>=3] = p[y=3] + p[y=4] + p[y=5] + p[y=6]\n- p[y>=3] can be calculated as follows: ((6 choose 3)*0.6^3*(1-0.6)^(6-3))+((6 choose 4)*0.6^4*(1-0.6)^(6-4))+((6 choose 5)*0.6^5*(1-0.6)^(6-5))+((6 choose 6)*0.6^6*(1-0.6)^(6-6))\n- the probability for event a is 0.8208\n\nevent b:\n- the probability that the coin flip results have a specific order is just the product of the probabilities of each desired result\n- p[hhhttt] = 0.6^3*(1-0.6)^3\n- the probability for event b is 0.013824\n\nevent c:\n- p[y=3] = (6 choose 3)*0.6^3*(1-0.6)^(6-3)\n- the probability for event c is 0.27648\n\nhence, the order of the events is b,c,a. this makes sense because b is the most specific event and a the most general.",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "9b00eddbeb3645a6abf0f639fe5f4579",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "p(event b) is  less than p(event c)and p(event c) less than  p(event a)\nevent a is the most generic event, whereby event b and c are subsets of the probability set a. therefore, if event b or c occur, a also occurs. this makes a the most probable event. the same logic applies to c and b, whereby c is a more generic (and therefore probable) event than b.\nin detail: b occurs if the sequence hhhttt happens. this event has exactly three h's (and three t's). therefore, this event also includes event c (\"exactly three h’s\"). but, the set of valid sequences for c is bigger than c, i.e. with sequences like hththt. the sequence of the h's doesn't matter in c. furthermore, event a is also always true if c is true. but the set of a is bigger, since events like hhhhht are only in a and not in c.",
        "answer_feedback": "the response correctly answers the order of the events with appropriate justification.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "5f294cda98324fda84e0ca390670124d",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\n-this service has no flow control and the data unit does not get acknowledged from receiver. so there are no timeouts.\nconfirmed connectionless service:\n-this service has no flow control and the data unit does get acknowledged from receiver. so there could be timeouts and retransmits.\n\nconnection-oriented service:\n-this service has flow control. is implemented in a 3-phased communication.\n1. connection\n2. data transfer\n3. disconnection",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "5735037e9a4e476ab99117dade0cb730",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "-unconfirmed connection less service\n-confirmed connection less service\n-connection-oriented service \n\nfor unconfirmed data is send by data request (data.req) and receiver gets the data stating an indication.\nthe data is send immediately on the contrary to the connection-oriented service. in unconfirmed conn. less service, you have to expect that \nthe sent packet arrives but you have no feedback acknowledge-signal (ack) whether the packet arrived. \n\nfor confirmed conn. less service, when data is send via data request and arrived (data indication), the receiver answers to the sender by an \nacknowledgement (ack) , so there is a feedback signal stating that data arrived successfully. \n\nso far (for unconfirmed and confirmed connection less service), data is send and acknowledged (for confirmed conn. less) immediately. \nthere is no difference for connection, data or disconnection phases. by using connection-oriented service, you have requests and indications for connection\nestablishment, data transfer and the disconnection. instead of just sending data, you send a request first for establishing a connection, then\nthere is an indication (=able to receive) on the receiver and the receiver sends a response back, after that the sender has a confirmation.\nthere is the same principle for the phases 'data transfer' and 'disconnection'. \nwith connection-oriented service the system is able to send more than 1 bit bidirectional\nbetween sender and receiver and vice versa.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "811b7a820069414bb4157178acbfb298",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "1.\tunconfirmed connection less service: has no flow control, connect or disconnect; sender’s frames are transmitted as it is without taking in account possible loss during transmission with no acknowledgement from receiver. suitable with communication channels with very low error rate.\n2.\t confirmed connection less service: sender’s transmitted frames get acknowledged by receiver, may result in duplicate and sequence errors; still no flow control, connect or disconnect. better reliability than unconfirmed connection less service.\n3.\tconfirmed connection oriented service: starts with connect, then data transfer and end with disconnect. uses flow control to synchronize frame sequence and prevent loss due to speed mismatch. reliable compared to 2 types of connection less services.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "57a03a5534194184804ca573c0628408",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "the 3 service classes of the data link layer are the unconfirmed connectionless service, the confirmed connectionless service and the connection-oriented service.\nthe connection-oriented service has a 3-phased communication. first the entities have to connect, then they can transmit data and after this they disconnect. there is a data flow in both directions. the sender gets an acknowledgement if the receiver receives the data, so there is no loss of data. this service offers also flow control and prevents duplication or sequencing error. \nthe other services have no connect or disconnect and no flow control. \nthe confirmed connectionless service can only ensure that there will be no loss of data because the receiver sends an acknowledgement. \nthe unconfirmed connectionless service cannot because only the sender can send data and the receiver sends nothing back.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "ea1fd487c58d46a3b5c771c8ce16f72f",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service: transmission of isolated, independent units which are called frames. data loss is possible. l2 doesn’t correct this and only transmit correct frames.\n\nconfirmed connectionless service: no data loss, because each frame is acknowledged. timeout and retransmit is possible when a sender doesn’t receive an acknowledgement within a certain time frame.\n\nconnection-oriented service: connection over error free channel. theres no loss, duplication or sequencing errors. it also features flow control.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "818ab13b29984849a1240284a5f4787b",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "the data link layer offers these :\n\n-unconfirmed conn.less service ->  no flow control , no connect or disconnect , sender will never get an acknowledgement from receiver (radio/broadcast).\n\n-confirmed conn.less service -> no flow control, no connect or disconnect , duplicates and sequence errors may happen due to “retransmit”\n\n-the connection oriented service -> no loss, no duplication, no sequencing error ,flow control  (3phased communication : connection, data transfer and disconnection)",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "0674617659e94f2e9ef5acae1248a870",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "- unconfirmed connectionless service\n- confirmed connectionless service\n- connection-oriented service\n\nthe first class offers no flow control or feedback if a frame arrived to its destination. the second class offers no flow control, but the sender resends the frame, if an error occured, which is noticable due to implicit acknowledments. the third class resends the frames, too, but detects additionally duplicates and offers flow control due to \"states\" of sender and receiver and 3-phased communication.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "73e94f5e24c2455da27100b560a8f19c",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\nin this service, the data that is sent by the sender is expected to arrive at the receiver, however, there is no feedback from the receiver's side. due to a lack of acknowledgement from the receiver side, there exists a possibility of data units getting lost. furthermore, in this service there is no flow control taking place and neither is there a possibility of connect/disconnect. this form of service is best suited for l1 communication channels with a very low error rate.\n\nconfirmed connectionless service:\nthis service is a form of bi-directional communication, where upon sending information the receiver responds with an acknowledgment of whether the information has been received or not. it is particularly used in applications where a high error rate is expected, such as for moving devices. similar to the unconfirmed connectionless service, no flow control or a connect/disconnect phase takes place. due to the additional acknowledgement here, no data loss is possible, however, duplication and sequencing errors are still possible\n\nconnection-oriented service:\nas opposed to the connectionless services, the connection-oriented service operates with flow control, achieved by a 3-phase bi-directional communication (connect, transfer, disconnect). this prevents data loss, duplication of data or sequencing errors. this form of service requires some sort of connection management as both the sides agree to perform the communication.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "adab1a2e9d244302af340fd101cfe9b3",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connectionless service:\n  -  units are transmitted isolated and independently. errors are detected by upper layers.\n\nconfirmed connectionless service:\n  -  the receiver acknowledges received data with a receipt for data units\n  -  in comparison to unconfirmed c. s. data units can be retransmitted if they are missing/not acknowledged. retransmitted packages may lead to duplications and sequence errors\n\nconnection-oriented service\n  -  no package loss, no duplication, no error sequences due to flow control\n  -  the sender sends connection request, to make sure the receiver is ready to get data\n -  data is transferred and the connection is closed after that",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f27f52883c194ad59e4166166aa6da5d",
        "question": "name the 3 service classes the data link layer offers and explain the differences between the classes.",
        "reference_answer": "1.unconfirmed connectionless - no ack, loss of data possible, no flow control, no connect or disconnect.\n2.confirmed connectionless - with ack, no loss of data (timeout and retransmit instead→ duplicates and sequence errors possible), no flow control, no connect or disconnect.\n3.connection-oriented - no data loss, duplication or sequencing errors. instead a 3 phased communication with connect and disconnect, and flow control",
        "provided_answer": "unconfirmed connection-less service, confirmed connection-less service, and connection-oriented service.\nan unconfirmed connection-less service offers no feedback, if the sent frame was received. a confirmed connection-less service offers this feedback with a simple acknowledgment per frame, therefore no loss occurs. but the acknowledgment can also lead to duplicates because the sender may have not received the ack yet and retransmits the frame. in contrast to other two, a connection-oriented service provides a connection without duplication or sequencing errors and provides flow control, because the connection is setup (exchange of parameters, i.e. sequence number) and teared down afterwards.",
        "answer_feedback": "the response answers the services' names and differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "fff2da8d44e347959a1f27516b5dee7a",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb has a fairness problem. the likelihood to access the medium (reserve a slot on other bus) is not the same for all stations because it depends on the location. that means that a station that is wired at the beginning (or end) of the bus, sometimes has an advantage and sometimes a disadvantage compared to other stations at different locations. this is not fair.",
        "answer_feedback": "the response correctly identifies the fairness problem in dqdb and also provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7b88ac884d6743a7ba508c5140c9be5a",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the mentioned problem with distributed queue dual bus is fairness. each node when it wants to send something, it has to make “reservation” on one side of a bus and then when allocated at the other side of other bus, it is able to send something. for this reason, some nodes which is located near either one or two ends of the two buses might have too much advantage and disadvantage when it comes to transmission reservation (near and far ends). only nodes which are in between may have average fairness to reach both ends of the two bus.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and also provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7ce6c42b8aab47dcb42ff916e315af97",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "dqdb describes a man structure, where every node (mostly lans) is connected with two unidirectional buses, which have a frame generator at the end. a node can reserve on one bus and then send one the other one. the problem is the reservation is depending on the location of the node and therefore you sometimes have an advantage and sometimes a disadvantage and so it is not fair.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and provides an appropriate explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "85cceca5ac3d4bbcb77b5536095a5e52",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem is the fairness, because it can depend on the location of the station if you have an advantage or disadvantage in getting access to the bus and send data. this is, because to send data a station has to make a reservation on one bus and after the reservation arrives on the other bus, the station can send its data on that other bus (so reservation on one and sending on the other). therefore the location of a station has influence on the fairness because for example if the station is at the beginning it could be more likely to get a reservation to send some data than it is when the station is at the end of the bus.",
        "answer_feedback": "the response answer is correct because it identifies the correct problem in dqdb including an appropriate explanation.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8f80ae2c67b74a8399292637d61374af",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem with dqdb is fairness. while stations in the middle might have a chance of 50% to send data, stations at the beginning or at the end can have advantages/disadvantages depending on the situation.",
        "answer_feedback": "the response correctly identifies the fairness problem in dqdb which is due to the station location.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "bb791aa1baf445d7b0bbc0cb254a9663",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the problem with \"distributed queue dual buses\" is the fairness problem. the question that comes up here is how it can be fair, that everybody gets the same access to the data, or respectively depending on the location does it makes a difference in terms of fairness.",
        "answer_feedback": "the response correctly answers the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "2bb8dbc21dbf4f659fa263d5ff86dfe9",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "a node a close to the frame generator can pick up a “free” token and transmit data with a higher probability than a node b far away from the frame generator if the network is highly loaded. therefore, node a has a preference when trying to send a packet compared with node b which is a fairness problem. research to improve the dqdb protocol includes bandwidth balancing schemes to increase the fairness of bandwidth allocation.",
        "answer_feedback": "the response correctly states the fairness issue in dqdb and provides an appropriate reason for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "c99af755b29246b99f222838c503c6dd",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "to build a metropolitan area network (man), which can combine asynchronous data traffic(ieee 802.x mac) and isochrounous traffic (atm-b-isdn), the dqdb (ieee 802.6) was designed.\ntherefore, two unidirectional buses are used. one bus is in the opposite direction of the other. a node is connected to both buses, on one bus data can be requested, on the other one data is sent.\nthe main problem with this architecture is, that a node can request more data than others depending on its position in the network.  so fairness is the issue with dqdb. \nto sum up:\n\"for a light-to-medium load, dqdb is somewhat unfair.\", fairness issues of the dqdb protocol,",
        "answer_feedback": "the response states the correct problem in dqdb architecture, including the proper explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d3599bdb681643958fc2527811694bd7",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "the main problem is the \"fairness\" - the nodes in the beginning of the bus can reserve way more data than in the end, to send it to the other bus. this is only based of their position, which is unfair to the other nodes",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb which depends on the station location in bus.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7201777374034a4d93b8f6a86c7366bd",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "depending on the location a station may not be able to make a reservation. the further a station is at the bus-head end, the less reservating frames is possible due to fifo - first in first out scheduling. the main issue is fairness as the stations do not have the same chance to access the bus.",
        "answer_feedback": "the response correctly identifies the fairness issue in dqdb and also provides an explanation for it.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "023c9f799ee34803a8369b55db3ca0d0",
        "question": "please explain the problem with \"distributed queue dual buses\" that was discussed in the lecture in 1-3 sentences.",
        "reference_answer": "depending on your position in the bus station have a disadvantage/advantage when reserving transmission rights.",
        "provided_answer": "depending on where a node is connected to the two busses at some spots it is more likely to be able to reserve a time slot and send something than at other spots. making fairness the biggest problem of this solution for connecting subnetworks since the probability to be able to send depends on the position in the queue.",
        "answer_feedback": "the response correctly answers the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d299fe3447c64ce59ca95fe6d47a65e1",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "while both (udp and tcp headers) have source and destination port fields, every other part of their headers differ. for udp only a packet length and a checksum field follows the two previously mentioned fields. tcp needs more information. so after the source and destination port the header is followed by a sequence number field as well as a field for the ack number. the tcp header also stores information on hl/resv/flags, window size, checksum (as in udp), urgent pointer and options.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8c63e9d168d44078afeda29dbd478471",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the tcp header has some additional data fields for: acknowledgment number, flags, advertised win. or urgent pointers.\nit needs more information in the header to include more features than udp.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "0ede84ff4ca24cc39870d784c61a3aa7",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "-    since udp is a simple protocol that actually sends ip packets with limited header additions to the receiver where the packet is forwarded to the application directly, i.e. w/o reordering, etc. the udp header consists only of \n     essential needs for data transmission, i.e. a sender and receiver port, packet length, and an optional checksum.\n-    in difference to that tcp it is more complicated, since the goal is to receive exactly the same data as transmitted by the sender, i.e. fully complete and in the right order of the packets. to achieve a reliable connection some \n     additional parameters vs. udp have to be added in the header:\n      o\tsequence number: to get the right order of the packets\n      o\tacknowledgment number: needed together with sequence number for connection setup to get the starting sequence number (3-way handshake)\n\t        o\tvarious flags, e.g. syn-flag for 3-way handshake\n      o\tadvertised win. or win: needed for flow control",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "845aa6d5bd0c4cf7a5a154053612a70e",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "the udp header contains four parts, the sender port, the receiver port, the packet length and the checksum. the sender port is optional and the checksum also. the packet length minimum is 8 byte.\nthe tcp header also contains a source and destination port and a checksum but has some other contents too. so four fields which are different from the udp header are the sequence number, the acknowledgment number, the hl/resv/flags and the advertised window. additional there is an urgent pointer field and some space for options. the tcp header is also larger than the udp header.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. however, the abbreviations, such as hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d78c7fc4813547f99646c731ded74f34",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "udp is missing the sequence number, the acknowledgement number, the hl/resv/flags, and the urgent pointer fields. tcp has this fields.",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers. however, the terms hl and resv should be properly named.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "42694ac849ef4f4db912d4910fa48ae8",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- tcp has no packet length header, which udp does. this is not needed for tcp, because it is connection-based and once all packets have been acknowledged by the receiver, the connection is terminated. - tcp has a sequence number header, which udp does not. it is used to identify the current packet and ensure the correct order when reassembling the data at the receiver - tcp has an acknowledgement number header, which udp does not. it is used to confirm packet reception and connection setup and termination confirmation - tcp has an advertised window header, which udp does not. it is used by the receiver for flow control, indicating how much data the receiver can currently receive",
        "answer_feedback": "the response correctly states four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "1d5a4b22bbda4683877aff3f2514e8b5",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "there are the differences between tcp and udp headers:\n1. tcp has a at least 20 bytes variable length header while udp has an 8 bytes fixed length header.\n2. tcp provides extensive error checking mechanisms since it uses checksum but also provides flow control and acknowledgement of data while udp has only basic error checking mechanisms using checksum. in tcp, erroneous packets are retransmitted from the source to the destination.\n3. tcp header contains the sequence number of data but udp does not contain the sequence number. there is no sequencing of data in udp.\n4. tcp header has urgent pointer to show receiver where urgent data ends but udp does not have this urgent pointer.\n5. tcp contains information for not only compulsory but also optional functions while udp has only the information for compulsory function.\n6. udp is comparatively faster, simpler and more efficient than tcp. however, tcp is reliable since it guarantees delivery of data to the destination.\n7. tcp is heavy-weight, since tcp requires three packets to set up a socket connection, before any user data can be sent. tcp handles reliability and congestion control. however, udp is lightweight. there is no ordering of messages, no tracking connections, etc.\n8. udp is connectionless, but tcp is connection-oriented. therefore, tcp header has fields used for connection setup and maintenance, specifically the flags. udp does not.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers. the response contains extra points, but they are general differences between the tcp and udp protocol.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "895fa634de6140e8a23cd5c85c300d5e",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "- the tcp header has a sequence number to enable reliable communication, the udp header doesn't.\n- the tcp header has a acknowledgment number, which is used in the 3-way handshake. it is also necessary for the reliable communication. udp doesn't need this field, because it is a connectionless protocol.\n- the tcp header has some flags, which are used for connection management. for example syn for connection establishment and fin for connection release.\n- the tcp header has a field for the advertised window, it is used for flow control. udp doesn't have any flow or congestion control.",
        "answer_feedback": "the response correctly identifies four differences between tcp and udp headers.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "2ae50d00ea364c1f933d0f6b3a67b6cc",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no it does not hold for real internet traffic. take video traffic as an example. client fetches data from server and fill them in its buffer. data could come more and more if the previous of them has been transmitted and filled successfully. if not successfully, the retransmission can happen. therefore each time interval are dependent on others, i.e. they are not independent.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d996cc3e109a4b56967621458b111446",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no this assumption does not holds for the real internet traffic because in real scenarios whenever the packet arrives then it is expected that much more packets will be received and if pick a time duration for that such as the night or day then there will be a variance in the packets arrival as we will be checking for packets during the day and which will be more also similarly for a video buffering application, the interval at which we request the packets will be different and infrequent.",
        "answer_feedback": "the response is partially correct because the arrival process' parameters can be time-dependent. in this way, the arrival rate wouldn't depend on the previous arrivals, but instead on the time of the day.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "818672b5e7994da38c1a65c64b7a04cd",
        "question": "to model the packet arrivals as a poisson process, we assumed that the arrivals for each time interval δt are independent. does this assumption hold for real internet traffic? explain your answer in 2-5 sentences. ",
        "reference_answer": "no. real internet traffic often comes in bursts. therefore, arrivals are not independent because the probability of an arrival happening at a node is influenced by previous arrivals at the node. for example, on-demand video streams selectively load the next video segments when needed. this means the actual network utilization depends on the current playback state on the client-side. the packet arrivals are not independent, as it is likely that there is a low utilization directly after the next segments have been loaded.",
        "provided_answer": "no, this assumption does not hold for real internet traffic. if somebody for example streams videos on the internet, the probability that after the first packet another packet will arrive is much higher than the probability for the first packet. if you increase the interval δt there is the possibility the assumption become true again, but it’s not a realistic case.",
        "answer_feedback": "the response is correct as it correctly associates the probability of a packet arrival happening at a node with previous arrivals at the node.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "ed948069470e4c2e94bbe808037d1ac5",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds the information which output lines/lans to use to get to a certain station. the bridge inspects the traffic (backward learning) and when the bridge receives frames with source address q on lan l it learns that q can be reached over l and creates a table entry accordingly so it can adapt to changes in topology. when the bridge gets a frame with the identical source and destination lans in its table, the frame can be immediately dropped since it was already on the right lan. when the source and destination lans differ, the frame is rerouted to the destination lan. the frame is only flooded when the destination is unknown; with this decision procedure unnecessary flooding or forwarding is prevented.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "32df26c8533744bdbf877f2551ace2f2",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "each entry in the bridge table holds: a destination address s, which lan (link) l is to be used to reach s, and a timestamp t of when last the frame from s arrived.\n\nwith backward learning, the bridge learns from an incoming frame and the lan connected to the link through which the frame was received that the frame's source s can be reached via lan l (directly or through other bridges) and stores/updates this information (s, l and frame arrival time t) on any arrival of a frame with s as the source address (and purge it by another process if it is too old, that's why t is stored).\n\nthe forwarding process uses the bridge table by looking up the entry for a given destination address s to decide what to do with an incoming frame addressed for s: if an entry is found then the frame is either rerouted via the destination link l if that link is different from the incoming link or discarded (as it should not leave the lan), else flooding is used as a fallback (destination lan unknown).\n\nthe benefit is a reduced network load (compared to flooding the network) if an entry exists for a destination because then only the relevant outgoing link is used and no needless copies of the frame are created and flooded into the network.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "0a1f610a742642bda082343309a95528",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the table holds the infromation which source can be reached over which lan. during the backwards learning process the bridge creates table entries, when it recieved a frame. when it gets a frame from source x over lan y, a new entry will be created that x can be reacher over y. during the forwarding process the bridge deciedes based on the information table over which lan the frame should be routed (in case the source an the destination lan are the same, the packet can be dropped). if the table does not hold any information about the destination point, it will be flooded. since the bridge keeps track of which lan contains which station (mac address) it usually only has to forward a frame to the destination lan containing this station without having to send it to all connected lans.",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "ed05839fdb8e42d39bf484d7b16fa92e",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "the bridge table holds information about which station is attached on which lan. it includes a timestamp, adress of station and lan. \nwhenever the bridge receives a frame from a station, it can determine in which lan the station is attached. from this information the bridge builds an entry for the station in the bridging table. the advantage from backwards learning is, that the bridge does not have to flood the frames, therefore decreasing the network traffic. additionally, the bridge can drop frames, that are adressed for a receiver in the same lan as the sender station. \nthe entries are deleted, if they haven‘t been updated for a set time (usually several minutes).",
        "answer_feedback": "the response answers all the four requirements of the question correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b4ddfa2c03ee4f4eb1ad0729d9bdf65a",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "hidden terminal problem: having three nodes a, b and c where a and c are in range of b, but not in range of each other, if a and c send at the same time to b, there will be interference at b, but they dont know because they are out of range of each other. exposed terminal problem: the constellation of the exposed terminal problem are two sender-receiver pairs where the senders are in range of each other, but not the receivers. if s1 sends data to r1, s2 will assume that the channel is occupied and cannot send data, while in theory it could because r2 is out of range of s1.",
        "answer_feedback": "the response correctly states and describes the hidden and exposed terminal problems in wireless networks.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "eab91bf79f2640e3ad08ed9fadbc11b0",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "there are a multitude of challenges facing mobile routing. from the speed the mobile hosts have, to security, scalability etc.  two challenges of mobile routing are hidden terminals and exposed terminals. hidden terminals:  the hidden terminal problem occurs when multiple nodes can access one is, but not each other. this leads to issues when both nodes try to send data packets to the is in the middle simulatenously. as the nodes that are not in each others reach are \"hidden\" from each other, they cannot detect the collision at the is in the middle.  exposed terminals:  the exposed terminal problem occurs when multiple nodes are in close vicinity and in their neighboring radio range. a node (lets call it b) has to wait for an adjacent one (c) to finish with their data transmission (to a node d) before starting their own, even if their destination node (lets call it a) would be a node that is not in the radio range of c. the sender node that has to wait (b) is \"exposed\" to the traffic from the is next to it (c). this leads to underutilization of the channel and low efficiency.",
        "answer_feedback": "the response correctly states and describes the hidden and exposed terminal problems in wireless networks.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "c6b126b160dd48c88c07c97e3860b222",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "in mobile communication, nodes can move, i.e. are not placed on a fixed location, and are transmitting over the air, i.e. they use wireless communication. this stands in big contrast to fixed and wired networks.\n\nto adapt to these new factors, challenges on many different layers occur. whether the discovery of service in the application layer, the specific needs for routing in the network layer, or the control of power used for transmission in the physical layer and even more have to be taken into account to set up such a mobile network.\n\n             -  for mobile routing, the following challenges exist:\n\n                         o   hosts can move and change the attachment to a certain network segment (handover). this handover mechanisms occur in cellular networks and in complex wlan infrastructures as well. for the  example of wlan, handover can be handled at the link layer if both ace points are in the same networks. if there are different networks, a network layer handoff occurs and needs to be considered to implement routing for a seamless service.\n\n                         o   in mobile ad-hoc networks, nodes can disappear due to the radio system and channel characteristics. therefore the network topology may change rapidly and pre-calculated, pro-active routing may fail. in this case, reactive routing maybe of preference, as the route is calculated using the actual network topology.\n\n             - moreover, the general challenges in mobile communication include:\n\n                        o   hidden terminals\n\n                                §  since in mobile communication no wire is used, the nodes can only listen for a certain distance defined by the radio parameters and the channel characteristics, which makes the usage of csma/cd not practicable as the concept of carrier detection (cd) does not work.\n\n                                    an already happening transmission to a certain destination node could not be detected by an intermediate system (is) if the node communicating with the destination node is out of the “listening”-range of the is. to solve this problem the collision will not be “detected” but “avoided” using certain acks (csma/ca, rts/cts).\n\n                       o   exposed terminals\n\n                                 §  when a node wants to send a packet and detects an already existing transmission in its transmission area, it waits until the existing transmission is finished and only thereafter sends its packet to avoid collisions.\n                                     this can cause underutilization of a channel if the receiving nodes are far enough away from each other, i.e. beyond the radio range, and therefore both transmissions would not affect each other and could have successfully be completed in parallel.\n\n                       o  near and far terminals\n\n                                  §  if multiple packets arrive at the receiver, they will typically arrive with different signal strengths. depending on the modulation used, the receiver will detect the “stronger” packet and ignore the “weaker” packets if the power difference is large enough. however, fading and multipath may lead to changing power levels and add complexity to the problem.\n\n                                  §  using a multipath receiver design, both packets can be detected as different paths and the receiver may fail to detect these packets. the near/far problem is difficult to solve in direct sequence spread spectrum systems (rake receivers). in ofdm based system, this problem is less severe.",
        "answer_feedback": "the response correctly states the challenges faced in the wireless network.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "ecd34f9671014025964c4f46ac582f65",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "1. hidden terminals: for example there are 3 nodes a, b, c. a cannot hear c and vice versa, and b is located between a and c. b can hear a and c. when a sends to b, c still thinks that b is free, thus start sending to b as well. this results in a collision in b. 2. near and far terminals: assume there are 3 nodes a, b, c. b and c are located near to each other, while a is located farther from them. when both a and b send to c, b's stronger signal drowns a's weaker signal, thus making c cannot hear/receive a.",
        "answer_feedback": "the response correctly states two challenges of mobile routing.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3cc97149924e40a8b122b8a6f346142c",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "one challenge are \"hidden terminals\". in this case, there are 3 nodes a, b and c and a and c cannot hear each other but a and b and b and c can. so when a sends to b due to the fact that c can't receive a c senses b as \"free\" medium and also sends to b. then at b a collision occurs which a can't detect. a is therefore \"hidden\" for c and c for a. another challenge are \"exposed terminals\". there we have 4 nodes a, b, c and d. a can reach b, b can reach a and c, c can reach b and d and d can reach c. now b sends to a and c wants to send to d. but because c signals a medium in use it has to wait, even if the medium in use is  b sending to a and a is outside the radio range of c and the waiting is not necessary. so c is \"exposed\" to b. the third challenge are \"near and far terminals\" which is about 3 terminals a, b and c where a and b are sending and c is receiving. due to the decrease of the signal strength proportionally to the square of distance the stronger signal (e.g. b's) drowns out the weaker signal (e.g. a's). the result is that c cannot receive a.",
        "answer_feedback": "in the exposed terminal description, c senses the busy channel rather than signaling it. apart from that, the answer is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "12e6aeea55ad4924869e5b5f2bc48f30",
        "question": "what are the challenges of mobile routing compared to routing in fixed and wired networks? please name and describe two challenges.",
        "reference_answer": "possible challenges:\n1.adaptation: the network has to handle the dynamic positioning of the nodes/topology changes. additionally, nodes can leave or join the network anywhere (within signal range) at any time.\n2.security: interception of packets or injection of faulty packages is easily possible in wireless networks. this may necessitate encryption and authentication.\n3.medium access control: wireless networks feature new possibilities for inference and collisions of the transmitted signals. see the following correct example challenges:\ni)hidden terminal: nodes’ transmissions may collide at other nodes without them noticing, because they are out of detection range of each other (a and c in this example) and therefore sense the medium to be free even though there is an overlap of the transmission ranges. \nii)exposed terminal: nodes (c in this example) may not realize they could send collision-free, because a node in their detection range (b) is sending and they, therefore, detect the medium as busy, but the sending node (b) is out of the detection range of the destination node (d) so that no collision would occur.\niii)near and far terminals: signal strength decreases proportionally to the square of distance, so closer nodes may drown out the weaker signals of nodes farther away.\n4.quality of service (qos): due to the rapidly changing network topology, imprecise network information, and resource constraints of participating nodes, it is challenging to provide the desired qos. additionally, signal quality may also decline due to noise and occlusion.\n5.scalability: since it is not possible to know the number of participating nodes beforehand, it is vital that routing protocols, etc. are capable of dealing with increasing network sizes and workloads. \n6.heterogeneity: nodes may have different capabilities, responsibilities, and constraints, e.g. processing capacity, transmission ranges\n7.dependability: providing consistent, performant, and reliable routing behavior that higher-level services can trust is challenging in such a dynamic environment. \n8.power consumption: as most mobile devices are battery-powered, power consumption becomes an important optimization factor in routing, etc.",
        "provided_answer": "energy efficiency: not having infinite power leads to the problem of having to safe power as to not empty the mobile instantly.\nadaption of routing protocols: in a constantly changing network you have to use other routing algorithms, than in a normal network",
        "answer_feedback": "the response states and describes both the challenges correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "26a002ad89bc42d2abcf9bcb604424f5",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "purpose of rpf and rpb: avoid receiving duplicate packets * rpf: use unicast routing information to decide if an incoming packet is dropped or sent further via the outgoing links: * send further if incoming packet used path in unicast routing info * drop if incoming packet did not use path in unicast routing info * rpb: select outgoing edges: * select edge if a packet coming from the connected node to the sender would use this edge. * sent incoming packet via selected edges (not including the incoming edge).",
        "answer_feedback": "the response correctly answers the purpose and the explanation for both broadcast types. the purpose is to avoid forwarding duplicate packets not receiving but it is acceptable.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f898735b8bf444c3b10f97085cdd2c7e",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding (rpf) and reverse path broadcast (rpb) are techniques used in routers. they enable loop-free forwarding of multicast packets in multicast routing. reverse path forwarding:  in this procedure, each node i checks whether an incoming packet from source q has been received on the connection on which node i also transmits its packets to q. if this is the case, then the packet is assumed to have been transmitted on the shortest route and it is forwarded on all other lines. if, on the other hand, a packet was received on a line other than the one on which data is transmitted to the sender, then it is assumed that it is a duplicate that did not take the shortest route. this duplicate is then discarded instead of being forwarded. reverse path broadcast:  rpb is an improvement on rpf. rpb not only evaluates the shortest path with respect to the interface where the multicast packets are received, but also influences the forwarding of data to the interface of the router. as a result, multicast packets are only forwarded to the interfaces where the next router is located in the reverse direction on the shortest path to the data source. rpb specifically checks whether the incoming packet arrives at the is through which the packets for this station/source are normally also sent.  if not, the packet is discarded directly. if yes, it will be further checked if the packet has taken the best path so far. if yes → select the edge at which the packets arrived and from which they are then rerouted to source s (in reversed direction) if not → do not send over all edges (without the incoming one)",
        "answer_feedback": "the purpose of reverse path forwarding and reverse path broadcast is not limited to the multicast but also used in broadcast. the explanation of rpf and rpb is correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d641379a69a34431b09b2b668efc9219",
        "question": "what is the purpose of reverse path forwarding and reverse path broadcast? how do they work?",
        "reference_answer": "purpose: both implement a more efficient kind (in terms of duplicate packets) of broadcasting than flooding / to minimize the number of duplicate packets in the network when broadcasting.\n\nreverse path forwarding:  each node has a routing table stemming from unicast routing algorithms. when receiving a packet of sender s from neighbor n at node x, check the routing table and only forward the packet to all adjacent nodes (except for n) when you would send packets to s over n → the assumption is that the packet used the best route until now.\nreverse path broadcast: nodes monitor unicast traffic to learn which paths in the network they are a part of, that is node x knows that is on the best path between two nodes a and b if it receives unicast packets coming from a and going to b or visa versa. in other words, each node knows which spanning trees it is part of in the network. reverse path broadcasting works identical to reverse path forwarding with the exception that it only forwards packets on edges that are part of a spanning tree (again excluding the incoming line to n).",
        "provided_answer": "reverse path forwarding and reverse path broadcast are both broadcast algorithms that attempt to minimize the number of duplicates packets in the network compared to other algorithms like the simple flooding algorithm. the idea of reverse path forwarding is that each sender/node has an own spanning tree, but the other iss do not need to know them. the algorithm is based on a simple condition for each node. the node has to decide, whether the received packet sent over the best route, i.e. it used the edge the node would use to send it back to the sender/author or not. if this is true, the node resends this packet over all other edges, i.e. excluding the incoming one, otherwise, the packet is most likely a duplicate and it will be discarded. the reverse path broadcast goes a little further and the is sends the packet from the best route only to the nodes it is responsible for/the sender used before. if the is is on the best path between the sender and his neighbor node, i.e. it is responsible for it, it learns over time.",
        "answer_feedback": "the response correctly explains rpf and rpb and their purpose.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7928e70858a448d0904ef1e7a59f243d",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "properties of spanning tree for broad- and multicast:  * the spanning tree does not have any cycle  * a connected graph can have more than one spanning tree  * all possible spanning trees of the graph have the same number of edges and vertices  * the spanning tree is minimally connected, means it generates less complexity modifying link state routing to construct a spanning tree:  * all is sent link state packets periodically containing information on distance to neighbours, information on multicast groups, which will be broadcasted to all others  * each is calculating a multicast tree from the now locally available and complete state information  * based on the information about the multicast tree is determines the outgoing lines and on which packets have to be transmitted",
        "answer_feedback": "the response correctly identifies the spanning-tree property that makes it appealing for broadcast and multicast and how the link-state algorithm is modified to construct a  multicast spanning tree.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "54124f3eb2584e1e9c35fc2669c4cbcd",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "the extension headers in ipv6 are additional data contains in an ipv6 packet, located between the fixed header and the payload. \nthe main advantage compared to ipv4 is that it allows to add new options without changing the fixed header.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "fbac64191c55418ebba611378b07d145",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "extension headers are optional headers in ipv6 that are not limited by any size limitation as they are located in between the ip header and the data payload and therefore don't change the ip header. one header links thereby to the next header with the first header being pointed to by the ipv6 \"next header\" field. because of that flexibility, new headers may be invented as the need arises.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "0c28b4c85c564dcbbf05a8b4c386824a",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "- in order to keep the core packet structure simple, ipv6 removed some unnecessary header fields and provide instead a extension headers, which can be used only when really need it. \n\n-extension headers are located between the main header and the payload.\n\n- advantage: it will help to extend the protocol in the future without affecting other\ncore fields in the packet.( flexibility)",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "bf916abced404fc2829eec86bd2770d3",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "the extension headers are placed between fixed header and payload. extension headers have advantages compared to ipv4 because they are optional, help to overcome size limitation, and allow to append new options without changing the fixed header.",
        "answer_feedback": "the response answers all three parts of the question. there is no specific definition stated in the response but it is present within the advantage part.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d5300a0f61a84dc790d78e03af2554ac",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "extension headers can hold additional options that are not possible in the simplified and fixed ipv6 header, replacing the options from ipv4. they are optionally placed between the fixed header and the payload. they help overcome the size limitation and allow for more options without having to change the fixed header (like we have to in ipv4).",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8cbec38131b7417986e73f74dc80cadc",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "they are placed between the fixed header and the payload and are used to add additional non-necessary information to the ip package. the main advantage is, that they are allowing to append new options and the fixed header stays the same.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "52342d6a955249d0bf12402b8146fd56",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "each ipv6 data packet consists of a header and the payload in which the user data is located. compared to ipv4, the internet protocol v6 is characterized by a significantly simplified packet format. in order to facilitate the processing of ipv6 packets, a standard length of 40 bytes was specified for the header. optional information that is only required for special cases is outsourced to so-called extension headers, which are embedded between the header data area and the payload. therefore the main advantage is that options can be inserted without having to change the header. the ipv6 packet header now comprises only eight header fields with ipv4 thirteen fields were used.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "c2e95e496d0e47b58e782471b224e08b",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "the extension headers are optional additions to the fixed header. they are located between the fixed header and the payload.\nas a main advantage compared to ipv4 the optional headers allow to append new options without needing to change anything in the fixed header.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6f98da583f4a4f418c9978e434113fcd",
        "question": "what are extension headers in ipv6 and where are they located in a packet? what is the main advantage of extension headers compared to ipv4?",
        "reference_answer": "extension headers are used to extend the fixed ipv6 header with additional, optional network layer information. if present, they are located between the fixed header/main header and payload/upper-layer header/ transport-layer header.\n\nmain advantage: one of the following advantages are considered fully correct:\n1. it allows the appending of new options without changing the header.\n2. ipv6 packets with optional headers are typically processed faster/simpler by intermediate devices as most of the options are ignored (except “hop-by-hop extension”) while they are processed by all routers in ipv4 unless ordered otherwise.",
        "provided_answer": "extension headers in ipv6 contain supplementary (additional) information used by network devices to decide how to direct or process an ipv6 packet and they are located between fixed header and payload. they allow to append new options without changing the fixed header.",
        "answer_feedback": "the response answers the description, location of extension headers, and advantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7ae93aeb10ea4d069bfbe498cf4ab388",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "1.support larger address space. \n\nthe number of user has increased dramatically. in order to support more addresses,  we need ipv6 with longer address (128 bits) since we are out of addresses with ipv4 (only 32 bits). \n\n2. ipv6 can perform multicasting(and anycast). \n\nin other word, it can send to multiple persons with multiple addresses, which ipv4 can not deliver (ipv4 can only have 1 destination address for unicast).\n\n3.  it helps providing flexibility.\n\nit provides a extension header field, which can be used for appending new field(if need it in the future) without affecting the other fixed headers. \n\n4. ipv6 can simplify the protocol processing.\n\nthe header fields in ipv6 is simpler than ipv4. some header fields, which were rarely used in ipv4, have been removed. therefore ipv6 can simplify the protocol processing.",
        "answer_feedback": "all the ipv6 objectives mentioned in the response are completely correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "98347b34a8384006a10407db071c6870",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "-to support more end-systems than ipv4\n-to reduce routing tables and simplify protocol processing\n-to increase security\n-to support real time data traffic",
        "answer_feedback": "the response is correct because all stated objectives of ipv 6 are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f5dfc163fb6a4f828155f069f0e04018",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "ipv6 is made for supporting more addresses allowing billions of end-systems. it also gives the possibility to increase security and to simplify protocol processing. additional ipv6 provides multicasting beneath a few other objectives.",
        "answer_feedback": "the response contains four correct objectives of ipv6.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6434f998b0a2414f9d3ed8f7288819d1",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "four objectives of ipv6 are:\nlonger addresses to be able support more end-systems\nto be more adaptable than ipv4 in the future by providing extension headers\nmake the header simpler to allow for faster processing in routers\nincrease the security by including ipsec as a mandatory feature",
        "answer_feedback": "the response is correct because all stated objectives of ipv 6 are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "477c49d65416411fa9125650b68a3e21",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "more addresses\nrefactor of header, enables future modifications\nipv4 allow broadcast and unicast, ipv6 supports anycast (e.g. nearest node)\nno checksum\nno fragmenting\nincrease security\nsimplify protocol processing",
        "answer_feedback": "the response correctly answers the four objectives of ipv6.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8dc6ce06de3e42dda595b7427c06ca2b",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "- support more end-systems by using longer addresses\n- reduce the size of the routing tables\n- simplify the protocol, to allow routers to process packets faster.\n- integrate security\n- provide multicasting\n- support real time data traffic",
        "answer_feedback": "all six ipv6 objectives are completely correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e1cba3c3e874470386a0190e5c5c7e7c",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "objectives of ipv6 are: 1.to support billions of end-systems-it has longer addresses 2.to reduce routing tables 3.to simplify protocol processing by simplified header 4.to increase security (integrated) 5.to support real time data traffic (quality of service) by flow label, traffic class,etc",
        "answer_feedback": "all five ipv6 objectives in the response are completely accurate.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "aca20a0b5f144ca49b18706bdb4e029a",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "to support billions of addresses, since it has much longer addresses than ipv4\nto be open to change, it does so by the support of extension headers.\nto provide better multicasting features than ipv4\nto increase security.",
        "answer_feedback": "the response answers all four objectives of ipv6 correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "c31d7c06926745a9903e6fdf4a721d77",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "1. enlarge the available address pool:\n    by increasing the ip address length from 32 bits to 128 bits, a greater number of addresses can be assigned to end systems.\n2. simplify protocol processing:\n    any previous shortcomings in ipv4 can be removed and optimized in ipv6.\n3. provide multicasting:\n    packets can now be sent to multiple destination addresses, which makes multicasting possible.\n4. better security:\n    security means are already integrated in ipv6.",
        "answer_feedback": "the response correctly states four objectives of ipv6 with explanations.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7a846709b3b24276bc2135926eac0aa6",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "- bigger adress room\n- better security \n- reduce routing tables\n- simplify headers",
        "answer_feedback": "the response is correct because all stated objectives of ipv 6 are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "be063b4ed6244dd09eab20108556a12d",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "1.to support billions of end-systems.\n2.to reduce routing tables.\n3.to simplify protocol processing.\n4.to increase security.\n5.to support real time data traffic.",
        "answer_feedback": "all five ipv6 objectives mentioned in the response are completely accurate.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6985cfa5268541a58f069e90cf8001ed",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "- support larger number of end systems than ipv4 by using longer addresses\n- reduce size of routing tables\n- simplify protocol processing by simplifying header\n- improve multicast support",
        "answer_feedback": "all four objectives of ipv6 are completely accurate.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "350fb8e5ac97453eb5cdbd66f772461e",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "some of the objectives are: support billion of end-systems, reduce routing tables, simplify protocol processing, increase security, support real ti,e data traffic, provide multicasting, support mobility, be open for change, coexistence with existing protocols",
        "answer_feedback": "all the ipv6 objectives mentioned in the response are completely accurate.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7f578adfd0274a7c887e03af2f84f48a",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "ipv6 aims to:\n- support billions of end systems, through longer adresses;\n- reduce routing tables;\n- simplify protocol processing, since headers have less fields;\n- provide multicasting;\n- be open for change in future, through extension headers.",
        "answer_feedback": "all the objectives of ipv6 mentioned in the response are completely correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "fd11ecdf38d947a0ba88a48386529cf9",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "support billions of end systems due to a longer addressing scheme.\nreduce routing tables and simplify protocol processing due to simpler header structures.\nsupport real time data traffic due to traffic classes and flow labels\nprovide multicasting and support mobile end systems",
        "answer_feedback": "the response states four correct objectives of ipv6.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3b4ec11883eb48768dcc099f98074f2f",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "support billions of end-systems \n\nsimplify routing tables and protocol processing \n\nsupport real time traffic (quality of service)\n\nto be open for change",
        "answer_feedback": "the response answers four objectives of ipv6 correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "2e0228e7a0974409b491d6475e08d36a",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "- extending the address space of ipv4 (longer addresses), to support billions of end systems.\n- simplify protocol processing (simplified header)\n- increase security (security means integrated)\n- allow multicast",
        "answer_feedback": "the response is correct as all four ipv6 objectives are completely accurate.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e254210354a04d349c78462f1fe45608",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "- support billions of end-systems by using longer addresses\n- coexistence with existing protocols\n- support roaming\n- reduce routing tables",
        "answer_feedback": "the response is correct as it contains accurate ipv6 objectives.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e5d5852e3ad3423bbabbbe55bfe2a7c5",
        "question": "what are the objectives of ipv6? please state at least 4 objectives. ",
        "reference_answer": "to support billions of end-systems.\nto reduce routing tables.\nto simplify protocol processing with simplified header.\nto increase security.\nto support real time data traffic (quality of service).\nflow label, traffic class.\nto provide multicasting.\nto support mobility (roaming).\nto be open for change (future): extension headers for additional change incorporation.\nto coexistence with existing protocols.",
        "provided_answer": "1.) global addressing concept for end systems\n2.) simplified address allocation\n3.) addresses independent from\n  - type and topology of the subnetworks\n  - number and type of the subnetworks to which the end systems have been connected \n  - location of a source end systems\n4.) increasing data security",
        "answer_feedback": "the response correctly answers four objectives of ipv6.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "5d8a457fea9c4c349f93286a7170e569",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the size of \"collision domain diameter\" is dreduced by about 10 times, e.g. from ca.3000m to ca.300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b0aa489b5d74455f9738e62973a8b853",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter decreases by the factor of 10. that means:\nnew collision diameter = old colision diameter / 10",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e3271b5f2c5040b9ad42c038aa8b0d6c",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the possible distance is reduced by factor 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8b4ae5ccaa28417ba297250d73b6c86a",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter reduces by the same factor for example for a network with 10mb/s has a collision domain diameter of 3000m and when we increase the speed of the network by 10 to 100mb/s, the collision domain diameter will become 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "5a142b9a85d54691836d731cd644409d",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "collision domain diameter means the maximum length of line between two nodes in the network which you can use in respect to the length of used frames, the sending speed and the fact, that you want to be able to detect any kind of data collision during transmission. if we now increase the speed of transmission with all other factors remaining the same - especially the frame length -, the time of transmission for each node decreases. so there is less time of data frames travelling on the line during which the stations could detect a collision. to keep the function of collision detection, the maximum length of line - a.k.a. the collision domain diameter - in the network has to decrease to the same factor. so an increase of transmission speed from 10 mbit/s to 100 mbit/s - factor 10 - causes a reduction of collision domain diameter to the factor of 10, too. for example, in ethernet 802.3 this means a reduction from 3000m to 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "05b3625fdc8c40a3a0e19806c2339216",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is decreased by the same factor, the network speed is increased by, i.e. if the collision domain diameter in a 10mb/s network was 100m, the collision domain diameter in the same network with 100mb/s would be 10m. \n\nthis is because the sender still must be able to recognize a collision during simultaneous sending.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "38b98440b2e847c9958f6ac42146eacf",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the diameter decreases by factor 10. the increased  bit rate leads to a reduced bit duration but the transfer speed remains the same. the result of that is a shorter maximal distance between two stations which is allowed so that collisions can still be detected.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6176b653698d4948993db9f32ba43d07",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "with csma/cd, if the speed of the network increases by a factor of 10, the collision domain diameter shrinks. the distance decreases by a factor of 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "32d2706a54e9419baef58a125245c9ff",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter is shortened by factor 10. assuming the collision domain diameter is 3000m at 10mb/s. if the speed is increased to 100mb/s, the collision domain diameter will be 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "550fada62f364553943bba67078eb54c",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter would be 10 times smaller which would have many collisions as a consequence, making it inadvisable to choose these dimensions.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "65d61ac26fa64080977237ce85808b9f",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "collision domain diameter is the distance between the two furthest nodes. if i use csma/cd, then the distance limitation for collision domain diameter will be one tenth as large as before when i increase the speed of a network by a factor of 10.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "39e0833365ec46119b62807232ca5f22",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter, the maximal distance where collisions can be recognized decreases tenfold. if the collision domain diameter was 3000 meters before, it now is 300 meters.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8806b3fc084b468ea7b4be4a605dbc3f",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter (cdd) is reduced to 1/10th of the original. in the given example cdd is reduced from approximately 3000m to about 300m.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "fd3ad1d878a945238165b56f9be3cb21",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the maximal distance between stations reduces by a factor of 10.\n\nex. : 64 byte sent with 10 mb/s: max distance of 5.12 km\n        64 byte send with 100 mb/s: max distance of 112 km",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "50bd285e3ca54b17af8e0b28812d0f59",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "if the speed got ten times faster, we have to decrease the maximum collision domain diameter by 90%, that is the distance between the nodes, so that a collision can still be detected while sending. so there is basically a tradeoff between distance and efficiency.",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "389546012a3a4983b34fc2e9f599d451",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "when the speed of a network is increased by a factor of ten, while letting everything else remain the same, the collision domain diameter reduces by the same factor. so, the diameter will decrease by a factor of 10 (that is, divide by 10)",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7014f6b6797442549d5f70e2a16c28b5",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the “collision domain diameter” is the distance two station can have and still detect a collision while sending. it depends on the minimum frame size, the speed of the signal through the medium and the bit rate of the network. if the bit rate increases while nothing else changes in csma/cd a frame is transmitted in less time than before. in this time the signal travels a shorter distance thus decreasing the “collision domain diameter”. if the speed of the network increases by a factor of 10 the “collision domain diameter” shrinks by a factor of 1/10",
        "answer_feedback": "the response is correct as it answers the change in the diameter scale accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "417fc4927628483e8c95798669800600",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting means, that the sender can concatenate a sequence of multiple frames and transmit them in a single transmission.\nan advantage is, that frame bursting has a better efficiency than carrier extension, because carrier extension extends the length of the frame from 512 bit to 512 byte but not the data and therefore ca. 90% of the frame is useless.\na disadvantage is, that while with carrier extension every frame is send immediately, with frame bursting the sender must wait until he has reached the number of frames neccessary for a transmission, e.g. 10 frames. so if you want to send 1 frame now, the sender will wait until 9 other frames arrive and then transmits the whole concatenated sequence.",
        "answer_feedback": "the response correctly answers the definition of frame bursting, its advantage and disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "a0ed266d6e24435c92d90f3a7fb24509",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting enables the sender to transmit concentrated sequence of multiple spaces in a single transmission. therefore a buffer waits for a set of packets to send them all once together.\n an advantage of frame bursting is the high efficiency due to the amount of data that can be sent in one transmission. in the carrier extension only 9% user data is possible to send which leads to a low efficiency. \na disadvantage of frame bursting is the long time it takes to be transmitted. if you just want to send two packets you have to put some additional data or rubbish inside because the frame only will send if the whole frame is filled with data. the higher latency is introduced through the packing/filling of the buffer, depending on the implementation, either the two packages get stuck or transmitted with a higher latency with rubbish frames to fill the buffer.  this causes a delay. therefore the carrier extension is better to send less packages and does not lead to a delay.",
        "answer_feedback": "the response answers all three parts of the question correctly. however, 9% efficiency of the carrier extension feature is only for the worst case. the efficiency depends on the  size of actual data sent which can be between 46-1500 bytes.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "398f33db00fd481d8a682c66d825e6fb",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "when using frame bursting within a shared broadcast mode, the stations wait until they have a min. number of frames to send and then send them all at once in a single transmission as a sequence of multiple frames. it is more efficient as carrier extension, especially if the station has continiously a lot to send. otherwise the frames have a lot of waiting time to be ready for a transmission.",
        "answer_feedback": "the response correctly explains the frame bursting concept, an advantage and a disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "38f264d805e74e9789e0c49b42bc2a01",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting is a communication protocol, where one transmission can consist of a concatenation of frames. compared to the carrier extension the throughput increases and has higher efficiency. one disadvantage is that the frames have to wait for their transmission. so frame bursting shouldn't\nbe used with more than 3 clients as this disadvantage can result in lower for every client.",
        "answer_feedback": "the response correctly states the frame bursting definition, advantage and disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d42d4a39f7c7484f8cb8a941889c5b6c",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "in frame bursting the sender can transmit several frames in one single transmission. \nthe advantage of the frame bursting is definitely a lot higher efficiency than the carrier extension has (which loses around 90% for collision detection). \nthe disadvantage of frame bursting is that the frames have to wait for their transmission.",
        "answer_feedback": "the response gives the frame bursting definition, its advantage and disadvantage correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "06b55442218c4bc5b125637cf76dedd8",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "t1.allow sender to transmit concatenated sequence of multiple frames in single transmission .\n2.needs frames waiting for transmission .\n3.better efficiency .",
        "answer_feedback": "the response is correct as it answers all parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "8d5b141fab5142d4aa2ab6f445831b14",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting allows sender to transmit concatenated sequence of multiple frames in single transmission\n\nadvantage: better efficiency\ndisadvantage: it needs frames waiting for transmission. therefore, it has end-to-end delay problem",
        "answer_feedback": "the response correctly answers all the parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "458eafc25d934b8e83b27048e3abe3c0",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting is a technique where the sender waits for a certain number of frames to be concatenated into one single “big” frame and then send this “big” frame in one go. \n\nadvantage: better efficiency in data transmission, while in carrier extension introduces only trash information just to extend the frame length. \n\ndisadvantage: because the sender has to wait until the concatenation buffer is full then the big frame is only ready to send. this accidentally introduces more end-to-end delay which hampers the performance and user experience of interactive applications (e.g. live stream video, live phone and video calls, etc).",
        "answer_feedback": "the response correctly answers the frame bursting definition, its advantage and disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "db995f3ea4aa423197ff275bf805d06d",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting is a shared broadcast mode of gigabit ethernet which concatenates multiple frames and send them in one transmission. \ndisadvantage: frames must wait for transmission until enough frames are queued for sending so that the minimal length is achieved\nadvantage: better efficiency because in carrier extension mode short frames are extended with non-sense bits to achieve the minimal transmission length",
        "answer_feedback": "the response correctly answers all the parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b97868de7d8446728f38b923edca30ee",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting allows sender to transmit concatenated sequence of multiple frames in a single transmission.\n\nadvantage as compared to carrier extension is:\n-better efficiency\n\ndisadvantage as compared to carrier extension is:\n-it needs frames waiting for transmission",
        "answer_feedback": "the response gives the correct definition of frame bursting, including an advantage and a disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "735fff07b0504e01969b250613bb006e",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "two solutions to the problem mentioned before are carrier extension and frame bursting. the basic principle in carrier extension is to attach a new extension field containing “scrap” data to the frame just to make it larger so that collisions can be detected. in frame bursting you take a similar approach, but instead of appending otherwise useless data, you just send a concatenated sequence of multiple frames in a single transmission. this is much more efficient than the carrier extension as no bandwidth is wasted on “scrap” data but the drawback is that the end-to-end delay for a frame is increased since you generally have to wait until you have the specified number of frames to send as a sequence which is bad for interactive services.",
        "answer_feedback": "the response correctly answers the definition of frame bursting, its advantage and disadvantage.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "94cd0306a0d14d699264c91ebf092277",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting: allows sender to transmit concatenated sequence of multiple frames in a single transmission\n\nadvantage: more efficient than carrier extension\n\ndisadvantage: needs frames waiting for transmission",
        "answer_feedback": "the response answers all three parts of the question accurately.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "9e534a26afb6424698450cd623677687",
        "question": "what is \"frame bursting\"? also, give 1 advantage and disadvantage compared to the carrier extension.",
        "reference_answer": "frame bursting reduces the overhead for transmitting small frames by concatenating a sequence of multiple frames in one single transmission, without ever releasing control of the channel.\nadvantage :it is more efficient than carrier extension as single frames not filled up with garbage.\ndisadvantage :need frames waiting for transmission or buffering and delay of frames",
        "provided_answer": "frame bursting is the transmission of concatenated frames in a single transmission. this increases the efficiency in comparison to the carrier extension because we only send relevant data. however, we have to wait until the buffer is full in order to concatenate and send them which increases the end to end delay.",
        "answer_feedback": "the response correctly answers all three parts of the question.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "37f19cc6f2c847bbad071400d736264b",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous:\n- each character is bounded by a start bit and a stop bit\n- generally low transmission rates, often up to 200 bit/sec\n- simple and inexpensive\n\nsynchronous:\n- several characters are pooled to frames and those frames are sent\n- frames are defined by syn or flag\n- more complex, but higher transmission rates",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3d7eea11a7ac4db9a4f4f8accbec46fd",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "in the asynchronous transmission mode each character is bounded by a start bit and a stop bit. in the synchronous transmission several characters are pooled to frames, that are defined by syn or flag.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "357ae5ef987443aeb7d4f44e2c50ef9a",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission (byte-oriented/ block-oriented):\ndata is sent in form of byte or character. the data (byte/character) is then bounded by a start bit and a stop bit. this is considered to be the simpler and less expensive way but it only supports low transmission rates.\n\nsynchronous transmission (character-oriented/ count-oriented/ bit-oriented):\ndata is sent in form of frames. therefore, several characters are bundled to frames. the frames are defined by syn or flag. this is considered to be the more complex approach. however, it supports higher transmission rates.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b44f0154cbc7463fb0b7dc76faf5b19c",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission mode: \n- each bit is transmitted individually\n- each character is bounded by a start bit and stop bit\n- simple and inexpensive\n- low transmission rate\n\nsynchronous transmission mode:\n- combine multiple bits to be transmitted at the same time\n- several characters pooled to frames -> different possibilities of frames bounding\n- complex\n- high transmission rate",
        "answer_feedback": "the response answer is correct as it correctly explains the differences between synchronous and asynchronous mode.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "dc46d268504d456faca768ba30c821bf",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "the asynchronous transmission mode needs a start and a stop character before and after each byte. therefore it has low transmission rates. but it is very simple and inexpensive.\nthe synchronous transmission mode has higher transmission rates. it works by pooling several characters to frames defined by syn or flag. therefore it is more complex than the asynchronous transmission mode.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "be35f019cc624cbca2bf4113ce3e4d3b",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "in asynchronous transmission, each character contains a start bit as prefix and a stop bit as suffix.\nin a synchronous transmission, several characters are grouped together in a frame, which are defined by a syn or flag.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "a0cd5a4831d54518b4caacf3a690785a",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission:\n each character is bounded by a strat bit and a stop bit.\n+ simple and not expensive\n- low transmission rates, often up to 200 bit/sec\n\nsynchronous transmission:\n several characters pooled to frames.\n frames defined by syn or flag.\n+ higher transmission rates\n- more complex",
        "answer_feedback": "the response correctly answers the differences between synchronous and asynchronous transmission mode.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d76164668ffa46bf87857c79650b6d71",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "async. transmission: each character of a message is bounded by a start and stop bit.this mode is both simple and inexpensive, but to the costs of low transmission rates which are mostly limited to 200 bit/sec.\n\nsync.transmission: several characters of the message a \"pooled\" to frames and those frames are defined by syn or flag. this apporach is more complex but enables higher transmission rate.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "e73c345e659f4f029cd414b28e40ec34",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "in asynchronous mode each byte is bounded by start- and stop bit and sent individually at any time. this is inefficient and has low transmission rate.\nsynchronous has higher transmission rate, but complex with regards to “how to detect beginning and ending of fields within a frame?”",
        "answer_feedback": "the response is correct as it answers the differences between synchronous and asynchronous transmission mode correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7849853c8aa94b6bb38be70517905c19",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "- asynchronous: start and stop bit between every byte (bad transmission rate, but easy to realize)\n\n- synchronous: use of flags/syn for start and end of data frames containing multiple bytes (higher transmission rate, but more complex)",
        "answer_feedback": "the response explains the differences between asynchronous and synchronous transmission correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3c109c56a5b24e998c01fe7d2daa1cf5",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronisation between sender and receiver.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "cc472cee228247ad9a4bbd89a24b7c17",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "the asynchronous transmission puts on each byte (character) a starter bit and a stop bit. that way is cheap and easy to implement, but the transmission rate would be low.\n\nthe synchronous transmission puts several bytes (characters) to a frame. syn or flags define these frames at the end and beginning of the frame. this mode is more complicated but has a higher transmission rate.",
        "answer_feedback": "the response correctly explains the differences between asynchronous and synchronous transmission.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b0cdf13ad14846a1a6ef94f123c01b58",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission:\n- each character is bounded by a start bit and a stop bit\n- simple + inexpensive, but low transmission rates, often up to 200 bit/sec\n\nsynchronous transmission:\n- several characters pooled to frames\n- frames defined by syn or flag\n- more complex, but higher transmission rates",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "b54f189b594c4d4fb0b9523c466250be",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "synchronous: characters are sent in frames. their size defined by a syn or flag sent at the start and the end of the transmission.\nasynchronous: characters begin and end are marked a start and a stop bit. each character is sent independently.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "d68d1f223c324e9ea6ca1e98b2ddf14f",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous mode: each character is bound between a start bit and a stop bit. -> simple and inexpensive but low transmission rate. \n\nsynchronous mode: several characters form into one frame, frames defined by syn or other flags.  -> more complex but higher transmission rate.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "65f4e7c08f6f4dd7b2a238cea8a088eb",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission: in this type of transmission, each character is bounded by a start and end bit. this is simple but offers low transmission rates upto 200bits/sec.\n\nsynchronous transmission: in this type of transmission, several characters are pooled  into frames and these frames are added syn or flag, this offers more transmission rates than the asynchronous.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "bb9c185b275d4a8fb38cf04bd710c6ec",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission – characters are transmitted individually, by encapsulating them within start and stop bit. its simple and inexpensive but has low data transmission rates\nsynchronous transmission – several characters are combined into a frame and encapsulating frame within syn or flag symbol. its complex but offers higher data transmission rates.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7c82ae35ed854048a9128949169fa15e",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission:\n- byte-oriented / block-oriented\n- each byte/block (packet) is bounded by start bit and stop bit\n- low transmission rates, often up to 200 bit/s\n- simple, inexpensive\nsynchronous transmission:\n- multiple characters pooled to frames\n- frames begin and end with syn or flag\n- higher transmission rates\n- requires additional effort / time\n- eg. character-oriented, count-oriented, bit-oriented protocols",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "61201db677b54b49a7200dae2f4d4616",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous transmission: each character (byte) is sent one-by-one at any time and is surrounded by a start and stop bit. this allows only low transmission rates, but is a simple and inexpensive form of transmission.\n\nsynchronous transmission: here the characters are combined to frames, and headers and trailers (syn or flag) are attached. as the frames can have different lengths, protocols (character oriented, count oriented, bit oriented) are needed to be declared, defining what is part of the flag and what is part of the data. this form of transmission is more complex, however it offers higher transmission rates.",
        "answer_feedback": "the response correctly explains the differences between asynchronous and synchronous transmission.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f1faf83f6b364136b818f271a6e00596",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asynchronous: \n•\teach character is framed by a start bit and an end bit\n•\tslow transmission\n•\tno gaps between data\n\nsynchronous:  \n•\tcharacters are pooled in frames, which are defined by flags or syns (synchronous idle characters)\n•\tfast transmission\n•\tgaps between data",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "9d309c81477b4bff8481025038e6286c",
        "question": "what is the difference between asynchronous and synchronous transmission mode in the data link layer.",
        "reference_answer": "asynchronous transmission: every character a self-contained unit surrounded by a start bit and a stop bit, which is an easy and cheap pattern, but causes low transmission rates.\n\nsynchronous transmission: several characters pooled to a continuous stream of data (frames), frames defined by syn or flag, higher complexity, but higher transmission rates. requires synchronization between sender and receiver.",
        "provided_answer": "asychronous: each charactes is wrapped by a start and stop bit. \nsynchronous: several characters are pooled to frames, defined by syns or any other type of flags.\n\nin the asychronous transmission mode multiple characters are combined in frames. the frames can be bounded by idle times, character-oriented, count-oriented, bit-oriented or by invalid characters of the physical layer. \nthe synchronous transmission is more complex, but has a higher transmission rate than the asychronous.",
        "answer_feedback": "the response answers the differences correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "62b60b31759e421da9ef16d680871fd4",
        "question": "what is the “dynamic host configuration protocol (dhcp)”? what is it used for? ",
        "reference_answer": "the dynamic host configuration protocol (dhcp) is a network management protocol used in internet protocol (ip) networks, whereby a dhcp server dynamically assigns an ip address and other network configuration parameters to each device on the network. further, dhcp has largely replaced rarp (and bootp)\n\t uses of dhcp are: simplifies installation and configuration of end systems. allows for manual and automatic ip address assignment. may provide additional configuration information  (dns server, netmask, default router, etc.)",
        "provided_answer": "with the “dynamic host configuration protocol” a host can find out about the ip address to a dedicated hardware address. it simplifies the installation and configuration of end-systems and it is used for manual and automatic ip address assignment. it may also provide additional configuration information such as dns server or netmask information.",
        "answer_feedback": "the response answers the definition and the usage of dhcp correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "df0a1cfb4efe42c5983d100ed2ac2d7a",
        "question": "what is the “dynamic host configuration protocol (dhcp)”? what is it used for? ",
        "reference_answer": "the dynamic host configuration protocol (dhcp) is a network management protocol used in internet protocol (ip) networks, whereby a dhcp server dynamically assigns an ip address and other network configuration parameters to each device on the network. further, dhcp has largely replaced rarp (and bootp)\n\t uses of dhcp are: simplifies installation and configuration of end systems. allows for manual and automatic ip address assignment. may provide additional configuration information  (dns server, netmask, default router, etc.)",
        "provided_answer": "dhcp is used to assign ip addresses and other configuration to (new) hosts in a network. after an initial dhcp discover packet of a client the server sends the assigned ip address back with additional information, like dns server or netmask.",
        "answer_feedback": "the response answers the definition and the usage of dhcp correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "dbecb8c382d84d629f8cfda0d4349b4d",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "if you send data in both direcions, you can add the acknowledgment ,for earlier packages, on the next data package.",
        "answer_feedback": "the response identifies the underlying requirement duplex connection correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "82911b1bdf4e4833aa4856ca1126ab9a",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the communication needs to be duplex.\nadditionally, there should be a time period, within this time period, data link layer should wait for the next packet, and attach the acknowledgement to the outgoing data frame and then send the frame.\nwhen time expires and there is no packet to be sent, link layer sends a separate acknowledgement frame.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "f61b064a65ad4e3b976e706c26dc77c9",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "before using piggybacking extension, there should be duplex operation. furthermore, a new packet should arrive quickly then the acknowledgement is piggybacked onto it; otherwise, if no new packet has arrived by the end of this time period, the data link layer just sends a separate acknowledgment frame. \n\nalso, the sliding windows protocol will utilize the bandwidth of the communication channel with piggybacking, frames may contain implicit acknowledges. for example, the intuitive seqno. is 0, then the next seqno. and the next ack-seqno to be expected is given.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "796d2be28fe943b19c2bac6d36fd060e",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "-it has to be a full-duplex operation\n-frames must contain implicit acknowledgments",
        "answer_feedback": "the response answers the underlying requirement correctly. both points are correct.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3f4dfec8e6804088896b64c370cf8838",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "data and acknowledgements are send in both directions (sender to receiver and receiver to sender). the data and acknowledgements are bundled into one package.",
        "answer_feedback": "the response is correct as it implicitly answers the requirement of duplex communication.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "3a73cb0819ee4608aaf03f438de28127",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "duplex operation",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "0feac5f89e2c448aaa965172753d53ba",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "piggybacking means the acks are not sent separately but are inside the header of the next package that the party who is acknowledging the last package wants to send.\nso piggybacking only makes sense when both partners are sending and receiving data, i.e. we have a duplex transfer operating mode.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "95c60c298fbd43ca9a82d4d302c37d59",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "we require atleast a (semi)duplex data transfer",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "7f3e239e989241fd9d6ddcaee5a7ef07",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "we need a duplex operation. this means that sender and receiver both sends and receives frames. then ack and data can be merged into one frame and sent together.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "070e2ed4e09044d08c1e3dbca7043683",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "sending must be possible in both directions in order to send data and acks (two-way-communication) and the frames must be able to contain acks.",
        "answer_feedback": "the response states both the requirements correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "6b783d4c1f82440a8d3143e39653c53e",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "both parties must be able to send data and acknowledge information",
        "answer_feedback": "the response answers the underlying requirement, i.e. duplex connection, correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "99e09920912547c2841ed020d5520cfe",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "to be able to take advantage of the piggybacking extension in the sliding window protocol, a full duplex communication channel with both parties actively sending messages is required. otherwise, the implicit acks cannot be added to outgoing data frames.",
        "answer_feedback": "the response answers the underlying requirement correctly.",
        "verification_feedback": "correct",
        "max_score": 1.0,
        "normalized_score": 1.0
    },
    {
        "id": "90ccaf87dcd440ae8602a5b2a2b73b22",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "the problem will occur at the receivers end which cannot differentiate between the correct and the duplicated data without given any additional information",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "c555871e7efe4e5fa02352b4b1888acc",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "cf67ef58d125439eb4bd7a5cff26f5f2",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "without additional means the receiver\ncannot differentiate between correct\ndata and duplicated data.",
        "answer_feedback": "the response is correct. the response can also state what will be the consequence in such a scenario.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "4521515af2f34a6a82b2d8c0bc8bb80d",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "without additional safeguards duplicate packets could trigger an action (i.e. bank transfer) a second time.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "a59c5c1849e640fda2d37cf5ffa352e3",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "without additional measures in a network duplicate packets can not be differentiated from the correct packets and therefore a transaction would be re-executed by the duplicates.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "d344fa984a1f458895c9aa58011f29af",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "the network protocol needs a method to prevent duplicate packets otherwise a loop could be formed where the duplicate packet is forwarded indefinitely. an is would need to keep track of all packets it has seen recently which is not feasible.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "a046d27716434e61b787e0a2ebd30db5",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "the performance of the network goes down with too many duplicate packets and we need to find ways to differentiate between correct date and duplicate date.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "2032f14f3ef14833a27a8614b9ce44b8",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicate packages are handed over to the receiver too late at an undesired time, so that the receiver can't handle it or handles it twice, which for example can result in a loss if for example money is booked twice.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "f73fb47f8a8f476787e243ad43f06df1",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "if the receiver can't detect that a certain packet is a duplicate of one that arrived before, it might be processed independently causing maybe an action to be executed twice (for example a bank transaction).",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "6c177189b5fb40dea9f8eabffd812f81",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "if you have too many duplicates the performance goes down and the network gets overloaded.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "e3b363d9bd114126a3106a82b6cac438",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicates can lead to network congestion.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "4dbcd208aeac40d3b6b9428afb8640cc",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "they congest the network by creating unnecessary traffic.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "2bddea03f90c4eb6bb79fc3cb177818d",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "if there are many duplicates in the network, the performance may decrease (-> congestion) and problems might occur (bank example from the lecture).",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "be15d5fcf63d4d2f837cc59e1bb413a6",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicate packets arriving at receiver may cause a transaction to be completed multiple times.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "f7b5e8354f284f4b9736378b4524b0ba",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicate data cannot be differentiated from correct data , and it would re-execute the transaction.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "0db1acd6622b44eb919b3fda5f84e725",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicate können zum problem werden, weil zum beispiel befehle mehrmals ankommen und auch mehrmals ausgeführt werden.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "02fb0d14e1764a14a0e3e1d93d01c00b",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "duplicates may look like two separate commands/messages to the receiver.",
        "answer_feedback": "the response is correct. the response can also state what will be the consequence in such a scenario.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "a4fc8dcddb9a4dc4b3a970565c90bbfd",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "they can cause an action to happen twice since the receiver may not be able to distinguish between a packet that was sent twice and one packet that arrives twice.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "0198472195004fc2a3a7e8fc00dfc332",
        "question": "why can duplicate packets be a problem in a network? please state your answer in a single sentence.",
        "reference_answer": "if the receiver is not capable of differentiating between valid and duplicated packets it may act on the same information twice.",
        "provided_answer": "this can be a problem if the recipient of the duplicates has no way to distinguish between correct and duplicate data, such that late duplicates could be incorrectly considered as new data.",
        "answer_feedback": "the response is correct.",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "32bce467b7764dc5acce04d213290af9",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 and 127.x.y.z",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "f53726e7af9c4765b21e0e9c9880c5c6",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved for host\n0.0.0.0/8 - 0.255.255.255/8 \nreserved for loopback addresses/broadcast\n127.0.0.0/8 - 127.255.255.255/8",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "0467703ff80547778fed769656beed43",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "for each x ∈ {1,...,127} the network address x.0.0.0 and the broadcast address x.255.255.255 are reserved.\naccording to rfc 6890addresses 10.0.0.0-10.255.255.255 are reserved for private-use networks\naddresses 100.64.0.0-100.127.255.255 are reserved for shared address space\naddresses 127.0.0.0-127.255.255.255 are reserved for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "a6e7baf8415e481183a565419c0bf35d",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 - 0.255.255.255\n\n10.0.0.0 - 10.255.2555.255\n\n100.64.0.0 - 100.127.255.255\n127.0.0.0 - 127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "cfa2be07eac64025875dff4e65c0f752",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - dummy address\n10.0.0.0/8 - private network\n127.0.0.0/8 - loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "dee1d8ee89d14b08a58dc9a79a9b20df",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0/8 - start address\n127.0.0.0/8 through 127.255.255.255/8 are reserved for loopback addresses",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "0ddb032ad52f40f28f13410e5f1501e4",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "class a:\n1.0.0.0 up to 127.255.255.255\nreserved addresses:\n(1-126).0.0.0\n(1-126).255.255.255\n127.0.0.0 to 127.255.255.255 (loopback adresses)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "e00c5179dd19478591a83272fb13b53f",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "according to slide 45 of the lecture \"internet protocol: ip addressing – interior and exterior gateway protocols\", following adresses are reserved:\nreserved for current network:0.0.0.0 - 0.255.255.255\nreserved for loopback adresses to the local host:127.0.0.0 - 127.255.255.255\nmoreover, the first and last adress of every network can't be used, because they are for network and broadcast: (1-126).0.0.0 and (1-126).255.255.255.",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "379367506ec44f90904d8a61d5b31f53",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 to 0.255.255.255 is for current network and 127.0.0.0 to 127.255.255.255 for loop-back addresses",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "e6537b3af62b469d85e797322b866d8f",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "10.0.0.0 to 10.255.255.255 private ip addresses\n\n127.0.0.0 to 127.255.255.255 reserved for loopback",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "3e105de6d26840329998610e34fbe0b0",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0–0.255.255.255\n127.0.0.0 - 127.255.255.255\n10.0.0.0–10.255.255.255 (reserved for private networks, not routed through the internet)\n100.64.0.0–100.127.255.25 (reserved for private networks, not routed through the internet)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "363d29b2e2eb4e819965c55aa6edd715",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "according to rfc 6890 the following address blocks are reserved (https://datatracker.ietf.org/doc/html/rfc6890#section-2.2.2):\n127.0.0.0/8 with the range 127.0.0.0 - 127.255.255.255 loopback adresses\n100.64.0.0/10 with the range   100.64.0.0–100.127.255.255 if carrier-grade nat is used this is the shared address space between a service provider and its subscribers\n\n10.0.0.0/8  with the range 10.0.0.0 - 10.255.255.255 private network adresses\n\n0.0.0.0/8 with the range 0.0.0.0 - 0.255.255.255 host adresses at this network with 0.0.0.0 being this host\n\nadditionally these adresses are reserved:\nx.0.0.0 network adresses, where x is 0-127 (excluding 0.0.0.0 and 127.0.0.0 as reserved rfc addresses)\nx.255.255.255 broadcast adresses, where x is 0-127 (excluding 0.255.255.255 and 127.255.255.255 as reserved rfc addresses)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "4b96973e77894c519c0f58a3a97d2bf6",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved addresses:\n127.0.0.0 – 127.255.255.255 (for loop-backs)",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "50602b62a9cb4dcdb3648ec7d4fcfdfb",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0\n127.0.0.0 to 127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "230c8812eab44963b03df9b3d4a59e34",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0–0.255.255.255\n10.0.0.0–10.255.255.255\n100.64.0.0–100.127.255.255\n127.0.0.0–127.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "1bc63176fd804b428e663faa77424a98",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "reserved for loopback : 127.0.0.0 - 127.255.255.255\nclass a reserved range : 10.0.0.0 to 10.255.255.255",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    },
    {
        "id": "2343d07a6e6d4069b87b1c54564c9c7f",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "the host itself:\n0.0.0.0 (00000000.00000000.00000000.00000000)\n\na host at the same network:\n0.x.x.x (00000000.yyyyyyyy.yyyyyyyy.yyyyyyyy)\n\nbroaodcast on another network:\nx.255.255.255 (yyyyyyyy.11111111.11111111.11111111) for x in range [0,127]\n\nloopback:\n127.x.x.x",
        "answer_feedback": "correct",
        "verification_feedback": "correct",
        "max_score": 0.5,
        "normalized_score": 1.0
    }
]
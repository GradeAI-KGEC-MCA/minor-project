[
    {
        "id": "smp0051q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used, since all users have perfect code and all frequency modulation is utilized (users have access to selected frequencies at all times)",
        "answer_feedback": "the response is incorrect as under the given scenario binary encoding is better suited.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0367q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the initial seqno needs to be known + the next seqno and the next ack-seqno needs to be known.\notherwise, piggybacking is not possible.",
        "answer_feedback": "the response is incorrect as the main requirement for piggybacking is a two-way/duplex channel. the points stated in the response are an implementation detail of the sliding window protocol.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0165q009",
        "question": "let us assume that you flip a coin 6 times where the probability of heads (h) showing up is 0.6. please arrange the following events in the increasing order of their likelihood (i.e., least probable → most probable): ● event a: you see at least three h’s ● event b: you see the sequence hhhttt ● event c: you see exactly three h’s include justification in your answer headers.",
        "reference_answer": "the correct sequence is bca , where b is the least probable. one of the following justifications should be given:\n\t\t● event b is a subset/part/special case of c, and c is a subset/part/special case of a\n\t\t● event b is more specific/strict than c and c is more specific/strict than a\n\t\t● an actual, correct calculation of the probabilities:\n\t\t○ p(b) = 0.6 * 0.6 * 0.6 * 0.4 * 0.4 *0.4 = 0.6^3 *0.4^3 = 0.013824 \n\t\t○ p(c) = (6 choose 3) * p(b) = 0.27648 \n\t\t○ p(a) = p(c) + p(y=4) + p(y=5) + p(y=6) = 1 - p(y=0) - p(y=1) - p(y=2)\n\t\t= (6 choose 3) * 0.6^3 * 0.4^3 + (6 choose 4) * 0.6^4 * 0.4^2 +(6 choose 5) *\n\t\t0.6^5 * 0.4 + (6 choose 6) * 0.6^6\n\t\t= 0.27648 + 15 * 0.020736 + 6 * 0.031104 + 1 * 0.046656\n\t\t= 0.8208 \n\t\t○ the answer may be rounded to up to 2 decimal places, e.g. p(b) = 0.01 or\n\t\tp(b) = 0.014\n\t\t○ it is also sufficient to give a formula without the actual calculation, if it is apparent that p(b) less than p(c) less than p(a), e.g. by stating p(c) = 20 * p(b)",
        "provided_answer": "event c, event a and event b",
        "answer_feedback": "the stated order of events is incorrect. the correct order is b, c, a. additionally, the response lacks a justification regarding all event probabilities.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0263q017",
        "question": "which property of spanning trees makes them appealing for broad- and multicasting? explain how you can modify link state routing to construct a spanning tree for multicasting.",
        "reference_answer": "property: there is a single unique path between every pair of nodes in the tree. alternatively, you can say that spanning trees are subnets of a network that do not contain loops but contain all nodes. this means that no unnecessary duplicates are distributed in the network when forwarding packets using that tree structure.\n\nspanning tree with link state routing: each intermediate system knows which multicast groups it belongs to, but initially doesn’t know which other is belong to the groups. therefore, you can add multicast group information to the link state packet and each node can construct multicast trees once the full network topology and group information are distributed in the whole network, as each node then has the complete state information stored locally (e.g. with prim or kruskal)",
        "provided_answer": "spanning trees allows to reach all other nodes of a network with a small subset of links. a spanning tree therefore \"provides\" information for broad- and multicasting to send the packets through the \"best\" route (e.g. minimum hops).",
        "answer_feedback": "the response incorrectly describes the reason why a spanning tree is attractive for broadcast and multicast. although the number of links is reduced, they also need to connect without loops, reducing duplicates. the modification related to the link state algorithm to construct a  multicast spanning tree is not provided.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0405q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 \n127.255.255.255\nthe first adress and the last adress of each subnet are reserved",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0383q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "both parties have to advertise their window sizes to each other to avoid the received data to be thrown away (so the receiving buffer was full). therefore, they need to introduce a new field to the frames which holds this value. alternatively, they agree upon first communication to some static window size and afterwards send their data (and hope the free buffer sizes of both remain the same). in both cases it would be recommandable not to send huge data chunks upon first communication, because both parties don't know the window sizes of the other one yet. with each frame they send a sequence number (even if no data is sent, so the receiver is able to acknowledge it), the ack-number (even if no new data has been received, so the receiver can use this as base for their sequence number), and lastly the window size.",
        "answer_feedback": "the response is incorrect. all the stated points are correct but are related to the window sliding mechanism in general and how the initial setup occurs.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0415q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "0.0.0.0 and 127.255.255.255",
        "answer_feedback": "the addresses have a range: 127.0.0.0 - 127.255.255.255\nmissing loopback",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0381q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the participant, who sends the ack, has to have data, which he wants to send. if there is no data to \"biggyback\" the ack on, the participant will wait infinitly for data to send with the ack and therefore the piggyback extension would not work.",
        "answer_feedback": "the response is incorrect because a dedicated timer can be used on the receiver side to overcome the above problem of no data on the receiver side. after the timeout, an acknowledgment is sent independently.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0033q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "as there is no global clock, i would not suggest binary encoding. as there is much traffic i would choose differential manchester encoding, rather than the normal one which is more susceptible to noise.",
        "answer_feedback": "as the perfect clocks are already provided, self-clocking is not required.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0305q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "then the maximum segment length becomes 2000m, which is too long for collision recognition.",
        "answer_feedback": "the collision diameter decreases by a factor of 10 rather than becoming 2000m for a collision to be still detected.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0197q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "tcp header: 1.reliable bidirectional in-order byte stream 2.connections established and torn down 3.multiplexing/ demultiplexing 4.ports at both ends 5.end-to-end flow control 6.congestion avoidance udp 1.udp is a simple transport protocol 2.unreliable 3.connectionless 4.message-oriented 5. no flow control 6. no error control",
        "answer_feedback": "the question requirement is to identify differences between tcp and udp headers instead of general differences.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0030q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "differential manchester encoding should be used because it is overall more complex. \n\nsimilarly to manchester encoding, dm encoding takes advantage of splitting the interval into two, where a voltage level shift takes place (either from high voltage to low voltage or vice versa). however, manchester encoding is still too similar to binary encoding in that a 1 will always be equivalent to a voltage shift from high --> low and a 0 will always be low --> high voltage. instead, if the voltage shift occurs between intervals (either high -> low or low -> high), a 0 will be encoded. likewise, if there is no voltage shift between intervals then a 1 is encoded. by comparing the current interval to the previous interval's voltage level, a more accurate encoding technique can be realized.\n\nand unlike the binary encoding system, dm encoding does not rely on binary voltage levels to encode a bit stream. instead, merely a change in voltage level between intervals encodes the bit stream. (ex. a lack of voltage level change between the first and second interval would mean that the second bit in the stream is a 1) therefore, because the voltages only need to differ between intervals, the bit stream is less susceptible to noise/error.",
        "answer_feedback": "the preference is always for a simple solution. further self-clocking is not required here and manchester provides lower bandwidth utilization which can further complicate the congestion problem.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0371q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "a relieable in-order delivery of packets (like data link layer 2 in osi)\n\nat least an acknowledged connectionless service or an acknowledged connection-oriented service (for feedback if the packets / frames are received).",
        "answer_feedback": "the response is not directly related to the piggybacking but to sliding window protocol in general.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0024q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "tcp should be used because it has a bidirectional bitstream. furthermore it provides a flow control in order to handle too musch traffic.",
        "answer_feedback": "the response is not related to the theme of the encoding type.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0053q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the differential manchester encoding might be the best option here. both manchester and differential manchester encoding have a self-clocking feature which enables users to know if a tansmission is happening at the moment (every clock cycle a change if there is an active transmission). the differential variant has a low susceptibility to noise which might be beneficial in a multi-user environment because it might lower the chances of e.g. retransmissions.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0384q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "every transmission must contain an ack.",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. a duplex connection is needed, so that data and acknowledgments can be sent both ways.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0370q024",
        "question": "what requirement has to be met so that you can use the piggybacking extension to the sliding window protocol?",
        "reference_answer": "piggybacking only makes sense if there is a full-duplex or semi-duplex connection between sender and receiver i.e.  two-way communication or frames must contain additional field for acknowledgement.",
        "provided_answer": "the receiver must have data to send back to the sender so he can attach the ack information to that data. if he has no data to send, the service can be jammed. to prevent this, a receiver timeout can be added so that after the timeout has expired and no data was sent, an ack packet is sent independently",
        "answer_feedback": "the response does not answer the underlying requirement for piggybacking. the response states a possible situation in piggybacking and how to overcome it.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0225q014",
        "question": "transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2-5 sentences. ",
        "reference_answer": "1.a mapping between destinations/stations (macs) and outgoing lan interfaces.\n2.this table is initially empty and received packages are flooded on every line. when a bridge receives a frame (as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links) with source address q on lan l, it adds the timestamped entry “q can be reached over l” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time-stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic.\n3.to do selective forwarding instead of flooding. \n4.i)less duplication/unnecessary flooding is prevented.\nii)less congestion.\niii)better bandwidth usage than flooding.",
        "provided_answer": "transparent bridges store destination addresses and start with an empty forwarding table.this table is populated by using backward learning (once the bridge receives a frame from an unknown source over router x, it stores the address information of the source). whenever a frame is sent to an unknown destination (no table entry), that frame is then flooded and the destination responds to the bridge to create a table entry. transparent bridges are invisible to other components during the forwarding process, thus simplifying other components.",
        "answer_feedback": "the response has the following errors a) transparent bridges store not just the destination but also the corresponding outgoing lan along with the timestamp. b) the stated backward learning process is incorrect. c)yes, the transparent bridges are invisible but that is not the benefit derived from using selective forwarding instead of flooding.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0060q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "if the equilibrium has been already reached then assuming that the packets during this 1 minute are evenly distribute, the system would be most of the time in the state where less than 10 packets wait in the queue.\nwe calculate the probability that there are packets p(0) for 0 -9 using this (1-r)^n-1\nthen we",
        "answer_feedback": "the first step of calculating probabilities for 0, 1, …, 9 packets to be in the queue is correct, but it is incomplete. additionally, the final step of multiplying it with the time frame to receive the expected number of seconds is missing in the response.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0059q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "less than 60 seconds, more than 50 seconds (50-60 seconds),\nbecause the buffer size has 10 and 9 packets go in 10 packets go out. the buffer size of 10 is never exceeded.\n\n- steps involved :\n1.arrival process: how customers/requests arrive?(time between requests ,inter-arrival time)\n2.service process: how much demand do requests generate?(service time of single requests)\n3.how many places in queue?\n4.how many service stations?\n5.how are queues processed?(first-come-first-serve (fcfs), shortest job first, priority queue, and so on)",
        "answer_feedback": "the required justification is missing and a broad time interval is provided but the precise time in seconds was expected.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0319q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter will be increased.",
        "answer_feedback": "the response is incorrect as it states that the diameter increases. instead, for collisions to be detected, the diameter decreases by a factor of 10.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0078q004",
        "question": "consider the following network topology from the lecture:with routing, we want to find the best path for our packets. for this, we first need to define a metric to evaluate the quality of a path. one possible choice could be the current load (i.e. the current utilization in terms of sent packets/bytes) on this path. assume that a wants to send data to g, could this routing strategy cause any problems at the receiver end? please explain your answer in 1-2 sentences.",
        "reference_answer": "yes, using the current load to find the best path can lead to fluctuations/oscillations when there is more than one path between any pair of end systems in the network (here: cf and ei). this can cause packet reorderings at the receiving side.",
        "provided_answer": "using current load could be not the lowest cost path.",
        "answer_feedback": "but this is no problem at the receiver end",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0047q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "cdma\nin cdma, all the stations can transmit data simultaneously. it allows each station to transmit data over the entire frequency all the time. multiple simultaneous transmissions are separated by unique code sequence. each user is assigned with a unique code sequence. which means the rate of data is high.",
        "answer_feedback": "the question asks for the type of encoding to be used, not for access types.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0202q012",
        "question": "state at least 4 of the differences shown in the lecture between the udp and tcp headers.",
        "reference_answer": "possible differences :\nthe upd header (8 bytes) is much shorter than the tcp header (20-60 bytes)\nthe udp header has a fixed length while the tcp header has a variable length\nfields contained in the tcp header and not the udp header :\n-sequence number\n-acknowledgment number\n-reserved\n-flags/control bits\n-advertised window\n-urgent pointer\n-options + padding if the options are\nudp includes the packet length (data + header) while tcp has the header length/data offset (just header) field instead\nthe sender port field is optional in udp, while the source port in tcp is necessary to establish the connection",
        "provided_answer": "1. udp is connectionless and the tcp is connection oriented.\n2. udp does not control the errors, this means that if there was a with the order of the packets or one of them got lost, the udp won´t correct anything and will send it exactly the same to the application layer. instead, the tcp corrects all the errors and transmit the packets reliably.\n3. the udp needs few resources. the tcp instead has higher resource requirements for buffering, status information and timer usage.\n4. the udp transmission is fast because it is connectionless. the tcp instead needs to wait for the connection establishment and the disconnection to send any message.",
        "answer_feedback": "the response is incorrect as the question asked for the differences between headers, but the answer enumerates differences between tcp and udp protocol instead.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0055q003",
        "question": "consider a single server queueing system with a buffer of size 10. let us assume that 9 packets arrive per second and 10 packets are served per second on an average. assume you monitor the system for exactly one minute after the system reaches equilibrium. how many seconds would you expect the system to be in a state in which there are less than 10 packets waiting in the queue? you need to justify your answer by showing steps involved; calculations, however, need not be included. headers.",
        "reference_answer": "since we have a buffer size (n) of 10, we will always have less than 10 packets waiting in the queue unless there are exactly 10 packets in the queue. therefore, we first calculate the probability of the system being full/having 10 packets in the queue. this is also called “blocking probability” or p_b.\np_b = ((1 - utilization) * utilization^n) / 1 - utilization^(n+1) = ((1-0.9) * 0.9^10) / (1 - 0.9^11) = 0.0508\nalternatively to the blocking probability, it is also valid to directly calculate p(x less than 10) = (1 -p_b) by summing up the probabilities for 0, 1, …, 9 packets to be in the queue. to calculate the expected time where the system is not blocked in the 60-second observation time-frame, we simply multiply the time frame with p(x less than 10) or the complement of p_b (0.25p) = 60 * (1-p_b) = 56.9512 seconds",
        "provided_answer": "assuming 9 packets arrive each second and 10 are served. on average the buffer should never be full leading to a 60s time where there are less than 10 packets in the queue.",
        "answer_feedback": "the stated justification is incorrect as the given rates are not constant and can vary through time, so an average needs to be calculated for the given time. therefore, the stated time is also incorrect.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    },
    {
        "id": "smp0410q026",
        "question": "write-down all addresses in class a networks that are reserved.",
        "reference_answer": "126 class a nets can be addressed in classful ip addressing (1.xx.yy.zz - 126.xx.yy.zz) 127.xx.yy.zz is reserved for loopback testing 0.xx.yy.zz can be accepted if stated accordingly (definitions defer whether this is in class a)",
        "provided_answer": "class a:\n0.0.0.0. - 127.255.255.255",
        "answer_feedback": "not all addresses in class a are reserved",
        "verification_feedback": "incorrect",
        "max_score": 0.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0050q002",
        "question": "assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link’s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2-4 sentences.",
        "reference_answer": "binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0.5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self-clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons.",
        "provided_answer": "the users can use both manchester or differential manchester encoding. the reason behind as fol:\n1. both of them uses .5 bit per baus so channel capacity is reduced.\n2. less susceptible to noise due to interfearance.",
        "answer_feedback": "the binary encoding is the better option because of better bandwidth utilization and no self-clocking requirement.",
        "verification_feedback": "incorrect",
        "max_score": 2.5,
        "normalized_score": 0.0
    },
    {
        "id": "smp0309q020",
        "question": "what happens to the \"collision domain diameter\" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s (all else being equal)?",
        "reference_answer": "diameter decreases by a factor of 10, e.g 300m to 30m.",
        "provided_answer": "the collision domain diameter will be increased to 10times compared with the distance in 10mb/s.",
        "answer_feedback": "the diameter is decreased by a factor of 10 instead of increased.",
        "verification_feedback": "incorrect",
        "max_score": 1.0,
        "normalized_score": 0.0
    }
]
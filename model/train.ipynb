{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8845ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mav204/Documents/minor-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOT = '/home/mav204/Documents/minor-project'\n",
    "os.chdir(ROOT)\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe96637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd drive/MyDrive/minor-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c55727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mav204/Documents/minor-project/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misc.dataset_modifier \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from model.tokenizer import tokenize\n",
    "from misc.dataset_modifier import separate, combine_data, get_json\n",
    "from model.b_trainer import BertTrainer\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    # Macro F1 is critical here because both files are skewed\n",
    "    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa364131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined size:  1339\n",
      "combined size:  160\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your specific split files\n",
    "data_files = {\n",
    "    \"train\": get_json(\"./data/updated/combined/train.json\"),\n",
    "    \"validation\": get_json(\"./data/curated/validation.json\")\n",
    "}\n",
    "train = separate(data_files[\"train\"])\n",
    "val = separate(data_files['validation'])\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": combine_data(train['correct'], train['incorrect']),\n",
    "    \"validation\": combine_data(val['correct'], val['incorrect'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8492bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1339/1339 [00:01<00:00, 789.35 examples/s] \n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 1070.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Incorrect=402, Correct=937\n",
      "Class Weights: tensor([1.6654, 0.7145])\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Tokenize ---\n",
    "# Pass your raw dictionary of lists (train and validation)\n",
    "tokenized_data = tokenize(data_dict=data_files, is_training=True)\n",
    "\n",
    "# --- 2. Handle Training Labels & Weights ---\n",
    "# We extract labels from the 'train' split specifically\n",
    "# Use int() to ensure it works whether it's a tensor, numpy scalar, or plain int\n",
    "train_labels = [int(x[\"labels\"]) for x in tokenized_data[\"train\"]]\n",
    "counts = np.bincount(train_labels)\n",
    "total = len(train_labels)\n",
    "\n",
    "# Skew adjustment: Weight = Total / (Num_Classes * Count_per_Class)\n",
    "class_weights = torch.tensor(\n",
    "    [total / (2 * counts[0]), total / (2 * counts[1])], \n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "print(f\"Train distribution: Incorrect={counts[0]}, Correct={counts[1]}\")\n",
    "print(f\"Class Weights: {class_weights}\")\n",
    "\n",
    "# --- 3. Dataset Assignment ---\n",
    "train_dataset = tokenized_data[\"train\"]\n",
    "eval_dataset = tokenized_data[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17803f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------- Datasets --------------------------------------------\n",
      "\n",
      "============================== TRAINING (COMBINED) ==============================\n",
      "Label: 1 (correct)\n",
      "\n",
      "Decoded Input Text:\n",
      "[CLS] question : what happens to the \" collision domain diameter \" if you use csma / cd and increase the speed of a network by a factor of 10, eg from 10mb / s to 100mb / s ( all else being equal )? reference : diameter decreases by a factor of 10, e. g 300m to 30m. [SEP] the collision domain diameter will be reduced by the factor 10, when only the speed parameter would be increased by the factor 10. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Metadata Fields: ['id', 'question', 'reference_answer', 'provided_answer', 'answer_feedback', 'verification_feedback', 'max_score', 'normalized_score', 'is_augmented', 'question_id']\n",
      "\n",
      "============================== VALIDATION ==============================\n",
      "Label: 1 (correct)\n",
      "\n",
      "Decoded Input Text:\n",
      "[CLS] question : transparent bridges manage a bridge table for the forwarding process. please describe what information the table holds and how it is modified during the backwards learning phase. how is the table used in the forwarding process and what is one benefit of that? please answer the question in 2 - 5 sentences. reference : 1. a mapping between destinations / stations ( macs ) and outgoing lan interfaces. 2. this table is initially empty and received packages are flooded on every line. when a bridge receives a frame ( as the bridge runs in promiscuous mode it listens in on all the traffic arriving at its lan links ) with source address q on lan l, it adds the timestamped entry “ q can be reached over l ” to the table and the next time a packet with destination q arrives, it is forwarded on link l. the time - stamp is used to update or purge old entries. therefore, it learns by observing the incoming traffic. 3. to do selective forwarding instead of flooding. 4. i ) less duplication / unnecessary flooding is prevented. ii ) less congestion. iii ) better bandwidth usage than flooding. [SEP] the bridge table holds the information which output lines / lans to use to get to a certain station. the bridge inspects the traffic ( backward learning ) and when the bridge receives frames with source address q on lan l it learns that q can be reached over l and creates a table entry accordingly so it can adapt to changes in topology. when the bridge gets a frame with the identical source and destination lans in its table, the frame can be immediately dropped since it was already on the right lan. when the source and destination lans differ, the frame is rerouted to the destination lan. the frame is only flooded when the destination is unknown ; with this decision procedure unnecessary flooding or forwarding is prevented. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Metadata Fields: ['id', 'question', 'reference_answer', 'provided_answer', 'answer_feedback', 'verification_feedback', 'max_score', 'normalized_score']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./model/bert_tokenizer\")\n",
    "\n",
    "def print_dataset_sample(dataset, name):\n",
    "    print(f\"\\n{'='*30} {name} {'='*30}\")\n",
    "    batch = dataset[0]\n",
    "    \n",
    "    # Use int() to safely handle both Tensors and plain integers\n",
    "    label_val = int(batch['labels'])\n",
    "    label_text = \"correct\" if label_val == 1 else \"incorrect\"\n",
    "    \n",
    "    # Decode the input_ids back into text\n",
    "    decoded_text = tokenizer.decode(batch[\"input_ids\"], skip_special_tokens=False)\n",
    "    \n",
    "    print(f\"Label: {label_val} ({label_text})\")\n",
    "    print(f\"\\nDecoded Input Text:\\n{decoded_text}\")\n",
    "    \n",
    "    # Print extra fields (the \"stuff\") that might be in this specific split\n",
    "    extra_fields = [k for k in batch.keys() if k not in [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]]\n",
    "    if extra_fields:\n",
    "        print(f\"\\nMetadata Fields: {extra_fields}\")\n",
    "        \n",
    "print('-------------------------------------------- Datasets --------------------------------------------')\n",
    "\n",
    "if \"train\" in tokenized_data:\n",
    "    print_dataset_sample(tokenized_data[\"train\"], \"TRAINING (COMBINED)\")\n",
    "    \n",
    "if \"validation\" in tokenized_data:\n",
    "    print_dataset_sample(tokenized_data[\"validation\"], \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model/results\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = BertTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

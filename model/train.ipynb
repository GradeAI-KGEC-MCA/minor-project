{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8845ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mav204/Documents/minor-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOT = '/home/mav204/Documents/minor-project'\n",
    "os.chdir(ROOT)\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe96637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd drive/MyDrive/minor-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c55727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from model.tokenizer import tokenize\n",
    "from misc.dataset_modifier import separate, combine_data, get_json\n",
    "from model.b_trainer import BertTrainer\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    # Macro F1 is critical here because both files are skewed\n",
    "    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa364131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined size:  666\n",
      "combined size:  160\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your specific split files\n",
    "data_files = {\n",
    "    \"train\": get_json(\"./data/curated/train.json\"),\n",
    "    \"validation\": get_json(\"./data/curated/validation.json\")\n",
    "}\n",
    "train = separate(data_files[\"train\"])\n",
    "val = separate(data_files['validation'])\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": combine_data(train['correct'], train['incorrect']),\n",
    "    \"validation\": combine_data(val['correct'], val['incorrect'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8492bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 666/666 [00:00<00:00, 1069.49 examples/s]\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 1119.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Incorrect=82, Correct=584\n",
      "Class Weights: tensor([4.0610, 0.5702])\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Tokenize ---\n",
    "# Pass your raw dictionary of lists (train and validation)\n",
    "tokenized_data = tokenize(data_dict=data_files, is_training=True)\n",
    "\n",
    "# --- 2. Handle Training Labels & Weights ---\n",
    "# We extract labels from the 'train' split specifically\n",
    "# Use int() to ensure it works whether it's a tensor, numpy scalar, or plain int\n",
    "train_labels = [int(x[\"labels\"]) for x in tokenized_data[\"train\"]]\n",
    "counts = np.bincount(train_labels)\n",
    "total = len(train_labels)\n",
    "\n",
    "# Skew adjustment: Weight = Total / (Num_Classes * Count_per_Class)\n",
    "class_weights = torch.tensor(\n",
    "    [total / (2 * counts[0]), total / (2 * counts[1])], \n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "print(f\"Train distribution: Incorrect={counts[0]}, Correct={counts[1]}\")\n",
    "print(f\"Class Weights: {class_weights}\")\n",
    "\n",
    "# --- 3. Dataset Assignment ---\n",
    "train_dataset = tokenized_data[\"train\"]\n",
    "eval_dataset = tokenized_data[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17803f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------- Datasets --------------------------------------------\n",
      "\n",
      "============================== TRAINING (COMBINED) ==============================\n",
      "Label: 0 (incorrect)\n",
      "\n",
      "Decoded Input Text:\n",
      "[CLS] question : assume you have a local network with 3 users that are all interconnected and have perfect clocks. typically the network is often congested as all users generate more traffic than the link ’ s capacities. which of the encoding techniques introduced in the lecture should be used in this network to encode bitstreams? give two reasons for your answer in 2 - 4 sentences. reference : binary encoding, as it is the most efficient in terms of bandwidth since you get a full bit per baud instead of only 0. 5. additionally, you do not have to deal with clock drift and various ticking rates as all clocks are perfect. therefore, self - clocking / clock recovery is not as necessary. simple and cheap is also acceptable as one of the reasons. [SEP] differential manchester encoding should be used, because - it is not susceptible to noise, it depends on signal polarity, not absolute values - it has a good self - clocking feature, so it is synchronous, which is useful for when the traffic is greater than the link ' s capacities. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Metadata Fields: ['id', 'question', 'reference_answer', 'provided_answer', 'answer_feedback', 'verification_feedback', 'max_score', 'normalized_score', 'is_augmented', 'question_id']\n",
      "\n",
      "============================== VALIDATION ==============================\n",
      "Label: 1 (correct)\n",
      "\n",
      "Decoded Input Text:\n",
      "[CLS] question : state at least 4 of the differences shown in the lecture between the udp and tcp headers. reference : possible differences : the upd header ( 8 bytes ) is much shorter than the tcp header ( 20 - 60 bytes ) the udp header has a fixed length while the tcp header has a variable length fields contained in the tcp header and not the udp header : - sequence number - acknowledgment number - reserved - flags / control bits - advertised window - urgent pointer - options + padding if the options are udp includes the packet length ( data + header ) while tcp has the header length / data offset ( just header ) field instead the sender port field is optional in udp, while the source port in tcp is necessary to establish the connection [SEP] - since udp is a simple protocol that actually sends ip packets with limited header additions to the receiver where the packet is forwarded to the application directly, i. e. w / o reordering, etc. the udp header consists only of essential needs for data transmission, i. e. a sender and receiver port, packet length, and an optional checksum. - in difference to that tcp it is more complicated, since the goal is to receive exactly the same data as transmitted by the sender, i. e. fully complete and in the right order of the packets. to achieve a reliable connection some additional parameters vs. udp have to be added in the header : o sequence number : to get the right order of the packets o acknowledgment number : needed together with sequence number for connection setup to get the starting sequence number ( 3 - way handshake ) o various flags, e. g. syn - flag for 3 - way handshake o advertised win. or win : needed for flow control [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Metadata Fields: ['id', 'question', 'reference_answer', 'provided_answer', 'answer_feedback', 'verification_feedback', 'max_score', 'normalized_score']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./model/bert_tokenizer\")\n",
    "\n",
    "def print_dataset_sample(dataset, name):\n",
    "    print(f\"\\n{'='*30} {name} {'='*30}\")\n",
    "    batch = dataset[0]\n",
    "    \n",
    "    # Use int() to safely handle both Tensors and plain integers\n",
    "    label_val = int(batch['labels'])\n",
    "    label_text = \"correct\" if label_val == 1 else \"incorrect\"\n",
    "    \n",
    "    # Decode the input_ids back into text\n",
    "    decoded_text = tokenizer.decode(batch[\"input_ids\"], skip_special_tokens=False)\n",
    "    \n",
    "    print(f\"Label: {label_val} ({label_text})\")\n",
    "    print(f\"\\nDecoded Input Text:\\n{decoded_text}\")\n",
    "    \n",
    "    # Print extra fields (the \"stuff\") that might be in this specific split\n",
    "    extra_fields = [k for k in batch.keys() if k not in [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]]\n",
    "    if extra_fields:\n",
    "        print(f\"\\nMetadata Fields: {extra_fields}\")\n",
    "        \n",
    "print('-------------------------------------------- Datasets --------------------------------------------')\n",
    "\n",
    "if \"train\" in tokenized_data:\n",
    "    print_dataset_sample(tokenized_data[\"train\"], \"TRAINING (COMBINED)\")\n",
    "    \n",
    "if \"validation\" in tokenized_data:\n",
    "    print_dataset_sample(tokenized_data[\"validation\"], \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model/results\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = BertTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
